<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#36890;&#36807;&#22312;&#20302;&#32500;&#26367;&#20195;&#31354;&#38388;&#20013;&#30340;&#20984;&#22810;&#38754;&#20307;&#39030;&#28857;&#19978;&#23884;&#20837;&#32467;&#26524;&#65292;&#24182;&#25506;&#31350;&#21333;&#32431;&#24418;&#20013;&#30340;&#19968;&#33268;&#24615;&#21306;&#22495;&#65292;&#26435;&#34913;&#20102;&#26367;&#20195;&#25439;&#22833;&#32500;&#24230;&#12289;&#38382;&#39064;&#23454;&#20363;&#25968;&#37327;&#12290;</title><link>https://arxiv.org/abs/2402.10818</link><description>&lt;p&gt;
&#22312;&#27169;&#22411;&#30340;&#20984;&#26367;&#20195;&#21697;&#30340;&#19968;&#33268;&#24615;&#21644;&#32500;&#24230;&#20043;&#38388;&#36827;&#34892;&#26435;&#34913;
&lt;/p&gt;
&lt;p&gt;
Trading off Consistency and Dimensionality of Convex Surrogates for the Mode
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10818
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#22312;&#20302;&#32500;&#26367;&#20195;&#31354;&#38388;&#20013;&#30340;&#20984;&#22810;&#38754;&#20307;&#39030;&#28857;&#19978;&#23884;&#20837;&#32467;&#26524;&#65292;&#24182;&#25506;&#31350;&#21333;&#32431;&#24418;&#20013;&#30340;&#19968;&#33268;&#24615;&#21306;&#22495;&#65292;&#26435;&#34913;&#20102;&#26367;&#20195;&#25439;&#22833;&#32500;&#24230;&#12289;&#38382;&#39064;&#23454;&#20363;&#25968;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22810;&#31867;&#20998;&#31867;&#20013;&#65292;&#24517;&#39035;&#23558;&#32467;&#26524;&#23884;&#20837;&#21040;&#33267;&#23569;&#26377;$n-1$&#32500;&#30340;&#23454;&#25968;&#31354;&#38388;&#20013;&#65292;&#20197;&#35774;&#35745;&#19968;&#31181;&#19968;&#33268;&#30340;&#26367;&#20195;&#25439;&#22833;&#20989;&#25968;&#65292;&#36825;&#20250;&#23548;&#33268;"&#27491;&#30830;"&#30340;&#20998;&#31867;&#65292;&#32780;&#19981;&#21463;&#25968;&#25454;&#20998;&#24067;&#30340;&#24433;&#21709;&#12290;&#22312;&#20449;&#24687;&#26816;&#32034;&#21644;&#32467;&#26500;&#21270;&#39044;&#27979;&#20219;&#21153;&#31561;&#38656;&#35201;&#22823;&#37327;n&#26102;&#65292;&#20248;&#21270;n-1&#32500;&#26367;&#20195;&#24120;&#24120;&#26159;&#26840;&#25163;&#30340;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#22810;&#31867;&#20998;&#31867;&#20013;&#22914;&#20309;&#26435;&#34913;&#26367;&#20195;&#25439;&#22833;&#32500;&#24230;&#12289;&#38382;&#39064;&#23454;&#20363;&#25968;&#37327;&#20197;&#21450;&#22312;&#21333;&#32431;&#24418;&#19978;&#32422;&#26463;&#19968;&#33268;&#24615;&#21306;&#22495;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#36319;&#38543;&#36807;&#21435;&#30340;&#30740;&#31350;&#65292;&#25506;&#35752;&#20102;&#19968;&#31181;&#30452;&#35266;&#30340;&#23884;&#20837;&#36807;&#31243;&#65292;&#23558;&#32467;&#26524;&#26144;&#23556;&#21040;&#20302;&#32500;&#26367;&#20195;&#31354;&#38388;&#20013;&#30340;&#20984;&#22810;&#38754;&#20307;&#30340;&#39030;&#28857;&#19978;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#27599;&#20010;&#28857;&#36136;&#37327;&#20998;&#24067;&#21608;&#22260;&#23384;&#22312;&#21333;&#32431;&#24418;&#30340;&#20840;&#32500;&#23376;&#38598;&#65292;&#20854;&#20013;&#19968;&#33268;&#24615;&#25104;&#31435;&#65292;&#20294;&#26159;&#65292;&#23569;&#20110;n-1&#32500;&#24230;&#30340;&#24773;&#20917;&#19979;&#65292;&#23384;&#22312;&#19968;&#20123;&#20998;&#24067;&#65292;&#23545;&#20110;&#36825;&#20123;&#20998;&#24067;&#65292;&#19968;&#31181;&#29616;&#35937;&#24615;&#26159;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10818v1 Announce Type: new  Abstract: In multiclass classification over $n$ outcomes, the outcomes must be embedded into the reals with dimension at least $n-1$ in order to design a consistent surrogate loss that leads to the "correct" classification, regardless of the data distribution. For large $n$, such as in information retrieval and structured prediction tasks, optimizing a surrogate in $n-1$ dimensions is often intractable. We investigate ways to trade off surrogate loss dimension, the number of problem instances, and restricting the region of consistency in the simplex for multiclass classification. Following past work, we examine an intuitive embedding procedure that maps outcomes into the vertices of convex polytopes in a low-dimensional surrogate space. We show that full-dimensional subsets of the simplex exist around each point mass distribution for which consistency holds, but also, with less than $n-1$ dimensions, there exist distributions for which a phenomeno
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#27604;&#36739;&#20102;&#26356;&#28145;&#30340;&#31070;&#32463;&#32593;&#32476;&#21644;&#26356;&#23485;&#30340;&#31070;&#32463;&#32593;&#32476;&#22312;Sobolev&#25439;&#22833;&#30340;&#26368;&#20248;&#27867;&#21270;&#35823;&#24046;&#26041;&#38754;&#30340;&#34920;&#29616;&#65292;&#30740;&#31350;&#21457;&#29616;&#31070;&#32463;&#32593;&#32476;&#30340;&#26550;&#26500;&#21463;&#22810;&#31181;&#22240;&#32032;&#24433;&#21709;&#65292;&#21442;&#25968;&#25968;&#37327;&#26356;&#22810;&#20542;&#21521;&#20110;&#36873;&#25321;&#26356;&#23485;&#30340;&#32593;&#32476;&#65292;&#32780;&#26679;&#26412;&#28857;&#25968;&#37327;&#21644;&#25439;&#22833;&#20989;&#25968;&#35268;&#21017;&#24615;&#26356;&#39640;&#20542;&#21521;&#20110;&#36873;&#25321;&#26356;&#28145;&#30340;&#32593;&#32476;&#12290;</title><link>https://arxiv.org/abs/2402.00152</link><description>&lt;p&gt;
&#26356;&#28145;&#36824;&#26159;&#26356;&#23485;: &#20174;Sobolev&#25439;&#22833;&#30340;&#26368;&#20248;&#27867;&#21270;&#35823;&#24046;&#35282;&#24230;&#30475;
&lt;/p&gt;
&lt;p&gt;
Deeper or Wider: A Perspective from Optimal Generalization Error with Sobolev Loss
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.00152
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#27604;&#36739;&#20102;&#26356;&#28145;&#30340;&#31070;&#32463;&#32593;&#32476;&#21644;&#26356;&#23485;&#30340;&#31070;&#32463;&#32593;&#32476;&#22312;Sobolev&#25439;&#22833;&#30340;&#26368;&#20248;&#27867;&#21270;&#35823;&#24046;&#26041;&#38754;&#30340;&#34920;&#29616;&#65292;&#30740;&#31350;&#21457;&#29616;&#31070;&#32463;&#32593;&#32476;&#30340;&#26550;&#26500;&#21463;&#22810;&#31181;&#22240;&#32032;&#24433;&#21709;&#65292;&#21442;&#25968;&#25968;&#37327;&#26356;&#22810;&#20542;&#21521;&#20110;&#36873;&#25321;&#26356;&#23485;&#30340;&#32593;&#32476;&#65292;&#32780;&#26679;&#26412;&#28857;&#25968;&#37327;&#21644;&#25439;&#22833;&#20989;&#25968;&#35268;&#21017;&#24615;&#26356;&#39640;&#20542;&#21521;&#20110;&#36873;&#25321;&#26356;&#28145;&#30340;&#32593;&#32476;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26500;&#24314;&#31070;&#32463;&#32593;&#32476;&#30340;&#26550;&#26500;&#26159;&#26426;&#22120;&#23398;&#20064;&#30028;&#19968;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#36861;&#27714;&#65292;&#21040;&#24213;&#26159;&#26356;&#28145;&#36824;&#26159;&#26356;&#23485;&#19968;&#30452;&#26159;&#19968;&#20010;&#25345;&#32493;&#30340;&#38382;&#39064;&#12290;&#26412;&#25991;&#25506;&#32034;&#20102;&#26356;&#28145;&#30340;&#31070;&#32463;&#32593;&#32476;&#65288;DeNNs&#65289;&#21644;&#20855;&#26377;&#26377;&#38480;&#38544;&#34255;&#23618;&#30340;&#26356;&#23485;&#30340;&#31070;&#32463;&#32593;&#32476;&#65288;WeNNs&#65289;&#22312;Sobolev&#25439;&#22833;&#30340;&#26368;&#20248;&#27867;&#21270;&#35823;&#24046;&#26041;&#38754;&#30340;&#27604;&#36739;&#12290;&#36890;&#36807;&#20998;&#26512;&#30740;&#31350;&#21457;&#29616;&#65292;&#31070;&#32463;&#32593;&#32476;&#30340;&#26550;&#26500;&#21487;&#20197;&#21463;&#21040;&#22810;&#31181;&#22240;&#32032;&#30340;&#26174;&#33879;&#24433;&#21709;&#65292;&#21253;&#25324;&#26679;&#26412;&#28857;&#30340;&#25968;&#37327;&#65292;&#31070;&#32463;&#32593;&#32476;&#20869;&#30340;&#21442;&#25968;&#20197;&#21450;&#25439;&#22833;&#20989;&#25968;&#30340;&#35268;&#21017;&#24615;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#26356;&#22810;&#30340;&#21442;&#25968;&#20542;&#21521;&#20110;&#36873;&#25321;WeNNs&#65292;&#32780;&#26356;&#22810;&#30340;&#26679;&#26412;&#28857;&#21644;&#26356;&#39640;&#30340;&#25439;&#22833;&#20989;&#25968;&#35268;&#21017;&#24615;&#20542;&#21521;&#20110;&#36873;&#25321;DeNNs&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23558;&#36825;&#20010;&#29702;&#35770;&#24212;&#29992;&#20110;&#20351;&#29992;&#28145;&#24230;Ritz&#21644;&#29289;&#29702;&#24863;&#30693;&#31070;&#32463;&#32593;&#32476;&#65288;PINN&#65289;&#26041;&#27861;&#35299;&#20915;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Constructing the architecture of a neural network is a challenging pursuit for the machine learning community, and the dilemma of whether to go deeper or wider remains a persistent question. This paper explores a comparison between deeper neural networks (DeNNs) with a flexible number of layers and wider neural networks (WeNNs) with limited hidden layers, focusing on their optimal generalization error in Sobolev losses. Analytical investigations reveal that the architecture of a neural network can be significantly influenced by various factors, including the number of sample points, parameters within the neural networks, and the regularity of the loss function. Specifically, a higher number of parameters tends to favor WeNNs, while an increased number of sample points and greater regularity in the loss function lean towards the adoption of DeNNs. We ultimately apply this theory to address partial differential equations using deep Ritz and physics-informed neural network (PINN) methods,
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20004;&#23618;ReLU&#32593;&#32476;&#20013;&#30340;&#38544;&#34255;&#26497;&#23567;&#20540;&#29616;&#35937;&#65292;&#24182;&#25552;&#20986;&#26041;&#27861;&#26469;&#30740;&#31350;&#36825;&#20123;&#38544;&#34255;&#26497;&#23567;&#20540;&#30340;&#29420;&#29305;&#35299;&#26512;&#24615;&#36136;&#12290;</title><link>https://arxiv.org/abs/2312.16819</link><description>&lt;p&gt;
&#20004;&#23618;ReLU&#32593;&#32476;&#20013;&#30340;&#38544;&#34255;&#26497;&#23567;&#20540;
&lt;/p&gt;
&lt;p&gt;
Hidden Minima in Two-Layer ReLU Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.16819
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20004;&#23618;ReLU&#32593;&#32476;&#20013;&#30340;&#38544;&#34255;&#26497;&#23567;&#20540;&#29616;&#35937;&#65292;&#24182;&#25552;&#20986;&#26041;&#27861;&#26469;&#30740;&#31350;&#36825;&#20123;&#38544;&#34255;&#26497;&#23567;&#20540;&#30340;&#29420;&#29305;&#35299;&#26512;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#25311;&#21512;&#20855;&#26377;$d$&#20010;&#36755;&#20837;&#12289;$k$&#20010;&#31070;&#32463;&#20803;&#20197;&#21450;&#30001;&#30446;&#26631;&#32593;&#32476;&#29983;&#25104;&#30340;&#26631;&#31614;&#30340;&#20004;&#23618;ReLU&#32593;&#32476;&#25152;&#28041;&#21450;&#30340;&#20248;&#21270;&#38382;&#39064;&#12290;&#26368;&#36817;&#21457;&#29616;&#20102;&#20004;&#31181;&#26080;&#31351;&#26063;&#30340;&#34394;&#20551;&#26497;&#23567;&#20540;&#65292;&#27599;&#20010;$d$&#23545;&#24212;&#19968;&#20010;&#26497;&#23567;&#20540;&#12290;&#23646;&#20110;&#31532;&#19968;&#31867;&#30340;&#26497;&#23567;&#20540;&#30340;&#25439;&#22833;&#22312;$d$&#22686;&#21152;&#26102;&#25910;&#25947;&#20110;&#38646;&#12290;&#22312;&#31532;&#20108;&#31867;&#20013;&#65292;&#25439;&#22833;&#20445;&#25345;&#36828;&#31163;&#20110;&#38646;&#12290;&#37027;&#20040;&#65292;&#22914;&#20309;&#36991;&#20813;&#23646;&#20110;&#21518;&#19968;&#31867;&#30340;&#26497;&#23567;&#20540;&#21602;&#65311;&#24184;&#36816;&#30340;&#26159;&#65292;&#36825;&#26679;&#30340;&#26497;&#23567;&#20540;&#20174;&#19981;&#20250;&#34987;&#26631;&#20934;&#20248;&#21270;&#26041;&#27861;&#26816;&#27979;&#21040;&#12290;&#21463;&#21040;&#27492;&#29616;&#35937;&#24615;&#36136;&#30340;&#38382;&#39064;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#30740;&#31350;&#38544;&#34255;&#26497;&#23567;&#20540;&#29420;&#29305;&#35299;&#26512;&#24615;&#36136;&#30340;&#26041;&#27861;&#12290;&#26681;&#25454;&#29616;&#26377;&#30340;&#20998;&#26512;&#65292;&#20004;&#31181;&#31867;&#22411;&#30340;Hessian&#35889;&#22312;$O(d^{-1/2})$&#39033;&#27169;&#24847;&#20041;&#19979;&#19968;&#33268; -- &#19981;&#22826;&#20048;&#35266;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#36890;&#36807;&#30740;&#31350;&#25439;&#22833;&#34987;&#26368;&#23567;&#21270;&#25110;&#26368;&#22823;&#21270;&#30340;&#26354;&#32447;&#36827;&#34892;&#65292;&#36890;&#24120;&#31216;&#20026;&#20999;&#32447;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.16819v2 Announce Type: replace  Abstract: The optimization problem associated to fitting two-layer ReLU networks having $d$~inputs, $k$~neurons, and labels generated by a target network, is considered. Two types of infinite families of spurious minima, giving one minimum per $d$, were recently found. The loss at minima belonging to the first type converges to zero as $d$ increases. In the second type, the loss remains bounded away from zero. That being so, how may one avoid minima belonging to the latter type? Fortunately, such minima are never detected by standard optimization methods. Motivated by questions concerning the nature of this phenomenon, we develop methods to study distinctive analytic properties of hidden minima.   By existing analyses, the Hessian spectrum of both types agree modulo $O(d^{-1/2})$-terms -- not promising. Thus, rather, our investigation proceeds by studying curves along which the loss is minimized or maximized, generally referred to as tangency 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#26399;&#26395;&#26465;&#20214;&#39118;&#38505;&#24230;&#37327;&#30340;&#39118;&#38505;&#21388;&#24694;&#31574;&#30053;&#26799;&#24230;&#26041;&#27861;&#65292;&#25552;&#20986;&#20102;&#31574;&#30053;&#26799;&#24230;&#26356;&#26032;&#65292;&#35777;&#26126;&#20102;&#20854;&#22312;&#32422;&#26463;&#21644;&#26080;&#32422;&#26463;&#24773;&#20917;&#19979;&#30340;&#20840;&#23616;&#25910;&#25947;&#24615;&#21644;&#36845;&#20195;&#22797;&#26434;&#24230;&#65292;&#24182;&#27979;&#35797;&#20102;REINFORCE&#21644;actor-critic&#31639;&#27861;&#30340;&#39118;&#38505;&#21388;&#24694;&#21464;&#20307;&#26469;&#23637;&#31034;&#26041;&#27861;&#30340;&#23454;&#29992;&#20215;&#20540;&#21644;&#39118;&#38505;&#25511;&#21046;&#30340;&#37325;&#35201;&#24615;&#12290;</title><link>http://arxiv.org/abs/2301.10932</link><description>&lt;p&gt;
&#20851;&#20110;&#20855;&#26377;&#26399;&#26395;&#26465;&#20214;&#39118;&#38505;&#24230;&#37327;&#30340;&#39118;&#38505;&#21388;&#24694;&#31574;&#30053;&#26799;&#24230;&#26041;&#27861;&#30340;&#20840;&#23616;&#25910;&#25947;&#24615;
&lt;/p&gt;
&lt;p&gt;
On the Global Convergence of Risk-Averse Policy Gradient Methods with Expected Conditional Risk Measures. (arXiv:2301.10932v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.10932
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#26399;&#26395;&#26465;&#20214;&#39118;&#38505;&#24230;&#37327;&#30340;&#39118;&#38505;&#21388;&#24694;&#31574;&#30053;&#26799;&#24230;&#26041;&#27861;&#65292;&#25552;&#20986;&#20102;&#31574;&#30053;&#26799;&#24230;&#26356;&#26032;&#65292;&#35777;&#26126;&#20102;&#20854;&#22312;&#32422;&#26463;&#21644;&#26080;&#32422;&#26463;&#24773;&#20917;&#19979;&#30340;&#20840;&#23616;&#25910;&#25947;&#24615;&#21644;&#36845;&#20195;&#22797;&#26434;&#24230;&#65292;&#24182;&#27979;&#35797;&#20102;REINFORCE&#21644;actor-critic&#31639;&#27861;&#30340;&#39118;&#38505;&#21388;&#24694;&#21464;&#20307;&#26469;&#23637;&#31034;&#26041;&#27861;&#30340;&#23454;&#29992;&#20215;&#20540;&#21644;&#39118;&#38505;&#25511;&#21046;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39118;&#38505;&#25935;&#24863;&#30340;&#24378;&#21270;&#23398;&#20064;&#24050;&#32463;&#25104;&#20026;&#25511;&#21046;&#19981;&#30830;&#23450;&#32467;&#26524;&#21644;&#30830;&#20445;&#21508;&#31181;&#39034;&#24207;&#20915;&#31574;&#38382;&#39064;&#30340;&#21487;&#38752;&#24615;&#33021;&#30340;&#27969;&#34892;&#24037;&#20855;&#12290;&#34429;&#28982;&#38024;&#23545;&#39118;&#38505;&#25935;&#24863;&#30340;&#24378;&#21270;&#23398;&#20064;&#24050;&#32463;&#24320;&#21457;&#20986;&#20102;&#31574;&#30053;&#26799;&#24230;&#26041;&#27861;&#65292;&#20294;&#36825;&#20123;&#26041;&#27861;&#26159;&#21542;&#20855;&#26377;&#19982;&#39118;&#38505;&#20013;&#24615;&#24773;&#20917;&#19979;&#30456;&#21516;&#30340;&#20840;&#23616;&#25910;&#25947;&#20445;&#35777;&#36824;&#19981;&#28165;&#26970;&#12290;&#26412;&#25991;&#32771;&#34385;&#20102;&#19968;&#31867;&#21160;&#24577;&#26102;&#38388;&#19968;&#33268;&#39118;&#38505;&#24230;&#37327;&#65292;&#31216;&#20026;&#26399;&#26395;&#26465;&#20214;&#39118;&#38505;&#24230;&#37327;&#65288;ECRM&#65289;&#65292;&#24182;&#20026;&#22522;&#20110;ECRM&#30340;&#30446;&#26631;&#20989;&#25968;&#25512;&#23548;&#20986;&#31574;&#30053;&#26799;&#24230;&#26356;&#26032;&#12290;&#22312;&#32422;&#26463;&#30452;&#25509;&#21442;&#25968;&#21270;&#21644;&#26080;&#32422;&#26463;softmax&#21442;&#25968;&#21270;&#19979;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#30456;&#24212;&#30340;&#39118;&#38505;&#21388;&#24694;&#31574;&#30053;&#26799;&#24230;&#31639;&#27861;&#30340;&#20840;&#23616;&#25910;&#25947;&#24615;&#21644;&#36845;&#20195;&#22797;&#26434;&#24230;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#27979;&#35797;&#20102;REINFORCE&#21644;actor-critic&#31639;&#27861;&#30340;&#39118;&#38505;&#21388;&#24694;&#21464;&#20307;&#65292;&#20197;&#23637;&#31034;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#21644;&#39118;&#38505;&#25511;&#21046;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Risk-sensitive reinforcement learning (RL) has become a popular tool to control the risk of uncertain outcomes and ensure reliable performance in various sequential decision-making problems. While policy gradient methods have been developed for risk-sensitive RL, it remains unclear if these methods enjoy the same global convergence guarantees as in the risk-neutral case. In this paper, we consider a class of dynamic time-consistent risk measures, called Expected Conditional Risk Measures (ECRMs), and derive policy gradient updates for ECRM-based objective functions. Under both constrained direct parameterization and unconstrained softmax parameterization, we provide global convergence and iteration complexities of the corresponding risk-averse policy gradient algorithms. We further test risk-averse variants of REINFORCE and actor-critic algorithms to demonstrate the efficacy of our method and the importance of risk control.
&lt;/p&gt;</description></item></channel></rss>