<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#36890;&#36807;&#23558;&#20272;&#35745;&#38382;&#39064;&#36716;&#21270;&#20026;&#21487;&#30452;&#25509;&#35299;&#20915;&#30340;&#20248;&#21270;&#20219;&#21153;&#65292;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#21464;&#20998;&#25512;&#26029;&#26469;&#20272;&#35745;&#24847;&#35265;&#21160;&#24577;ABM&#21442;&#25968;&#30340;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2403.05358</link><description>&lt;p&gt;
&#24847;&#35265;&#21160;&#24577;&#27169;&#22411;&#20013;&#21442;&#25968;&#30340;&#21464;&#20998;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Variational Inference of Parameters in Opinion Dynamics Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.05358
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23558;&#20272;&#35745;&#38382;&#39064;&#36716;&#21270;&#20026;&#21487;&#30452;&#25509;&#35299;&#20915;&#30340;&#20248;&#21270;&#20219;&#21153;&#65292;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#21464;&#20998;&#25512;&#26029;&#26469;&#20272;&#35745;&#24847;&#35265;&#21160;&#24577;ABM&#21442;&#25968;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#22522;&#20110;&#20195;&#29702;&#20154;&#30340;&#27169;&#22411;&#65288;ABMs&#65289;&#22312;&#30740;&#31350;&#31038;&#20250;&#29616;&#35937;&#20013;&#34987;&#39057;&#32321;&#20351;&#29992;&#65292;&#20294;&#21442;&#25968;&#20272;&#35745;&#20173;&#28982;&#26159;&#19968;&#20010;&#25361;&#25112;&#65292;&#36890;&#24120;&#20381;&#36182;&#20110;&#26114;&#36149;&#30340;&#22522;&#20110;&#27169;&#25311;&#30340;&#21551;&#21457;&#24335;&#26041;&#27861;&#12290;&#26412;&#30740;&#31350;&#21033;&#29992;&#21464;&#20998;&#25512;&#26029;&#26469;&#20272;&#35745;&#24847;&#35265;&#21160;&#24577;ABM&#30340;&#21442;&#25968;&#65292;&#36890;&#36807;&#23558;&#20272;&#35745;&#38382;&#39064;&#36716;&#21270;&#20026;&#21487;&#30452;&#25509;&#35299;&#20915;&#30340;&#20248;&#21270;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.05358v1 Announce Type: cross  Abstract: Despite the frequent use of agent-based models (ABMs) for studying social phenomena, parameter estimation remains a challenge, often relying on costly simulation-based heuristics. This work uses variational inference to estimate the parameters of an opinion dynamics ABM, by transforming the estimation problem into an optimization task that can be solved directly.   Our proposal relies on probabilistic generative ABMs (PGABMs): we start by synthesizing a probabilistic generative model from the ABM rules. Then, we transform the inference process into an optimization problem suitable for automatic differentiation. In particular, we use the Gumbel-Softmax reparameterization for categorical agent attributes and stochastic variational inference for parameter estimation. Furthermore, we explore the trade-offs of using variational distributions with different complexity: normal distributions and normalizing flows.   We validate our method on a
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#24341;&#20837;&#23610;&#23544;&#27867;&#21270;&#27010;&#24565;&#65292;&#30740;&#31350;&#20102;&#22312;&#21322;&#30417;&#30563;&#35774;&#32622;&#19979;&#30340;&#32858;&#31867;&#31639;&#27861;&#36873;&#25321;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#33021;&#22815;&#22312;&#23567;&#23454;&#20363;&#19978;&#20445;&#35777;&#20934;&#30830;&#24230;&#26368;&#39640;&#30340;&#31639;&#27861;&#20063;&#23558;&#22312;&#21407;&#22987;&#22823;&#23454;&#20363;&#19978;&#25317;&#26377;&#26368;&#39640;&#20934;&#30830;&#24230;&#30340;&#26465;&#20214;&#12290;</title><link>https://arxiv.org/abs/2402.14332</link><description>&lt;p&gt;
&#20174;&#22823;&#35268;&#27169;&#21040;&#23567;&#35268;&#27169;&#25968;&#25454;&#38598;&#65306;&#29992;&#20110;&#32858;&#31867;&#31639;&#27861;&#36873;&#25321;&#30340;&#23610;&#23544;&#27867;&#21270;
&lt;/p&gt;
&lt;p&gt;
From Large to Small Datasets: Size Generalization for Clustering Algorithm Selection
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14332
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24341;&#20837;&#23610;&#23544;&#27867;&#21270;&#27010;&#24565;&#65292;&#30740;&#31350;&#20102;&#22312;&#21322;&#30417;&#30563;&#35774;&#32622;&#19979;&#30340;&#32858;&#31867;&#31639;&#27861;&#36873;&#25321;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#33021;&#22815;&#22312;&#23567;&#23454;&#20363;&#19978;&#20445;&#35777;&#20934;&#30830;&#24230;&#26368;&#39640;&#30340;&#31639;&#27861;&#20063;&#23558;&#22312;&#21407;&#22987;&#22823;&#23454;&#20363;&#19978;&#25317;&#26377;&#26368;&#39640;&#20934;&#30830;&#24230;&#30340;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32858;&#31867;&#31639;&#27861;&#36873;&#25321;&#20013;&#65292;&#25105;&#20204;&#20250;&#24471;&#21040;&#19968;&#20010;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#65292;&#24182;&#35201;&#26377;&#25928;&#22320;&#36873;&#25321;&#35201;&#20351;&#29992;&#30340;&#32858;&#31867;&#31639;&#27861;&#12290;&#25105;&#20204;&#22312;&#21322;&#30417;&#30563;&#35774;&#32622;&#19979;&#30740;&#31350;&#20102;&#36825;&#20010;&#38382;&#39064;&#65292;&#20854;&#20013;&#26377;&#19968;&#20010;&#26410;&#30693;&#30340;&#22522;&#20934;&#32858;&#31867;&#65292;&#25105;&#20204;&#21482;&#33021;&#36890;&#36807;&#26114;&#36149;&#30340;oracle&#26597;&#35810;&#26469;&#35775;&#38382;&#12290;&#29702;&#24819;&#24773;&#20917;&#19979;&#65292;&#32858;&#31867;&#31639;&#27861;&#30340;&#36755;&#20986;&#23558;&#19982;&#22522;&#26412;&#20107;&#23454;&#32467;&#26500;&#19978;&#25509;&#36817;&#12290;&#25105;&#20204;&#36890;&#36807;&#24341;&#20837;&#19968;&#31181;&#32858;&#31867;&#31639;&#27861;&#20934;&#30830;&#24615;&#30340;&#23610;&#23544;&#27867;&#21270;&#27010;&#24565;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#30830;&#23450;&#22312;&#21738;&#20123;&#26465;&#20214;&#19979;&#25105;&#20204;&#21487;&#20197;&#65288;1&#65289;&#23545;&#22823;&#35268;&#27169;&#32858;&#31867;&#23454;&#20363;&#36827;&#34892;&#23376;&#37319;&#26679;&#65292;&#65288;2&#65289;&#22312;&#36739;&#23567;&#23454;&#20363;&#19978;&#35780;&#20272;&#19968;&#32452;&#20505;&#36873;&#31639;&#27861;&#65292;&#65288;3&#65289;&#20445;&#35777;&#22312;&#23567;&#23454;&#20363;&#19978;&#20934;&#30830;&#24230;&#26368;&#39640;&#30340;&#31639;&#27861;&#23558;&#22312;&#21407;&#22987;&#22823;&#23454;&#20363;&#19978;&#25317;&#26377;&#26368;&#39640;&#30340;&#20934;&#30830;&#24230;&#12290;&#25105;&#20204;&#20026;&#19977;&#31181;&#32463;&#20856;&#32858;&#31867;&#31639;&#27861;&#25552;&#20379;&#20102;&#29702;&#35770;&#23610;&#23544;&#27867;&#21270;&#20445;&#35777;&#65306;&#21333;&#38142;&#25509;&#12289;k-means++&#21644;Gonzalez&#30340;k&#20013;&#24515;&#21551;&#21457;&#24335;&#65288;&#19968;&#31181;&#24179;&#28369;&#30340;&#21464;&#31181;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14332v1 Announce Type: new  Abstract: In clustering algorithm selection, we are given a massive dataset and must efficiently select which clustering algorithm to use. We study this problem in a semi-supervised setting, with an unknown ground-truth clustering that we can only access through expensive oracle queries. Ideally, the clustering algorithm's output will be structurally close to the ground truth. We approach this problem by introducing a notion of size generalization for clustering algorithm accuracy. We identify conditions under which we can (1) subsample the massive clustering instance, (2) evaluate a set of candidate algorithms on the smaller instance, and (3) guarantee that the algorithm with the best accuracy on the small instance will have the best accuracy on the original big instance. We provide theoretical size generalization guarantees for three classic clustering algorithms: single-linkage, k-means++, and (a smoothed variant of) Gonzalez's k-centers heuris
&lt;/p&gt;</description></item></channel></rss>