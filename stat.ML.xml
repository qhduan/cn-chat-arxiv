<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#22810;&#35270;&#22270;&#32858;&#31867;&#26694;&#26550;&#65292;&#21033;&#29992;&#26032;&#39062;&#30340;&#22522;&#20110;&#32622;&#25442;&#30340;&#35268;&#33539;&#30456;&#20851;&#24615;&#30446;&#26631;&#23398;&#20064;&#34701;&#21512;&#25968;&#25454;&#34920;&#31034;&#65292;&#24182;&#36890;&#36807;&#35782;&#21035;&#22810;&#20010;&#35270;&#22270;&#30340;&#19968;&#33268;&#20266;&#26631;&#31614;&#26469;&#23398;&#20064;&#32858;&#31867;&#20998;&#37197;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#27169;&#22411;&#26377;&#25928;&#24615;&#65292;&#29702;&#35770;&#19978;&#35777;&#26126;&#36924;&#36817;&#30417;&#30563;&#32447;&#24615;&#21028;&#21035;&#20998;&#26512;&#65288;LDA&#65289;&#34920;&#31034;&#65292;&#25552;&#20379;&#20102;&#30001;&#38169;&#35823;&#20266;&#26631;&#31614;&#27880;&#37322;&#24341;&#36215;&#30340;&#35823;&#24046;&#30028;&#38480;&#12290;</title><link>https://arxiv.org/abs/2402.16383</link><description>&lt;p&gt;
&#33258;&#30417;&#30563;&#22522;&#20110;&#30456;&#20851;&#24615;&#30340;&#22810;&#35270;&#22270;&#32858;&#31867;&#25490;&#24207;
&lt;/p&gt;
&lt;p&gt;
Self Supervised Correlation-based Permutations for Multi-View Clustering
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.16383
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#22810;&#35270;&#22270;&#32858;&#31867;&#26694;&#26550;&#65292;&#21033;&#29992;&#26032;&#39062;&#30340;&#22522;&#20110;&#32622;&#25442;&#30340;&#35268;&#33539;&#30456;&#20851;&#24615;&#30446;&#26631;&#23398;&#20064;&#34701;&#21512;&#25968;&#25454;&#34920;&#31034;&#65292;&#24182;&#36890;&#36807;&#35782;&#21035;&#22810;&#20010;&#35270;&#22270;&#30340;&#19968;&#33268;&#20266;&#26631;&#31614;&#26469;&#23398;&#20064;&#32858;&#31867;&#20998;&#37197;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#27169;&#22411;&#26377;&#25928;&#24615;&#65292;&#29702;&#35770;&#19978;&#35777;&#26126;&#36924;&#36817;&#30417;&#30563;&#32447;&#24615;&#21028;&#21035;&#20998;&#26512;&#65288;LDA&#65289;&#34920;&#31034;&#65292;&#25552;&#20379;&#20102;&#30001;&#38169;&#35823;&#20266;&#26631;&#31614;&#27880;&#37322;&#24341;&#36215;&#30340;&#35823;&#24046;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34701;&#21512;&#26469;&#33258;&#19981;&#21516;&#27169;&#24577;&#30340;&#20449;&#24687;&#21487;&#20197;&#22686;&#24378;&#25968;&#25454;&#20998;&#26512;&#20219;&#21153;&#65292;&#21253;&#25324;&#32858;&#31867;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#22810;&#35270;&#22270;&#32858;&#31867;&#65288;MVC&#65289;&#35299;&#20915;&#26041;&#26696;&#20165;&#38480;&#20110;&#29305;&#23450;&#39046;&#22495;&#65292;&#25110;&#32773;&#20381;&#36182;&#20110;&#27425;&#20248;&#30340;&#19988;&#35745;&#31639;&#38656;&#27714;&#39640;&#30340;&#34920;&#31034;&#21644;&#32858;&#31867;&#20004;&#38454;&#27573;&#31243;&#24207;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#31471;&#21040;&#31471;&#28145;&#24230;&#23398;&#20064;&#30340;&#36890;&#29992;&#25968;&#25454;&#65288;&#22270;&#20687;&#12289;&#34920;&#26684;&#31561;&#65289;&#30340;MVC&#26694;&#26550;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#28041;&#21450;&#20351;&#29992;&#22522;&#20110;&#26032;&#39062;&#32622;&#25442;&#30340;&#35268;&#33539;&#30456;&#20851;&#24615;&#30446;&#26631;&#26469;&#23398;&#20064;&#26377;&#24847;&#20041;&#30340;&#34701;&#21512;&#25968;&#25454;&#34920;&#31034;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36890;&#36807;&#35782;&#21035;&#36328;&#22810;&#20010;&#35270;&#22270;&#30340;&#19968;&#33268;&#20266;&#26631;&#31614;&#26469;&#23398;&#20064;&#32858;&#31867;&#20998;&#37197;&#12290;&#25105;&#20204;&#20351;&#29992;&#21313;&#20010;MVC&#22522;&#20934;&#25968;&#25454;&#38598;&#23637;&#31034;&#20102;&#25105;&#20204;&#27169;&#22411;&#30340;&#26377;&#25928;&#24615;&#12290;&#22312;&#29702;&#35770;&#19978;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#27169;&#22411;&#36924;&#36817;&#20102;&#30417;&#30563;&#32447;&#24615;&#21028;&#21035;&#20998;&#26512;&#65288;LDA&#65289;&#34920;&#31034;&#12290;&#21478;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#30001;&#38169;&#35823;&#20266;&#26631;&#31614;&#27880;&#37322;&#24341;&#36215;&#30340;&#35823;&#24046;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.16383v1 Announce Type: new  Abstract: Fusing information from different modalities can enhance data analysis tasks, including clustering. However, existing multi-view clustering (MVC) solutions are limited to specific domains or rely on a suboptimal and computationally demanding two-stage procedure of representation and clustering. We propose an end-to-end deep learning-based MVC framework for general data (image, tabular, etc.). Our approach involves learning meaningful fused data representations with a novel permutation-based canonical correlation objective. Concurrently, we learn cluster assignments by identifying consistent pseudo-labels across multiple views. We demonstrate the effectiveness of our model using ten MVC benchmark datasets. Theoretically, we show that our model approximates the supervised linear discrimination analysis (LDA) representation. Additionally, we provide an error bound induced by false-pseudo label annotations.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#21363;&#19968;&#33268;&#24615;&#33945;&#29305;&#21345;&#27931;&#20803;&#23398;&#20064;&#27169;&#22411;&#65292;&#29992;&#20110;&#39044;&#27979;&#20010;&#20307;&#27835;&#30103;&#25928;&#26524;&#12290;&#36890;&#36807;&#21033;&#29992;&#19968;&#33268;&#24615;&#39044;&#27979;&#31995;&#32479;&#12289;&#33945;&#29305;&#21345;&#27931;&#37319;&#26679;&#21644;CATE&#20803;&#23398;&#20064;&#27169;&#22411;&#65292;&#35813;&#26041;&#27861;&#29983;&#25104;&#21487;&#29992;&#20110;&#20010;&#24615;&#21270;&#20915;&#31574;&#30340;&#39044;&#27979;&#20998;&#24067;&#12290;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;&#35813;&#26041;&#27861;&#22312;&#20445;&#25345;&#36739;&#23567;&#21306;&#38388;&#23485;&#24230;&#30340;&#24773;&#20917;&#19979;&#20855;&#26377;&#24378;&#22823;&#30340;&#23454;&#39564;&#35206;&#30422;&#33539;&#22260;&#65292;&#21487;&#20197;&#25552;&#20379;&#30495;&#23454;&#20010;&#20307;&#27835;&#30103;&#25928;&#26524;&#30340;&#20272;&#35745;&#12290;</title><link>https://arxiv.org/abs/2402.04906</link><description>&lt;p&gt;
&#39044;&#27979;&#20010;&#20307;&#27835;&#30103;&#25928;&#26524;&#30340;&#19968;&#33268;&#24615;&#33945;&#29305;&#21345;&#27931;&#20803;&#23398;&#20064;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Conformal Monte Carlo Meta-learners for Predictive Inference of Individual Treatment Effects
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04906
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#21363;&#19968;&#33268;&#24615;&#33945;&#29305;&#21345;&#27931;&#20803;&#23398;&#20064;&#27169;&#22411;&#65292;&#29992;&#20110;&#39044;&#27979;&#20010;&#20307;&#27835;&#30103;&#25928;&#26524;&#12290;&#36890;&#36807;&#21033;&#29992;&#19968;&#33268;&#24615;&#39044;&#27979;&#31995;&#32479;&#12289;&#33945;&#29305;&#21345;&#27931;&#37319;&#26679;&#21644;CATE&#20803;&#23398;&#20064;&#27169;&#22411;&#65292;&#35813;&#26041;&#27861;&#29983;&#25104;&#21487;&#29992;&#20110;&#20010;&#24615;&#21270;&#20915;&#31574;&#30340;&#39044;&#27979;&#20998;&#24067;&#12290;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;&#35813;&#26041;&#27861;&#22312;&#20445;&#25345;&#36739;&#23567;&#21306;&#38388;&#23485;&#24230;&#30340;&#24773;&#20917;&#19979;&#20855;&#26377;&#24378;&#22823;&#30340;&#23454;&#39564;&#35206;&#30422;&#33539;&#22260;&#65292;&#21487;&#20197;&#25552;&#20379;&#30495;&#23454;&#20010;&#20307;&#27835;&#30103;&#25928;&#26524;&#30340;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35748;&#35782;&#24178;&#39044;&#25928;&#26524;&#65292;&#21363;&#27835;&#30103;&#25928;&#26524;&#65292;&#23545;&#20110;&#20915;&#31574;&#33267;&#20851;&#37325;&#35201;&#12290;&#29992;&#26465;&#20214;&#24179;&#22343;&#27835;&#30103;&#25928;&#26524; (CATE) &#20272;&#35745;&#31561;&#26041;&#27861;&#36890;&#24120;&#21482;&#25552;&#20379;&#27835;&#30103;&#25928;&#26524;&#30340;&#28857;&#20272;&#35745;&#65292;&#32780;&#24120;&#24120;&#38656;&#35201;&#39069;&#22806;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#26041;&#27861;&#65292;&#21363;&#19968;&#33268;&#24615;&#33945;&#29305;&#21345;&#27931; (CMC) &#20803;&#23398;&#20064;&#27169;&#22411;&#65292;&#21033;&#29992;&#19968;&#33268;&#24615;&#39044;&#27979;&#31995;&#32479;&#12289;&#33945;&#29305;&#21345;&#27931;&#37319;&#26679;&#21644; CATE &#20803;&#23398;&#20064;&#27169;&#22411;&#65292;&#26469;&#20135;&#29983;&#21487;&#29992;&#20110;&#20010;&#24615;&#21270;&#20915;&#31574;&#30340;&#39044;&#27979;&#20998;&#24067;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#32467;&#26524;&#22122;&#22768;&#20998;&#24067;&#30340;&#29305;&#23450;&#20551;&#35774;&#22914;&#20309;&#20005;&#37325;&#24433;&#21709;&#36825;&#20123;&#19981;&#30830;&#23450;&#24615;&#39044;&#27979;&#12290;&#23613;&#31649;&#22914;&#27492;&#65292;CMC&#26694;&#26550;&#23637;&#31034;&#20102;&#24378;&#22823;&#30340;&#23454;&#39564;&#35206;&#30422;&#33539;&#22260;&#65292;&#21516;&#26102;&#20445;&#25345;&#36739;&#23567;&#30340;&#21306;&#38388;&#23485;&#24230;&#65292;&#20197;&#25552;&#20379;&#30495;&#23454;&#20010;&#20307;&#27835;&#30103;&#25928;&#26524;&#30340;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
Knowledge of the effect of interventions, called the treatment effect, is paramount for decision-making. Approaches to estimating this treatment effect, e.g. by using Conditional Average Treatment Effect (CATE) estimators, often only provide a point estimate of this treatment effect, while additional uncertainty quantification is frequently desired instead. Therefore, we present a novel method, the Conformal Monte Carlo (CMC) meta-learners, leveraging conformal predictive systems, Monte Carlo sampling, and CATE meta-learners, to instead produce a predictive distribution usable in individualized decision-making. Furthermore, we show how specific assumptions on the noise distribution of the outcome heavily affect these uncertainty predictions. Nonetheless, the CMC framework shows strong experimental coverage while retaining small interval widths to provide estimates of the true individual treatment effect.
&lt;/p&gt;</description></item><item><title>&#38750;&#32447;&#24615;&#20803;&#23398;&#20064;&#21487;&#20197;&#20445;&#35777;&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;</title><link>http://arxiv.org/abs/2307.10870</link><description>&lt;p&gt;
&#38750;&#32447;&#24615;&#20803;&#23398;&#20064;&#21487;&#20197;&#20445;&#35777;&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;
&lt;/p&gt;
&lt;p&gt;
Nonlinear Meta-Learning Can Guarantee Faster Rates. (arXiv:2307.10870v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10870
&lt;/p&gt;
&lt;p&gt;
&#38750;&#32447;&#24615;&#20803;&#23398;&#20064;&#21487;&#20197;&#20445;&#35777;&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#35768;&#22810;&#20851;&#20110;&#20803;&#23398;&#20064;&#30340;&#29702;&#35770;&#30740;&#31350;&#26088;&#22312;&#21033;&#29992;&#30456;&#20851;&#20219;&#21153;&#20013;&#30340;&#30456;&#20284;&#34920;&#31034;&#32467;&#26500;&#26469;&#31616;&#21270;&#30446;&#26631;&#20219;&#21153;&#65292;&#24182;&#23454;&#29616;&#25910;&#25947;&#36895;&#29575;&#30340;&#20445;&#35777;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#36341;&#20013;&#65292;&#34920;&#31034;&#24448;&#24448;&#26159;&#39640;&#24230;&#38750;&#32447;&#24615;&#30340;&#65292;&#24341;&#20837;&#20102;&#27599;&#20010;&#20219;&#21153;&#20013;&#19981;&#21487;&#31616;&#21333;&#24179;&#22343;&#30340;&#38750;&#24179;&#20961;&#20559;&#24046;&#12290;&#26412;&#30740;&#31350;&#36890;&#36807;&#38750;&#32447;&#24615;&#34920;&#31034;&#25512;&#23548;&#20986;&#20803;&#23398;&#20064;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many recent theoretical works on \emph{meta-learning} aim to achieve guarantees in leveraging similar representational structures from related tasks towards simplifying a target task. Importantly, the main aim in theory works on the subject is to understand the extent to which convergence rates -- in learning a common representation -- \emph{may scale with the number $N$ of tasks} (as well as the number of samples per task). First steps in this setting demonstrate this property when both the shared representation amongst tasks, and task-specific regression functions, are linear. This linear setting readily reveals the benefits of aggregating tasks, e.g., via averaging arguments. In practice, however, the representation is often highly nonlinear, introducing nontrivial biases in each task that cannot easily be averaged out as in the linear case. In the present work, we derive theoretical guarantees for meta-learning with nonlinear representations. In particular, assuming the shared nonl
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#39034;&#24207;&#26680;&#29420;&#31435;&#24615;&#27979;&#35797;&#30340;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#20256;&#32479;&#25209;&#37327;&#27979;&#35797;&#22312;&#27969;&#25968;&#25454;&#19978;&#30340;&#38382;&#39064;&#65292;&#23454;&#29616;&#20102;&#26681;&#25454;&#20219;&#21153;&#22797;&#26434;&#24615;&#33258;&#36866;&#24212;&#35843;&#25972;&#26679;&#26412;&#22823;&#23567;&#65292;&#24182;&#22312;&#25910;&#38598;&#26032;&#25968;&#25454;&#21518;&#25345;&#32493;&#30417;&#27979;&#21644;&#25511;&#21046;&#35823;&#25253;&#29575;&#12290;</title><link>http://arxiv.org/abs/2212.07383</link><description>&lt;p&gt;
&#39034;&#24207;&#26680;&#29420;&#31435;&#24615;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
Sequential Kernelized Independence Testing. (arXiv:2212.07383v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.07383
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#39034;&#24207;&#26680;&#29420;&#31435;&#24615;&#27979;&#35797;&#30340;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#20256;&#32479;&#25209;&#37327;&#27979;&#35797;&#22312;&#27969;&#25968;&#25454;&#19978;&#30340;&#38382;&#39064;&#65292;&#23454;&#29616;&#20102;&#26681;&#25454;&#20219;&#21153;&#22797;&#26434;&#24615;&#33258;&#36866;&#24212;&#35843;&#25972;&#26679;&#26412;&#22823;&#23567;&#65292;&#24182;&#22312;&#25910;&#38598;&#26032;&#25968;&#25454;&#21518;&#25345;&#32493;&#30417;&#27979;&#21644;&#25511;&#21046;&#35823;&#25253;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29420;&#31435;&#24615;&#27979;&#35797;&#26159;&#19968;&#20010;&#32463;&#20856;&#30340;&#32479;&#35745;&#38382;&#39064;&#65292;&#22312;&#22266;&#23450;&#37319;&#38598;&#25968;&#25454;&#20043;&#21069;&#30340;&#25209;&#37327;&#35774;&#32622;&#20013;&#24471;&#21040;&#20102;&#24191;&#27867;&#30740;&#31350;&#12290;&#28982;&#32780;&#65292;&#23454;&#36341;&#32773;&#20204;&#24448;&#24448;&#26356;&#21916;&#27426;&#33021;&#22815;&#26681;&#25454;&#38382;&#39064;&#30340;&#22797;&#26434;&#24615;&#36827;&#34892;&#33258;&#36866;&#24212;&#30340;&#31243;&#24207;&#65292;&#32780;&#19981;&#26159;&#20107;&#20808;&#35774;&#23450;&#26679;&#26412;&#22823;&#23567;&#12290;&#29702;&#24819;&#24773;&#20917;&#19979;&#65292;&#36825;&#26679;&#30340;&#31243;&#24207;&#24212;&#35813;&#65288;a&#65289;&#22312;&#31616;&#21333;&#20219;&#21153;&#19978;&#23613;&#26089;&#20572;&#27490;&#65288;&#22312;&#22256;&#38590;&#20219;&#21153;&#19978;&#31245;&#21518;&#20572;&#27490;&#65289;&#65292;&#22240;&#27492;&#26356;&#22909;&#22320;&#21033;&#29992;&#21487;&#29992;&#36164;&#28304;&#65292;&#20197;&#21450;&#65288;b&#65289;&#22312;&#25910;&#38598;&#26032;&#25968;&#25454;&#20043;&#21518;&#65292;&#25345;&#32493;&#30417;&#27979;&#25968;&#25454;&#24182;&#39640;&#25928;&#22320;&#25972;&#21512;&#32479;&#35745;&#35777;&#25454;&#65292;&#21516;&#26102;&#25511;&#21046;&#35823;&#25253;&#29575;&#12290;&#32463;&#20856;&#30340;&#25209;&#37327;&#27979;&#35797;&#19981;&#36866;&#29992;&#20110;&#27969;&#25968;&#25454;&#65306;&#22312;&#25968;&#25454;&#35266;&#23519;&#21518;&#36827;&#34892;&#26377;&#25928;&#25512;&#26029;&#38656;&#35201;&#23545;&#22810;&#37325;&#27979;&#35797;&#36827;&#34892;&#26657;&#27491;&#65292;&#36825;&#23548;&#33268;&#20102;&#20302;&#21151;&#29575;&#12290;&#36981;&#24490;&#36890;&#36807;&#25237;&#27880;&#36827;&#34892;&#27979;&#35797;&#30340;&#21407;&#21017;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#39034;&#24207;&#26680;&#29420;&#31435;&#24615;&#27979;&#35797;&#65292;&#20811;&#26381;&#20102;&#36825;&#20123;&#32570;&#28857;&#12290;&#25105;&#20204;&#36890;&#36807;&#37319;&#29992;&#30001;&#26680;&#30456;&#20851;&#24615;&#27979;&#24230;&#65288;&#22914;Hilbert-&#65289;&#21551;&#21457;&#30340;&#25237;&#27880;&#26469;&#35828;&#26126;&#25105;&#20204;&#30340;&#24191;&#27867;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
Independence testing is a classical statistical problem that has been extensively studied in the batch setting when one fixes the sample size before collecting data. However, practitioners often prefer procedures that adapt to the complexity of a problem at hand instead of setting sample size in advance. Ideally, such procedures should (a) stop earlier on easy tasks (and later on harder tasks), hence making better use of available resources, and (b) continuously monitor the data and efficiently incorporate statistical evidence after collecting new data, while controlling the false alarm rate. Classical batch tests are not tailored for streaming data: valid inference after data peeking requires correcting for multiple testing which results in low power. Following the principle of testing by betting, we design sequential kernelized independence tests that overcome such shortcomings. We exemplify our broad framework using bets inspired by kernelized dependence measures, e.g., the Hilbert-
&lt;/p&gt;</description></item></channel></rss>