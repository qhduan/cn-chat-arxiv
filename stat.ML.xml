<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#36890;&#36807;&#20004;&#38454;&#27573;&#20272;&#35745;&#31574;&#30053;&#65292;&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#22240;&#26524;&#20013;&#20171;&#20998;&#26512;&#20013;&#24178;&#25200;&#20989;&#25968;&#30340;&#26041;&#27861;&#65292;&#26088;&#22312;&#26681;&#25454;&#20854;&#22312;&#20559;&#24046;&#32467;&#26500;&#20013;&#30340;&#20316;&#29992;&#26469;&#20272;&#35745;&#24178;&#25200;&#20989;&#25968;&#12290;</title><link>https://arxiv.org/abs/2404.00735</link><description>&lt;p&gt;
&#22240;&#26524;&#20013;&#20171;&#20998;&#26512;&#30340;&#20004;&#38454;&#27573;&#24178;&#25200;&#20989;&#25968;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Two-Stage Nuisance Function Estimation for Causal Mediation Analysis
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00735
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20004;&#38454;&#27573;&#20272;&#35745;&#31574;&#30053;&#65292;&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#22240;&#26524;&#20013;&#20171;&#20998;&#26512;&#20013;&#24178;&#25200;&#20989;&#25968;&#30340;&#26041;&#27861;&#65292;&#26088;&#22312;&#26681;&#25454;&#20854;&#22312;&#20559;&#24046;&#32467;&#26500;&#20013;&#30340;&#20316;&#29992;&#26469;&#20272;&#35745;&#24178;&#25200;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20351;&#29992;&#22522;&#20110;&#24433;&#21709;&#20989;&#25968;&#30340;&#20013;&#20171;&#21151;&#33021;&#20272;&#35745;&#22120;&#20272;&#35745;&#30452;&#25509;&#21644;&#38388;&#25509;&#22240;&#26524;&#25928;&#24212;&#26102;&#65292;&#20102;&#35299;&#24212;&#35813;&#20851;&#27880;&#27835;&#30103;&#12289;&#20013;&#20171;&#21644;&#32467;&#26524;&#30340;&#21738;&#20123;&#26041;&#38754;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#23558;&#23427;&#20204;&#35270;&#20026;&#24178;&#25200;&#20989;&#25968;&#65292;&#24182;&#35797;&#22270;&#23613;&#21487;&#33021;&#20934;&#30830;&#22320;&#25311;&#21512;&#36825;&#20123;&#24178;&#25200;&#20989;&#25968;&#24182;&#19981;&#19968;&#23450;&#26159;&#26368;&#22909;&#30340;&#26041;&#27861;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#24178;&#25200;&#20989;&#25968;&#30340;&#20004;&#38454;&#27573;&#20272;&#35745;&#31574;&#30053;&#65292;&#35813;&#31574;&#30053;&#26681;&#25454;&#24178;&#25200;&#20989;&#25968;&#22312;&#24433;&#21709;&#20989;&#25968;&#30340;&#20013;&#20171;&#21151;&#33021;&#20272;&#35745;&#22120;&#30340;&#20559;&#24046;&#32467;&#26500;&#20013;&#21457;&#25381;&#30340;&#20316;&#29992;&#26469;&#20272;&#35745;&#24178;&#25200;&#20989;&#25968;&#12290;&#25105;&#20204;&#23545;&#25152;&#25552;&#20986;&#26041;&#27861;&#36827;&#34892;&#20102;&#31283;&#20581;&#24615;&#20998;&#26512;&#65292;&#20197;&#21450;&#21442;&#25968;&#20272;&#35745;&#22120;&#30340;&#19968;&#33268;&#24615;&#21644;&#28176;&#36817;&#27491;&#24577;&#24615;&#30340;&#20805;&#20998;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00735v1 Announce Type: cross  Abstract: When estimating the direct and indirect causal effects using the influence function-based estimator of the mediation functional, it is crucial to understand what aspects of the treatment, the mediator, and the outcome mean mechanisms should be focused on. Specifically, considering them as nuisance functions and attempting to fit these nuisance functions as accurate as possible is not necessarily the best approach to take. In this work, we propose a two-stage estimation strategy for the nuisance functions that estimates the nuisance functions based on the role they play in the structure of the bias of the influence function-based estimator of the mediation functional. We provide robustness analysis of the proposed method, as well as sufficient conditions for consistency and asymptotic normality of the estimator of the parameter of interest.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#24369;&#20998;&#24067;&#37325;&#21472;&#19979;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#30340;&#31163;&#31574;&#30053;&#35780;&#20272;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#25130;&#26029;&#21452;&#37325;&#31283;&#20581;&#65288;TDR&#65289;&#20272;&#35745;&#22120;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#34920;&#29616;&#33391;&#22909;&#12290;</title><link>https://arxiv.org/abs/2402.08201</link><description>&lt;p&gt;
&#24369;&#20998;&#24067;&#37325;&#21472;&#19979;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#30340;&#31163;&#31574;&#30053;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Off-Policy Evaluation in Markov Decision Processes under Weak Distributional Overlap
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08201
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24369;&#20998;&#24067;&#37325;&#21472;&#19979;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#30340;&#31163;&#31574;&#30053;&#35780;&#20272;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#25130;&#26029;&#21452;&#37325;&#31283;&#20581;&#65288;TDR&#65289;&#20272;&#35745;&#22120;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#34920;&#29616;&#33391;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;MDP&#65289;&#20013;&#65292;&#21452;&#37325;&#31283;&#20581;&#26041;&#27861;&#22312;&#24207;&#21015;&#21487;&#24573;&#30053;&#24615;&#19979;&#23545;&#31163;&#31574;&#30053;&#35780;&#20272;&#20855;&#26377;&#24456;&#22823;&#30340;&#28508;&#21147;&#65306;&#23427;&#20204;&#24050;&#32463;&#35777;&#26126;&#20102;&#38543;&#30528;&#26102;&#38271;T&#30340;&#25910;&#25947;&#36895;&#24230;&#20026;$1/\sqrt{T}$&#65292;&#22312;&#22823;&#26679;&#26412;&#20013;&#20855;&#26377;&#32479;&#35745;&#25928;&#29575;&#65292;&#24182;&#19988;&#21487;&#20197;&#36890;&#36807;&#26631;&#20934;&#24378;&#21270;&#23398;&#20064;&#25216;&#26415;&#25191;&#34892;&#39044;&#20272;&#20219;&#21153;&#65292;&#20855;&#26377;&#27169;&#22359;&#21270;&#23454;&#29616;&#30340;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#32467;&#26524;&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#20351;&#29992;&#20102;&#24378;&#20998;&#24067;&#37325;&#21472;&#20551;&#35774;&#65292;&#21363;&#30446;&#26631;&#25919;&#31574;&#21644;&#25968;&#25454;&#25910;&#38598;&#25919;&#31574;&#30340;&#31283;&#24577;&#20998;&#24067;&#30456;&#24046;&#22312;&#26377;&#38480;&#22240;&#23376;&#20869;&#65292;&#32780;&#36825;&#20010;&#20551;&#35774;&#36890;&#24120;&#21482;&#22312;MDP&#30340;&#29366;&#24577;&#31354;&#38388;&#26377;&#30028;&#26102;&#25165;&#21487;&#20449;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#37325;&#26032;&#23457;&#35270;&#20102;&#22312;&#24369;&#20998;&#24067;&#37325;&#21472;&#27010;&#24565;&#19979;&#30340;MDP&#31163;&#31574;&#30053;&#35780;&#20272;&#20219;&#21153;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31867;&#25130;&#26029;&#21452;&#37325;&#31283;&#20581;&#65288;TDR&#65289;&#20272;&#35745;&#22120;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#34920;&#29616;&#33391;&#22909;&#12290;&#24403;&#30446;&#26631;&#21644;&#25968;&#25454;&#25910;&#38598;&#30340;&#20998;&#24067;&#27604;&#29575;&#26377;&#30028;&#26102;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#20123;&#20272;&#35745;&#22120;&#30340;&#19968;&#33268;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Doubly robust methods hold considerable promise for off-policy evaluation in Markov decision processes (MDPs) under sequential ignorability: They have been shown to converge as $1/\sqrt{T}$ with the horizon $T$, to be statistically efficient in large samples, and to allow for modular implementation where preliminary estimation tasks can be executed using standard reinforcement learning techniques. Existing results, however, make heavy use of a strong distributional overlap assumption whereby the stationary distributions of the target policy and the data-collection policy are within a bounded factor of each other -- and this assumption is typically only credible when the state space of the MDP is bounded. In this paper, we re-visit the task of off-policy evaluation in MDPs under a weaker notion of distributional overlap, and introduce a class of truncated doubly robust (TDR) estimators which we find to perform well in this setting. When the distribution ratio of the target and data-coll
&lt;/p&gt;</description></item><item><title>&#22312;&#23384;&#22312;&#32456;&#32467;&#20107;&#20214;&#30340;&#24773;&#20917;&#19979;&#65292;&#30740;&#31350;&#32463;&#24120;&#24615;&#20107;&#20214;&#30340;&#22240;&#26524;&#25512;&#26029;&#21644;&#39640;&#25928;&#20272;&#35745;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20056;&#27861;&#40065;&#26834;&#20272;&#35745;&#30340;&#26041;&#27861;&#65292;&#19981;&#20381;&#36182;&#20110;&#20998;&#24067;&#20551;&#35774;&#65292;&#24182;&#25351;&#20986;&#20102;&#19968;&#20123;&#26377;&#36259;&#30340;&#22240;&#26524;&#29983;&#21629;&#21608;&#26399;&#20013;&#30340;&#19981;&#19968;&#33268;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.16571</link><description>&lt;p&gt;
&#22312;&#23384;&#22312;&#32456;&#32467;&#20107;&#20214;&#30340;&#24773;&#20917;&#19979;&#65292;&#20851;&#20110;&#32463;&#24120;&#24615;&#20107;&#20214;&#30340;&#22240;&#26524;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Causal inference for the expected number of recurrent events in the presence of a terminal event. (arXiv:2306.16571v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.16571
&lt;/p&gt;
&lt;p&gt;
&#22312;&#23384;&#22312;&#32456;&#32467;&#20107;&#20214;&#30340;&#24773;&#20917;&#19979;&#65292;&#30740;&#31350;&#32463;&#24120;&#24615;&#20107;&#20214;&#30340;&#22240;&#26524;&#25512;&#26029;&#21644;&#39640;&#25928;&#20272;&#35745;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20056;&#27861;&#40065;&#26834;&#20272;&#35745;&#30340;&#26041;&#27861;&#65292;&#19981;&#20381;&#36182;&#20110;&#20998;&#24067;&#20551;&#35774;&#65292;&#24182;&#25351;&#20986;&#20102;&#19968;&#20123;&#26377;&#36259;&#30340;&#22240;&#26524;&#29983;&#21629;&#21608;&#26399;&#20013;&#30340;&#19981;&#19968;&#33268;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#23384;&#22312;&#32456;&#32467;&#20107;&#20214;&#30340;&#24773;&#20917;&#19979;&#65292;&#20851;&#20110;&#32463;&#24120;&#24615;&#20107;&#20214;&#30340;&#22240;&#26524;&#25512;&#26029;&#21644;&#39640;&#25928;&#20272;&#35745;&#12290;&#25105;&#20204;&#23558;&#20272;&#35745;&#30446;&#26631;&#23450;&#20041;&#20026;&#21253;&#25324;&#32463;&#24120;&#24615;&#20107;&#20214;&#30340;&#39044;&#26399;&#25968;&#37327;&#20197;&#21450;&#22312;&#19968;&#31995;&#21015;&#37324;&#31243;&#30865;&#26102;&#38388;&#28857;&#22788;&#35780;&#20272;&#30340;&#22833;&#36133;&#29983;&#23384;&#20989;&#25968;&#30340;&#21521;&#37327;&#12290;&#25105;&#20204;&#22312;&#21491;&#25130;&#23614;&#21644;&#22240;&#26524;&#36873;&#25321;&#30340;&#24773;&#20917;&#19979;&#30830;&#23450;&#20102;&#20272;&#35745;&#30446;&#26631;&#65292;&#20316;&#20026;&#35266;&#23519;&#25968;&#25454;&#30340;&#21151;&#33021;&#24615;&#65292;&#25512;&#23548;&#20102;&#38750;&#21442;&#25968;&#25928;&#29575;&#30028;&#38480;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#37325;&#40065;&#26834;&#20272;&#35745;&#22120;&#65292;&#35813;&#20272;&#35745;&#22120;&#36798;&#21040;&#20102;&#30028;&#38480;&#65292;&#24182;&#20801;&#35768;&#38750;&#21442;&#25968;&#20272;&#35745;&#36741;&#21161;&#21442;&#25968;&#12290;&#22312;&#25972;&#20010;&#36807;&#31243;&#20013;&#65292;&#25105;&#20204;&#23545;&#22833;&#36133;&#12289;&#25130;&#23614;&#25110;&#35266;&#23519;&#25968;&#25454;&#30340;&#27010;&#29575;&#20998;&#24067;&#27809;&#26377;&#20570;&#32477;&#23545;&#36830;&#32493;&#24615;&#30340;&#20551;&#35774;&#12290;&#27492;&#22806;&#65292;&#24403;&#20998;&#21106;&#20998;&#24067;&#24050;&#30693;&#26102;&#65292;&#25105;&#20204;&#23548;&#20986;&#20102;&#24433;&#21709;&#20989;&#25968;&#30340;&#31867;&#21035;&#65292;&#24182;&#22238;&#39038;&#20102;&#24050;&#21457;&#34920;&#20272;&#35745;&#22120;&#22914;&#20309;&#23646;&#20110;&#35813;&#31867;&#21035;&#12290;&#22312;&#27492;&#36807;&#31243;&#20013;&#65292;&#25105;&#20204;&#24378;&#35843;&#20102;&#22240;&#26524;&#29983;&#21629;&#21608;&#26399;&#20013;&#19968;&#20123;&#26377;&#36259;&#30340;&#19981;&#19968;&#33268;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study causal inference and efficient estimation for the expected number of recurrent events in the presence of a terminal event. We define our estimand as the vector comprising both the expected number of recurrent events and the failure survival function evaluated along a sequence of landmark times. We identify the estimand in the presence of right-censoring and causal selection as an observed data functional under coarsening at random, derive the nonparametric efficiency bound, and propose a multiply-robust estimator that achieves the bound and permits nonparametric estimation of nuisance parameters. Throughout, no absolute continuity assumption is made on the underlying probability distributions of failure, censoring, or the observed data. Additionally, we derive the class of influence functions when the coarsening distribution is known and review how published estimators may belong to the class. Along the way, we highlight some interesting inconsistencies in the causal lifetime 
&lt;/p&gt;</description></item></channel></rss>