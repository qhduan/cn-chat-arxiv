<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#24378;&#30423;&#20984;&#20248;&#21270;&#30340;&#22522;&#26412;&#26694;&#26550;&#21644;&#29992;&#20110;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#30340;&#22810;&#31181;&#24037;&#20855;&#12290;&#34429;&#28982;&#27809;&#26377;&#22826;&#22810;&#21019;&#26032;&#65292;&#20294;&#36890;&#36807;&#20197;&#26032;&#39062;&#30340;&#26041;&#24335;&#24212;&#29992;&#29616;&#26377;&#24037;&#20855;&#65292;&#33719;&#24471;&#20102;&#26032;&#30340;&#31639;&#27861;&#21644;&#25913;&#36827;&#20102;&#19968;&#20123;&#30028;&#38480;&#12290;</title><link>https://arxiv.org/abs/2402.06535</link><description>&lt;p&gt;
Bandit Convex Optimisation&#65288;&#24378;&#30423;&#20984;&#20248;&#21270;&#65289;
&lt;/p&gt;
&lt;p&gt;
Bandit Convex Optimisation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06535
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#24378;&#30423;&#20984;&#20248;&#21270;&#30340;&#22522;&#26412;&#26694;&#26550;&#21644;&#29992;&#20110;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#30340;&#22810;&#31181;&#24037;&#20855;&#12290;&#34429;&#28982;&#27809;&#26377;&#22826;&#22810;&#21019;&#26032;&#65292;&#20294;&#36890;&#36807;&#20197;&#26032;&#39062;&#30340;&#26041;&#24335;&#24212;&#29992;&#29616;&#26377;&#24037;&#20855;&#65292;&#33719;&#24471;&#20102;&#26032;&#30340;&#31639;&#27861;&#21644;&#25913;&#36827;&#20102;&#19968;&#20123;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24378;&#30423;&#20984;&#20248;&#21270;&#26159;&#30740;&#31350;&#38646;&#38454;&#20984;&#20248;&#21270;&#30340;&#22522;&#26412;&#26694;&#26550;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#29992;&#20110;&#35299;&#20915;&#35813;&#38382;&#39064;&#30340;&#35768;&#22810;&#24037;&#20855;&#65292;&#21253;&#25324;&#20999;&#24179;&#38754;&#26041;&#27861;&#12289;&#20869;&#28857;&#26041;&#27861;&#12289;&#36830;&#32493;&#25351;&#25968;&#26435;&#37325;&#12289;&#26799;&#24230;&#19979;&#38477;&#21644;&#22312;&#32447;&#29275;&#39039;&#27493;&#39588;&#12290;&#35299;&#37322;&#20102;&#35768;&#22810;&#20551;&#35774;&#21644;&#35774;&#32622;&#20043;&#38388;&#30340;&#32454;&#24494;&#24046;&#21035;&#12290;&#23613;&#31649;&#22312;&#36825;&#37324;&#27809;&#26377;&#22826;&#22810;&#30495;&#27491;&#26032;&#30340;&#19996;&#35199;&#65292;&#20294;&#19968;&#20123;&#29616;&#26377;&#24037;&#20855;&#20197;&#26032;&#39062;&#30340;&#26041;&#24335;&#24212;&#29992;&#20110;&#33719;&#24471;&#26032;&#31639;&#27861;&#12290;&#19968;&#20123;&#30028;&#38480;&#31245;&#24494;&#25913;&#36827;&#20102;&#19968;&#20123;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bandit convex optimisation is a fundamental framework for studying zeroth-order convex optimisation. These notes cover the many tools used for this problem, including cutting plane methods, interior point methods, continuous exponential weights, gradient descent and online Newton step. The nuances between the many assumptions and setups are explained. Although there is not much truly new here, some existing tools are applied in novel ways to obtain new algorithms. A few bounds are improved in minor ways.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#30340;&#31232;&#30095;&#27491;&#21017;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#36125;&#21494;&#26031;&#20272;&#35745;&#65292;&#26377;&#25928;&#22320;&#35299;&#20915;&#20102;&#36870;&#38382;&#39064;&#20013;&#30340;&#31232;&#30095;&#24314;&#27169;&#21644;&#21442;&#25968;&#20272;&#35745;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2401.16612</link><description>&lt;p&gt;
&#22312;&#36870;&#38382;&#39064;&#20013;&#23398;&#20064;&#39640;&#26031;&#28151;&#21512;&#29289;&#36827;&#34892;&#31232;&#30095;&#27491;&#21017;&#21270;
&lt;/p&gt;
&lt;p&gt;
Learning a Gaussian Mixture for Sparsity Regularization in Inverse Problems. (arXiv:2401.16612v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.16612
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#30340;&#31232;&#30095;&#27491;&#21017;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#36125;&#21494;&#26031;&#20272;&#35745;&#65292;&#26377;&#25928;&#22320;&#35299;&#20915;&#20102;&#36870;&#38382;&#39064;&#20013;&#30340;&#31232;&#30095;&#24314;&#27169;&#21644;&#21442;&#25968;&#20272;&#35745;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36870;&#38382;&#39064;&#20013;&#65292;&#24191;&#27867;&#35748;&#20026;&#24341;&#20837;&#31232;&#30095;&#20808;&#39564;&#23545;&#35299;&#20915;&#26041;&#26696;&#20855;&#26377;&#27491;&#21017;&#21270;&#25928;&#26524;&#12290;&#36825;&#31181;&#26041;&#27861;&#26159;&#22522;&#20110;&#19968;&#20010;&#20808;&#39564;&#20551;&#35774;&#65292;&#21363;&#26410;&#30693;&#37327;&#21487;&#20197;&#22312;&#19968;&#20010;&#26377;&#38480;&#25968;&#37327;&#30340;&#26174;&#33879;&#25104;&#20998;&#30340;&#22522;&#30784;&#19978;&#36866;&#24403;&#34920;&#31034;&#65292;&#32780;&#22823;&#22810;&#25968;&#31995;&#25968;&#25509;&#36817;&#20110;&#38646;&#12290;&#36825;&#31181;&#24773;&#20917;&#22312;&#29616;&#23454;&#19990;&#30028;&#20013;&#32463;&#24120;&#20986;&#29616;&#65292;&#27604;&#22914;&#20998;&#27573;&#24179;&#28369;&#20449;&#21495;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20197;&#39640;&#26031;&#36864;&#21270;&#28151;&#21512;&#29289;&#24418;&#24335;&#34920;&#36848;&#30340;&#27010;&#29575;&#31232;&#30095;&#20808;&#39564;&#65292;&#33021;&#22815;&#23545;&#20110;&#20219;&#24847;&#22522;&#36827;&#34892;&#31232;&#30095;&#24314;&#27169;&#12290;&#22312;&#36825;&#20010;&#21069;&#25552;&#19979;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#21487;&#20197;&#35299;&#37322;&#20026;&#32447;&#24615;&#36870;&#38382;&#39064;&#30340;&#36125;&#21494;&#26031;&#20272;&#35745;&#22120;&#30340;&#31070;&#32463;&#32593;&#32476;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#30417;&#30563;&#21644;&#26080;&#30417;&#30563;&#30340;&#35757;&#32451;&#31574;&#30053;&#26469;&#20272;&#35745;&#36825;&#20010;&#32593;&#32476;&#30340;&#21442;&#25968;&#12290;&#20026;&#20102;&#35780;&#20272;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#19982;&#24120;&#29992;&#30340;&#31232;&#30095;&#27491;&#21017;&#21270;&#26041;&#27861;&#30340;&#25968;&#20540;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
In inverse problems, it is widely recognized that the incorporation of a sparsity prior yields a regularization effect on the solution. This approach is grounded on the a priori assumption that the unknown can be appropriately represented in a basis with a limited number of significant components, while most coefficients are close to zero. This occurrence is frequently observed in real-world scenarios, such as with piecewise smooth signals. In this study, we propose a probabilistic sparsity prior formulated as a mixture of degenerate Gaussians, capable of modeling sparsity with respect to a generic basis. Under this premise, we design a neural network that can be interpreted as the Bayes estimator for linear inverse problems. Additionally, we put forth both a supervised and an unsupervised training strategy to estimate the parameters of this network. To evaluate the effectiveness of our approach, we conduct a numerical comparison with commonly employed sparsity-promoting regularization
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35777;&#26126;&#20102;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#20013;&#30340;&#23567;&#25209;&#37327;&#22122;&#38899;&#20250;&#20351;&#35299;&#20915;&#26041;&#26696;&#21521;&#24179;&#34913;&#35299;&#38752;&#36817;&#65292;&#21482;&#35201;&#25439;&#22833;&#20989;&#25968;&#21253;&#21547;&#37325;&#26032;&#32553;&#25918;&#23545;&#31216;&#24615;&#12290;&#21033;&#29992;&#36825;&#20010;&#32467;&#26524;&#65292;&#25105;&#20204;&#23548;&#20986;&#20102;&#23545;&#35282;&#32447;&#24615;&#32593;&#32476;&#30340;&#38543;&#26426;&#26799;&#24230;&#27969;&#31283;&#24577;&#20998;&#24067;&#65292;&#35813;&#20998;&#24067;&#23637;&#31034;&#20102;&#22797;&#26434;&#30340;&#38750;&#32447;&#24615;&#29616;&#35937;&#12290;&#36825;&#20123;&#21457;&#29616;&#25581;&#31034;&#20102;&#21160;&#24577;&#26799;&#24230;&#19979;&#38477;&#27861;&#22312;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#24037;&#20316;&#21407;&#29702;&#12290;</title><link>http://arxiv.org/abs/2308.06671</link><description>&lt;p&gt;
&#21160;&#24577;&#26799;&#24230;&#19979;&#38477;&#27861;&#30340;&#24179;&#34913;&#27861;&#21017;&#19982;&#31283;&#24577;&#20998;&#24067;
&lt;/p&gt;
&lt;p&gt;
Law of Balance and Stationary Distribution of Stochastic Gradient Descent. (arXiv:2308.06671v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.06671
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#20102;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#20013;&#30340;&#23567;&#25209;&#37327;&#22122;&#38899;&#20250;&#20351;&#35299;&#20915;&#26041;&#26696;&#21521;&#24179;&#34913;&#35299;&#38752;&#36817;&#65292;&#21482;&#35201;&#25439;&#22833;&#20989;&#25968;&#21253;&#21547;&#37325;&#26032;&#32553;&#25918;&#23545;&#31216;&#24615;&#12290;&#21033;&#29992;&#36825;&#20010;&#32467;&#26524;&#65292;&#25105;&#20204;&#23548;&#20986;&#20102;&#23545;&#35282;&#32447;&#24615;&#32593;&#32476;&#30340;&#38543;&#26426;&#26799;&#24230;&#27969;&#31283;&#24577;&#20998;&#24067;&#65292;&#35813;&#20998;&#24067;&#23637;&#31034;&#20102;&#22797;&#26434;&#30340;&#38750;&#32447;&#24615;&#29616;&#35937;&#12290;&#36825;&#20123;&#21457;&#29616;&#25581;&#31034;&#20102;&#21160;&#24577;&#26799;&#24230;&#19979;&#38477;&#27861;&#22312;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#24037;&#20316;&#21407;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#31639;&#27861;&#26159;&#25105;&#20204;&#29992;&#20110;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#30340;&#31639;&#27861;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#24456;&#38590;&#29702;&#35299;SGD&#22914;&#20309;&#22312;&#31070;&#32463;&#32593;&#32476;&#30340;&#38750;&#32447;&#24615;&#21644;&#36864;&#21270;&#30340;&#25439;&#22833;&#26354;&#38754;&#20013;&#36827;&#34892;&#23548;&#33322;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;SGD&#30340;&#23567;&#25209;&#37327;&#22122;&#38899;&#21487;&#20197;&#20351;&#35299;&#20915;&#26041;&#26696;&#21521;&#24179;&#34913;&#35299;&#38752;&#36817;&#65292;&#21482;&#35201;&#25439;&#22833;&#20989;&#25968;&#21253;&#21547;&#19968;&#20010;&#37325;&#26032;&#32553;&#25918;&#23545;&#31216;&#24615;&#12290;&#30001;&#20110;&#31616;&#21333;&#25193;&#25955;&#36807;&#31243;&#21644;SGD&#21160;&#21147;&#23398;&#30340;&#24046;&#24322;&#22312;&#23545;&#31216;&#24615;&#23384;&#22312;&#26102;&#26368;&#37325;&#35201;&#65292;&#25105;&#20204;&#30340;&#29702;&#35770;&#34920;&#26126;&#65292;&#25439;&#22833;&#20989;&#25968;&#30340;&#23545;&#31216;&#24615;&#26159;&#20102;&#35299;SGD&#24037;&#20316;&#26041;&#24335;&#30340;&#37325;&#35201;&#32447;&#32034;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23558;&#36825;&#20010;&#32467;&#26524;&#24212;&#29992;&#20110;&#23548;&#20986;&#20855;&#26377;&#20219;&#24847;&#28145;&#24230;&#21644;&#23485;&#24230;&#30340;&#23545;&#35282;&#32447;&#24615;&#32593;&#32476;&#30340;&#38543;&#26426;&#26799;&#24230;&#27969;&#30340;&#31283;&#24577;&#20998;&#24067;&#12290;&#31283;&#24577;&#20998;&#24067;&#23637;&#29616;&#20102;&#22797;&#26434;&#30340;&#38750;&#32447;&#24615;&#29616;&#35937;&#65292;&#22914;&#30456;&#21464;&#12289;&#30772;&#22351;&#30340;&#36941;&#21382;&#24615;&#21644;&#27874;&#21160;&#21453;&#36716;&#12290;&#36825;&#20123;&#29616;&#35937;&#20165;&#22312;&#28145;&#23618;&#32593;&#32476;&#20013;&#23384;&#22312;&#65292;&#34920;&#26126;&#20102;&#19968;&#31181;&#22522;&#26412;&#30340;&#26032;&#30340;&#21152;&#28145;&#35757;&#32451;&#29702;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
The stochastic gradient descent (SGD) algorithm is the algorithm we use to train neural networks. However, it remains poorly understood how the SGD navigates the highly nonlinear and degenerate loss landscape of a neural network. In this work, we prove that the minibatch noise of SGD regularizes the solution towards a balanced solution whenever the loss function contains a rescaling symmetry. Because the difference between a simple diffusion process and SGD dynamics is the most significant when symmetries are present, our theory implies that the loss function symmetries constitute an essential probe of how SGD works. We then apply this result to derive the stationary distribution of stochastic gradient flow for a diagonal linear network with arbitrary depth and width. The stationary distribution exhibits complicated nonlinear phenomena such as phase transitions, broken ergodicity, and fluctuation inversion. These phenomena are shown to exist uniquely in deep networks, implying a fundam
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#20108;&#38454;&#26465;&#20214;&#26799;&#24230;&#28369;&#21160;&#65288;SOCGS&#65289;&#31639;&#27861;&#65292;&#21487;&#20197;&#39640;&#25928;&#35299;&#20915;&#32422;&#26463;&#20108;&#27425;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#22312;&#26377;&#38480;&#27425;&#32447;&#24615;&#25910;&#25947;&#36845;&#20195;&#21518;&#20108;&#27425;&#25910;&#25947;&#20110;&#21407;&#22987;&#38388;&#38553;&#12290;</title><link>http://arxiv.org/abs/2002.08907</link><description>&lt;p&gt;
&#20108;&#38454;&#26465;&#20214;&#26799;&#24230;&#28369;&#21160;
&lt;/p&gt;
&lt;p&gt;
Second-order Conditional Gradient Sliding. (arXiv:2002.08907v3 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2002.08907
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#20108;&#38454;&#26465;&#20214;&#26799;&#24230;&#28369;&#21160;&#65288;SOCGS&#65289;&#31639;&#27861;&#65292;&#21487;&#20197;&#39640;&#25928;&#35299;&#20915;&#32422;&#26463;&#20108;&#27425;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#22312;&#26377;&#38480;&#27425;&#32447;&#24615;&#25910;&#25947;&#36845;&#20195;&#21518;&#20108;&#27425;&#25910;&#25947;&#20110;&#21407;&#22987;&#38388;&#38553;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#38656;&#35201;&#39640;&#31934;&#24230;&#35299;&#20915;&#38382;&#39064;&#26102;&#65292;&#32422;&#26463;&#20108;&#38454;&#20984;&#20248;&#21270;&#31639;&#27861;&#26159;&#39318;&#36873;&#65292;&#22240;&#20026;&#23427;&#20204;&#20855;&#26377;&#23616;&#37096;&#20108;&#27425;&#25910;&#25947;&#24615;&#12290;&#36825;&#20123;&#31639;&#27861;&#22312;&#27599;&#27425;&#36845;&#20195;&#26102;&#38656;&#35201;&#35299;&#20915;&#19968;&#20010;&#32422;&#26463;&#20108;&#27425;&#23376;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;\emph{&#20108;&#38454;&#26465;&#20214;&#26799;&#24230;&#28369;&#21160;}&#65288;SOCGS&#65289;&#31639;&#27861;&#65292;&#23427;&#20351;&#29992;&#19968;&#31181;&#26080;&#25237;&#24433;&#31639;&#27861;&#26469;&#36817;&#20284;&#35299;&#20915;&#32422;&#26463;&#20108;&#27425;&#23376;&#38382;&#39064;&#12290;&#24403;&#21487;&#34892;&#22495;&#26159;&#19968;&#20010;&#22810;&#38754;&#20307;&#26102;&#65292;&#35813;&#31639;&#27861;&#22312;&#26377;&#38480;&#27425;&#32447;&#24615;&#25910;&#25947;&#36845;&#20195;&#21518;&#20108;&#27425;&#25910;&#25947;&#20110;&#21407;&#22987;&#38388;&#38553;&#12290;&#36827;&#20837;&#20108;&#27425;&#25910;&#25947;&#38454;&#27573;&#21518;&#65292;SOCGS&#31639;&#27861;&#38656;&#36890;&#36807;$\mathcal{O}(\log(\log 1/\varepsilon))$&#27425;&#19968;&#38454;&#21644;Hessian&#27491;&#20132;&#35843;&#29992;&#20197;&#21450;$\mathcal{O}(\log (1/\varepsilon) \log(\log1/\varepsilon))$&#27425;&#32447;&#24615;&#26368;&#23567;&#21270;&#27491;&#20132;&#35843;&#29992;&#26469;&#23454;&#29616;$\varepsilon$-&#26368;&#20248;&#35299;&#12290;&#24403;&#21487;&#34892;&#22495;&#21482;&#33021;&#36890;&#36807;&#32447;&#24615;&#20248;&#21270;&#27491;&#20132;&#35843;&#29992;&#39640;&#25928;&#35775;&#38382;&#26102;&#65292;&#27492;&#31639;&#27861;&#38750;&#24120;&#26377;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Constrained second-order convex optimization algorithms are the method of choice when a high accuracy solution to a problem is needed, due to their local quadratic convergence. These algorithms require the solution of a constrained quadratic subproblem at every iteration. We present the \emph{Second-Order Conditional Gradient Sliding} (SOCGS) algorithm, which uses a projection-free algorithm to solve the constrained quadratic subproblems inexactly. When the feasible region is a polytope the algorithm converges quadratically in primal gap after a finite number of linearly convergent iterations. Once in the quadratic regime the SOCGS algorithm requires $\mathcal{O}(\log(\log 1/\varepsilon))$ first-order and Hessian oracle calls and $\mathcal{O}(\log (1/\varepsilon) \log(\log1/\varepsilon))$ linear minimization oracle calls to achieve an $\varepsilon$-optimal solution. This algorithm is useful when the feasible region can only be accessed efficiently through a linear optimization oracle, 
&lt;/p&gt;</description></item></channel></rss>