<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#26680;PCA&#36827;&#34892;&#22806;&#20998;&#24067;&#26816;&#27979;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#20027;&#25104;&#20998;&#23376;&#31354;&#38388;&#20013;&#24341;&#20837;&#38750;&#32447;&#24615;&#26144;&#23556;&#65292;&#23454;&#29616;&#20102;&#23545;&#20869;&#20998;&#24067;&#21644;&#22806;&#20998;&#24067;&#25968;&#25454;&#30340;&#26377;&#25928;&#21306;&#20998;&#12290;</title><link>https://arxiv.org/abs/2402.02949</link><description>&lt;p&gt;
&#22806;&#20998;&#24067;&#26816;&#27979;&#30340;&#26680;PCA
&lt;/p&gt;
&lt;p&gt;
Kernel PCA for Out-of-Distribution Detection
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02949
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#26680;PCA&#36827;&#34892;&#22806;&#20998;&#24067;&#26816;&#27979;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#20027;&#25104;&#20998;&#23376;&#31354;&#38388;&#20013;&#24341;&#20837;&#38750;&#32447;&#24615;&#26144;&#23556;&#65292;&#23454;&#29616;&#20102;&#23545;&#20869;&#20998;&#24067;&#21644;&#22806;&#20998;&#24067;&#25968;&#25454;&#30340;&#26377;&#25928;&#21306;&#20998;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22806;&#20998;&#24067;&#65288;OoD&#65289;&#26816;&#27979;&#23545;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNN&#65289;&#30340;&#21487;&#38752;&#24615;&#33267;&#20851;&#37325;&#35201;&#12290;&#29616;&#26377;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#30452;&#25509;&#24212;&#29992;&#20110;DNN&#29305;&#24449;&#30340;&#20027;&#25104;&#20998;&#20998;&#26512;&#65288;PCA&#65289;&#22312;&#26816;&#27979;&#26469;&#33258;&#20869;&#20998;&#24067;&#65288;InD&#65289;&#25968;&#25454;&#30340;OoD&#25968;&#25454;&#26041;&#38754;&#19981;&#36275;&#22815;&#12290;PCA&#30340;&#22833;&#36133;&#34920;&#26126;&#65292;&#20165;&#36890;&#36807;&#22312;&#32447;&#24615;&#23376;&#31354;&#38388;&#20013;&#36827;&#34892;&#31616;&#21333;&#22788;&#29702;&#26080;&#27861;&#24456;&#22909;&#22320;&#23558;OoD&#21644;InD&#20013;&#30340;&#32593;&#32476;&#29305;&#24449;&#20998;&#31163;&#24320;&#26469;&#65292;&#32780;&#21487;&#20197;&#36890;&#36807;&#36866;&#24403;&#30340;&#38750;&#32447;&#24615;&#26144;&#23556;&#26469;&#35299;&#20915;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#26680;PCA&#65288;KPCA&#65289;&#26694;&#26550;&#36827;&#34892;OoD&#26816;&#27979;&#65292;&#23547;&#25214;OoD&#21644;InD&#29305;&#24449;&#20197;&#26174;&#33879;&#19981;&#21516;&#30340;&#27169;&#24335;&#20998;&#37197;&#30340;&#23376;&#31354;&#38388;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#20004;&#31181;&#29305;&#24449;&#26144;&#23556;&#65292;&#22312;KPCA&#20013;&#24341;&#20837;&#38750;&#32447;&#24615;&#20869;&#26680;&#65292;&#20197;&#20419;&#36827;&#22312;&#20027;&#25104;&#20998;&#24352;&#25104;&#30340;&#23376;&#31354;&#38388;&#20013;InD&#21644;OoD&#25968;&#25454;&#20043;&#38388;&#30340;&#21487;&#20998;&#24615;&#12290;&#28982;&#21518;&#65292;&#36890;&#36807;&#22312;&#36825;&#31181;&#23376;&#31354;&#38388;&#20013;&#30340;&#37325;&#26500;&#35823;&#24046;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#24471;&#21040;$\mathcal{O}(1)$&#26102;&#38388;&#22797;&#26434;&#24230;&#30340;&#26816;&#27979;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Out-of-Distribution (OoD) detection is vital for the reliability of Deep Neural Networks (DNNs). Existing works have shown the insufficiency of Principal Component Analysis (PCA) straightforwardly applied on the features of DNNs in detecting OoD data from In-Distribution (InD) data. The failure of PCA suggests that the network features residing in OoD and InD are not well separated by simply proceeding in a linear subspace, which instead can be resolved through proper nonlinear mappings. In this work, we leverage the framework of Kernel PCA (KPCA) for OoD detection, seeking subspaces where OoD and InD features are allocated with significantly different patterns. We devise two feature mappings that induce non-linear kernels in KPCA to advocate the separability between InD and OoD data in the subspace spanned by the principal components. Given any test sample, the reconstruction error in such subspace is then used to efficiently obtain the detection result with $\mathcal{O}(1)$ time comp
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#28176;&#36827;&#22495;&#33258;&#36866;&#24212;&#20013;&#30340;&#28176;&#36827;&#33258;&#35757;&#32451;&#31639;&#27861;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#25913;&#36827;&#30340;&#27867;&#21270;&#30028;&#38480;&#65292;&#24182;&#25351;&#20986;&#20102;&#20013;&#38388;&#22495;&#22312;&#28304;&#22495;&#21644;&#30446;&#26631;&#22495;&#20043;&#38388;&#22343;&#21248;&#25918;&#32622;&#30340;&#37325;&#35201;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.13852</link><description>&lt;p&gt;
&#28176;&#36827;&#22495;&#33258;&#36866;&#24212;&#65306;&#29702;&#35770;&#19982;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Gradual Domain Adaptation: Theory and Algorithms. (arXiv:2310.13852v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13852
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#28176;&#36827;&#22495;&#33258;&#36866;&#24212;&#20013;&#30340;&#28176;&#36827;&#33258;&#35757;&#32451;&#31639;&#27861;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#25913;&#36827;&#30340;&#27867;&#21270;&#30028;&#38480;&#65292;&#24182;&#25351;&#20986;&#20102;&#20013;&#38388;&#22495;&#22312;&#28304;&#22495;&#21644;&#30446;&#26631;&#22495;&#20043;&#38388;&#22343;&#21248;&#25918;&#32622;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#30417;&#30563;&#22495;&#33258;&#36866;&#24212;&#65288;UDA&#65289;&#26159;&#23558;&#27169;&#22411;&#20174;&#26377;&#26631;&#35760;&#30340;&#28304;&#22495;&#36866;&#24212;&#21040;&#26080;&#26631;&#35760;&#30340;&#30446;&#26631;&#22495;&#30340;&#19968;&#31181;&#19968;&#27425;&#24615;&#26041;&#27861;&#12290;&#23613;&#31649;&#34987;&#24191;&#27867;&#24212;&#29992;&#65292;&#20294;&#24403;&#28304;&#22495;&#21644;&#30446;&#26631;&#22495;&#20043;&#38388;&#30340;&#20998;&#24067;&#20559;&#31227;&#36739;&#22823;&#26102;&#65292;UDA&#38754;&#20020;&#24040;&#22823;&#25361;&#25112;&#12290;&#28176;&#36827;&#22495;&#33258;&#36866;&#24212;&#65288;GDA&#65289;&#36890;&#36807;&#20351;&#29992;&#20013;&#38388;&#22495;&#36880;&#28176;&#20174;&#28304;&#22495;&#36866;&#24212;&#21040;&#30446;&#26631;&#22495;&#26469;&#32531;&#35299;&#36825;&#20010;&#38480;&#21046;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#39318;&#20808;&#20174;&#29702;&#35770;&#19978;&#20998;&#26512;&#20102;&#19968;&#31181;&#24120;&#35265;&#30340;GDA&#31639;&#27861;&#8212;&#8212;&#28176;&#36827;&#33258;&#35757;&#32451;&#65292;&#24182;&#25552;&#20379;&#20102;&#19982;Kumar&#31561;&#20154;&#65288;2020&#65289;&#30456;&#27604;&#26174;&#33879;&#25913;&#36827;&#30340;&#27867;&#21270;&#30028;&#38480;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#20998;&#26512;&#24471;&#20986;&#19968;&#20010;&#26377;&#36259;&#30340;&#35266;&#28857;&#65306;&#20026;&#20102;&#26368;&#23567;&#21270;&#30446;&#26631;&#22495;&#19978;&#30340;&#27867;&#21270;&#35823;&#24046;&#65292;&#20013;&#38388;&#22495;&#30340;&#39034;&#24207;&#24212;&#35813;&#22343;&#21248;&#22320;&#25918;&#32622;&#22312;&#28304;&#22495;&#21644;&#30446;&#26631;&#22495;&#20043;&#38388;&#30340;Wasserstein&#27979;&#22320;&#32447;&#19978;&#12290;&#36825;&#20010;&#35266;&#28857;&#22312;&#20013;&#38388;&#22495;&#32570;&#22833;&#25110;&#31232;&#32570;&#30340;&#24773;&#20917;&#19979;&#23588;&#20854;&#26377;&#29992;&#65292;&#32780;&#36825;&#22312;&#29616;&#23454;&#19990;&#30028;&#30340;&#24212;&#29992;&#20013;&#32463;&#24120;&#20986;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Unsupervised domain adaptation (UDA) adapts a model from a labeled source domain to an unlabeled target domain in a one-off way. Though widely applied, UDA faces a great challenge whenever the distribution shift between the source and the target is large. Gradual domain adaptation (GDA) mitigates this limitation by using intermediate domains to gradually adapt from the source to the target domain. In this work, we first theoretically analyze gradual self-training, a popular GDA algorithm, and provide a significantly improved generalization bound compared with Kumar et al. (2020). Our theoretical analysis leads to an interesting insight: to minimize the generalization error on the target domain, the sequence of intermediate domains should be placed uniformly along the Wasserstein geodesic between the source and target domains. The insight is particularly useful under the situation where intermediate domains are missing or scarce, which is often the case in real-world applications. Based
&lt;/p&gt;</description></item><item><title>Ano-SuPs&#26159;&#19968;&#31181;&#36890;&#36807;&#35782;&#21035;&#21487;&#30097;&#21306;&#22359;&#26469;&#36827;&#34892;&#21046;&#36896;&#20135;&#21697;&#30340;&#22810;&#23610;&#24230;&#24322;&#24120;&#26816;&#27979;&#30340;&#20004;&#38454;&#27573;&#31574;&#30053;&#26041;&#27861;&#12290;&#23427;&#21487;&#20197;&#35299;&#20915;&#22270;&#20687;&#32972;&#26223;&#22797;&#26434;&#24615;&#21644;&#24322;&#24120;&#27169;&#24335;&#30340;&#25361;&#25112;&#65292;&#24182;&#20855;&#26377;&#36739;&#39640;&#30340;&#20934;&#30830;&#24615;&#21644;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.11120</link><description>&lt;p&gt;
Ano-SuPs: &#36890;&#36807;&#35782;&#21035;&#21487;&#30097;&#30340;&#21306;&#22359;&#36827;&#34892;&#21046;&#36896;&#20135;&#21697;&#30340;&#22810;&#23610;&#24230;&#24322;&#24120;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Ano-SuPs: Multi-size anomaly detection for manufactured products by identifying suspected patches. (arXiv:2309.11120v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.11120
&lt;/p&gt;
&lt;p&gt;
Ano-SuPs&#26159;&#19968;&#31181;&#36890;&#36807;&#35782;&#21035;&#21487;&#30097;&#21306;&#22359;&#26469;&#36827;&#34892;&#21046;&#36896;&#20135;&#21697;&#30340;&#22810;&#23610;&#24230;&#24322;&#24120;&#26816;&#27979;&#30340;&#20004;&#38454;&#27573;&#31574;&#30053;&#26041;&#27861;&#12290;&#23427;&#21487;&#20197;&#35299;&#20915;&#22270;&#20687;&#32972;&#26223;&#22797;&#26434;&#24615;&#21644;&#24322;&#24120;&#27169;&#24335;&#30340;&#25361;&#25112;&#65292;&#24182;&#20855;&#26377;&#36739;&#39640;&#30340;&#20934;&#30830;&#24615;&#21644;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#22270;&#20687;&#30340;&#31995;&#32479;&#22240;&#20854;&#25552;&#20379;&#20016;&#23500;&#30340;&#21046;&#36896;&#29366;&#24577;&#20449;&#24687;&#12289;&#20302;&#23454;&#26045;&#25104;&#26412;&#21644;&#39640;&#37319;&#38598;&#36895;&#24230;&#32780;&#21463;&#21040;&#27426;&#36814;&#12290;&#28982;&#32780;&#65292;&#22270;&#20687;&#32972;&#26223;&#30340;&#22797;&#26434;&#24615;&#21644;&#21508;&#31181;&#24322;&#24120;&#27169;&#24335;&#32473;&#29616;&#26377;&#30340;&#30697;&#38453;&#20998;&#35299;&#26041;&#27861;&#24102;&#26469;&#20102;&#26032;&#30340;&#25361;&#25112;&#65292;&#36825;&#20123;&#26041;&#27861;&#19981;&#36275;&#20197;&#28385;&#36275;&#24314;&#27169;&#38656;&#27714;&#12290;&#27492;&#22806;&#65292;&#24322;&#24120;&#30340;&#19981;&#30830;&#23450;&#24615;&#21487;&#33021;&#23548;&#33268;&#24322;&#24120;&#30340;&#27745;&#26579;&#38382;&#39064;&#65292;&#20351;&#24471;&#35774;&#35745;&#30340;&#27169;&#22411;&#21644;&#26041;&#27861;&#23545;&#22806;&#37096;&#24178;&#25200;&#38750;&#24120;&#25935;&#24863;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#35782;&#21035;&#21487;&#30097;&#21306;&#22359;&#65288;Ano-SuPs&#65289;&#26469;&#26816;&#27979;&#24322;&#24120;&#30340;&#20004;&#38454;&#27573;&#31574;&#30053;&#24322;&#24120;&#26816;&#27979;&#26041;&#27861;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#36890;&#36807;&#20004;&#27425;&#37325;&#24314;&#36755;&#20837;&#22270;&#20687;&#26469;&#26816;&#27979;&#24102;&#26377;&#24322;&#24120;&#30340;&#21306;&#22359;&#30340;&#26041;&#27861;&#65306;&#31532;&#19968;&#27493;&#26159;&#36890;&#36807;&#21435;&#38500;&#37027;&#20123;&#21487;&#30097;&#21306;&#22359;&#26469;&#33719;&#24471;&#19968;&#32452;&#27491;&#24120;&#21306;&#22359;&#65292;&#31532;&#20108;&#27493;&#26159;&#20351;&#29992;&#36825;&#20123;&#27491;&#24120;&#21306;&#22359;&#26469;&#20248;&#21270;&#23545;&#24102;&#26377;&#24322;&#24120;&#21306;&#22359;&#30340;&#35782;&#21035;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Image-based systems have gained popularity owing to their capacity to provide rich manufacturing status information, low implementation costs and high acquisition rates. However, the complexity of the image background and various anomaly patterns pose new challenges to existing matrix decomposition methods, which are inadequate for modeling requirements. Moreover, the uncertainty of the anomaly can cause anomaly contamination problems, making the designed model and method highly susceptible to external disturbances. To address these challenges, we propose a two-stage strategy anomaly detection method that detects anomalies by identifying suspected patches (Ano-SuPs). Specifically, we propose to detect the patches with anomalies by reconstructing the input image twice: the first step is to obtain a set of normal patches by removing those suspected patches, and the second step is to use those normal patches to refine the identification of the patches with anomalies. To demonstrate its ef
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#31232;&#30095;&#21270;&#21516;&#26102;&#32622;&#20449;&#21306;&#38388;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#39640;&#32500;&#32447;&#24615;&#27169;&#22411;&#30340;&#32479;&#35745;&#25512;&#26029;&#12290;&#36890;&#36807;&#23558;&#26576;&#20123;&#21306;&#38388;&#30340;&#19978;&#19979;&#30028;&#25910;&#32553;&#20026;&#38646;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#30830;&#23450;&#19981;&#37325;&#35201;&#30340;&#21327;&#21464;&#37327;&#24182;&#23558;&#20854;&#25490;&#38500;&#22312;&#26368;&#32456;&#27169;&#22411;&#20043;&#22806;&#65292;&#21516;&#26102;&#36890;&#36807;&#20854;&#20182;&#21306;&#38388;&#21028;&#26029;&#20986;&#21487;&#20449;&#21644;&#26174;&#33879;&#30340;&#21327;&#21464;&#37327;&#12290;</title><link>http://arxiv.org/abs/2307.07574</link><description>&lt;p&gt;
&#39640;&#32500;&#32447;&#24615;&#27169;&#22411;&#30340;&#31232;&#30095;&#21270;&#21516;&#26102;&#32622;&#20449;&#21306;&#38388;
&lt;/p&gt;
&lt;p&gt;
Sparsified Simultaneous Confidence Intervals for High-Dimensional Linear Models. (arXiv:2307.07574v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.07574
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#31232;&#30095;&#21270;&#21516;&#26102;&#32622;&#20449;&#21306;&#38388;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#39640;&#32500;&#32447;&#24615;&#27169;&#22411;&#30340;&#32479;&#35745;&#25512;&#26029;&#12290;&#36890;&#36807;&#23558;&#26576;&#20123;&#21306;&#38388;&#30340;&#19978;&#19979;&#30028;&#25910;&#32553;&#20026;&#38646;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#30830;&#23450;&#19981;&#37325;&#35201;&#30340;&#21327;&#21464;&#37327;&#24182;&#23558;&#20854;&#25490;&#38500;&#22312;&#26368;&#32456;&#27169;&#22411;&#20043;&#22806;&#65292;&#21516;&#26102;&#36890;&#36807;&#20854;&#20182;&#21306;&#38388;&#21028;&#26029;&#20986;&#21487;&#20449;&#21644;&#26174;&#33879;&#30340;&#21327;&#21464;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37492;&#20110;&#27169;&#22411;&#36873;&#25321;&#36807;&#31243;&#24341;&#20837;&#30340;&#19981;&#30830;&#23450;&#24615;&#38590;&#20197;&#32771;&#34385;&#65292;&#23545;&#39640;&#32500;&#22238;&#24402;&#31995;&#25968;&#30340;&#32479;&#35745;&#25512;&#26029;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#19968;&#20010;&#20851;&#38190;&#38382;&#39064;&#20173;&#26410;&#35299;&#20915;&#65292;&#21363;&#26159;&#21542;&#21487;&#33021;&#20197;&#21450;&#22914;&#20309;&#23558;&#27169;&#22411;&#30340;&#25512;&#26029;&#23884;&#20837;&#21040;&#31995;&#25968;&#30340;&#21516;&#26102;&#25512;&#26029;&#20013;&#65311;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#31232;&#30095;&#21270;&#21516;&#26102;&#32622;&#20449;&#21306;&#38388;&#30340;&#27010;&#24565;&#12290;&#25105;&#20204;&#30340;&#21306;&#38388;&#22312;&#26576;&#20123;&#19978;&#19979;&#30028;&#19978;&#36827;&#34892;&#20102;&#31232;&#30095;&#65292;&#21363;&#32553;&#23567;&#20026;&#38646;&#65288;&#20363;&#22914;&#65292;$[0,0]$&#65289;&#65292;&#34920;&#31034;&#30456;&#24212;&#21327;&#21464;&#37327;&#30340;&#19981;&#37325;&#35201;&#24615;&#12290;&#36825;&#20123;&#21327;&#21464;&#37327;&#24212;&#35813;&#20174;&#26368;&#32456;&#27169;&#22411;&#20013;&#25490;&#38500;&#12290;&#20854;&#20313;&#30340;&#21306;&#38388;&#65292;&#26080;&#35770;&#26159;&#21253;&#21547;&#38646;&#65288;&#20363;&#22914;&#65292;$[-1,1]$&#25110;$[0,1]$&#65289;&#36824;&#26159;&#19981;&#21253;&#21547;&#38646;&#65288;&#20363;&#22914;&#65292;$[2,3]$&#65289;&#65292;&#20998;&#21035;&#34920;&#31034;&#21487;&#20449;&#21644;&#26174;&#33879;&#30340;&#21327;&#21464;&#37327;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#21487;&#20197;&#19982;&#21508;&#31181;&#36873;&#25321;&#36807;&#31243;&#30456;&#32467;&#21512;&#65292;&#20351;&#20854;&#38750;&#24120;&#36866;&#21512;&#27604;&#36739;&#23427;&#20204;&#30340;&#20351;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Statistical inference of the high-dimensional regression coefficients is challenging because the uncertainty introduced by the model selection procedure is hard to account for. A critical question remains unsettled; that is, is it possible and how to embed the inference of the model into the simultaneous inference of the coefficients? To this end, we propose a notion of simultaneous confidence intervals called the sparsified simultaneous confidence intervals. Our intervals are sparse in the sense that some of the intervals' upper and lower bounds are shrunken to zero (i.e., $[0,0]$), indicating the unimportance of the corresponding covariates. These covariates should be excluded from the final model. The rest of the intervals, either containing zero (e.g., $[-1,1]$ or $[0,1]$) or not containing zero (e.g., $[2,3]$), indicate the plausible and significant covariates, respectively. The proposed method can be coupled with various selection procedures, making it ideal for comparing their u
&lt;/p&gt;</description></item></channel></rss>