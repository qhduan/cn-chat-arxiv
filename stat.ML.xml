<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#23545;&#20998;&#24067;&#21464;&#21270;&#20855;&#26377;&#40065;&#26834;&#24615;&#30340;&#26368;&#20248;&#20998;&#31867;&#26641;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#28151;&#21512;&#25972;&#25968;&#40065;&#26834;&#20248;&#21270;&#25216;&#26415;&#23558;&#35813;&#38382;&#39064;&#36716;&#21270;&#20026;&#21333;&#38454;&#27573;&#28151;&#21512;&#25972;&#25968;&#40065;&#26834;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#35774;&#35745;&#20102;&#22522;&#20110;&#32422;&#26463;&#29983;&#25104;&#30340;&#35299;&#20915;&#36807;&#31243;&#12290;</title><link>http://arxiv.org/abs/2310.17772</link><description>&lt;p&gt;
&#23398;&#20064;&#23545;&#20998;&#24067;&#21464;&#21270;&#20855;&#26377;&#40065;&#26834;&#24615;&#30340;&#26368;&#20248;&#20998;&#31867;&#26641;
&lt;/p&gt;
&lt;p&gt;
Learning Optimal Classification Trees Robust to Distribution Shifts. (arXiv:2310.17772v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17772
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#23545;&#20998;&#24067;&#21464;&#21270;&#20855;&#26377;&#40065;&#26834;&#24615;&#30340;&#26368;&#20248;&#20998;&#31867;&#26641;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#28151;&#21512;&#25972;&#25968;&#40065;&#26834;&#20248;&#21270;&#25216;&#26415;&#23558;&#35813;&#38382;&#39064;&#36716;&#21270;&#20026;&#21333;&#38454;&#27573;&#28151;&#21512;&#25972;&#25968;&#40065;&#26834;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#35774;&#35745;&#20102;&#22522;&#20110;&#32422;&#26463;&#29983;&#25104;&#30340;&#35299;&#20915;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#23398;&#20064;&#23545;&#35757;&#32451;&#21644;&#27979;&#35797;/&#37096;&#32626;&#25968;&#25454;&#20043;&#38388;&#30340;&#20998;&#24067;&#21464;&#21270;&#20855;&#26377;&#40065;&#26834;&#24615;&#30340;&#20998;&#31867;&#26641;&#30340;&#38382;&#39064;&#12290;&#36825;&#20010;&#38382;&#39064;&#32463;&#24120;&#22312;&#39640;&#39118;&#38505;&#29615;&#22659;&#20013;&#20986;&#29616;&#65292;&#20363;&#22914;&#20844;&#20849;&#21355;&#29983;&#21644;&#31038;&#20250;&#24037;&#20316;&#65292;&#20854;&#20013;&#25968;&#25454;&#36890;&#24120;&#26159;&#36890;&#36807;&#33258;&#25105;&#25253;&#21578;&#30340;&#35843;&#26597;&#25910;&#38598;&#30340;&#65292;&#36825;&#20123;&#35843;&#26597;&#23545;&#38382;&#39064;&#30340;&#34920;&#36848;&#26041;&#24335;&#12289;&#35843;&#26597;&#36827;&#34892;&#30340;&#26102;&#38388;&#21644;&#22320;&#28857;&#12289;&#20197;&#21450;&#21463;&#35775;&#32773;&#19982;&#35843;&#26597;&#21592;&#20998;&#20139;&#20449;&#24687;&#30340;&#33298;&#36866;&#31243;&#24230;&#38750;&#24120;&#25935;&#24863;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28151;&#21512;&#25972;&#25968;&#40065;&#26834;&#20248;&#21270;&#25216;&#26415;&#30340;&#23398;&#20064;&#26368;&#20248;&#40065;&#26834;&#20998;&#31867;&#26641;&#30340;&#26041;&#27861;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#35777;&#26126;&#23398;&#20064;&#26368;&#20248;&#40065;&#26834;&#26641;&#30340;&#38382;&#39064;&#21487;&#20197;&#31561;&#20215;&#22320;&#34920;&#36798;&#20026;&#19968;&#20010;&#20855;&#26377;&#39640;&#24230;&#38750;&#32447;&#24615;&#21644;&#19981;&#36830;&#32493;&#30446;&#26631;&#30340;&#21333;&#38454;&#27573;&#28151;&#21512;&#25972;&#25968;&#40065;&#26834;&#20248;&#21270;&#38382;&#39064;&#12290;&#25105;&#20204;&#23558;&#36825;&#20010;&#38382;&#39064;&#31561;&#20215;&#22320;&#37325;&#26032;&#34920;&#36848;&#20026;&#19968;&#20010;&#20004;&#38454;&#27573;&#32447;&#24615;&#40065;&#26834;&#20248;&#21270;&#38382;&#39064;&#65292;&#20026;&#27492;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#22522;&#20110;&#32422;&#26463;&#29983;&#25104;&#30340;&#23450;&#21046;&#35299;&#20915;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of learning classification trees that are robust to distribution shifts between training and testing/deployment data. This problem arises frequently in high stakes settings such as public health and social work where data is often collected using self-reported surveys which are highly sensitive to e.g., the framing of the questions, the time when and place where the survey is conducted, and the level of comfort the interviewee has in sharing information with the interviewer. We propose a method for learning optimal robust classification trees based on mixed-integer robust optimization technology. In particular, we demonstrate that the problem of learning an optimal robust tree can be cast as a single-stage mixed-integer robust optimization problem with a highly nonlinear and discontinuous objective. We reformulate this problem equivalently as a two-stage linear robust optimization problem for which we devise a tailored solution procedure based on constraint gene
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#24341;&#20837;&#39640;&#38454;&#24635;&#21464;&#24046;&#27491;&#21017;&#21270;&#30340;&#38543;&#26426;&#20248;&#21270;&#31639;&#27861;&#65292;&#21487;&#20197;&#39640;&#25928;&#22320;&#35757;&#32451;&#38750;&#32447;&#24615;&#31070;&#32463;&#32593;&#32476;&#65292;&#36991;&#20813;&#36807;&#25311;&#21512;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2308.02293</link><description>&lt;p&gt;
&#29992;&#27491;&#21017;&#21270;&#39640;&#38454;&#24635;&#21464;&#24046;&#30340;&#38543;&#26426;&#20248;&#21270;&#26041;&#27861;&#35757;&#32451;&#38750;&#32447;&#24615;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
A stochastic optimization approach to train non-linear neural networks with regularization of higher-order total variation. (arXiv:2308.02293v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.02293
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24341;&#20837;&#39640;&#38454;&#24635;&#21464;&#24046;&#27491;&#21017;&#21270;&#30340;&#38543;&#26426;&#20248;&#21270;&#31639;&#27861;&#65292;&#21487;&#20197;&#39640;&#25928;&#22320;&#35757;&#32451;&#38750;&#32447;&#24615;&#31070;&#32463;&#32593;&#32476;&#65292;&#36991;&#20813;&#36807;&#25311;&#21512;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#21253;&#25324;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#20869;&#30340;&#39640;&#24230;&#34920;&#36798;&#30340;&#21442;&#25968;&#27169;&#22411;&#21487;&#20197;&#26356;&#22909;&#22320;&#24314;&#27169;&#22797;&#26434;&#27010;&#24565;&#65292;&#20294;&#35757;&#32451;&#36825;&#31181;&#39640;&#24230;&#38750;&#32447;&#24615;&#27169;&#22411;&#24050;&#30693;&#20250;&#23548;&#33268;&#20005;&#37325;&#30340;&#36807;&#25311;&#21512;&#39118;&#38505;&#12290;&#38024;&#23545;&#36825;&#20010;&#38382;&#39064;&#65292;&#26412;&#30740;&#31350;&#32771;&#34385;&#20102;&#19968;&#31181;k&#38454;&#24635;&#21464;&#24046;&#65288;k-TV&#65289;&#27491;&#21017;&#21270;&#65292;&#23427;&#34987;&#23450;&#20041;&#20026;&#35201;&#35757;&#32451;&#30340;&#21442;&#25968;&#27169;&#22411;&#30340;k&#38454;&#23548;&#25968;&#30340;&#24179;&#26041;&#31215;&#20998;&#65292;&#36890;&#36807;&#24809;&#32602;k-TV&#26469;&#20135;&#29983;&#19968;&#20010;&#26356;&#24179;&#28369;&#30340;&#20989;&#25968;&#65292;&#20174;&#32780;&#36991;&#20813;&#36807;&#25311;&#21512;&#12290;&#23613;&#31649;&#23558;k-TV&#39033;&#24212;&#29992;&#20110;&#19968;&#33324;&#30340;&#21442;&#25968;&#27169;&#22411;&#30001;&#20110;&#31215;&#20998;&#32780;&#23548;&#33268;&#35745;&#31639;&#22797;&#26434;&#65292;&#26412;&#30740;&#31350;&#25552;&#20379;&#20102;&#19968;&#31181;&#38543;&#26426;&#20248;&#21270;&#31639;&#27861;&#65292;&#21487;&#20197;&#39640;&#25928;&#22320;&#35757;&#32451;&#24102;&#26377;k-TV&#27491;&#21017;&#21270;&#30340;&#19968;&#33324;&#27169;&#22411;&#65292;&#32780;&#26080;&#38656;&#36827;&#34892;&#26174;&#24335;&#30340;&#25968;&#20540;&#31215;&#20998;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#24212;&#29992;&#20110;&#32467;&#26500;&#20219;&#24847;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#35757;&#32451;&#65292;&#22240;&#20026;&#23427;&#21482;&#38656;&#35201;&#36827;&#34892;&#31616;&#21333;&#30340;&#38543;&#26426;&#26799;&#24230;&#20248;&#21270;&#21363;&#21487;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
While highly expressive parametric models including deep neural networks have an advantage to model complicated concepts, training such highly non-linear models is known to yield a high risk of notorious overfitting. To address this issue, this study considers a $k$th order total variation ($k$-TV) regularization, which is defined as the squared integral of the $k$th order derivative of the parametric models to be trained; penalizing the $k$-TV is expected to yield a smoother function, which is expected to avoid overfitting. While the $k$-TV terms applied to general parametric models are computationally intractable due to the integration, this study provides a stochastic optimization algorithm, that can efficiently train general models with the $k$-TV regularization without conducting explicit numerical integration. The proposed approach can be applied to the training of even deep neural networks whose structure is arbitrary, as it can be implemented by only a simple stochastic gradien
&lt;/p&gt;</description></item></channel></rss>