<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#35813;&#35770;&#25991;&#35777;&#26126;&#20102;&#24403;&#23398;&#20064;&#36895;&#29575;&#25353;&#29031;&#36870;&#26102;&#38388;&#34928;&#20943;&#35268;&#21017;&#26102;&#65292;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#24212;&#29992;&#20110;&#20462;&#25913;&#30340;&#24102;&#26377;L2&#27491;&#21017;&#21270;&#30340;&#31574;&#30053;&#26799;&#24230;&#22810;&#33218;&#36172;&#21338;&#26426;&#65288;MAB&#65289;&#30340;&#25910;&#25947;&#24615;&#20998;&#26512;&#12290;</title><link>https://arxiv.org/abs/2402.06388</link><description>&lt;p&gt;
&#20851;&#20110;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#30340;&#25910;&#25947;&#36895;&#24230;&#21450;&#20854;&#22312;&#20462;&#25913;&#30340;&#22810;&#33218;&#36172;&#21338;&#26426;&#19978;&#30340;&#31574;&#30053;&#26799;&#24230;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
On the Convergence Rate of the Stochastic Gradient Descent (SGD) and application to a modified policy gradient for the Multi Armed Bandit
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06388
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#35777;&#26126;&#20102;&#24403;&#23398;&#20064;&#36895;&#29575;&#25353;&#29031;&#36870;&#26102;&#38388;&#34928;&#20943;&#35268;&#21017;&#26102;&#65292;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#24212;&#29992;&#20110;&#20462;&#25913;&#30340;&#24102;&#26377;L2&#27491;&#21017;&#21270;&#30340;&#31574;&#30053;&#26799;&#24230;&#22810;&#33218;&#36172;&#21338;&#26426;&#65288;MAB&#65289;&#30340;&#25910;&#25947;&#24615;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#33258;&#21253;&#21547;&#30340;&#35777;&#26126;&#65292;&#35777;&#26126;&#20102;&#24403;&#23398;&#20064;&#36895;&#29575;&#36981;&#24490;&#36870;&#26102;&#38388;&#34928;&#20943;&#35268;&#21017;&#26102;&#65292;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#30340;&#25910;&#25947;&#36895;&#24230;&#65307;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#23558;&#36825;&#20123;&#32467;&#26524;&#24212;&#29992;&#20110;&#24102;&#26377;L2&#27491;&#21017;&#21270;&#30340;&#20462;&#25913;&#30340;&#31574;&#30053;&#26799;&#24230;&#22810;&#33218;&#36172;&#21338;&#26426;&#65288;MAB&#65289;&#30340;&#25910;&#25947;&#24615;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a self-contained proof of the convergence rate of the Stochastic Gradient Descent (SGD) when the learning rate follows an inverse time decays schedule; we next apply the results to the convergence of a modified form of policy gradient Multi-Armed Bandit (MAB) with $L2$ regularization.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#20419;&#36827;&#25968;&#20540;MD&#27169;&#25311;&#24182;&#26377;&#25928;&#27169;&#25311;&#34507;&#30333;&#36136;-&#37197;&#20307;&#32467;&#21512;&#21160;&#21147;&#23398;&#30340;NeuralMD&#26041;&#27861;&#65292;&#37319;&#29992;&#29289;&#29702;&#20449;&#24687;&#22810;&#32423;&#23545;&#31216;&#26694;&#26550;&#65292;&#23454;&#29616;&#20102;&#20934;&#30830;&#24314;&#27169;&#22810;&#32423;&#34507;&#30333;&#36136;-&#37197;&#20307;&#30456;&#20114;&#20316;&#29992;&#12290;</title><link>http://arxiv.org/abs/2401.15122</link><description>&lt;p&gt;
&#19968;&#31181;&#22810;&#32423;&#23545;&#31216;&#24494;&#20998;&#26041;&#31243;&#27169;&#22411;&#29992;&#20110;&#23398;&#20064;&#34507;&#30333;&#36136;-&#37197;&#20307;&#32467;&#21512;&#21160;&#21147;&#23398;
&lt;/p&gt;
&lt;p&gt;
A Multi-Grained Symmetric Differential Equation Model for Learning Protein-Ligand Binding Dynamics. (arXiv:2401.15122v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15122
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#20419;&#36827;&#25968;&#20540;MD&#27169;&#25311;&#24182;&#26377;&#25928;&#27169;&#25311;&#34507;&#30333;&#36136;-&#37197;&#20307;&#32467;&#21512;&#21160;&#21147;&#23398;&#30340;NeuralMD&#26041;&#27861;&#65292;&#37319;&#29992;&#29289;&#29702;&#20449;&#24687;&#22810;&#32423;&#23545;&#31216;&#26694;&#26550;&#65292;&#23454;&#29616;&#20102;&#20934;&#30830;&#24314;&#27169;&#22810;&#32423;&#34507;&#30333;&#36136;-&#37197;&#20307;&#30456;&#20114;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#33647;&#29289;&#21457;&#29616;&#20013;&#65292;&#34507;&#30333;&#36136;-&#37197;&#20307;&#32467;&#21512;&#30340;&#20998;&#23376;&#21160;&#21147;&#23398;&#65288;MD&#65289;&#27169;&#25311;&#25552;&#20379;&#20102;&#19968;&#31181;&#24378;&#22823;&#30340;&#24037;&#20855;&#65292;&#29992;&#20110;&#39044;&#27979;&#32467;&#21512;&#20146;&#21644;&#21147;&#65292;&#20272;&#35745;&#36816;&#36755;&#24615;&#33021;&#21644;&#25506;&#32034;&#21475;&#34955;&#20301;&#28857;&#12290;&#36890;&#36807;&#25913;&#36827;&#25968;&#20540;&#26041;&#27861;&#20197;&#21450;&#26368;&#36817;&#36890;&#36807;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#26041;&#27861;&#22686;&#24378;MD&#27169;&#25311;&#30340;&#25928;&#29575;&#24050;&#32463;&#26377;&#20102;&#24456;&#38271;&#30340;&#21382;&#21490;&#12290;&#28982;&#32780;&#65292;&#20173;&#28982;&#23384;&#22312;&#19968;&#20123;&#25361;&#25112;&#65292;&#20363;&#22914;&#20934;&#30830;&#24314;&#27169;&#25193;&#23637;&#26102;&#38388;&#23610;&#24230;&#30340;&#27169;&#25311;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;NeuralMD&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#33021;&#22815;&#20419;&#36827;&#25968;&#20540;MD&#24182;&#25552;&#20379;&#20934;&#30830;&#30340;&#34507;&#30333;&#36136;-&#37197;&#20307;&#32467;&#21512;&#21160;&#21147;&#23398;&#27169;&#25311;&#30340;ML&#36741;&#21161;&#24037;&#20855;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21512;&#29702;&#30340;&#26041;&#27861;&#65292;&#23558;&#19968;&#31181;&#26032;&#30340;&#29289;&#29702;&#20449;&#24687;&#22810;&#32423;&#23545;&#31216;&#26694;&#26550;&#32435;&#20837;&#27169;&#22411;&#20013;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#65288;1&#65289;&#19968;&#20010;&#20351;&#29992;&#21521;&#37327;&#26694;&#26550;&#28385;&#36275;&#32676;&#23545;&#31216;&#24615;&#24182;&#25429;&#33719;&#22810;&#32423;&#34507;&#30333;&#36136;-&#37197;&#20307;&#30456;&#20114;&#20316;&#29992;&#30340;BindingNet&#27169;&#22411;&#65292;&#20197;&#21450;&#65288;2&#65289;&#19968;&#20010;&#22686;&#24378;&#30340;&#31070;&#32463;&#24494;&#20998;&#26041;&#31243;&#27714;&#35299;&#22120;&#65292;&#23398;&#20064;&#36712;&#36857;&#30340;&#28436;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
In drug discovery, molecular dynamics (MD) simulation for protein-ligand binding provides a powerful tool for predicting binding affinities, estimating transport properties, and exploring pocket sites. There has been a long history of improving the efficiency of MD simulations through better numerical methods and, more recently, by augmenting them with machine learning (ML) methods. Yet, challenges remain, such as accurate modeling of extended-timescale simulations. To address this issue, we propose NeuralMD, the first ML surrogate that can facilitate numerical MD and provide accurate simulations of protein-ligand binding dynamics. We propose a principled approach that incorporates a novel physics-informed multi-grained group symmetric framework. Specifically, we propose (1) a BindingNet model that satisfies group symmetry using vector frames and captures the multi-level protein-ligand interactions, and (2) an augmented neural differential equation solver that learns the trajectory und
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#38750;&#32447;&#24615;&#21452;&#26102;&#38388;&#23610;&#24230;&#38543;&#26426;&#36924;&#36817;&#20013;&#26377;&#38480;&#26102;&#38388;&#35299;&#32806;&#25910;&#25947;&#30340;&#28508;&#21147;&#65292;&#24182;&#36890;&#36807;&#24341;&#20837;&#23884;&#22871;&#23616;&#37096;&#32447;&#24615;&#26465;&#20214;&#35777;&#26126;&#20102;&#20854;&#21487;&#34892;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.03893</link><description>&lt;p&gt;
&#38750;&#32447;&#24615;&#21452;&#26102;&#38388;&#23610;&#24230;&#38543;&#26426;&#36924;&#36817;&#20013;&#30340;&#26377;&#38480;&#26102;&#38388;&#35299;&#32806;&#25910;&#25947;
&lt;/p&gt;
&lt;p&gt;
Finite-Time Decoupled Convergence in Nonlinear Two-Time-Scale Stochastic Approximation. (arXiv:2401.03893v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.03893
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#38750;&#32447;&#24615;&#21452;&#26102;&#38388;&#23610;&#24230;&#38543;&#26426;&#36924;&#36817;&#20013;&#26377;&#38480;&#26102;&#38388;&#35299;&#32806;&#25910;&#25947;&#30340;&#28508;&#21147;&#65292;&#24182;&#36890;&#36807;&#24341;&#20837;&#23884;&#22871;&#23616;&#37096;&#32447;&#24615;&#26465;&#20214;&#35777;&#26126;&#20102;&#20854;&#21487;&#34892;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21452;&#26102;&#38388;&#23610;&#24230;&#38543;&#26426;&#36924;&#36817;&#20013;&#65292;&#20351;&#29992;&#19981;&#21516;&#30340;&#27493;&#38271;&#20197;&#19981;&#21516;&#30340;&#36895;&#24230;&#26356;&#26032;&#20004;&#20010;&#36845;&#20195;&#65292;&#27599;&#27425;&#26356;&#26032;&#37117;&#20250;&#24433;&#21709;&#21478;&#19968;&#20010;&#12290;&#20808;&#21069;&#30340;&#32447;&#24615;&#21452;&#26102;&#38388;&#23610;&#24230;&#38543;&#26426;&#36924;&#36817;&#30740;&#31350;&#21457;&#29616;&#65292;&#36825;&#20123;&#26356;&#26032;&#30340;&#22343;&#26041;&#35823;&#24046;&#30340;&#25910;&#25947;&#36895;&#24230;&#20165;&#20165;&#21462;&#20915;&#20110;&#23427;&#20204;&#21508;&#33258;&#30340;&#27493;&#38271;&#65292;&#23548;&#33268;&#20102;&#25152;&#35859;&#30340;&#35299;&#32806;&#25910;&#25947;&#12290;&#28982;&#32780;&#65292;&#22312;&#38750;&#32447;&#24615;&#38543;&#26426;&#36924;&#36817;&#20013;&#23454;&#29616;&#36825;&#31181;&#35299;&#32806;&#25910;&#25947;&#30340;&#21487;&#33021;&#24615;&#20173;&#19981;&#26126;&#30830;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#25506;&#35752;&#20102;&#38750;&#32447;&#24615;&#21452;&#26102;&#38388;&#23610;&#24230;&#38543;&#26426;&#36924;&#36817;&#20013;&#26377;&#38480;&#26102;&#38388;&#35299;&#32806;&#25910;&#25947;&#30340;&#28508;&#21147;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#22312;&#36739;&#24369;&#30340;Lipschitz&#26465;&#20214;&#19979;&#65292;&#20256;&#32479;&#20998;&#26512;&#26080;&#27861;&#23454;&#29616;&#35299;&#32806;&#25910;&#25947;&#12290;&#36825;&#19968;&#21457;&#29616;&#22312;&#25968;&#20540;&#19978;&#24471;&#21040;&#20102;&#36827;&#19968;&#27493;&#30340;&#25903;&#25345;&#12290;&#20294;&#26159;&#36890;&#36807;&#24341;&#20837;&#19968;&#20010;&#23884;&#22871;&#23616;&#37096;&#32447;&#24615;&#26465;&#20214;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#36866;&#24403;&#36873;&#25321;&#19982;&#24179;&#28369;&#24230;&#30456;&#20851;&#30340;&#27493;&#38271;&#30340;&#24773;&#20917;&#19979;&#65292;&#35299;&#32806;&#25910;&#25947;&#20173;&#28982;&#26159;&#21487;&#34892;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
In two-time-scale stochastic approximation (SA), two iterates are updated at varying speeds using different step sizes, with each update influencing the other. Previous studies in linear two-time-scale SA have found that the convergence rates of the mean-square errors for these updates are dependent solely on their respective step sizes, leading to what is referred to as decoupled convergence. However, the possibility of achieving this decoupled convergence in nonlinear SA remains less understood. Our research explores the potential for finite-time decoupled convergence in nonlinear two-time-scale SA. We find that under a weaker Lipschitz condition, traditional analyses are insufficient for achieving decoupled convergence. This finding is further numerically supported by a counterexample. But by introducing an additional condition of nested local linearity, we show that decoupled convergence is still feasible, contingent on the appropriate choice of step sizes associated with smoothnes
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#26377;&#30028;&#23485;&#24230;&#21644;&#20219;&#24847;&#28145;&#24230;&#30340;&#22797;&#20540;&#31070;&#32463;&#32593;&#32476;&#30340;&#26222;&#36866;&#24615;&#65292;&#21457;&#29616;&#24403;&#19988;&#20165;&#24403;&#28608;&#27963;&#20989;&#25968;&#26082;&#19981;&#26159;&#20840;&#32431;&#30340;&#65292;&#20063;&#19981;&#26159;&#21453;&#20840;&#32431;&#30340;&#65292;&#20063;&#19981;&#26159; $\mathbb{R}$-&#20223;&#23556;&#30340;&#26102;&#65292;&#28145;&#31364;&#30340;&#22797;&#20540;&#32593;&#32476;&#20855;&#26377;&#26222;&#36866;&#36924;&#36817;&#33021;&#21147;&#12290;&#25105;&#20204;&#36824;&#21457;&#29616;&#36275;&#22815;&#30340;&#23485;&#24230;&#20381;&#36182;&#20110;&#32771;&#34385;&#30340;&#28608;&#27963;&#20989;&#25968;&#65292;&#23545;&#20110;&#19968;&#31867;&#21487;&#20801;&#35768;&#30340;&#28608;&#27963;&#20989;&#25968;&#65292;&#23485;&#24230;&#20026; $n+m+4$ &#26159;&#36275;&#22815;&#30340;&#12290;</title><link>http://arxiv.org/abs/2305.16910</link><description>&lt;p&gt;
&#24102;&#26377;&#22797;&#20540;&#30340;&#28145;&#31364;&#31070;&#32463;&#32593;&#32476;&#30340;&#26222;&#36866;&#36924;&#36817;
&lt;/p&gt;
&lt;p&gt;
Universal approximation with complex-valued deep narrow neural networks. (arXiv:2305.16910v1 [math.FA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16910
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#26377;&#30028;&#23485;&#24230;&#21644;&#20219;&#24847;&#28145;&#24230;&#30340;&#22797;&#20540;&#31070;&#32463;&#32593;&#32476;&#30340;&#26222;&#36866;&#24615;&#65292;&#21457;&#29616;&#24403;&#19988;&#20165;&#24403;&#28608;&#27963;&#20989;&#25968;&#26082;&#19981;&#26159;&#20840;&#32431;&#30340;&#65292;&#20063;&#19981;&#26159;&#21453;&#20840;&#32431;&#30340;&#65292;&#20063;&#19981;&#26159; $\mathbb{R}$-&#20223;&#23556;&#30340;&#26102;&#65292;&#28145;&#31364;&#30340;&#22797;&#20540;&#32593;&#32476;&#20855;&#26377;&#26222;&#36866;&#36924;&#36817;&#33021;&#21147;&#12290;&#25105;&#20204;&#36824;&#21457;&#29616;&#36275;&#22815;&#30340;&#23485;&#24230;&#20381;&#36182;&#20110;&#32771;&#34385;&#30340;&#28608;&#27963;&#20989;&#25968;&#65292;&#23545;&#20110;&#19968;&#31867;&#21487;&#20801;&#35768;&#30340;&#28608;&#27963;&#20989;&#25968;&#65292;&#23485;&#24230;&#20026; $n+m+4$ &#26159;&#36275;&#22815;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#20855;&#26377;&#26377;&#30028;&#23485;&#24230;&#21644;&#20219;&#24847;&#28145;&#24230;&#30340;&#22797;&#20540;&#31070;&#32463;&#32593;&#32476;&#30340;&#26222;&#36866;&#24615;&#12290;&#22312;&#28201;&#21644;&#30340;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#37027;&#20123;&#28608;&#27963;&#20989;&#25968; $\varrho:\mathbb{CC}\to \mathbb{C}$ &#30340;&#23436;&#25972;&#25551;&#36848;&#65292;&#36825;&#20123;&#20989;&#25968;&#20855;&#26377;&#36825;&#26679;&#19968;&#20010;&#23646;&#24615;&#65306;&#23427;&#20204;&#20851;&#32852;&#30340;&#32593;&#32476;&#26159;&#26222;&#36866;&#30340;&#65292;&#21363;&#33021;&#22815;&#22312;&#32039;&#33268;&#22495;&#19978;&#36924;&#36817;&#36830;&#32493;&#20989;&#25968;&#33267;&#20219;&#24847;&#31934;&#24230;&#12290;&#20934;&#30830;&#22320;&#35828;&#65292;&#25105;&#20204;&#34920;&#26126;&#20102;&#24403;&#19988;&#20165;&#24403;&#23427;&#20204;&#30340;&#28608;&#27963;&#20989;&#25968;&#26082;&#19981;&#26159;&#20840;&#32431;&#30340;&#65292;&#20063;&#19981;&#26159;&#21453;&#20840;&#32431;&#30340;&#65292;&#20063;&#19981;&#26159; $\mathbb{R}$-&#20223;&#23556;&#30340;&#65292;&#28145;&#31364;&#30340;&#22797;&#20540;&#32593;&#32476;&#26159;&#26222;&#36866;&#30340;&#12290;&#36825;&#26159;&#19968;&#20010;&#27604;&#23485;&#24230;&#20219;&#24847;&#12289;&#28145;&#24230;&#22266;&#23450;&#30340;&#23545;&#20598;&#35774;&#32622;&#20013;&#26356;&#22823;&#30340;&#20989;&#25968;&#31867;&#12290;&#19982;&#23454;&#20540;&#24773;&#20917;&#19981;&#21516;&#30340;&#26159;&#65292;&#36275;&#22815;&#30340;&#23485;&#24230;&#20381;&#36182;&#20110;&#32771;&#34385;&#30340;&#28608;&#27963;&#20989;&#25968;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#23485;&#24230;&#20026; $2n+2m+5$ &#24635;&#26159;&#36275;&#22815;&#30340;&#65292;&#24182;&#19988;&#36890;&#24120; $\max\{2n,2m\}$ &#26159;&#24517;&#35201;&#30340;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#20110;&#19968;&#31867;&#21487;&#20801;&#35768;&#30340;&#28608;&#27963;&#20989;&#25968;&#65292;&#23485;&#24230;&#20026; $n+m+4$ &#26159;&#36275;&#22815;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the universality of complex-valued neural networks with bounded widths and arbitrary depths. Under mild assumptions, we give a full description of those activation functions $\varrho:\mathbb{CC}\to \mathbb{C}$ that have the property that their associated networks are universal, i.e., are capable of approximating continuous functions to arbitrary accuracy on compact domains. Precisely, we show that deep narrow complex-valued networks are universal if and only if their activation function is neither holomorphic, nor antiholomorphic, nor $\mathbb{R}$-affine. This is a much larger class of functions than in the dual setting of arbitrary width and fixed depth. Unlike in the real case, the sufficient width differs significantly depending on the considered activation function. We show that a width of $2n+2m+5$ is always sufficient and that in general a width of $\max\{2n,2m\}$ is necessary. We prove, however, that a width of $n+m+4$ suffices for a rich subclass of the admissible acti
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#30740;&#31350;&#20102;Conformal Prediction&#26041;&#27861;&#23545;&#20110;&#26631;&#31614;&#22122;&#22768;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#25214;&#20986;&#20102;&#26500;&#24314;&#21487;&#20197;&#27491;&#30830;&#35206;&#30422;&#26080;&#22122;&#22768;&#30495;&#23454;&#26631;&#31614;&#30340;&#19981;&#30830;&#23450;&#24615;&#38598;&#21512;&#30340;&#26465;&#20214;&#65292;&#24182;&#25552;&#20986;&#20102;&#23545;&#20855;&#26377;&#22122;&#22768;&#26631;&#31614;&#30340;&#19968;&#33324;&#25439;&#22833;&#20989;&#25968;&#36827;&#34892;&#27491;&#30830;&#25511;&#21046;&#30340;&#35201;&#27714;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#22312;&#23545;&#25239;&#24615;&#26696;&#20363;&#20043;&#22806;&#65292;&#20351;&#29992;Conformal Prediction&#21644;&#39118;&#38505;&#25511;&#21046;&#25216;&#26415;&#21487;&#20197;&#23454;&#29616;&#23545;&#24178;&#20928;&#30495;&#23454;&#26631;&#31614;&#30340;&#20445;&#23432;&#39118;&#38505;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#30028;&#23610;&#23544;&#22122;&#22768;&#20462;&#27491;&#30340;&#26041;&#27861;&#65292;&#20197;&#30830;&#20445;&#23454;&#29616;&#27491;&#30830;&#30340;&#30495;&#23454;&#26631;&#31614;&#39118;&#38505;&#12290;</title><link>http://arxiv.org/abs/2209.14295</link><description>&lt;p&gt;
Conformal Prediction&#23545;&#20998;&#25955;&#26631;&#31614;&#22122;&#22768;&#20855;&#26377;&#31283;&#20581;&#24615;
&lt;/p&gt;
&lt;p&gt;
Conformal Prediction is Robust to Dispersive Label Noise. (arXiv:2209.14295v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.14295
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#30740;&#31350;&#20102;Conformal Prediction&#26041;&#27861;&#23545;&#20110;&#26631;&#31614;&#22122;&#22768;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#25214;&#20986;&#20102;&#26500;&#24314;&#21487;&#20197;&#27491;&#30830;&#35206;&#30422;&#26080;&#22122;&#22768;&#30495;&#23454;&#26631;&#31614;&#30340;&#19981;&#30830;&#23450;&#24615;&#38598;&#21512;&#30340;&#26465;&#20214;&#65292;&#24182;&#25552;&#20986;&#20102;&#23545;&#20855;&#26377;&#22122;&#22768;&#26631;&#31614;&#30340;&#19968;&#33324;&#25439;&#22833;&#20989;&#25968;&#36827;&#34892;&#27491;&#30830;&#25511;&#21046;&#30340;&#35201;&#27714;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#22312;&#23545;&#25239;&#24615;&#26696;&#20363;&#20043;&#22806;&#65292;&#20351;&#29992;Conformal Prediction&#21644;&#39118;&#38505;&#25511;&#21046;&#25216;&#26415;&#21487;&#20197;&#23454;&#29616;&#23545;&#24178;&#20928;&#30495;&#23454;&#26631;&#31614;&#30340;&#20445;&#23432;&#39118;&#38505;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#30028;&#23610;&#23544;&#22122;&#22768;&#20462;&#27491;&#30340;&#26041;&#27861;&#65292;&#20197;&#30830;&#20445;&#23454;&#29616;&#27491;&#30830;&#30340;&#30495;&#23454;&#26631;&#31614;&#39118;&#38505;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#23545;&#26631;&#31614;&#22122;&#22768;&#20855;&#26377;&#40065;&#26834;&#24615;&#30340;Conformal Prediction&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#26159;&#19968;&#31181;&#29992;&#20110;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#24378;&#22823;&#24037;&#20855;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#28085;&#30422;&#20102;&#22238;&#24402;&#21644;&#20998;&#31867;&#38382;&#39064;&#65292;&#23545;&#20110;&#22914;&#20309;&#26500;&#24314;&#33021;&#22815;&#27491;&#30830;&#35206;&#30422;&#26410;&#35266;&#23519;&#21040;&#30340;&#26080;&#22122;&#22768;&#30495;&#23454;&#26631;&#31614;&#30340;&#19981;&#30830;&#23450;&#24615;&#38598;&#21512;&#36827;&#34892;&#20102;&#30028;&#23450;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25193;&#23637;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#65292;&#24182;&#25552;&#20986;&#20102;&#23545;&#20110;&#24102;&#26377;&#22122;&#22768;&#26631;&#31614;&#27491;&#30830;&#25511;&#21046;&#19968;&#33324;&#25439;&#22833;&#20989;&#25968;&#65288;&#22914;&#20551;&#38452;&#24615;&#27604;&#20363;&#65289;&#30340;&#35201;&#27714;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#21644;&#23454;&#39564;&#34920;&#26126;&#65292;&#22312;&#24102;&#26377;&#22122;&#22768;&#26631;&#31614;&#30340;&#24773;&#20917;&#19979;&#65292;Conformal Prediction&#21644;&#39118;&#38505;&#25511;&#21046;&#25216;&#26415;&#33021;&#22815;&#23454;&#29616;&#23545;&#24178;&#20928;&#30495;&#23454;&#26631;&#31614;&#30340;&#20445;&#23432;&#39118;&#38505;&#65292;&#38500;&#20102;&#22312;&#23545;&#25239;&#24615;&#26696;&#20363;&#20013;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#36824;&#21487;&#20197;&#36890;&#36807;&#23545;Conformal Prediction&#31639;&#27861;&#36827;&#34892;&#26377;&#30028;&#23610;&#23544;&#30340;&#22122;&#22768;&#20462;&#27491;&#65292;&#20197;&#30830;&#20445;&#23454;&#29616;&#27491;&#30830;&#30340;&#30495;&#23454;&#26631;&#31614;&#39118;&#38505;&#65292;&#32780;&#26080;&#38656;&#32771;&#34385;&#20998;&#25968;&#25110;&#25968;&#25454;&#30340;&#35268;&#21017;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the robustness of conformal prediction, a powerful tool for uncertainty quantification, to label noise. Our analysis tackles both regression and classification problems, characterizing when and how it is possible to construct uncertainty sets that correctly cover the unobserved noiseless ground truth labels. We further extend our theory and formulate the requirements for correctly controlling a general loss function, such as the false negative proportion, with noisy labels. Our theory and experiments suggest that conformal prediction and risk-controlling techniques with noisy labels attain conservative risk over the clean ground truth labels except in adversarial cases. In such cases, we can also correct for noise of bounded size in the conformal prediction algorithm in order to ensure achieving the correct risk of the ground truth labels without score or data regularity.
&lt;/p&gt;</description></item></channel></rss>