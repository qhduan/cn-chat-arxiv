<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#20171;&#32461;&#20102;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#20989;&#25968;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19981;&#20381;&#36182;&#20110;&#24378;&#20984;&#20551;&#35774;&#30340;&#26041;&#27861;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#20202;&#34920;&#22238;&#24402;&#21644;&#24378;&#21270;&#23398;&#20064;&#20219;&#21153;&#20013;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#30340;&#20248;&#21183;&#12290;</title><link>https://arxiv.org/abs/2403.20233</link><description>&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#20989;&#25968;&#21452;&#23618;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Functional Bilevel Optimization for Machine Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.20233
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#20989;&#25968;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19981;&#20381;&#36182;&#20110;&#24378;&#20984;&#20551;&#35774;&#30340;&#26041;&#27861;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#20202;&#34920;&#22238;&#24402;&#21644;&#24378;&#21270;&#23398;&#20064;&#20219;&#21153;&#20013;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#38024;&#23545;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#30340;&#19968;&#31181;&#26032;&#30340;&#20989;&#25968;&#35270;&#35282;&#65292;&#20854;&#20013;&#20869;&#37096;&#30446;&#26631;&#22312;&#20989;&#25968;&#31354;&#38388;&#19978;&#34987;&#26368;&#23567;&#21270;&#12290;&#36825;&#20123;&#31867;&#22411;&#30340;&#38382;&#39064;&#36890;&#24120;&#36890;&#36807;&#22312;&#21442;&#25968;&#35774;&#32622;&#19979;&#24320;&#21457;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#65292;&#20854;&#20013;&#20869;&#37096;&#30446;&#26631;&#23545;&#20110;&#39044;&#27979;&#20989;&#25968;&#30340;&#21442;&#25968;&#24378;&#20984;&#12290;&#20989;&#25968;&#35270;&#35282;&#19981;&#20381;&#36182;&#20110;&#27492;&#20551;&#35774;&#65292;&#29305;&#21035;&#20801;&#35768;&#20351;&#29992;&#36229;&#21442;&#25968;&#21270;&#30340;&#31070;&#32463;&#32593;&#32476;&#20316;&#20026;&#20869;&#37096;&#39044;&#27979;&#20989;&#25968;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#21487;&#25193;&#23637;&#21644;&#39640;&#25928;&#30340;&#31639;&#27861;&#26469;&#35299;&#20915;&#20989;&#25968;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#22312;&#36866;&#21512;&#33258;&#28982;&#20989;&#25968;&#21452;&#23618;&#32467;&#26500;&#30340;&#20202;&#34920;&#22238;&#24402;&#21644;&#24378;&#21270;&#23398;&#20064;&#20219;&#21153;&#19978;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.20233v1 Announce Type: cross  Abstract: In this paper, we introduce a new functional point of view on bilevel optimization problems for machine learning, where the inner objective is minimized over a function space. These types of problems are most often solved by using methods developed in the parametric setting, where the inner objective is strongly convex with respect to the parameters of the prediction function. The functional point of view does not rely on this assumption and notably allows using over-parameterized neural networks as the inner prediction function. We propose scalable and efficient algorithms for the functional bilevel optimization problem and illustrate the benefits of our approach on instrumental regression and reinforcement learning tasks, which admit natural functional bilevel structures.
&lt;/p&gt;</description></item><item><title>&#22312;&#26410;&#35266;&#27979;&#28151;&#26434;&#22240;&#32032;&#30340;&#24773;&#20917;&#19979;&#65292;&#26412;&#25991;&#23637;&#31034;&#20102;&#21363;&#20351;&#22312;&#25918;&#23485;&#25110;&#29978;&#33267;&#22312;&#25490;&#38500;&#25152;&#26377;&#30456;&#20851;&#39118;&#38505;&#22240;&#32032;&#34987;&#35266;&#27979;&#21040;&#30340;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;&#20173;&#28982;&#21487;&#20197;&#32473;&#20986;&#23545;&#39640;&#39118;&#38505;&#20010;&#20307;&#20998;&#37197;&#29575;&#30340;&#20449;&#24687;&#20016;&#23500;&#30340;&#30028;&#38480;&#12290;</title><link>https://arxiv.org/abs/2403.14713</link><description>&lt;p&gt;
&#22312;&#26410;&#35266;&#27979;&#28151;&#26434;&#22240;&#32032;&#19979;&#23457;&#35745;&#20844;&#24179;&#24615;
&lt;/p&gt;
&lt;p&gt;
Auditing Fairness under Unobserved Confounding
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.14713
&lt;/p&gt;
&lt;p&gt;
&#22312;&#26410;&#35266;&#27979;&#28151;&#26434;&#22240;&#32032;&#30340;&#24773;&#20917;&#19979;&#65292;&#26412;&#25991;&#23637;&#31034;&#20102;&#21363;&#20351;&#22312;&#25918;&#23485;&#25110;&#29978;&#33267;&#22312;&#25490;&#38500;&#25152;&#26377;&#30456;&#20851;&#39118;&#38505;&#22240;&#32032;&#34987;&#35266;&#27979;&#21040;&#30340;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;&#20173;&#28982;&#21487;&#20197;&#32473;&#20986;&#23545;&#39640;&#39118;&#38505;&#20010;&#20307;&#20998;&#37197;&#29575;&#30340;&#20449;&#24687;&#20016;&#23500;&#30340;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20915;&#31574;&#31995;&#32479;&#20013;&#30340;&#19968;&#20010;&#22522;&#26412;&#38382;&#39064;&#26159;&#36328;&#36234;&#20154;&#21475;&#32479;&#35745;&#32447;&#23384;&#22312;&#19981;&#20844;&#24179;&#24615;&#12290;&#28982;&#32780;&#65292;&#19981;&#20844;&#24179;&#24615;&#21487;&#33021;&#38590;&#20197;&#37327;&#21270;&#65292;&#29305;&#21035;&#26159;&#22914;&#26524;&#25105;&#20204;&#23545;&#20844;&#24179;&#24615;&#30340;&#29702;&#35299;&#20381;&#36182;&#20110;&#38590;&#20197;&#34913;&#37327;&#30340;&#39118;&#38505;&#31561;&#35266;&#24565;&#65288;&#20363;&#22914;&#65292;&#23545;&#20110;&#37027;&#20123;&#27809;&#26377;&#20854;&#27835;&#30103;&#23601;&#20250;&#27515;&#20129;&#30340;&#20154;&#24179;&#31561;&#33719;&#24471;&#27835;&#30103;&#65289;&#12290;&#23457;&#35745;&#36825;&#31181;&#19981;&#20844;&#24179;&#24615;&#38656;&#35201;&#20934;&#30830;&#27979;&#37327;&#20010;&#20307;&#39118;&#38505;&#65292;&#32780;&#22312;&#26410;&#35266;&#27979;&#28151;&#26434;&#30340;&#29616;&#23454;&#29615;&#22659;&#20013;&#65292;&#38590;&#20197;&#20272;&#35745;&#12290;&#22312;&#36825;&#20123;&#26410;&#35266;&#27979;&#21040;&#30340;&#22240;&#32032;&#8220;&#35299;&#37322;&#8221;&#26126;&#26174;&#24046;&#24322;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#21487;&#33021;&#20302;&#20272;&#25110;&#39640;&#20272;&#19981;&#20844;&#24179;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#21363;&#20351;&#22312;&#25918;&#23485;&#25110;&#65288;&#20196;&#20154;&#24778;&#35766;&#22320;&#65289;&#29978;&#33267;&#22312;&#25490;&#38500;&#25152;&#26377;&#30456;&#20851;&#39118;&#38505;&#22240;&#32032;&#34987;&#35266;&#27979;&#21040;&#30340;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;&#20173;&#28982;&#21487;&#20197;&#23545;&#39640;&#39118;&#38505;&#20010;&#20307;&#30340;&#20998;&#37197;&#29575;&#32473;&#20986;&#20449;&#24687;&#20016;&#23500;&#30340;&#30028;&#38480;&#12290;&#25105;&#20204;&#21033;&#29992;&#20102;&#22312;&#35768;&#22810;&#23454;&#38469;&#29615;&#22659;&#20013;&#65288;&#20363;&#22914;&#24341;&#20837;&#26032;&#22411;&#27835;&#30103;&#65289;&#25105;&#20204;&#25317;&#26377;&#22312;&#20219;&#20309;&#20998;&#37197;&#20043;&#21069;&#30340;&#25968;&#25454;&#30340;&#20107;&#23454;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.14713v1 Announce Type: cross  Abstract: A fundamental problem in decision-making systems is the presence of inequity across demographic lines. However, inequity can be difficult to quantify, particularly if our notion of equity relies on hard-to-measure notions like risk (e.g., equal access to treatment for those who would die without it). Auditing such inequity requires accurate measurements of individual risk, which is difficult to estimate in the realistic setting of unobserved confounding. In the case that these unobservables "explain" an apparent disparity, we may understate or overstate inequity. In this paper, we show that one can still give informative bounds on allocation rates among high-risk individuals, even while relaxing or (surprisingly) even when eliminating the assumption that all relevant risk factors are observed. We utilize the fact that in many real-world settings (e.g., the introduction of a novel treatment) we have data from a period prior to any alloc
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#35757;&#32451;&#28145;&#24230;&#40784;&#27425;&#31070;&#32463;&#32593;&#32476;&#26102;&#26799;&#24230;&#27969;&#21160;&#21147;&#23398;&#30340;&#21160;&#24577;&#24615;&#65292;&#21457;&#29616;&#22312;&#36275;&#22815;&#23567;&#30340;&#21021;&#22987;&#21270;&#19979;&#65292;&#31070;&#32463;&#32593;&#32476;&#30340;&#26435;&#37325;&#22312;&#35757;&#32451;&#26089;&#26399;&#38454;&#27573;&#20445;&#25345;&#36739;&#23567;&#35268;&#33539;&#65292;&#24182;&#19988;&#27839;&#30528;&#31070;&#32463;&#30456;&#20851;&#20989;&#25968;&#30340;KKT&#28857;&#26041;&#21521;&#36817;&#20284;&#25910;&#25947;&#12290;</title><link>https://arxiv.org/abs/2403.08121</link><description>&lt;p&gt;
&#26089;&#26399;&#26041;&#21521;&#24615;&#25910;&#25947;&#22312;&#28145;&#24230;&#40784;&#27425;&#31070;&#32463;&#32593;&#32476;&#20013;&#36827;&#34892;&#23567;&#21021;&#22987;&#21270;&#26102;&#30340;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Early Directional Convergence in Deep Homogeneous Neural Networks for Small Initializations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.08121
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#35757;&#32451;&#28145;&#24230;&#40784;&#27425;&#31070;&#32463;&#32593;&#32476;&#26102;&#26799;&#24230;&#27969;&#21160;&#21147;&#23398;&#30340;&#21160;&#24577;&#24615;&#65292;&#21457;&#29616;&#22312;&#36275;&#22815;&#23567;&#30340;&#21021;&#22987;&#21270;&#19979;&#65292;&#31070;&#32463;&#32593;&#32476;&#30340;&#26435;&#37325;&#22312;&#35757;&#32451;&#26089;&#26399;&#38454;&#27573;&#20445;&#25345;&#36739;&#23567;&#35268;&#33539;&#65292;&#24182;&#19988;&#27839;&#30528;&#31070;&#32463;&#30456;&#20851;&#20989;&#25968;&#30340;KKT&#28857;&#26041;&#21521;&#36817;&#20284;&#25910;&#25947;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#35757;&#32451;&#28145;&#24230;&#40784;&#27425;&#31070;&#32463;&#32593;&#32476;&#26102;&#26799;&#24230;&#27969;&#21160;&#21147;&#23398;&#30340;&#21160;&#24577;&#24615;&#65292;&#36825;&#20123;&#32593;&#32476;&#20174;&#23567;&#21021;&#22987;&#21270;&#24320;&#22987;&#12290;&#26412;&#25991;&#32771;&#34385;&#21040;&#20855;&#26377;&#23616;&#37096;Lipschitz&#26799;&#24230;&#21644;&#38454;&#25968;&#20005;&#26684;&#22823;&#20110;&#20004;&#30340;&#31070;&#32463;&#32593;&#32476;&#12290;&#25991;&#31456;&#35777;&#26126;&#20102;&#23545;&#20110;&#36275;&#22815;&#23567;&#30340;&#21021;&#22987;&#21270;&#65292;&#22312;&#35757;&#32451;&#30340;&#26089;&#26399;&#38454;&#27573;&#65292;&#31070;&#32463;&#32593;&#32476;&#30340;&#26435;&#37325;&#20445;&#25345;&#35268;&#33539;&#36739;&#23567;&#65292;&#24182;&#19988;&#22312;Karush-Kuhn-Tucker (KKT)&#28857;&#22788;&#36817;&#20284;&#27839;&#30528;&#31070;&#32463;&#30456;&#20851;&#20989;&#25968;&#30340;&#26041;&#21521;&#25910;&#25947;&#12290;&#27492;&#22806;&#65292;&#23545;&#20110;&#24179;&#26041;&#25439;&#22833;&#24182;&#22312;&#31070;&#32463;&#32593;&#32476;&#26435;&#37325;&#19978;&#36827;&#34892;&#21487;&#20998;&#31163;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;&#36824;&#23637;&#31034;&#20102;&#22312;&#25439;&#22833;&#20989;&#25968;&#30340;&#26576;&#20123;&#38797;&#28857;&#38468;&#36817;&#26799;&#24230;&#27969;&#21160;&#21160;&#24577;&#30340;&#31867;&#20284;&#26041;&#21521;&#24615;&#25910;&#25947;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.08121v1 Announce Type: new  Abstract: This paper studies the gradient flow dynamics that arise when training deep homogeneous neural networks, starting with small initializations. The present work considers neural networks that are assumed to have locally Lipschitz gradients and an order of homogeneity strictly greater than two. This paper demonstrates that for sufficiently small initializations, during the early stages of training, the weights of the neural network remain small in norm and approximately converge in direction along the Karush-Kuhn-Tucker (KKT) points of the neural correlation function introduced in [1]. Additionally, for square loss and under a separability assumption on the weights of neural networks, a similar directional convergence of gradient flow dynamics is shown near certain saddle points of the loss function.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;RNNs&#21644;Transformer&#22312;&#22788;&#29702;&#31639;&#27861;&#38382;&#39064;&#26102;&#30340;&#34920;&#29616;&#33021;&#21147;&#24046;&#36317;&#65292;&#21457;&#29616;RNNs&#23384;&#22312;&#20851;&#38190;&#29942;&#39048;&#65292;&#21363;&#26080;&#27861;&#23436;&#32654;&#22320;&#20174;&#19978;&#19979;&#25991;&#20013;&#26816;&#32034;&#20449;&#24687;&#65292;&#23548;&#33268;&#26080;&#27861;&#20687;Transformer&#37027;&#26679;&#36731;&#26494;&#35299;&#20915;&#38656;&#35201;&#36825;&#31181;&#33021;&#21147;&#30340;&#20219;&#21153;&#12290;</title><link>https://arxiv.org/abs/2402.18510</link><description>&lt;p&gt;
RNNs&#36824;&#19981;&#26159;Transformer&#65306;&#22312;&#19978;&#19979;&#25991;&#26816;&#32034;&#20013;&#30340;&#20851;&#38190;&#29942;&#39048;
&lt;/p&gt;
&lt;p&gt;
RNNs are not Transformers (Yet): The Key Bottleneck on In-context Retrieval
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.18510
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;RNNs&#21644;Transformer&#22312;&#22788;&#29702;&#31639;&#27861;&#38382;&#39064;&#26102;&#30340;&#34920;&#29616;&#33021;&#21147;&#24046;&#36317;&#65292;&#21457;&#29616;RNNs&#23384;&#22312;&#20851;&#38190;&#29942;&#39048;&#65292;&#21363;&#26080;&#27861;&#23436;&#32654;&#22320;&#20174;&#19978;&#19979;&#25991;&#20013;&#26816;&#32034;&#20449;&#24687;&#65292;&#23548;&#33268;&#26080;&#27861;&#20687;Transformer&#37027;&#26679;&#36731;&#26494;&#35299;&#20915;&#38656;&#35201;&#36825;&#31181;&#33021;&#21147;&#30340;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#65288;RNNs&#65289;&#21644;Transformer&#22312;&#35299;&#20915;&#31639;&#27861;&#38382;&#39064;&#26102;&#30340;&#34920;&#31034;&#33021;&#21147;&#24046;&#36317;&#12290;&#25105;&#20204;&#37325;&#28857;&#20851;&#27880;RNNs&#26159;&#21542;&#33021;&#22312;&#22788;&#29702;&#38271;&#24207;&#21015;&#26102;&#65292;&#36890;&#36807;Chain-of-Thought (CoT)&#25552;&#31034;&#65292;&#19982;Transformer&#30340;&#24615;&#33021;&#30456;&#21305;&#37197;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#20998;&#26512;&#26174;&#31034;CoT&#21487;&#20197;&#25913;&#36827;RNNs&#65292;&#20294;&#26080;&#27861;&#24357;&#34917;&#19982;Transformer&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;&#20851;&#38190;&#29942;&#39048;&#22312;&#20110;RNNs&#26080;&#27861;&#23436;&#20840;&#20174;&#19978;&#19979;&#25991;&#20013;&#26816;&#32034;&#20449;&#24687;&#65292;&#21363;&#20351;&#32463;&#36807;CoT&#30340;&#22686;&#24378;&#65306;&#23545;&#20110;&#20960;&#20010;&#26126;&#30830;&#25110;&#38544;&#24335;&#38656;&#35201;&#36825;&#31181;&#33021;&#21147;&#30340;&#20219;&#21153;&#65292;&#22914;&#32852;&#24819;&#21484;&#22238;&#21644;&#30830;&#23450;&#22270;&#26159;&#21542;&#20026;&#26641;&#65292;&#25105;&#20204;&#35777;&#26126;RNNs&#34920;&#36798;&#33021;&#21147;&#19981;&#36275;&#20197;&#35299;&#20915;&#36825;&#20123;&#20219;&#21153;&#65292;&#32780;Transformer&#21487;&#20197;&#36731;&#26494;&#35299;&#20915;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#35777;&#26126;&#37319;&#29992;&#22686;&#24378;RNNs&#19978;&#19979;&#25991;&#26816;&#32034;&#33021;&#21147;&#30340;&#25216;&#26415;&#65292;&#21253;&#25324;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18510v1 Announce Type: cross  Abstract: This paper investigates the gap in representation powers of Recurrent Neural Networks (RNNs) and Transformers in the context of solving algorithmic problems. We focus on understanding whether RNNs, known for their memory efficiency in handling long sequences, can match the performance of Transformers, particularly when enhanced with Chain-of-Thought (CoT) prompting. Our theoretical analysis reveals that CoT improves RNNs but is insufficient to close the gap with Transformers. A key bottleneck lies in the inability of RNNs to perfectly retrieve information from the context, even with CoT: for several tasks that explicitly or implicitly require this capability, such as associative recall and determining if a graph is a tree, we prove that RNNs are not expressive enough to solve the tasks while Transformers can solve them with ease. Conversely, we prove that adopting techniques to enhance the in-context retrieval capability of RNNs, inclu
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#23558;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#21644;&#22522;&#30784;&#27169;&#22411;&#30456;&#32467;&#21512;&#65292;&#30740;&#31350;&#20102;&#22914;&#20309;&#20174;&#25968;&#25454;&#20013;&#23398;&#20064;&#20154;&#31867;&#21487;&#35299;&#37322;&#30340;&#27010;&#24565;&#12290;&#23454;&#39564;&#35777;&#26126;&#20102;&#36825;&#19968;&#32479;&#19968;&#26041;&#27861;&#30340;&#23454;&#29992;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.09236</link><description>&lt;p&gt;
&#23398;&#20064;&#21487;&#35299;&#37322;&#27010;&#24565;&#65306;&#32479;&#19968;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#19982;&#22522;&#30784;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Learning Interpretable Concepts: Unifying Causal Representation Learning and Foundation Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09236
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23558;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#21644;&#22522;&#30784;&#27169;&#22411;&#30456;&#32467;&#21512;&#65292;&#30740;&#31350;&#20102;&#22914;&#20309;&#20174;&#25968;&#25454;&#20013;&#23398;&#20064;&#20154;&#31867;&#21487;&#35299;&#37322;&#30340;&#27010;&#24565;&#12290;&#23454;&#39564;&#35777;&#26126;&#20102;&#36825;&#19968;&#32479;&#19968;&#26041;&#27861;&#30340;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26500;&#24314;&#26234;&#33021;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#26377;&#20004;&#31181;&#24191;&#27867;&#30340;&#26041;&#27861;&#12290;&#19968;&#31181;&#26041;&#27861;&#26159;&#26500;&#24314;&#22825;&#29983;&#21487;&#35299;&#37322;&#30340;&#27169;&#22411;&#65292;&#36825;&#26159;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#39046;&#22495;&#30340;&#21162;&#21147;&#26041;&#21521;&#12290;&#21478;&#19968;&#31181;&#26041;&#27861;&#26159;&#26500;&#24314;&#39640;&#24615;&#33021;&#30340;&#22522;&#30784;&#27169;&#22411;&#65292;&#28982;&#21518;&#25237;&#20837;&#21162;&#21147;&#21435;&#29702;&#35299;&#23427;&#20204;&#30340;&#24037;&#20316;&#21407;&#29702;&#12290;&#26412;&#30740;&#31350;&#23558;&#36825;&#20004;&#31181;&#26041;&#27861;&#32852;&#31995;&#36215;&#26469;&#65292;&#30740;&#31350;&#22914;&#20309;&#20174;&#25968;&#25454;&#20013;&#23398;&#20064;&#20154;&#31867;&#21487;&#35299;&#37322;&#30340;&#27010;&#24565;&#12290;&#36890;&#36807;&#32467;&#21512;&#36825;&#20004;&#20010;&#39046;&#22495;&#30340;&#24605;&#24819;&#65292;&#25105;&#20204;&#27491;&#24335;&#23450;&#20041;&#20102;&#27010;&#24565;&#30340;&#27010;&#24565;&#65292;&#24182;&#23637;&#31034;&#20102;&#23427;&#20204;&#21487;&#20197;&#20174;&#22810;&#26679;&#30340;&#25968;&#25454;&#20013;&#34987;&#21487;&#38752;&#22320;&#24674;&#22797;&#20986;&#26469;&#12290;&#23545;&#20110;&#21512;&#25104;&#25968;&#25454;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#32479;&#19968;&#26041;&#27861;&#30340;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09236v1 Announce Type: cross Abstract: To build intelligent machine learning systems, there are two broad approaches. One approach is to build inherently interpretable models, as endeavored by the growing field of causal representation learning. The other approach is to build highly-performant foundation models and then invest efforts into understanding how they work. In this work, we relate these two approaches and study how to learn human-interpretable concepts from data. Weaving together ideas from both fields, we formally define a notion of concepts and show that they can be provably recovered from diverse data. Experiments on synthetic data and large language models show the utility of our unified approach.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31867;$\ell_0$&#27491;&#21017;&#21270;&#38382;&#39064;&#30340;&#23545;&#20598;&#24418;&#24335;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#21407;&#23545;&#20598;&#31639;&#27861;&#65292;&#36890;&#36807;&#20805;&#20998;&#21033;&#29992;&#23545;&#20598;&#33539;&#22260;&#20272;&#35745;&#21644;&#22686;&#37327;&#31574;&#30053;&#65292;&#25552;&#39640;&#20102;&#26368;&#20339;&#23376;&#38598;&#36873;&#25321;&#38382;&#39064;&#30340;&#35299;&#20915;&#26041;&#26696;&#30340;&#25928;&#29575;&#21644;&#32479;&#35745;&#24615;&#36136;&#12290;</title><link>https://arxiv.org/abs/2402.02322</link><description>&lt;p&gt;
&#21160;&#24577;&#22686;&#37327;&#20248;&#21270;&#29992;&#20110;&#26368;&#20339;&#23376;&#38598;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
Dynamic Incremental Optimization for Best Subset Selection
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02322
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31867;$\ell_0$&#27491;&#21017;&#21270;&#38382;&#39064;&#30340;&#23545;&#20598;&#24418;&#24335;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#21407;&#23545;&#20598;&#31639;&#27861;&#65292;&#36890;&#36807;&#20805;&#20998;&#21033;&#29992;&#23545;&#20598;&#33539;&#22260;&#20272;&#35745;&#21644;&#22686;&#37327;&#31574;&#30053;&#65292;&#25552;&#39640;&#20102;&#26368;&#20339;&#23376;&#38598;&#36873;&#25321;&#38382;&#39064;&#30340;&#35299;&#20915;&#26041;&#26696;&#30340;&#25928;&#29575;&#21644;&#32479;&#35745;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#20339;&#23376;&#38598;&#36873;&#25321;&#34987;&#35748;&#20026;&#26159;&#31232;&#30095;&#23398;&#20064;&#38382;&#39064;&#30340;&#8220;&#40644;&#37329;&#26631;&#20934;&#8221;&#12290;&#24050;&#32463;&#25552;&#20986;&#20102;&#21508;&#31181;&#20248;&#21270;&#25216;&#26415;&#26469;&#25915;&#20987;&#36825;&#20010;&#38750;&#20809;&#28369;&#38750;&#20984;&#38382;&#39064;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31867;$\ell_0$&#27491;&#21017;&#21270;&#38382;&#39064;&#30340;&#23545;&#20598;&#24418;&#24335;&#12290;&#22522;&#20110;&#21407;&#22987;&#38382;&#39064;&#21644;&#23545;&#20598;&#38382;&#39064;&#30340;&#32467;&#26500;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#21407;&#23545;&#20598;&#31639;&#27861;&#12290;&#36890;&#36807;&#20805;&#20998;&#21033;&#29992;&#23545;&#20598;&#33539;&#22260;&#20272;&#35745;&#21644;&#22686;&#37327;&#31574;&#30053;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#28508;&#22312;&#22320;&#20943;&#23569;&#20102;&#20887;&#20313;&#35745;&#31639;&#24182;&#25913;&#36827;&#20102;&#26368;&#20339;&#23376;&#38598;&#36873;&#25321;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#29702;&#35770;&#20998;&#26512;&#21644;&#23545;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#30340;&#23454;&#39564;&#39564;&#35777;&#20102;&#25152;&#25552;&#20986;&#35299;&#20915;&#26041;&#26696;&#30340;&#25928;&#29575;&#21644;&#32479;&#35745;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;
Best subset selection is considered the `gold standard' for many sparse learning problems. A variety of optimization techniques have been proposed to attack this non-smooth non-convex problem. In this paper, we investigate the dual forms of a family of $\ell_0$-regularized problems. An efficient primal-dual algorithm is developed based on the primal and dual problem structures. By leveraging the dual range estimation along with the incremental strategy, our algorithm potentially reduces redundant computation and improves the solutions of best subset selection. Theoretical analysis and experiments on synthetic and real-world datasets validate the efficiency and statistical properties of the proposed solutions.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#28789;&#27963;&#30340;&#36125;&#21494;&#26031;g&#24418;&#24335;&#20272;&#35745;&#22120;&#65292;&#29992;&#20110;&#20855;&#26377;&#26102;&#21464;&#28151;&#26434;&#30340;&#22240;&#26524;&#29983;&#23384;&#20998;&#26512;&#12290;&#23427;&#37319;&#29992;&#36125;&#21494;&#26031;&#38468;&#21152;&#22238;&#24402;&#26641;&#26469;&#27169;&#25311;&#26102;&#21464;&#29983;&#25104;&#32452;&#20214;&#65292;&#24182;&#24341;&#20837;&#20102;&#32437;&#21521;&#24179;&#34913;&#20998;&#25968;&#20197;&#38477;&#20302;&#27169;&#22411;&#38169;&#35823;&#35268;&#33539;&#24341;&#36215;&#30340;&#20559;&#24046;&#12290;</title><link>https://arxiv.org/abs/2402.02306</link><description>&lt;p&gt;
&#24377;&#24615;&#36125;&#21494;&#26031;g&#24418;&#24335;&#22312;&#20855;&#26377;&#26102;&#21464;&#28151;&#26434;&#30340;&#22240;&#26524;&#29983;&#23384;&#20998;&#26512;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
A flexible Bayesian g-formula for causal survival analyses with time-dependent confounding
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02306
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#28789;&#27963;&#30340;&#36125;&#21494;&#26031;g&#24418;&#24335;&#20272;&#35745;&#22120;&#65292;&#29992;&#20110;&#20855;&#26377;&#26102;&#21464;&#28151;&#26434;&#30340;&#22240;&#26524;&#29983;&#23384;&#20998;&#26512;&#12290;&#23427;&#37319;&#29992;&#36125;&#21494;&#26031;&#38468;&#21152;&#22238;&#24402;&#26641;&#26469;&#27169;&#25311;&#26102;&#21464;&#29983;&#25104;&#32452;&#20214;&#65292;&#24182;&#24341;&#20837;&#20102;&#32437;&#21521;&#24179;&#34913;&#20998;&#25968;&#20197;&#38477;&#20302;&#27169;&#22411;&#38169;&#35823;&#35268;&#33539;&#24341;&#36215;&#30340;&#20559;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20855;&#26377;&#26102;&#38388;&#33267;&#20107;&#20214;&#32467;&#26524;&#30340;&#32437;&#21521;&#35266;&#23519;&#24615;&#30740;&#31350;&#20013;&#65292;&#22240;&#26524;&#20998;&#26512;&#30340;&#24120;&#35265;&#30446;&#26631;&#26159;&#22312;&#30740;&#31350;&#32676;&#20307;&#20013;&#20272;&#35745;&#22312;&#20551;&#35774;&#24178;&#39044;&#24773;&#26223;&#19979;&#30340;&#22240;&#26524;&#29983;&#23384;&#26354;&#32447;&#12290;g&#24418;&#24335;&#26159;&#36825;&#31181;&#20998;&#26512;&#30340;&#19968;&#20010;&#29305;&#21035;&#26377;&#29992;&#30340;&#24037;&#20855;&#12290;&#20026;&#20102;&#22686;&#24378;&#20256;&#32479;&#30340;&#21442;&#25968;&#21270;g&#24418;&#24335;&#26041;&#27861;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26356;&#28789;&#27963;&#30340;&#36125;&#21494;&#26031;g&#24418;&#24335;&#20272;&#35745;&#22120;&#12290;&#35813;&#20272;&#35745;&#22120;&#21516;&#26102;&#25903;&#25345;&#32437;&#21521;&#39044;&#27979;&#21644;&#22240;&#26524;&#25512;&#26029;&#12290;&#23427;&#22312;&#27169;&#25311;&#26102;&#21464;&#29983;&#25104;&#32452;&#20214;&#30340;&#24314;&#27169;&#20013;&#24341;&#20837;&#20102;&#36125;&#21494;&#26031;&#38468;&#21152;&#22238;&#24402;&#26641;&#65292;&#26088;&#22312;&#20943;&#36731;&#30001;&#20110;&#27169;&#22411;&#38169;&#35823;&#35268;&#33539;&#36896;&#25104;&#30340;&#20559;&#24046;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31867;&#26356;&#36890;&#29992;&#30340;&#31163;&#25955;&#29983;&#23384;&#25968;&#25454;g&#24418;&#24335;&#12290;&#36825;&#20123;&#20844;&#24335;&#21487;&#20197;&#24341;&#20837;&#32437;&#21521;&#24179;&#34913;&#20998;&#25968;&#65292;&#36825;&#22312;&#22788;&#29702;&#36234;&#26469;&#36234;&#22810;&#30340;&#26102;&#21464;&#28151;&#26434;&#22240;&#32032;&#26102;&#26159;&#19968;&#31181;&#26377;&#25928;&#30340;&#38477;&#32500;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In longitudinal observational studies with a time-to-event outcome, a common objective in causal analysis is to estimate the causal survival curve under hypothetical intervention scenarios within the study cohort. The g-formula is a particularly useful tool for this analysis. To enhance the traditional parametric g-formula approach, we developed a more adaptable Bayesian g-formula estimator. This estimator facilitates both longitudinal predictive and causal inference. It incorporates Bayesian additive regression trees in the modeling of the time-evolving generative components, aiming to mitigate bias due to model misspecification. Specifically, we introduce a more general class of g-formulas for discrete survival data. These formulas can incorporate the longitudinal balancing scores, which serve as an effective method for dimension reduction and are vital when dealing with an expanding array of time-varying confounders. The minimum sufficient formulation of these longitudinal balancing
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;PAC-Bayes&#30028;&#38480;&#65292;&#33021;&#22815;&#21516;&#26102;&#25511;&#21046;&#22810;&#20010;&#38169;&#35823;&#65292;&#24182;&#25552;&#20379;&#20016;&#23500;&#30340;&#20449;&#24687;&#65292;&#36866;&#29992;&#20110;&#22238;&#24402;&#20013;&#27979;&#35797;&#25439;&#22833;&#20998;&#24067;&#25110;&#20998;&#31867;&#20013;&#19981;&#21516;&#38169;&#35823;&#20998;&#31867;&#30340;&#27010;&#29575;&#12290;</title><link>https://arxiv.org/abs/2202.05560</link><description>&lt;p&gt;
&#20351;&#29992;PAC-Bayes&#30028;&#38480;&#21516;&#26102;&#25511;&#21046;&#22810;&#20010;&#38169;&#35823;
&lt;/p&gt;
&lt;p&gt;
Controlling Multiple Errors Simultaneously with a PAC-Bayes Bound
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2202.05560
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;PAC-Bayes&#30028;&#38480;&#65292;&#33021;&#22815;&#21516;&#26102;&#25511;&#21046;&#22810;&#20010;&#38169;&#35823;&#65292;&#24182;&#25552;&#20379;&#20016;&#23500;&#30340;&#20449;&#24687;&#65292;&#36866;&#29992;&#20110;&#22238;&#24402;&#20013;&#27979;&#35797;&#25439;&#22833;&#20998;&#24067;&#25110;&#20998;&#31867;&#20013;&#19981;&#21516;&#38169;&#35823;&#20998;&#31867;&#30340;&#27010;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#21069;&#30340;PAC-Bayes&#27867;&#21270;&#30028;&#38480;&#20165;&#38480;&#20110;&#24615;&#33021;&#30340;&#26631;&#37327;&#24230;&#37327;&#65292;&#22914;&#25439;&#22833;&#25110;&#38169;&#35823;&#29575;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#31532;&#19968;&#20010;&#33021;&#22815;&#25552;&#20379;&#20016;&#23500;&#20449;&#24687;&#30340;PAC-Bayes&#30028;&#38480;&#65292;&#36890;&#36807;&#30028;&#23450;&#19968;&#32452;M&#31181;&#38169;&#35823;&#31867;&#22411;&#30340;&#32463;&#39564;&#27010;&#29575;&#19982;&#30495;&#23454;&#27010;&#29575;&#20043;&#38388;&#30340;Kullback-Leibler&#24046;&#24322;&#26469;&#25511;&#21046;&#21487;&#33021;&#32467;&#26524;&#30340;&#25972;&#20010;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2202.05560v2 Announce Type: replace-cross  Abstract: Current PAC-Bayes generalisation bounds are restricted to scalar metrics of performance, such as the loss or error rate. However, one ideally wants more information-rich certificates that control the entire distribution of possible outcomes, such as the distribution of the test loss in regression, or the probabilities of different mis classifications. We provide the first PAC-Bayes bound capable of providing such rich information by bounding the Kullback-Leibler divergence between the empirical and true probabilities of a set of M error types, which can either be discretized loss values for regression, or the elements of the confusion matrix (or a partition thereof) for classification. We transform our bound into a differentiable training objective. Our bound is especially useful in cases where the severity of different mis-classifications may change over time; existing PAC-Bayes bounds can only bound a particular pre-decided w
&lt;/p&gt;</description></item><item><title>&#23545;&#20110;&#24490;&#29615;&#27169;&#22411;&#20013;&#21547;&#26377;&#38544;&#34255;&#22240;&#21464;&#37327;&#30340;&#22240;&#26524;&#21457;&#29616;&#65292;&#24050;&#32463;&#20986;&#29616;&#20102;&#33021;&#22815;&#22788;&#29702;&#36825;&#31181;&#24773;&#20917;&#30340;&#22810;&#31181;&#25216;&#26415;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2401.13009</link><description>&lt;p&gt;
&#24490;&#29615;&#27169;&#22411;&#20013;&#21547;&#26377;&#38544;&#34255;&#22240;&#21464;&#37327;&#30340;&#22240;&#26524;&#21457;&#29616;&#26041;&#27861;&#30340;&#27604;&#36739;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Comparative Study of Causal Discovery Methods for Cyclic Models with Hidden Confounders. (arXiv:2401.13009v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13009
&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#24490;&#29615;&#27169;&#22411;&#20013;&#21547;&#26377;&#38544;&#34255;&#22240;&#21464;&#37327;&#30340;&#22240;&#26524;&#21457;&#29616;&#65292;&#24050;&#32463;&#20986;&#29616;&#20102;&#33021;&#22815;&#22788;&#29702;&#36825;&#31181;&#24773;&#20917;&#30340;&#22810;&#31181;&#25216;&#26415;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22914;&#20170;&#65292;&#23545;&#22240;&#26524;&#21457;&#29616;&#30340;&#38656;&#27714;&#26080;&#22788;&#19981;&#22312;&#12290;&#29702;&#35299;&#31995;&#32479;&#20013;&#37096;&#20998;&#20043;&#38388;&#30340;&#38543;&#26426;&#20381;&#36182;&#24615;&#20197;&#21450;&#23454;&#38469;&#30340;&#22240;&#26524;&#20851;&#31995;&#23545;&#31185;&#23398;&#30340;&#21508;&#20010;&#37096;&#20998;&#37117;&#33267;&#20851;&#37325;&#35201;&#12290;&#22240;&#27492;&#65292;&#23547;&#25214;&#21487;&#38752;&#30340;&#26041;&#27861;&#26469;&#26816;&#27979;&#22240;&#26524;&#26041;&#21521;&#30340;&#38656;&#27714;&#19981;&#26029;&#22686;&#38271;&#12290;&#22312;&#36807;&#21435;&#30340;50&#24180;&#37324;&#65292;&#20986;&#29616;&#20102;&#35768;&#22810;&#22240;&#26524;&#21457;&#29616;&#31639;&#27861;&#65292;&#20294;&#22823;&#22810;&#25968;&#20165;&#36866;&#29992;&#20110;&#31995;&#32479;&#27809;&#26377;&#21453;&#39304;&#29615;&#36335;&#24182;&#19988;&#20855;&#26377;&#22240;&#26524;&#20805;&#20998;&#24615;&#30340;&#20551;&#35774;&#65292;&#21363;&#27809;&#26377;&#26410;&#27979;&#37327;&#30340;&#23376;&#31995;&#32479;&#33021;&#22815;&#24433;&#21709;&#22810;&#20010;&#24050;&#27979;&#37327;&#21464;&#37327;&#12290;&#36825;&#26159;&#19981;&#24184;&#30340;&#65292;&#22240;&#20026;&#36825;&#20123;&#38480;&#21046;&#22312;&#23454;&#36341;&#20013;&#24448;&#24448;&#19981;&#33021;&#20551;&#23450;&#12290;&#21453;&#39304;&#26159;&#35768;&#22810;&#36807;&#31243;&#30340;&#19968;&#20010;&#37325;&#35201;&#29305;&#24615;&#65292;&#29616;&#23454;&#19990;&#30028;&#30340;&#31995;&#32479;&#24456;&#23569;&#26159;&#23436;&#20840;&#38548;&#31163;&#21644;&#23436;&#20840;&#27979;&#37327;&#30340;&#12290;&#24184;&#36816;&#30340;&#26159;&#65292;&#22312;&#26368;&#36817;&#20960;&#24180;&#20013;&#65292;&#24050;&#32463;&#21457;&#23637;&#20102;&#20960;&#31181;&#33021;&#22815;&#22788;&#29702;&#24490;&#29615;&#30340;&#12289;&#22240;&#26524;&#19981;&#20805;&#20998;&#30340;&#31995;&#32479;&#30340;&#25216;&#26415;&#12290;&#38543;&#30528;&#22810;&#31181;&#26041;&#27861;&#30340;&#20986;&#29616;&#65292;&#19968;&#31181;&#23454;&#38469;&#30340;&#24212;&#29992;&#26041;&#27861;&#24320;&#22987;&#21464;&#24471;&#21487;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Nowadays, the need for causal discovery is ubiquitous. A better understanding of not just the stochastic dependencies between parts of a system, but also the actual cause-effect relations, is essential for all parts of science. Thus, the need for reliable methods to detect causal directions is growing constantly. In the last 50 years, many causal discovery algorithms have emerged, but most of them are applicable only under the assumption that the systems have no feedback loops and that they are causally sufficient, i.e. that there are no unmeasured subsystems that can affect multiple measured variables. This is unfortunate since those restrictions can often not be presumed in practice. Feedback is an integral feature of many processes, and real-world systems are rarely completely isolated and fully measured. Fortunately, in recent years, several techniques, that can cope with cyclic, causally insufficient systems, have been developed. And with multiple methods available, a practical ap
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#20154;&#24037;&#26234;&#33021;&#25913;&#21892;&#20154;&#31867;&#20915;&#31574;&#30340;&#32479;&#35745;&#26694;&#26550;&#65292;&#36890;&#36807;&#22522;&#20934;&#27979;&#35797;&#19982;&#26426;&#22120;&#39044;&#27979;&#65292;&#26367;&#25442;&#37096;&#20998;&#20154;&#31867;&#20915;&#31574;&#32773;&#30340;&#20915;&#31574;&#21046;&#23450;&#65292;&#24182;&#32463;&#36807;&#23454;&#39564;&#26816;&#39564;&#24471;&#20986;&#31639;&#27861;&#20855;&#26377;&#26356;&#39640;&#30340;&#30495;&#38451;&#24615;&#29575;&#21644;&#26356;&#20302;&#30340;&#20551;&#38451;&#24615;&#29575;&#65292;&#23588;&#20854;&#26159;&#26469;&#33258;&#20892;&#26449;&#22320;&#21306;&#30340;&#21307;&#29983;&#30340;&#35786;&#26029;&#26356;&#23481;&#26131;&#34987;&#26367;&#20195;&#12290;</title><link>http://arxiv.org/abs/2306.11689</link><description>&lt;p&gt;
&#32479;&#35745;&#27979;&#35797;&#26367;&#20195;&#20154;&#31867;&#20915;&#31574;&#32773;&#30340;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Statistical Tests for Replacing Human Decision Makers with Algorithms. (arXiv:2306.11689v1 [econ.EM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11689
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#20154;&#24037;&#26234;&#33021;&#25913;&#21892;&#20154;&#31867;&#20915;&#31574;&#30340;&#32479;&#35745;&#26694;&#26550;&#65292;&#36890;&#36807;&#22522;&#20934;&#27979;&#35797;&#19982;&#26426;&#22120;&#39044;&#27979;&#65292;&#26367;&#25442;&#37096;&#20998;&#20154;&#31867;&#20915;&#31574;&#32773;&#30340;&#20915;&#31574;&#21046;&#23450;&#65292;&#24182;&#32463;&#36807;&#23454;&#39564;&#26816;&#39564;&#24471;&#20986;&#31639;&#27861;&#20855;&#26377;&#26356;&#39640;&#30340;&#30495;&#38451;&#24615;&#29575;&#21644;&#26356;&#20302;&#30340;&#20551;&#38451;&#24615;&#29575;&#65292;&#23588;&#20854;&#26159;&#26469;&#33258;&#20892;&#26449;&#22320;&#21306;&#30340;&#21307;&#29983;&#30340;&#35786;&#26029;&#26356;&#23481;&#26131;&#34987;&#26367;&#20195;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#35745;&#26694;&#26550;&#65292;&#21487;&#20197;&#36890;&#36807;&#20154;&#24037;&#26234;&#33021;&#26469;&#25913;&#21892;&#20154;&#31867;&#30340;&#20915;&#31574;&#12290;&#39318;&#20808;&#23558;&#27599;&#20010;&#20154;&#31867;&#20915;&#31574;&#32773;&#30340;&#34920;&#29616;&#19982;&#26426;&#22120;&#39044;&#27979;&#36827;&#34892;&#22522;&#20934;&#27979;&#35797;&#65307;&#28982;&#21518;&#29992;&#25152;&#25552;&#20986;&#30340;&#20154;&#24037;&#26234;&#33021;&#31639;&#27861;&#30340;&#24314;&#35758;&#26367;&#25442;&#20915;&#31574;&#21046;&#23450;&#32773;&#30340;&#19968;&#20010;&#23376;&#38598;&#25152;&#20570;&#20986;&#30340;&#20915;&#31574;&#12290;&#21033;&#29992;&#20840;&#22269;&#22823;&#22411;&#23381;&#20135;&#32467;&#26524;&#21644;&#32321;&#27542;&#24180;&#40836;&#22827;&#22919;&#23381;&#21069;&#26816;&#26597;&#30340;&#21307;&#29983;&#35786;&#26029;&#25968;&#25454;&#38598;&#65292;&#25105;&#20204;&#35797;&#39564;&#20102;&#19968;&#31181;&#21551;&#21457;&#24335;&#39640;&#39057;&#29575;&#26041;&#27861;&#20197;&#21450;&#19968;&#31181;&#36125;&#21494;&#26031;&#21518;&#39564;&#25439;&#22833;&#20989;&#25968;&#26041;&#27861;&#65292;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;&#24322;&#24120;&#20986;&#29983;&#26816;&#27979;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#19968;&#20010;&#27979;&#35797;&#25968;&#25454;&#38598;&#19978;&#30340;&#32467;&#26524;&#27604;&#20165;&#30001;&#21307;&#29983;&#35786;&#26029;&#30340;&#32467;&#26524;&#20855;&#26377;&#26356;&#39640;&#30340;&#24635;&#20307;&#30495;&#38451;&#24615;&#29575;&#21644;&#26356;&#20302;&#30340;&#20551;&#38451;&#24615;&#29575;&#12290;&#25105;&#20204;&#36824;&#21457;&#29616;&#65292;&#26469;&#33258;&#20892;&#26449;&#22320;&#21306;&#30340;&#21307;&#29983;&#30340;&#35786;&#26029;&#26356;&#23481;&#26131;&#34987;&#26367;&#20195;&#65292;&#36825;&#34920;&#26126;&#20154;&#24037;&#26234;&#33021;&#36741;&#21161;&#20915;&#31574;&#21046;&#23450;&#26356;&#23481;&#26131;&#25552;&#39640;&#31934;&#30830;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a statistical framework with which artificial intelligence can improve human decision making. The performance of each human decision maker is first benchmarked against machine predictions; we then replace the decisions made by a subset of the decision makers with the recommendation from the proposed artificial intelligence algorithm. Using a large nationwide dataset of pregnancy outcomes and doctor diagnoses from prepregnancy checkups of reproductive age couples, we experimented with both a heuristic frequentist approach and a Bayesian posterior loss function approach with an application to abnormal birth detection. We find that our algorithm on a test dataset results in a higher overall true positive rate and a lower false positive rate than the diagnoses made by doctors only. We also find that the diagnoses of doctors from rural areas are more frequently replaceable, suggesting that artificial intelligence assisted decision making tends to improve precision more i
&lt;/p&gt;</description></item></channel></rss>