<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20989;&#25968;&#21487;&#24494;&#26041;&#27861;&#26469;&#35299;&#20915;&#32479;&#35745;&#26368;&#20248;&#20998;&#37197;&#38382;&#39064;&#65292;&#36890;&#36807;&#23545;&#25490;&#24207;&#36816;&#31639;&#31526;&#30340;&#19968;&#33324;&#23646;&#24615;&#36827;&#34892;&#35814;&#32454;&#20998;&#26512;&#65292;&#25512;&#23548;&#20986;&#20540;&#20989;&#25968;&#30340;Hadamard&#21487;&#24494;&#24615;&#65292;&#24182;&#23637;&#31034;&#20102;&#22914;&#20309;&#21033;&#29992;&#20989;&#25968;&#20559;&#24494;&#20998;&#27861;&#30452;&#25509;&#25512;&#23548;&#20986;&#20540;&#20989;&#25968;&#36807;&#31243;&#30340;&#28176;&#36817;&#24615;&#36136;&#12290;</title><link>https://arxiv.org/abs/2403.18248</link><description>&lt;p&gt;
&#32479;&#35745;&#25512;&#26029;&#20013;&#30340;&#26368;&#20248;&#20998;&#37197;I&#65306;&#35268;&#24459;&#24615;&#21450;&#20854;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Statistical Inference of Optimal Allocations I: Regularities and their Implications
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18248
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20989;&#25968;&#21487;&#24494;&#26041;&#27861;&#26469;&#35299;&#20915;&#32479;&#35745;&#26368;&#20248;&#20998;&#37197;&#38382;&#39064;&#65292;&#36890;&#36807;&#23545;&#25490;&#24207;&#36816;&#31639;&#31526;&#30340;&#19968;&#33324;&#23646;&#24615;&#36827;&#34892;&#35814;&#32454;&#20998;&#26512;&#65292;&#25512;&#23548;&#20986;&#20540;&#20989;&#25968;&#30340;Hadamard&#21487;&#24494;&#24615;&#65292;&#24182;&#23637;&#31034;&#20102;&#22914;&#20309;&#21033;&#29992;&#20989;&#25968;&#20559;&#24494;&#20998;&#27861;&#30452;&#25509;&#25512;&#23548;&#20986;&#20540;&#20989;&#25968;&#36807;&#31243;&#30340;&#28176;&#36817;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#35299;&#20915;&#32479;&#35745;&#26368;&#20248;&#20998;&#37197;&#38382;&#39064;&#30340;&#20989;&#25968;&#21487;&#24494;&#26041;&#27861;&#12290;&#36890;&#36807;&#23545;&#25490;&#24207;&#36816;&#31639;&#31526;&#30340;&#19968;&#33324;&#23646;&#24615;&#36827;&#34892;&#35814;&#32454;&#20998;&#26512;&#65292;&#25105;&#20204;&#39318;&#20808;&#25512;&#23548;&#20986;&#20102;&#20540;&#20989;&#25968;&#30340;Hadamard&#21487;&#24494;&#24615;&#12290;&#22312;&#25105;&#20204;&#30340;&#26694;&#26550;&#20013;&#65292;Hausdorff&#27979;&#24230;&#30340;&#27010;&#24565;&#20197;&#21450;&#20960;&#20309;&#27979;&#24230;&#35770;&#20013;&#30340;&#38754;&#31215;&#21644;&#20849;&#38754;&#31215;&#31215;&#20998;&#20844;&#24335;&#26159;&#26680;&#24515;&#12290;&#22522;&#20110;&#25105;&#20204;&#30340;Hadamard&#21487;&#24494;&#24615;&#32467;&#26524;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#21033;&#29992;&#20989;&#25968;&#20559;&#24494;&#20998;&#27861;&#30452;&#25509;&#25512;&#23548;&#20986;&#20108;&#20803;&#32422;&#26463;&#26368;&#20248;&#20998;&#37197;&#38382;&#39064;&#30340;&#20540;&#20989;&#25968;&#36807;&#31243;&#20197;&#21450;&#20004;&#27493;ROC&#26354;&#32447;&#20272;&#35745;&#37327;&#30340;&#28176;&#36817;&#24615;&#36136;&#12290;&#27492;&#22806;&#65292;&#21033;&#29992;&#23545;&#20984;&#21644;&#23616;&#37096;Lipschitz&#27867;&#20989;&#30340;&#28145;&#21051;&#35265;&#35299;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#26368;&#20248;&#20998;&#37197;&#38382;&#39064;&#30340;&#20540;&#20989;&#25968;&#30340;&#39069;&#22806;&#19968;&#33324;Frechet&#21487;&#24494;&#24615;&#32467;&#26524;&#12290;&#36825;&#20123;&#24341;&#20154;&#20837;&#32988;&#30340;&#21457;&#29616;&#28608;&#21169;&#20102;&#25105;&#20204;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18248v1 Announce Type: new  Abstract: In this paper, we develp a functional differentiability approach for solving statistical optimal allocation problems. We first derive Hadamard differentiability of the value function through a detailed analysis of the general properties of the sorting operator. Central to our framework are the concept of Hausdorff measure and the area and coarea integration formulas from geometric measure theory. Building on our Hadamard differentiability results, we demonstrate how the functional delta method can be used to directly derive the asymptotic properties of the value function process for binary constrained optimal allocation problems, as well as the two-step ROC curve estimator. Moreover, leveraging profound insights from geometric functional analysis on convex and local Lipschitz functionals, we obtain additional generic Fr\'echet differentiability results for the value functions of optimal allocation problems. These compelling findings moti
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#25552;&#20986;&#8220;&#24369;&#20449;&#21495;&#20998;&#26512;&#8221;&#26694;&#26550;&#65292;&#30740;&#31350;&#20102;&#24378;&#21270;&#23398;&#20064;&#20013;&#24448;&#36820;&#35774;&#35745;&#23545;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#20272;&#35745;&#20934;&#30830;&#24615;&#30340;&#24433;&#21709;&#65292;&#21457;&#29616;&#22312;&#22823;&#37096;&#20998;&#22870;&#21169;&#35823;&#24046;&#20026;&#27491;&#30456;&#20851;&#26102;&#65292;&#24448;&#36820;&#35774;&#35745;&#27604;&#27599;&#26085;&#20999;&#25442;&#31574;&#30053;&#26356;&#26377;&#25928;&#65292;&#22686;&#21152;&#25919;&#31574;&#20999;&#25442;&#39057;&#29575;&#21487;&#20197;&#38477;&#20302;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#20272;&#35745;&#22120;&#30340;&#22343;&#26041;&#35823;&#24046;&#12290;</title><link>https://arxiv.org/abs/2403.17285</link><description>&lt;p&gt;
&#23545;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#24448;&#36820;&#35774;&#35745;&#36827;&#34892;&#30340;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
An Analysis of Switchback Designs in Reinforcement Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17285
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#25552;&#20986;&#8220;&#24369;&#20449;&#21495;&#20998;&#26512;&#8221;&#26694;&#26550;&#65292;&#30740;&#31350;&#20102;&#24378;&#21270;&#23398;&#20064;&#20013;&#24448;&#36820;&#35774;&#35745;&#23545;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#20272;&#35745;&#20934;&#30830;&#24615;&#30340;&#24433;&#21709;&#65292;&#21457;&#29616;&#22312;&#22823;&#37096;&#20998;&#22870;&#21169;&#35823;&#24046;&#20026;&#27491;&#30456;&#20851;&#26102;&#65292;&#24448;&#36820;&#35774;&#35745;&#27604;&#27599;&#26085;&#20999;&#25442;&#31574;&#30053;&#26356;&#26377;&#25928;&#65292;&#22686;&#21152;&#25919;&#31574;&#20999;&#25442;&#39057;&#29575;&#21487;&#20197;&#38477;&#20302;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#20272;&#35745;&#22120;&#30340;&#22343;&#26041;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#23545;A/B&#27979;&#35797;&#20013;&#24448;&#36820;&#35774;&#35745;&#30340;&#35814;&#32454;&#30740;&#31350;&#65292;&#36825;&#20123;&#35774;&#35745;&#38543;&#26102;&#38388;&#22312;&#22522;&#20934;&#21644;&#26032;&#31574;&#30053;&#20043;&#38388;&#20132;&#26367;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#20840;&#38754;&#35780;&#20272;&#36825;&#20123;&#35774;&#35745;&#23545;&#20854;&#20135;&#29983;&#30340;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#65288;ATE&#65289;&#20272;&#35745;&#22120;&#20934;&#30830;&#24615;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#8220;&#24369;&#20449;&#21495;&#20998;&#26512;&#8221;&#26694;&#26550;&#65292;&#22823;&#22823;&#31616;&#21270;&#20102;&#36825;&#20123;ATE&#30340;&#22343;&#26041;&#35823;&#24046;&#65288;MSE&#65289;&#22312;&#39532;&#23572;&#31185;&#22827;&#20915;&#31574;&#36807;&#31243;&#29615;&#22659;&#20013;&#30340;&#35745;&#31639;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65306;(i) &#24403;&#22823;&#37096;&#20998;&#22870;&#21169;&#35823;&#24046;&#21576;&#27491;&#30456;&#20851;&#26102;&#65292;&#24448;&#36820;&#35774;&#35745;&#27604;&#27599;&#26085;&#20999;&#25442;&#31574;&#30053;&#30340;&#20132;&#26367;&#35774;&#35745;&#26356;&#26377;&#25928;&#12290;&#27492;&#22806;&#65292;&#22686;&#21152;&#25919;&#31574;&#20999;&#25442;&#30340;&#39057;&#29575;&#24448;&#24448;&#20250;&#38477;&#20302;ATE&#20272;&#35745;&#22120;&#30340;MSE&#12290;(ii) &#28982;&#32780;&#65292;&#24403;&#35823;&#24046;&#19981;&#30456;&#20851;&#26102;&#65292;&#25152;&#26377;&#36825;&#20123;&#35774;&#35745;&#21464;&#24471;&#28176;&#36817;&#31561;&#25928;&#12290;(iii) &#22312;&#22823;&#22810;&#25968;&#35823;&#24046;&#20026;&#36127;&#30456;&#20851;&#26102;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17285v1 Announce Type: cross  Abstract: This paper offers a detailed investigation of switchback designs in A/B testing, which alternate between baseline and new policies over time. Our aim is to thoroughly evaluate the effects of these designs on the accuracy of their resulting average treatment effect (ATE) estimators. We propose a novel "weak signal analysis" framework, which substantially simplifies the calculations of the mean squared errors (MSEs) of these ATEs in Markov decision process environments. Our findings suggest that (i) when the majority of reward errors are positively correlated, the switchback design is more efficient than the alternating-day design which switches policies in a daily basis. Additionally, increasing the frequency of policy switches tends to reduce the MSE of the ATE estimator. (ii) When the errors are uncorrelated, however, all these designs become asymptotically equivalent. (iii) In cases where the majority of errors are negative correlate
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#26088;&#22312;&#36229;&#36234;&#27604;&#20363;&#28176;&#36817;&#24773;&#20917;&#65292;&#37325;&#26032;&#23457;&#35270;&#23545;&#39640;&#32500;&#25968;&#25454;&#36827;&#34892;&#23725;&#22238;&#24402;&#65292;&#20801;&#35768;&#29305;&#24449;&#21521;&#37327;&#26159;&#39640;&#32500;&#29978;&#33267;&#26080;&#38480;&#32500;&#30340;&#65292;&#20026;&#32479;&#35745;&#23398;&#20013;&#30340;&#33258;&#28982;&#35774;&#32622;&#25552;&#20379;&#20102;&#26032;&#30340;&#30740;&#31350;&#26041;&#21521;&#12290;</title><link>https://arxiv.org/abs/2210.08571</link><description>&lt;p&gt;
&#26080;&#32500;&#24230;&#23725;&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
Dimension free ridge regression
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2210.08571
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#26088;&#22312;&#36229;&#36234;&#27604;&#20363;&#28176;&#36817;&#24773;&#20917;&#65292;&#37325;&#26032;&#23457;&#35270;&#23545;&#39640;&#32500;&#25968;&#25454;&#36827;&#34892;&#23725;&#22238;&#24402;&#65292;&#20801;&#35768;&#29305;&#24449;&#21521;&#37327;&#26159;&#39640;&#32500;&#29978;&#33267;&#26080;&#38480;&#32500;&#30340;&#65292;&#20026;&#32479;&#35745;&#23398;&#20013;&#30340;&#33258;&#28982;&#35774;&#32622;&#25552;&#20379;&#20102;&#26032;&#30340;&#30740;&#31350;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#24050;&#25104;&#20026;&#39640;&#32500;&#32479;&#35745;&#23398;&#21644;&#29702;&#35770;&#26426;&#22120;&#23398;&#20064;&#20013;&#38750;&#24120;&#26377;&#29992;&#30340;&#24037;&#20855;&#12290;&#28982;&#32780;&#65292;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#20027;&#35201;&#38598;&#20013;&#22312;&#27604;&#20363;&#28176;&#36817;&#24773;&#20917;&#19979;&#65292;&#20854;&#20013;&#21015;&#25968;&#19982;&#25968;&#25454;&#30697;&#38453;&#30340;&#34892;&#25968;&#25104;&#27604;&#20363;&#22686;&#38271;&#12290;&#36825;&#22312;&#32479;&#35745;&#23398;&#20013;&#24182;&#19981;&#24635;&#26159;&#26368;&#33258;&#28982;&#30340;&#35774;&#32622;&#65292;&#20854;&#20013;&#21015;&#23545;&#24212;&#21327;&#21464;&#37327;&#65292;&#34892;&#23545;&#24212;&#26679;&#26412;&#12290;&#20026;&#20102;&#36229;&#36234;&#27604;&#20363;&#28176;&#36817;&#65292;&#25105;&#20204;&#37325;&#26032;&#23457;&#35270;&#20102;&#23545;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;$(x_i, y_i)$&#65292;$i\le n$&#36827;&#34892;&#23725;&#22238;&#24402;&#65288;$\ell_2$-&#24809;&#32602;&#26368;&#23567;&#20108;&#20056;&#65289;&#65292;&#20854;&#20013;$x_i$&#20026;&#29305;&#24449;&#21521;&#37327;&#65292;$y_i = \beta^\top x_i +\epsilon_i \in\mathbb{R}$&#20026;&#21709;&#24212;&#12290;&#25105;&#20204;&#20801;&#35768;&#29305;&#24449;&#21521;&#37327;&#26159;&#39640;&#32500;&#30340;&#65292;&#29978;&#33267;&#26159;&#26080;&#38480;&#32500;&#30340;&#65292;&#27492;&#26102;&#23427;&#23646;&#20110;&#21487;&#20998;Hilbert&#31354;&#38388;&#65292;&#24182;&#19988;&#20551;&#35774;$z_i := \Sigma^{-1/2}x_i$&#20855;&#26377;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#26465;&#30446;&#65292;&#25110;&#32773;&#28385;&#36275;&#26576;&#31181;&#20984;&#38598;&#20013;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2210.08571v2 Announce Type: replace-cross  Abstract: Random matrix theory has become a widely useful tool in high-dimensional statistics and theoretical machine learning. However, random matrix theory is largely focused on the proportional asymptotics in which the number of columns grows proportionally to the number of rows of the data matrix. This is not always the most natural setting in statistics where columns correspond to covariates and rows to samples. With the objective to move beyond the proportional asymptotics, we revisit ridge regression ($\ell_2$-penalized least squares) on i.i.d. data $(x_i, y_i)$, $i\le n$, where $x_i$ is a feature vector and $y_i = \beta^\top x_i +\epsilon_i \in\mathbb{R}$ is a response. We allow the feature vector to be high-dimensional, or even infinite-dimensional, in which case it belongs to a separable Hilbert space, and assume either $z_i := \Sigma^{-1/2}x_i$ to have i.i.d. entries, or to satisfy a certain convex concentration property. With
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26356;&#19968;&#33324;&#30340;Tanimoto&#26680;&#20844;&#24335;&#65292;&#20801;&#35768;&#34913;&#37327;&#20219;&#24847;&#23454;&#20540;&#20989;&#25968;&#30340;&#30456;&#20284;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;&#20809;&#28369;&#36924;&#36817;&#30340;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2007.05943</link><description>&lt;p&gt;
&#23558;Tanimoto&#31867;&#22411;&#26680;&#27867;&#21270;&#21040;&#23454;&#20540;&#20989;&#25968;
&lt;/p&gt;
&lt;p&gt;
On the generalization of Tanimoto-type kernels to real valued functions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2007.05943
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26356;&#19968;&#33324;&#30340;Tanimoto&#26680;&#20844;&#24335;&#65292;&#20801;&#35768;&#34913;&#37327;&#20219;&#24847;&#23454;&#20540;&#20989;&#25968;&#30340;&#30456;&#20284;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;&#20809;&#28369;&#36924;&#36817;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Tanimoto&#26680;&#65288;Jaccard&#25351;&#25968;&#65289;&#26159;&#25551;&#36848;&#20108;&#20540;&#23646;&#24615;&#38598;&#30456;&#20284;&#24615;&#30340;&#30693;&#21517;&#24037;&#20855;&#12290;&#24050;&#23558;&#20854;&#25193;&#23637;&#21040;&#23646;&#24615;&#20026;&#38750;&#36127;&#23454;&#25968;&#20540;&#30340;&#24773;&#20917;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26356;&#19968;&#33324;&#30340;Tanimoto&#26680;&#20844;&#24335;&#65292;&#20801;&#35768;&#34913;&#37327;&#20219;&#24847;&#23454;&#20540;&#20989;&#25968;&#30340;&#30456;&#20284;&#24615;&#12290;&#36890;&#36807;&#36890;&#36807;&#36866;&#24403;&#36873;&#25321;&#30340;&#38598;&#21512;&#32479;&#19968;&#23646;&#24615;&#34920;&#31034;&#26469;&#26500;&#24314;&#27492;&#25193;&#23637;&#12290;&#22312;&#25512;&#23548;&#26680;&#30340;&#19968;&#33324;&#24418;&#24335;&#21518;&#65292;&#20174;&#26680;&#20989;&#25968;&#20013;&#25552;&#21462;&#20102;&#26174;&#24335;&#29305;&#24449;&#34920;&#31034;&#65292;&#24182;&#23637;&#31034;&#20102;&#23558;&#19968;&#33324;&#26680;&#21253;&#21547;&#21040;Tanimoto&#26680;&#20013;&#30340;&#31616;&#21333;&#26041;&#27861;&#12290;&#26368;&#21518;&#65292;&#26680;&#20063;&#34920;&#31034;&#20026;&#20998;&#27573;&#32447;&#24615;&#20989;&#25968;&#30340;&#21830;&#65292;&#24182;&#25552;&#20379;&#20102;&#20809;&#28369;&#36924;&#36817;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2007.05943v2 Announce Type: replace  Abstract: The Tanimoto kernel (Jaccard index) is a well known tool to describe the similarity between sets of binary attributes. It has been extended to the case when the attributes are nonnegative real values. This paper introduces a more general Tanimoto kernel formulation which allows to measure the similarity of arbitrary real-valued functions. This extension is constructed by unifying the representation of the attributes via properly chosen sets. After deriving the general form of the kernel, explicit feature representation is extracted from the kernel function, and a simply way of including general kernels into the Tanimoto kernel is shown. Finally, the kernel is also expressed as a quotient of piecewise linear functions, and a smooth approximation is provided.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#20010;&#24615;&#21270;&#27835;&#30103;&#25512;&#33616;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#19978;&#19979;&#25991;&#22266;&#23450;&#39044;&#31639;&#30340;&#26368;&#20339;&#33218;&#35782;&#21035;&#27169;&#22411;&#65292;&#36890;&#36807;&#33258;&#36866;&#24212;&#23454;&#39564;&#35774;&#35745;&#21644;&#31574;&#30053;&#23398;&#20064;&#26469;&#25512;&#33616;&#26368;&#20339;&#27835;&#30103;&#26041;&#26696;&#65292;&#24182;&#36890;&#36807;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#26399;&#26395;&#31616;&#21333;&#36951;&#25022;&#26469;&#34913;&#37327;&#25512;&#33616;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.03756</link><description>&lt;p&gt;
&#19978;&#19979;&#25991;&#22266;&#23450;&#39044;&#31639;&#30340;&#26368;&#20339;&#33218;&#35782;&#21035;&#65306;&#36866;&#24212;&#24615;&#23454;&#39564;&#35774;&#35745;&#19982;&#31574;&#30053;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Contextual Fixed-Budget Best Arm Identification: Adaptive Experimental Design with Policy Learning. (arXiv:2401.03756v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.03756
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#20010;&#24615;&#21270;&#27835;&#30103;&#25512;&#33616;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#19978;&#19979;&#25991;&#22266;&#23450;&#39044;&#31639;&#30340;&#26368;&#20339;&#33218;&#35782;&#21035;&#27169;&#22411;&#65292;&#36890;&#36807;&#33258;&#36866;&#24212;&#23454;&#39564;&#35774;&#35745;&#21644;&#31574;&#30053;&#23398;&#20064;&#26469;&#25512;&#33616;&#26368;&#20339;&#27835;&#30103;&#26041;&#26696;&#65292;&#24182;&#36890;&#36807;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#26399;&#26395;&#31616;&#21333;&#36951;&#25022;&#26469;&#34913;&#37327;&#25512;&#33616;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20010;&#24615;&#21270;&#27835;&#30103;&#25512;&#33616;&#26159;&#22522;&#20110;&#35777;&#25454;&#30340;&#20915;&#31574;&#20013;&#30340;&#20851;&#38190;&#20219;&#21153;&#12290;&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#23558;&#36825;&#20010;&#20219;&#21153;&#20316;&#20026;&#19968;&#20010;&#24102;&#26377;&#19978;&#19979;&#25991;&#20449;&#24687;&#30340;&#22266;&#23450;&#39044;&#31639;&#26368;&#20339;&#33218;&#35782;&#21035;&#65288;Best Arm Identification, BAI&#65289;&#38382;&#39064;&#26469;&#36827;&#34892;&#24314;&#27169;&#12290;&#22312;&#36825;&#20010;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#32473;&#23450;&#22810;&#20010;&#27835;&#30103;&#33218;&#30340;&#33258;&#36866;&#24212;&#35797;&#39564;&#12290;&#22312;&#27599;&#19968;&#36718;&#20013;&#65292;&#20915;&#31574;&#32773;&#35266;&#23519;&#19968;&#20010;&#21051;&#30011;&#23454;&#39564;&#21333;&#20301;&#30340;&#19978;&#19979;&#25991;&#65288;&#21327;&#21464;&#37327;&#65289;&#65292;&#24182;&#23558;&#35813;&#21333;&#20301;&#20998;&#37197;&#32473;&#20854;&#20013;&#19968;&#20010;&#27835;&#30103;&#33218;&#12290;&#22312;&#23454;&#39564;&#32467;&#26463;&#26102;&#65292;&#20915;&#31574;&#32773;&#25512;&#33616;&#19968;&#20010;&#22312;&#32473;&#23450;&#19978;&#19979;&#25991;&#26465;&#20214;&#19979;&#39044;&#35745;&#20135;&#29983;&#26368;&#39640;&#26399;&#26395;&#32467;&#26524;&#30340;&#27835;&#30103;&#33218;&#65288;&#26368;&#20339;&#27835;&#30103;&#33218;&#65289;&#12290;&#35813;&#20915;&#31574;&#30340;&#26377;&#25928;&#24615;&#36890;&#36807;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#26399;&#26395;&#31616;&#21333;&#36951;&#25022;&#65288;&#31574;&#30053;&#36951;&#25022;&#65289;&#26469;&#34913;&#37327;&#65292;&#35813;&#36951;&#25022;&#34920;&#31034;&#22312;&#32473;&#23450;&#19978;&#19979;&#25991;&#26465;&#20214;&#19979;&#65292;&#26368;&#20339;&#27835;&#30103;&#33218;&#21644;&#25512;&#33616;&#27835;&#30103;&#33218;&#30340;&#26465;&#20214;&#26399;&#26395;&#32467;&#26524;&#20043;&#38388;&#30340;&#26368;&#22823;&#24046;&#24322;&#12290;&#25105;&#20204;&#30340;&#21021;&#22987;&#27493;&#39588;&#26159;&#25512;&#23548;&#26368;&#22351;&#24773;&#20917;&#19979;&#26399;&#26395;&#31616;&#21333;&#36951;&#25022;&#30340;&#28176;&#36817;&#19979;&#30028;&#65292;&#35813;&#19979;&#30028;&#36824;&#26263;&#31034;&#30528;&#35299;&#20915;&#35813;&#38382;&#39064;&#30340;&#19968;&#20123;&#24605;&#36335;&#12290;
&lt;/p&gt;
&lt;p&gt;
Individualized treatment recommendation is a crucial task in evidence-based decision-making. In this study, we formulate this task as a fixed-budget best arm identification (BAI) problem with contextual information. In this setting, we consider an adaptive experiment given multiple treatment arms. At each round, a decision-maker observes a context (covariate) that characterizes an experimental unit and assigns the unit to one of the treatment arms. At the end of the experiment, the decision-maker recommends a treatment arm estimated to yield the highest expected outcome conditioned on a context (best treatment arm). The effectiveness of this decision is measured in terms of the worst-case expected simple regret (policy regret), which represents the largest difference between the conditional expected outcomes of the best and recommended treatment arms given a context. Our initial step is to derive asymptotic lower bounds for the worst-case expected simple regret, which also implies idea
&lt;/p&gt;</description></item><item><title>&#36825;&#20010;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#38750;&#21442;&#25968;&#30340;&#27169;&#22411;&#26080;&#20851;&#26694;&#26550;&#65292;&#29992;&#20110;&#24314;&#31435;&#20445;&#38505;&#29702;&#36180;&#30340;&#39044;&#27979;&#21306;&#38388;&#65292;&#24182;&#20855;&#26377;&#26377;&#38480;&#26679;&#26412;&#30340;&#32479;&#35745;&#20445;&#35777;&#65292;&#25193;&#23637;&#20102;split conformal prediction&#25216;&#26415;&#21040;&#20004;&#38454;&#27573;&#39057;&#29575;-&#20005;&#37325;&#24615;&#24314;&#27169;&#39046;&#22495;&#65292;&#24182;&#36890;&#36807;&#20351;&#29992;&#38543;&#26426;&#26862;&#26519;&#20316;&#20026;&#20005;&#37325;&#24615;&#27169;&#22411;&#65292;&#21033;&#29992;&#20102;&#34955;&#22806;&#26426;&#21046;&#28040;&#38500;&#20102;&#26657;&#20934;&#38598;&#30340;&#38656;&#35201;&#65292;&#24182;&#23454;&#29616;&#20102;&#20855;&#26377;&#33258;&#36866;&#24212;&#23485;&#24230;&#30340;&#39044;&#27979;&#21306;&#38388;&#30340;&#29983;&#25104;&#12290;</title><link>http://arxiv.org/abs/2307.13124</link><description>&lt;p&gt;
&#39057;&#29575;-&#20005;&#37325;&#24615;&#24314;&#27169;&#30340;&#31526;&#21512;&#24615;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Conformal prediction for frequency-severity modeling. (arXiv:2307.13124v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13124
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20010;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#38750;&#21442;&#25968;&#30340;&#27169;&#22411;&#26080;&#20851;&#26694;&#26550;&#65292;&#29992;&#20110;&#24314;&#31435;&#20445;&#38505;&#29702;&#36180;&#30340;&#39044;&#27979;&#21306;&#38388;&#65292;&#24182;&#20855;&#26377;&#26377;&#38480;&#26679;&#26412;&#30340;&#32479;&#35745;&#20445;&#35777;&#65292;&#25193;&#23637;&#20102;split conformal prediction&#25216;&#26415;&#21040;&#20004;&#38454;&#27573;&#39057;&#29575;-&#20005;&#37325;&#24615;&#24314;&#27169;&#39046;&#22495;&#65292;&#24182;&#36890;&#36807;&#20351;&#29992;&#38543;&#26426;&#26862;&#26519;&#20316;&#20026;&#20005;&#37325;&#24615;&#27169;&#22411;&#65292;&#21033;&#29992;&#20102;&#34955;&#22806;&#26426;&#21046;&#28040;&#38500;&#20102;&#26657;&#20934;&#38598;&#30340;&#38656;&#35201;&#65292;&#24182;&#23454;&#29616;&#20102;&#20855;&#26377;&#33258;&#36866;&#24212;&#23485;&#24230;&#30340;&#39044;&#27979;&#21306;&#38388;&#30340;&#29983;&#25104;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#38750;&#21442;&#25968;&#30340;&#27169;&#22411;&#26080;&#20851;&#26694;&#26550;&#65292;&#29992;&#20110;&#24314;&#31435;&#20445;&#38505;&#29702;&#36180;&#30340;&#39044;&#27979;&#21306;&#38388;&#65292;&#24182;&#20855;&#26377;&#26377;&#38480;&#26679;&#26412;&#30340;&#32479;&#35745;&#20445;&#35777;&#65292;&#23558;&#20998;&#21106;&#31526;&#21512;&#24615;&#39044;&#27979;&#25216;&#26415;&#25193;&#23637;&#21040;&#20004;&#38454;&#27573;&#39057;&#29575;-&#20005;&#37325;&#24615;&#24314;&#27169;&#39046;&#22495;&#12290;&#36890;&#36807;&#27169;&#25311;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#23637;&#31034;&#20102;&#35813;&#26694;&#26550;&#30340;&#26377;&#25928;&#24615;&#12290;&#24403;&#22522;&#30784;&#20005;&#37325;&#24615;&#27169;&#22411;&#26159;&#38543;&#26426;&#26862;&#26519;&#26102;&#65292;&#25105;&#20204;&#25193;&#23637;&#20102;&#20004;&#38454;&#27573;&#20998;&#21106;&#31526;&#21512;&#24615;&#39044;&#27979;&#36807;&#31243;&#65292;&#23637;&#31034;&#20102;&#22914;&#20309;&#21033;&#29992;&#34955;&#22806;&#26426;&#21046;&#28040;&#38500;&#26657;&#20934;&#38598;&#30340;&#38656;&#35201;&#65292;&#24182;&#23454;&#29616;&#20855;&#26377;&#33258;&#36866;&#24212;&#23485;&#24230;&#30340;&#39044;&#27979;&#21306;&#38388;&#30340;&#29983;&#25104;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a nonparametric model-agnostic framework for building prediction intervals of insurance claims, with finite sample statistical guarantees, extending the technique of split conformal prediction to the domain of two-stage frequency-severity modeling. The effectiveness of the framework is showcased with simulated and real datasets. When the underlying severity model is a random forest, we extend the two-stage split conformal prediction procedure, showing how the out-of-bag mechanism can be leveraged to eliminate the need for a calibration set and to enable the production of prediction intervals with adaptive width.
&lt;/p&gt;</description></item></channel></rss>