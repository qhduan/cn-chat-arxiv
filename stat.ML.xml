<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#30740;&#31350;&#20102;&#23545;&#20110;&#29420;&#31435;&#20294;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#30340;&#39640;&#32500;&#22238;&#24402;&#27169;&#22411;&#65292;&#25552;&#20986;&#20102;&#22312;&#23725;&#27491;&#21017;&#21270;&#21442;&#25968;&#36235;&#36817;&#20110;&#38646;&#26102;&#39640;&#32500;&#22238;&#24402;&#20013;&#30340;&#21452;&#35895;&#29616;&#35937;&#12290;</title><link>https://arxiv.org/abs/2403.20200</link><description>&lt;p&gt;
&#23545;&#20855;&#26377;&#26041;&#24046;&#36718;&#24275;&#30340;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#30340;&#23725;&#22238;&#24402;&#36827;&#34892;&#39640;&#32500;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
High-dimensional analysis of ridge regression for non-identically distributed data with a variance profile
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.20200
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#23545;&#20110;&#29420;&#31435;&#20294;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#30340;&#39640;&#32500;&#22238;&#24402;&#27169;&#22411;&#65292;&#25552;&#20986;&#20102;&#22312;&#23725;&#27491;&#21017;&#21270;&#21442;&#25968;&#36235;&#36817;&#20110;&#38646;&#26102;&#39640;&#32500;&#22238;&#24402;&#20013;&#30340;&#21452;&#35895;&#29616;&#35937;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38024;&#23545;&#29420;&#31435;&#20294;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#65292;&#25105;&#20204;&#25552;&#20986;&#30740;&#31350;&#39640;&#32500;&#22238;&#24402;&#27169;&#22411;&#12290;&#20551;&#35774;&#35266;&#27979;&#21040;&#30340;&#39044;&#27979;&#21464;&#37327;&#38598;&#21512;&#26159;&#24102;&#26377;&#26041;&#24046;&#36718;&#24275;&#30340;&#38543;&#26426;&#30697;&#38453;&#65292;&#24182;&#19988;&#20854;&#32500;&#24230;&#20197;&#30456;&#24212;&#36895;&#29575;&#22686;&#38271;&#12290;&#22312;&#20551;&#35774;&#38543;&#26426;&#25928;&#24212;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20855;&#26377;&#36825;&#31181;&#26041;&#24046;&#36718;&#24275;&#30340;&#23725;&#20272;&#35745;&#22120;&#30340;&#32447;&#24615;&#22238;&#24402;&#30340;&#39044;&#27979;&#39118;&#38505;&#12290;&#22312;&#36825;&#31181;&#35774;&#32622;&#19979;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#35813;&#39118;&#38505;&#30340;&#30830;&#23450;&#24615;&#31561;&#20215;&#29289;&#20197;&#21450;&#23725;&#20272;&#35745;&#22120;&#30340;&#33258;&#30001;&#24230;&#12290;&#23545;&#20110;&#26576;&#20123;&#26041;&#24046;&#36718;&#24275;&#31867;&#21035;&#65292;&#25105;&#20204;&#30340;&#24037;&#20316;&#31361;&#20986;&#20102;&#22312;&#23725;&#27491;&#21017;&#21270;&#21442;&#25968;&#36235;&#20110;&#38646;&#26102;&#65292;&#39640;&#32500;&#22238;&#24402;&#20013;&#30340;&#26368;&#23567;&#27169;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#22120;&#20986;&#29616;&#21452;&#35895;&#29616;&#35937;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#19968;&#20123;&#26041;&#24046;&#36718;&#24275;f...
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.20200v1 Announce Type: cross  Abstract: High-dimensional linear regression has been thoroughly studied in the context of independent and identically distributed data. We propose to investigate high-dimensional regression models for independent but non-identically distributed data. To this end, we suppose that the set of observed predictors (or features) is a random matrix with a variance profile and with dimensions growing at a proportional rate. Assuming a random effect model, we study the predictive risk of the ridge estimator for linear regression with such a variance profile. In this setting, we provide deterministic equivalents of this risk and of the degree of freedom of the ridge estimator. For certain class of variance profile, our work highlights the emergence of the well-known double descent phenomenon in high-dimensional regression for the minimum norm least-squares estimator when the ridge regularization parameter goes to zero. We also exhibit variance profiles f
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24320;&#21457;&#20102;&#19968;&#31181;&#19981;&#21516;&#30340;&#29702;&#35770;&#26469;&#25551;&#36848;&#27491;&#21017;&#21270;M&#20272;&#35745;&#22120;&#22312;&#21487;&#35266;&#27979;&#21333;&#25351;&#25968;&#27169;&#22411;&#20013;&#30340;&#35843;&#25972;&#12290;</title><link>http://arxiv.org/abs/2204.06990</link><description>&lt;p&gt;
&#21487;&#35266;&#27979;&#21333;&#25351;&#25968;&#27169;&#22411;&#20013;&#30340;&#27491;&#21017;&#21270;M&#20272;&#35745;&#22120;&#30340;&#35843;&#25972;
&lt;/p&gt;
&lt;p&gt;
Observable adjustments in single-index models for regularized M-estimators. (arXiv:2204.06990v3 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2204.06990
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24320;&#21457;&#20102;&#19968;&#31181;&#19981;&#21516;&#30340;&#29702;&#35770;&#26469;&#25551;&#36848;&#27491;&#21017;&#21270;M&#20272;&#35745;&#22120;&#22312;&#21487;&#35266;&#27979;&#21333;&#25351;&#25968;&#27169;&#22411;&#20013;&#30340;&#35843;&#25972;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20855;&#26377;&#26410;&#30693;&#36830;&#25509;&#20989;&#25968;&#12289;&#39640;&#26031;&#21327;&#21464;&#37327;&#21644;&#30001;&#20984;&#25439;&#22833;&#20989;&#25968;&#21644;&#27491;&#21017;&#21270;&#22120;&#26500;&#36896;&#30340;&#27491;&#21017;&#21270;M&#20272;&#35745;&#22120;&#967;&#770;&#30340;&#21333;&#25351;&#25968;&#27169;&#22411;&#30340;&#35266;&#27979;&#20540;(X, y)&#12290;&#22312;&#26679;&#26412;&#22823;&#23567;n&#21644;&#23610;&#24230;p&#37117;&#22312;&#22686;&#21152;&#30340;&#24773;&#20917;&#19979;&#65292;&#20351;&#24471;p/n&#26377;&#19968;&#20010;&#26377;&#38480;&#26497;&#38480;&#65292;&#24050;&#32463;&#22312;&#35768;&#22810;&#27169;&#22411;&#20013;&#34920;&#24449;&#20102;&#967;&#770;&#30340;&#32463;&#39564;&#20998;&#24067;&#21644;&#39044;&#27979;&#20540;X&#967;&#770;&#30340;&#34892;&#20026;&#65306;&#24050;&#30693;&#32463;&#39564;&#20998;&#24067;&#25910;&#25947;&#20110;&#30456;&#20851;&#39640;&#26031;&#24207;&#21015;&#27169;&#22411;&#20013;&#30340;&#25439;&#22833;&#21644;&#24809;&#32602;&#30340;&#37051;&#36817;&#31639;&#23376;&#65292;&#35813;&#27169;&#22411;&#25429;&#25417;&#20102;&#27604;&#29575;p/n&#12289;&#25439;&#22833;&#12289;&#27491;&#21017;&#21270;&#21644;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#12290;&#36825;&#31181;$(\hat\beta,X\hat\beta)$&#21644;&#30456;&#24212;&#30340;&#37051;&#36817;&#31639;&#23376;&#20043;&#38388;&#30340;&#36830;&#25509;&#38656;&#35201;&#35299;&#20915;&#36890;&#24120;&#28041;&#21450;&#26080;&#27861;&#35266;&#23519;&#21040;&#30340;&#25968;&#37327;&#65292;&#22914;&#25351;&#25968;&#19978;&#30340;&#20808;&#39564;&#20998;&#24067;&#25110;&#36830;&#25509;&#20989;&#25968;&#30340;&#22266;&#23450;&#28857;&#26041;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider observations $(X,y)$ from single index models with unknown link function, Gaussian covariates and a regularized M-estimator $\hat\beta$ constructed from convex loss function and regularizer. In the regime where sample size $n$ and dimension $p$ are both increasing such that $p/n$ has a finite limit, the behavior of the empirical distribution of $\hat\beta$ and the predicted values $X\hat\beta$ has been previously characterized in a number of models: The empirical distributions are known to converge to proximal operators of the loss and penalty in a related Gaussian sequence model, which captures the interplay between ratio $p/n$, loss, regularization and the data generating process. This connection between$(\hat\beta,X\hat\beta)$ and the corresponding proximal operators require solving fixed-point equations that typically involve unobservable quantities such as the prior distribution on the index or the link function.  This paper develops a different theory to describe the 
&lt;/p&gt;</description></item></channel></rss>