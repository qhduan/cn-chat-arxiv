<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#20351;&#29992;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GANs&#65289;&#20026;&#20219;&#20309;Copula&#29983;&#25104;&#20934;&#38543;&#26426;&#26679;&#26412;&#30340;&#39640;&#25928;&#26041;&#27861;</title><link>https://arxiv.org/abs/2403.05281</link><description>&lt;p&gt;
&#19968;&#31181;&#39640;&#25928;&#30340;&#29992;&#20110;Copulas&#30340;&#20934;&#38543;&#26426;&#25277;&#26679;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
An Efficient Quasi-Random Sampling for Copulas
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.05281
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GANs&#65289;&#20026;&#20219;&#20309;Copula&#29983;&#25104;&#20934;&#38543;&#26426;&#26679;&#26412;&#30340;&#39640;&#25928;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#22312;&#33945;&#29305;&#21345;&#32599;&#35745;&#31639;&#20013;&#29992;&#20110;Copulas&#30340;&#39640;&#25928;&#20934;&#38543;&#26426;&#25277;&#26679;&#26041;&#27861;&#12290;&#20256;&#32479;&#26041;&#27861;&#22914;&#26465;&#20214;&#20998;&#24067;&#27861;&#65288;CDM&#65289;&#22312;&#22788;&#29702;&#39640;&#32500;&#25110;&#38544;&#24335;Copulas&#26102;&#23384;&#22312;&#23616;&#38480;&#24615;&#65292;&#25351;&#30340;&#26159;&#37027;&#20123;&#26080;&#27861;&#36890;&#36807;&#29616;&#26377;&#21442;&#25968;Copulas&#20934;&#30830;&#34920;&#31034;&#30340;Copulas&#12290;&#30456;&#21453;&#65292;&#26412;&#25991;&#25552;&#20986;&#20351;&#29992;&#29983;&#25104;&#27169;&#22411;&#65292;&#20363;&#22914;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GANs&#65289;&#65292;&#20026;&#20219;&#20309;Copula&#29983;&#25104;&#20934;&#38543;&#26426;&#26679;&#26412;&#12290;GANs&#26159;&#19968;&#31181;&#29992;&#20110;&#23398;&#20064;&#22797;&#26434;&#25968;&#25454;&#20998;&#24067;&#30340;&#38544;&#24335;&#29983;&#25104;&#27169;&#22411;&#65292;&#26377;&#21161;&#20110;&#31616;&#21270;&#25277;&#26679;&#36807;&#31243;&#12290;&#22312;&#25105;&#20204;&#30340;&#30740;&#31350;&#20013;&#65292;GANs&#34987;&#29992;&#26469;&#23398;&#20064;&#20174;&#22343;&#21248;&#20998;&#24067;&#21040;Copulas&#30340;&#26144;&#23556;&#12290;&#19968;&#26086;&#23398;&#20064;&#20102;&#36825;&#31181;&#26144;&#23556;&#65292;&#20174;Copula&#33719;&#21462;&#20934;&#38543;&#26426;&#26679;&#26412;&#21482;&#38656;&#36755;&#20837;&#26469;&#33258;&#22343;&#21248;&#20998;&#24067;&#30340;&#20934;&#38543;&#26426;&#26679;&#26412;&#12290;&#36825;&#31181;&#26041;&#27861;&#20026;&#20219;&#20309;Copula&#25552;&#20379;&#20102;&#26356;&#28789;&#27963;&#30340;&#26041;&#24335;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;t
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.05281v1 Announce Type: new  Abstract: This paper examines an efficient method for quasi-random sampling of copulas in Monte Carlo computations. Traditional methods, like conditional distribution methods (CDM), have limitations when dealing with high-dimensional or implicit copulas, which refer to those that cannot be accurately represented by existing parametric copulas. Instead, this paper proposes the use of generative models, such as Generative Adversarial Networks (GANs), to generate quasi-random samples for any copula. GANs are a type of implicit generative models used to learn the distribution of complex data, thus facilitating easy sampling. In our study, GANs are employed to learn the mapping from a uniform distribution to copulas. Once this mapping is learned, obtaining quasi-random samples from the copula only requires inputting quasi-random samples from the uniform distribution. This approach offers a more flexible method for any copula. Additionally, we provide t
&lt;/p&gt;</description></item><item><title>GFlowNets&#26159;&#19968;&#31181;&#29983;&#25104;&#27969;&#32593;&#32476;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#20027;&#21160;&#23398;&#20064;&#29615;&#22659;&#20013;&#37319;&#26679;&#22810;&#26679;&#21270;&#30340;&#20505;&#36873;&#38598;&#12290;&#23427;&#20204;&#20855;&#26377;&#20272;&#35745;&#32852;&#21512;&#27010;&#29575;&#20998;&#24067;&#21644;&#36793;&#38469;&#20998;&#24067;&#30340;&#33021;&#21147;&#65292;&#21487;&#20197;&#34920;&#31034;&#20851;&#20110;&#22797;&#21512;&#23545;&#35937;&#65288;&#22914;&#38598;&#21512;&#21644;&#22270;&#65289;&#30340;&#20998;&#24067;&#12290;&#36890;&#36807;&#21333;&#27425;&#35757;&#32451;&#30340;&#29983;&#25104;&#20256;&#36882;&#65292;GFlowNets&#20998;&#25674;&#20102;&#35745;&#31639;&#26114;&#36149;&#30340;MCMC&#26041;&#27861;&#30340;&#24037;&#20316;&#12290;</title><link>http://arxiv.org/abs/2111.09266</link><description>&lt;p&gt;
GFlowNet&#22522;&#30784;
&lt;/p&gt;
&lt;p&gt;
GFlowNet Foundations. (arXiv:2111.09266v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2111.09266
&lt;/p&gt;
&lt;p&gt;
GFlowNets&#26159;&#19968;&#31181;&#29983;&#25104;&#27969;&#32593;&#32476;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#20027;&#21160;&#23398;&#20064;&#29615;&#22659;&#20013;&#37319;&#26679;&#22810;&#26679;&#21270;&#30340;&#20505;&#36873;&#38598;&#12290;&#23427;&#20204;&#20855;&#26377;&#20272;&#35745;&#32852;&#21512;&#27010;&#29575;&#20998;&#24067;&#21644;&#36793;&#38469;&#20998;&#24067;&#30340;&#33021;&#21147;&#65292;&#21487;&#20197;&#34920;&#31034;&#20851;&#20110;&#22797;&#21512;&#23545;&#35937;&#65288;&#22914;&#38598;&#21512;&#21644;&#22270;&#65289;&#30340;&#20998;&#24067;&#12290;&#36890;&#36807;&#21333;&#27425;&#35757;&#32451;&#30340;&#29983;&#25104;&#20256;&#36882;&#65292;GFlowNets&#20998;&#25674;&#20102;&#35745;&#31639;&#26114;&#36149;&#30340;MCMC&#26041;&#27861;&#30340;&#24037;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#27969;&#32593;&#32476;&#65288;GFlowNets&#65289;&#34987;&#24341;&#20837;&#20026;&#22312;&#20027;&#21160;&#23398;&#20064;&#29615;&#22659;&#20013;&#37319;&#26679;&#22810;&#26679;&#21270;&#30340;&#20505;&#36873;&#38598;&#30340;&#26041;&#27861;&#65292;&#20854;&#35757;&#32451;&#30446;&#26631;&#20351;&#20854;&#36817;&#20284;&#25353;&#29031;&#32473;&#23450;&#30340;&#22870;&#21169;&#20989;&#25968;&#36827;&#34892;&#37319;&#26679;&#12290;&#26412;&#25991;&#23637;&#31034;&#20102;GFlowNets&#30340;&#19968;&#20123;&#39069;&#22806;&#30340;&#29702;&#35770;&#24615;&#36136;&#12290;&#23427;&#20204;&#21487;&#20197;&#29992;&#20110;&#20272;&#35745;&#32852;&#21512;&#27010;&#29575;&#20998;&#24067;&#21644;&#30456;&#24212;&#30340;&#36793;&#38469;&#20998;&#24067;&#65292;&#20854;&#20013;&#19968;&#20123;&#21464;&#37327;&#26410;&#25351;&#23450;&#65292;&#29305;&#21035;&#26159;&#21487;&#20197;&#34920;&#31034;&#20851;&#20110;&#22797;&#21512;&#23545;&#35937;&#65288;&#22914;&#38598;&#21512;&#21644;&#22270;&#65289;&#30340;&#20998;&#24067;&#12290;GFlowNets&#36890;&#36807;&#21333;&#27425;&#35757;&#32451;&#30340;&#29983;&#25104;&#20256;&#36882;&#26469;&#20998;&#25674;&#36890;&#24120;&#30001;&#35745;&#31639;&#26114;&#36149;&#30340;MCMC&#26041;&#27861;&#23436;&#25104;&#30340;&#24037;&#20316;&#12290;&#23427;&#20204;&#36824;&#21487;&#20197;&#29992;&#20110;&#20272;&#35745;&#20998;&#21306;&#20989;&#25968;&#21644;&#33258;&#30001;&#33021;&#65292;&#32473;&#23450;&#19968;&#20010;&#23376;&#38598;&#65288;&#23376;&#22270;&#65289;&#30340;&#36229;&#38598;&#65288;&#36229;&#22270;&#65289;&#30340;&#26465;&#20214;&#27010;&#29575;&#65292;&#20197;&#21450;&#32473;&#23450;&#19968;&#20010;&#38598;&#21512;&#65288;&#22270;&#65289;&#30340;&#25152;&#26377;&#36229;&#38598;&#65288;&#36229;&#22270;&#65289;&#30340;&#36793;&#38469;&#20998;&#24067;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#20123;&#21464;&#20307;&#65292;&#20351;&#24471;&#21487;&#20197;&#20272;&#35745;&#29109;&#30340;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative Flow Networks (GFlowNets) have been introduced as a method to sample a diverse set of candidates in an active learning context, with a training objective that makes them approximately sample in proportion to a given reward function. In this paper, we show a number of additional theoretical properties of GFlowNets. They can be used to estimate joint probability distributions and the corresponding marginal distributions where some variables are unspecified and, of particular interest, can represent distributions over composite objects like sets and graphs. GFlowNets amortize the work typically done by computationally expensive MCMC methods in a single but trained generative pass. They could also be used to estimate partition functions and free energies, conditional probabilities of supersets (supergraphs) given a subset (subgraph), as well as marginal distributions over all supersets (supergraphs) of a given set (graph). We introduce variations enabling the estimation of entro
&lt;/p&gt;</description></item></channel></rss>