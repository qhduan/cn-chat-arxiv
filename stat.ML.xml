<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#25277;&#26679;&#30340;&#20551;&#35774;&#26816;&#39564;&#26694;&#26550;&#65292;&#33021;&#22815;&#22312;&#22823;&#23646;&#24615;&#22270;&#20013;&#22788;&#29702;&#33410;&#28857;&#12289;&#36793;&#21644;&#36335;&#24452;&#20551;&#35774;&#65292;&#36890;&#36807;&#25552;&#20986;&#36335;&#24452;&#20551;&#35774;&#24863;&#30693;&#37319;&#26679;&#22120; PHASE &#20197;&#21450; PHASEopt&#65292;&#23454;&#29616;&#20102;&#20934;&#30830;&#19988;&#39640;&#25928;&#30340;&#25277;&#26679;&#65292;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#22312;&#20551;&#35774;&#26816;&#39564;&#19978;&#30340;&#20248;&#21183;&#12290;</title><link>https://arxiv.org/abs/2403.13286</link><description>&lt;p&gt;
&#22522;&#20110;&#25277;&#26679;&#30340;&#22823;&#23646;&#24615;&#22270;&#20551;&#35774;&#26816;&#39564;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A Sampling-based Framework for Hypothesis Testing on Large Attributed Graphs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.13286
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#25277;&#26679;&#30340;&#20551;&#35774;&#26816;&#39564;&#26694;&#26550;&#65292;&#33021;&#22815;&#22312;&#22823;&#23646;&#24615;&#22270;&#20013;&#22788;&#29702;&#33410;&#28857;&#12289;&#36793;&#21644;&#36335;&#24452;&#20551;&#35774;&#65292;&#36890;&#36807;&#25552;&#20986;&#36335;&#24452;&#20551;&#35774;&#24863;&#30693;&#37319;&#26679;&#22120; PHASE &#20197;&#21450; PHASEopt&#65292;&#23454;&#29616;&#20102;&#20934;&#30830;&#19988;&#39640;&#25928;&#30340;&#25277;&#26679;&#65292;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#22312;&#20551;&#35774;&#26816;&#39564;&#19978;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20551;&#35774;&#26816;&#39564;&#26159;&#19968;&#31181;&#29992;&#20110;&#20174;&#26679;&#26412;&#25968;&#25454;&#20013;&#24471;&#20986;&#20851;&#20110;&#24635;&#20307;&#30340;&#32467;&#35770;&#30340;&#32479;&#35745;&#26041;&#27861;&#65292;&#36890;&#24120;&#29992;&#34920;&#26684;&#34920;&#31034;&#12290;&#38543;&#30528;&#29616;&#23454;&#24212;&#29992;&#20013;&#22270;&#34920;&#31034;&#30340;&#26222;&#21450;&#65292;&#22270;&#20013;&#30340;&#20551;&#35774;&#26816;&#39564;&#21464;&#24471;&#36234;&#26469;&#36234;&#37325;&#35201;&#12290;&#26412;&#25991;&#23545;&#23646;&#24615;&#22270;&#20013;&#30340;&#33410;&#28857;&#12289;&#36793;&#21644;&#36335;&#24452;&#20551;&#35774;&#36827;&#34892;&#20102;&#24418;&#24335;&#21270;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#22522;&#20110;&#25277;&#26679;&#30340;&#20551;&#35774;&#26816;&#39564;&#26694;&#26550;&#65292;&#21487;&#20197;&#23481;&#32435;&#29616;&#26377;&#30340;&#20551;&#35774;&#19981;&#21487;&#30693;&#30340;&#22270;&#25277;&#26679;&#26041;&#27861;&#12290;&#20026;&#20102;&#23454;&#29616;&#20934;&#30830;&#21644;&#39640;&#25928;&#30340;&#25277;&#26679;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36335;&#24452;&#20551;&#35774;&#24863;&#30693;&#37319;&#26679;&#22120; PHASE&#65292;&#23427;&#26159;&#19968;&#31181;&#32771;&#34385;&#20551;&#35774;&#20013;&#25351;&#23450;&#36335;&#24452;&#30340; m-&#32500;&#38543;&#26426;&#28216;&#36208;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#20248;&#21270;&#20102;&#20854;&#26102;&#38388;&#25928;&#29575;&#24182;&#25552;&#20986;&#20102; PHASEopt&#12290;&#23545;&#30495;&#23454;&#25968;&#25454;&#38598;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#33021;&#22815;&#21033;&#29992;&#24120;&#35265;&#30340;&#22270;&#25277;&#26679;&#26041;&#27861;&#36827;&#34892;&#20551;&#35774;&#26816;&#39564;&#65292;&#24182;&#19988;&#22312;&#20934;&#30830;&#24615;&#21644;&#26102;&#38388;&#25928;&#29575;&#26041;&#38754;&#20551;&#35774;&#24863;&#30693;&#25277;&#26679;&#20855;&#26377;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.13286v1 Announce Type: cross  Abstract: Hypothesis testing is a statistical method used to draw conclusions about populations from sample data, typically represented in tables. With the prevalence of graph representations in real-life applications, hypothesis testing in graphs is gaining importance. In this work, we formalize node, edge, and path hypotheses in attributed graphs. We develop a sampling-based hypothesis testing framework, which can accommodate existing hypothesis-agnostic graph sampling methods. To achieve accurate and efficient sampling, we then propose a Path-Hypothesis-Aware SamplEr, PHASE, an m- dimensional random walk that accounts for the paths specified in a hypothesis. We further optimize its time efficiency and propose PHASEopt. Experiments on real datasets demonstrate the ability of our framework to leverage common graph sampling methods for hypothesis testing, and the superiority of hypothesis-aware sampling in terms of accuracy and time efficiency.
&lt;/p&gt;</description></item><item><title>&#26412;&#20070;&#25552;&#20379;&#20102;&#23545;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#30340;&#25968;&#23398;&#20171;&#32461;&#65292;&#21253;&#25324;&#19981;&#21516;&#30340;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#21644;&#20248;&#21270;&#31639;&#27861;&#65292;&#24182;&#28085;&#30422;&#20102;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#30340;&#29702;&#35770;&#26041;&#38754;&#12290;&#27492;&#22806;&#65292;&#36824;&#20171;&#32461;&#20102;&#28145;&#24230;&#23398;&#20064;&#36924;&#36817;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#26041;&#27861;&#12290;&#24076;&#26395;&#23545;&#23398;&#29983;&#21644;&#31185;&#23398;&#23478;&#20204;&#26377;&#25152;&#24110;&#21161;&#12290;</title><link>http://arxiv.org/abs/2310.20360</link><description>&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#30340;&#25968;&#23398;&#20171;&#32461;&#65306;&#26041;&#27861;&#12289;&#23454;&#29616;&#21644;&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
Mathematical Introduction to Deep Learning: Methods, Implementations, and Theory. (arXiv:2310.20360v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20360
&lt;/p&gt;
&lt;p&gt;
&#26412;&#20070;&#25552;&#20379;&#20102;&#23545;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#30340;&#25968;&#23398;&#20171;&#32461;&#65292;&#21253;&#25324;&#19981;&#21516;&#30340;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#21644;&#20248;&#21270;&#31639;&#27861;&#65292;&#24182;&#28085;&#30422;&#20102;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#30340;&#29702;&#35770;&#26041;&#38754;&#12290;&#27492;&#22806;&#65292;&#36824;&#20171;&#32461;&#20102;&#28145;&#24230;&#23398;&#20064;&#36924;&#36817;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#26041;&#27861;&#12290;&#24076;&#26395;&#23545;&#23398;&#29983;&#21644;&#31185;&#23398;&#23478;&#20204;&#26377;&#25152;&#24110;&#21161;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#20070;&#26088;&#22312;&#20171;&#32461;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#30340;&#20027;&#39064;&#12290;&#25105;&#20204;&#35814;&#32454;&#20171;&#32461;&#20102;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#30340;&#22522;&#26412;&#32452;&#25104;&#37096;&#20998;&#65292;&#21253;&#25324;&#19981;&#21516;&#30340;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#65288;&#22914;&#20840;&#36830;&#25509;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#12289;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#12289;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#12289;&#27531;&#24046;&#31070;&#32463;&#32593;&#32476;&#21644;&#24102;&#26377;&#25209;&#24402;&#19968;&#21270;&#30340;&#31070;&#32463;&#32593;&#32476;&#65289;&#20197;&#21450;&#19981;&#21516;&#30340;&#20248;&#21270;&#31639;&#27861;&#65288;&#22914;&#22522;&#26412;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#27861;&#12289;&#21152;&#36895;&#26041;&#27861;&#21644;&#33258;&#36866;&#24212;&#26041;&#27861;&#65289;&#12290;&#25105;&#20204;&#36824;&#28085;&#30422;&#20102;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#30340;&#20960;&#20010;&#29702;&#35770;&#26041;&#38754;&#65292;&#22914;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#30340;&#36924;&#36817;&#33021;&#21147;&#65288;&#21253;&#25324;&#31070;&#32463;&#32593;&#32476;&#30340;&#24494;&#31215;&#20998;&#65289;&#12289;&#20248;&#21270;&#29702;&#35770;&#65288;&#21253;&#25324;Kurdyka-Lojasiewicz&#19981;&#31561;&#24335;&#65289;&#21644;&#27867;&#21270;&#35823;&#24046;&#12290;&#22312;&#26412;&#20070;&#30340;&#26368;&#21518;&#19968;&#37096;&#20998;&#65292;&#25105;&#20204;&#36824;&#22238;&#39038;&#20102;&#19968;&#20123;&#29992;&#20110;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#28145;&#24230;&#23398;&#20064;&#36924;&#36817;&#26041;&#27861;&#65292;&#21253;&#25324;&#29289;&#29702;&#20449;&#24687;&#31070;&#32463;&#32593;&#32476;&#65288;PINNs&#65289;&#21644;&#28145;&#24230;Galerkin&#26041;&#27861;&#12290;&#24076;&#26395;&#26412;&#20070;&#33021;&#23545;&#23398;&#29983;&#21644;&#31185;&#23398;&#23478;&#20204;&#26377;&#25152;&#24110;&#21161;&#12290;
&lt;/p&gt;
&lt;p&gt;
This book aims to provide an introduction to the topic of deep learning algorithms. We review essential components of deep learning algorithms in full mathematical detail including different artificial neural network (ANN) architectures (such as fully-connected feedforward ANNs, convolutional ANNs, recurrent ANNs, residual ANNs, and ANNs with batch normalization) and different optimization algorithms (such as the basic stochastic gradient descent (SGD) method, accelerated methods, and adaptive methods). We also cover several theoretical aspects of deep learning algorithms such as approximation capacities of ANNs (including a calculus for ANNs), optimization theory (including Kurdyka-{\L}ojasiewicz inequalities), and generalization errors. In the last part of the book some deep learning approximation methods for PDEs are reviewed including physics-informed neural networks (PINNs) and deep Galerkin methods. We hope that this book will be useful for students and scientists who do not yet 
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#30340;&#32858;&#31867;&#21487;&#20998;&#31163;&#24615;&#24230;&#37327;&#26041;&#27861;&#65292;&#26088;&#22312;&#37327;&#21270;&#31867;&#38388;&#20998;&#31163;&#21644;&#31867;&#20869;&#36830;&#36890;&#24615;&#65292;&#23545;&#20110;&#23494;&#24230;&#32858;&#31867;&#20855;&#26377;&#36739;&#22909;&#30340;&#24615;&#33021;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2310.12806</link><description>&lt;p&gt;
DCSI -- &#22522;&#20110;&#20998;&#31163;&#21644;&#36830;&#36890;&#24615;&#30340;&#25913;&#36827;&#30340;&#32858;&#31867;&#21487;&#20998;&#31163;&#24615;&#24230;&#37327;
&lt;/p&gt;
&lt;p&gt;
DCSI -- An improved measure of cluster separability based on separation and connectedness. (arXiv:2310.12806v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12806
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#30340;&#32858;&#31867;&#21487;&#20998;&#31163;&#24615;&#24230;&#37327;&#26041;&#27861;&#65292;&#26088;&#22312;&#37327;&#21270;&#31867;&#38388;&#20998;&#31163;&#21644;&#31867;&#20869;&#36830;&#36890;&#24615;&#65292;&#23545;&#20110;&#23494;&#24230;&#32858;&#31867;&#20855;&#26377;&#36739;&#22909;&#30340;&#24615;&#33021;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30830;&#23450;&#32473;&#23450;&#25968;&#25454;&#38598;&#20013;&#30340;&#31867;&#21035;&#26631;&#31614;&#26159;&#21542;&#23545;&#24212;&#20110;&#26377;&#24847;&#20041;&#30340;&#32858;&#31867;&#23545;&#20110;&#20351;&#29992;&#30495;&#23454;&#25968;&#25454;&#38598;&#35780;&#20272;&#32858;&#31867;&#31639;&#27861;&#33267;&#20851;&#37325;&#35201;&#12290;&#36825;&#20010;&#29305;&#24615;&#21487;&#20197;&#36890;&#36807;&#21487;&#20998;&#31163;&#24615;&#24230;&#37327;&#26469;&#37327;&#21270;&#12290;&#29616;&#26377;&#25991;&#29486;&#30340;&#32508;&#36848;&#26174;&#31034;&#65292;&#26082;&#26377;&#30340;&#22522;&#20110;&#20998;&#31867;&#30340;&#22797;&#26434;&#24615;&#24230;&#37327;&#26041;&#27861;&#21644;&#32858;&#31867;&#26377;&#25928;&#24615;&#25351;&#26631; (CVIs) &#37117;&#27809;&#26377;&#20805;&#20998;&#34701;&#20837;&#22522;&#20110;&#23494;&#24230;&#30340;&#32858;&#31867;&#30340;&#26680;&#24515;&#29305;&#24449;&#65306;&#31867;&#38388;&#20998;&#31163;&#21644;&#31867;&#20869;&#36830;&#36890;&#24615;&#12290;&#19968;&#31181;&#26032;&#24320;&#21457;&#30340;&#24230;&#37327;&#26041;&#27861; (&#23494;&#24230;&#32858;&#31867;&#21487;&#20998;&#31163;&#24615;&#25351;&#25968;, DCSI) &#26088;&#22312;&#37327;&#21270;&#36825;&#20004;&#20010;&#29305;&#24449;&#65292;&#24182;&#19988;&#20063;&#21487;&#29992;&#20316; CVI&#12290;&#23545;&#21512;&#25104;&#25968;&#25454;&#30340;&#24191;&#27867;&#23454;&#39564;&#34920;&#26126;&#65292;DCSI &#19982;&#36890;&#36807;&#35843;&#25972;&#20848;&#24503;&#25351;&#25968; (ARI) &#27979;&#37327;&#30340;DBSCAN&#30340;&#24615;&#33021;&#20043;&#38388;&#26377;&#24456;&#24378;&#30340;&#30456;&#20851;&#24615;&#65292;&#20294;&#22312;&#23545;&#22810;&#31867;&#25968;&#25454;&#38598;&#36827;&#34892;&#23494;&#24230;&#32858;&#31867;&#19981;&#36866;&#24403;&#30340;&#37325;&#21472;&#31867;&#21035;&#26102;&#32570;&#20047;&#40065;&#26834;&#24615;&#12290;&#23545;&#32463;&#24120;&#20351;&#29992;&#30340;&#30495;&#23454;&#25968;&#25454;&#38598;&#36827;&#34892;&#35814;&#32454;&#35780;&#20272;&#26174;&#31034;&#65292;DCSI &#33021;&#22815;&#26356;&#22909;&#22320;&#21306;&#20998;&#23494;&#24230;&#32858;&#31867;&#30340;&#21487;&#20998;&#31163;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Whether class labels in a given data set correspond to meaningful clusters is crucial for the evaluation of clustering algorithms using real-world data sets. This property can be quantified by separability measures. A review of the existing literature shows that neither classification-based complexity measures nor cluster validity indices (CVIs) adequately incorporate the central aspects of separability for density-based clustering: between-class separation and within-class connectedness. A newly developed measure (density cluster separability index, DCSI) aims to quantify these two characteristics and can also be used as a CVI. Extensive experiments on synthetic data indicate that DCSI correlates strongly with the performance of DBSCAN measured via the adjusted rand index (ARI) but lacks robustness when it comes to multi-class data sets with overlapping classes that are ill-suited for density-based hard clustering. Detailed evaluation on frequently used real-world data sets shows that
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#37319;&#29992;&#36793;&#38469;&#28789;&#25935;&#24230;&#27169;&#22411;&#26469;&#35299;&#20915;&#20154;&#24037;&#26234;&#33021;&#19982;&#20154;&#31867;&#21512;&#20316;&#20013;&#26410;&#34987;&#35266;&#23519;&#21040;&#30340;&#28151;&#28102;&#38382;&#39064;&#30340;&#26032;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#32467;&#21512;&#20102;&#39046;&#22495;&#19987;&#19994;&#30693;&#35782;&#21644;&#22522;&#20110;&#20154;&#24037;&#26234;&#33021;&#30340;&#32479;&#35745;&#24314;&#27169;&#65292;&#20197;&#25511;&#21046;&#28508;&#22312;&#30340;&#28151;&#28102;&#22240;&#32032;&#30340;&#24433;&#21709;&#65292;&#24182;&#36890;&#36807;&#25512;&#36831;&#21512;&#20316;&#31995;&#32479;&#26469;&#21033;&#29992;&#19981;&#21516;&#20915;&#31574;&#32773;&#30340;&#19987;&#19994;&#30693;&#35782;&#12290;</title><link>http://arxiv.org/abs/2310.08824</link><description>&lt;p&gt;
&#24102;&#26377;&#20154;&#24037;&#26234;&#33021;&#22242;&#38431;&#30340;&#28151;&#28102;&#40065;&#26834;&#30340;&#31574;&#30053;&#25913;&#36827;
&lt;/p&gt;
&lt;p&gt;
Confounding-Robust Policy Improvement with Human-AI Teams. (arXiv:2310.08824v1 [cs.HC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.08824
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#37319;&#29992;&#36793;&#38469;&#28789;&#25935;&#24230;&#27169;&#22411;&#26469;&#35299;&#20915;&#20154;&#24037;&#26234;&#33021;&#19982;&#20154;&#31867;&#21512;&#20316;&#20013;&#26410;&#34987;&#35266;&#23519;&#21040;&#30340;&#28151;&#28102;&#38382;&#39064;&#30340;&#26032;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#32467;&#21512;&#20102;&#39046;&#22495;&#19987;&#19994;&#30693;&#35782;&#21644;&#22522;&#20110;&#20154;&#24037;&#26234;&#33021;&#30340;&#32479;&#35745;&#24314;&#27169;&#65292;&#20197;&#25511;&#21046;&#28508;&#22312;&#30340;&#28151;&#28102;&#22240;&#32032;&#30340;&#24433;&#21709;&#65292;&#24182;&#36890;&#36807;&#25512;&#36831;&#21512;&#20316;&#31995;&#32479;&#26469;&#21033;&#29992;&#19981;&#21516;&#20915;&#31574;&#32773;&#30340;&#19987;&#19994;&#30693;&#35782;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#24037;&#26234;&#33021;&#19982;&#20154;&#31867;&#30340;&#21512;&#20316;&#26377;&#21487;&#33021;&#36890;&#36807;&#20805;&#20998;&#21457;&#25381;&#20154;&#31867;&#19987;&#23478;&#21644;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#30340;&#30456;&#20114;&#34917;&#20805;&#20248;&#21183;&#26469;&#25913;&#21464;&#21508;&#20010;&#39046;&#22495;&#12290;&#28982;&#32780;&#65292;&#26410;&#34987;&#35266;&#23519;&#21040;&#30340;&#28151;&#28102;&#21487;&#33021;&#20250;&#30772;&#22351;&#36825;&#31181;&#21512;&#20316;&#30340;&#26377;&#25928;&#24615;&#65292;&#23548;&#33268;&#20559;&#35265;&#21644;&#19981;&#21487;&#38752;&#30340;&#32467;&#26524;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#20154;&#24037;&#26234;&#33021;&#19982;&#20154;&#31867;&#21512;&#20316;&#20013;&#26410;&#34987;&#35266;&#23519;&#21040;&#30340;&#28151;&#28102;&#38382;&#39064;&#30340;&#26032;&#26041;&#27861;&#65292;&#21363;&#37319;&#29992;&#36793;&#38469;&#28789;&#25935;&#24230;&#27169;&#22411;&#65288;MSM&#65289;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#23558;&#39046;&#22495;&#19987;&#19994;&#30693;&#35782;&#19982;&#22522;&#20110;&#20154;&#24037;&#26234;&#33021;&#30340;&#32479;&#35745;&#24314;&#27169;&#30456;&#32467;&#21512;&#65292;&#20197;&#32771;&#34385;&#28508;&#22312;&#30340;&#21487;&#33021;&#20250;&#38544;&#34255;&#30340;&#28151;&#28102;&#22240;&#32032;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#25512;&#36831;&#21512;&#20316;&#26694;&#26550;&#65292;&#23558;&#36793;&#38469;&#28789;&#25935;&#24230;&#27169;&#22411;&#32435;&#20837;&#35266;&#27979;&#25968;&#25454;&#20013;&#30340;&#31574;&#30053;&#23398;&#20064;&#65292;&#20351;&#31995;&#32479;&#33021;&#22815;&#25511;&#21046;&#26410;&#34987;&#35266;&#23519;&#21040;&#30340;&#28151;&#28102;&#22240;&#32032;&#30340;&#24433;&#21709;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20010;&#24615;&#21270;&#30340;&#25512;&#36831;&#21512;&#20316;&#31995;&#32479;&#65292;&#20197;&#21033;&#29992;&#19981;&#21516;&#20154;&#31867;&#20915;&#31574;&#32773;&#30340;&#22810;&#26679;&#21270;&#19987;&#19994;&#30693;&#35782;&#12290;&#36890;&#36807;&#35843;&#25972;&#28508;&#22312;&#30340;&#20559;&#35265;&#65292;&#25105;&#20204;&#30340;&#35299;&#20915;&#26041;&#26696;&#33021;&#22815;&#25552;&#39640;&#21512;&#20316;&#32467;&#26524;&#30340;&#21487;&#38752;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Human-AI collaboration has the potential to transform various domains by leveraging the complementary strengths of human experts and Artificial Intelligence (AI) systems. However, unobserved confounding can undermine the effectiveness of this collaboration, leading to biased and unreliable outcomes. In this paper, we propose a novel solution to address unobserved confounding in human-AI collaboration by employing the marginal sensitivity model (MSM). Our approach combines domain expertise with AI-driven statistical modeling to account for potential confounders that may otherwise remain hidden. We present a deferral collaboration framework for incorporating the MSM into policy learning from observational data, enabling the system to control for the influence of unobserved confounding factors. In addition, we propose a personalized deferral collaboration system to leverage the diverse expertise of different human decision-makers. By adjusting for potential biases, our proposed solution e
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;p$^3$VAE&#29983;&#25104;&#27169;&#22411;&#65292;&#23427;&#23558;&#19968;&#20010;&#23436;&#32654;&#30340;&#29289;&#29702;&#27169;&#22411;&#38598;&#25104;&#21040;&#27169;&#22411;&#20013;&#65292;&#24182;&#24212;&#29992;&#20110;&#39640;&#20998;&#36776;&#29575;&#39640;&#20809;&#35889;&#36965;&#24863;&#22270;&#20687;&#30340;&#35821;&#20041;&#20998;&#21106;&#12290;&#27169;&#22411;&#20855;&#26377;&#26356;&#22909;&#30340;&#22806;&#25512;&#33021;&#21147;&#21644;&#21487;&#35299;&#37322;&#24615;&#65292;&#21516;&#26102;&#20855;&#26377;&#39640;&#24230;&#35299;&#32533;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2210.10418</link><description>&lt;p&gt;
p$^3$VAE&#65306;&#19968;&#20010;&#29289;&#29702;&#38598;&#25104;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#24212;&#29992;&#20110;&#20809;&#23398;&#36965;&#24863;&#22270;&#20687;&#30340;&#35821;&#20041;&#20998;&#21106;
&lt;/p&gt;
&lt;p&gt;
p$^3$VAE: a physics-integrated generative model. Application to the semantic segmentation of optical remote sensing images. (arXiv:2210.10418v3 [cs.CV] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.10418
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;p$^3$VAE&#29983;&#25104;&#27169;&#22411;&#65292;&#23427;&#23558;&#19968;&#20010;&#23436;&#32654;&#30340;&#29289;&#29702;&#27169;&#22411;&#38598;&#25104;&#21040;&#27169;&#22411;&#20013;&#65292;&#24182;&#24212;&#29992;&#20110;&#39640;&#20998;&#36776;&#29575;&#39640;&#20809;&#35889;&#36965;&#24863;&#22270;&#20687;&#30340;&#35821;&#20041;&#20998;&#21106;&#12290;&#27169;&#22411;&#20855;&#26377;&#26356;&#22909;&#30340;&#22806;&#25512;&#33021;&#21147;&#21644;&#21487;&#35299;&#37322;&#24615;&#65292;&#21516;&#26102;&#20855;&#26377;&#39640;&#24230;&#35299;&#32533;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23558;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#19982;&#29289;&#29702;&#27169;&#22411;&#30456;&#32467;&#21512;&#26159;&#23398;&#20064;&#24378;&#22823;&#25968;&#25454;&#34920;&#31034;&#30340;&#26368;&#26032;&#30740;&#31350;&#26041;&#21521;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;p$^3$VAE&#65292;&#36825;&#26159;&#19968;&#20010;&#29983;&#25104;&#27169;&#22411;&#65292;&#23427;&#38598;&#25104;&#20102;&#19968;&#20010;&#23436;&#32654;&#30340;&#29289;&#29702;&#27169;&#22411;&#65292;&#37096;&#20998;&#35299;&#37322;&#20102;&#25968;&#25454;&#20013;&#30495;&#23454;&#30340;&#21464;&#21270;&#22240;&#32032;&#12290;&#20026;&#20102;&#20805;&#20998;&#21033;&#29992;&#25105;&#20204;&#30340;&#28151;&#21512;&#35774;&#35745;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21322;&#30417;&#30563;&#20248;&#21270;&#36807;&#31243;&#21644;&#19968;&#31181;&#25512;&#26029;&#26041;&#26696;&#65292;&#21516;&#26102;&#20276;&#38543;&#30528;&#26377;&#24847;&#20041;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;&#25105;&#20204;&#23558;p$^3$VAE&#24212;&#29992;&#20110;&#39640;&#20998;&#36776;&#29575;&#39640;&#20809;&#35889;&#36965;&#24863;&#22270;&#20687;&#30340;&#35821;&#20041;&#20998;&#21106;&#12290;&#25105;&#20204;&#22312;&#19968;&#20010;&#27169;&#25311;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#19982;&#20256;&#32479;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#28151;&#21512;&#27169;&#22411;&#20855;&#26377;&#26356;&#22909;&#30340;&#22806;&#25512;&#33021;&#21147;&#21644;&#21487;&#35299;&#37322;&#24615;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;p$^3$VAE&#33258;&#28982;&#20855;&#26377;&#39640;&#24230;&#35299;&#32533;&#33021;&#21147;&#12290;&#25105;&#20204;&#30340;&#20195;&#30721;&#21644;&#25968;&#25454;&#24050;&#22312;https://github.com/Romain3Ch216/p3VAE&#19978;&#20844;&#24320;&#21457;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
The combination of machine learning models with physical models is a recent research path to learn robust data representations. In this paper, we introduce p$^3$VAE, a generative model that integrates a perfect physical model which partially explains the true underlying factors of variation in the data. To fully leverage our hybrid design, we propose a semi-supervised optimization procedure and an inference scheme that comes along meaningful uncertainty estimates. We apply p$^3$VAE to the semantic segmentation of high-resolution hyperspectral remote sensing images. Our experiments on a simulated data set demonstrated the benefits of our hybrid model against conventional machine learning models in terms of extrapolation capabilities and interpretability. In particular, we show that p$^3$VAE naturally has high disentanglement capabilities. Our code and data have been made publicly available at https://github.com/Romain3Ch216/p3VAE.
&lt;/p&gt;</description></item></channel></rss>