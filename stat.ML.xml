<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#20351;&#29992;Voronoi&#20505;&#36873;&#28857;&#36793;&#30028;&#21487;&#20197;&#22312;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#26377;&#25928;&#22320;&#20248;&#21270;&#40657;&#30418;&#20989;&#25968;&#65292;&#25552;&#39640;&#20102;&#22810;&#36215;&#22987;&#36830;&#32493;&#25628;&#32034;&#30340;&#25191;&#34892;&#26102;&#38388;&#12290;</title><link>https://arxiv.org/abs/2402.04922</link><description>&lt;p&gt;
Voronoi Candidates&#29992;&#20110;&#36125;&#21494;&#26031;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Voronoi Candidates for Bayesian Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04922
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;Voronoi&#20505;&#36873;&#28857;&#36793;&#30028;&#21487;&#20197;&#22312;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#26377;&#25928;&#22320;&#20248;&#21270;&#40657;&#30418;&#20989;&#25968;&#65292;&#25552;&#39640;&#20102;&#22810;&#36215;&#22987;&#36830;&#32493;&#25628;&#32034;&#30340;&#25191;&#34892;&#26102;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;BO&#65289;&#20026;&#39640;&#25928;&#20248;&#21270;&#40657;&#30418;&#20989;&#25968;&#25552;&#20379;&#20102;&#19968;&#31181;&#20248;&#38597;&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#37319;&#38598;&#20934;&#21017;&#38656;&#35201;&#36827;&#34892;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20869;&#37096;&#20248;&#21270;&#65292;&#36825;&#21487;&#33021;&#24341;&#36215;&#24456;&#22823;&#30340;&#24320;&#38144;&#12290;&#35768;&#22810;&#23454;&#38469;&#30340;BO&#26041;&#27861;&#65292;&#23588;&#20854;&#26159;&#22312;&#39640;&#32500;&#24773;&#20917;&#19979;&#65292;&#19981;&#37319;&#29992;&#23545;&#37319;&#38598;&#20989;&#25968;&#36827;&#34892;&#24418;&#24335;&#21270;&#36830;&#32493;&#20248;&#21270;&#65292;&#32780;&#26159;&#22312;&#26377;&#38480;&#30340;&#31354;&#38388;&#22635;&#20805;&#20505;&#36873;&#38598;&#19978;&#36827;&#34892;&#31163;&#25955;&#25628;&#32034;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#35758;&#20351;&#29992;&#20505;&#36873;&#28857;&#65292;&#20854;&#20301;&#20110;&#24403;&#21069;&#35774;&#35745;&#28857;&#30340;Voronoi&#38262;&#23884;&#36793;&#30028;&#19978;&#65292;&#22240;&#27492;&#23427;&#20204;&#19982;&#20004;&#20010;&#25110;&#22810;&#20010;&#35774;&#35745;&#28857;&#31561;&#36317;&#31163;&#12290;&#25105;&#20204;&#35752;&#35770;&#20102;&#36890;&#36807;&#30452;&#25509;&#37319;&#26679;Voronoi&#36793;&#30028;&#32780;&#19981;&#26126;&#30830;&#29983;&#25104;&#38262;&#23884;&#30340;&#31574;&#30053;&#65292;&#20174;&#32780;&#36866;&#24212;&#39640;&#32500;&#24230;&#20013;&#30340;&#22823;&#35774;&#35745;&#12290;&#36890;&#36807;&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#21644;&#26399;&#26395;&#25913;&#36827;&#26469;&#23545;&#19968;&#32452;&#27979;&#35797;&#38382;&#39064;&#36827;&#34892;&#20248;&#21270;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#19981;&#25439;&#22833;&#20934;&#30830;&#24615;&#30340;&#24773;&#20917;&#19979;&#26174;&#33879;&#25552;&#39640;&#20102;&#22810;&#36215;&#22987;&#36830;&#32493;&#25628;&#32034;&#30340;&#25191;&#34892;&#26102;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian optimization (BO) offers an elegant approach for efficiently optimizing black-box functions. However, acquisition criteria demand their own challenging inner-optimization, which can induce significant overhead. Many practical BO methods, particularly in high dimension, eschew a formal, continuous optimization of the acquisition function and instead search discretely over a finite set of space-filling candidates. Here, we propose to use candidates which lie on the boundary of the Voronoi tessellation of the current design points, so they are equidistant to two or more of them. We discuss strategies for efficient implementation by directly sampling the Voronoi boundary without explicitly generating the tessellation, thus accommodating large designs in high dimension. On a battery of test problems optimized via Gaussian processes with expected improvement, our proposed approach significantly improves the execution time of a multi-start continuous search without a loss in accuracy
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#25991;&#31456;&#20171;&#32461;&#20102;&#29992;&#20110;&#28508;&#22312;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#20013;&#30340;Vecchia-Laplace&#36817;&#20284;&#27861;&#30340;&#36845;&#20195;&#26041;&#27861;&#65292;&#30456;&#27604;&#20110;&#20256;&#32479;&#30340;Cholesky&#20998;&#35299;&#26041;&#27861;&#65292;&#21487;&#20197;&#26174;&#33879;&#21152;&#24555;&#35745;&#31639;&#36895;&#24230;&#12290;</title><link>http://arxiv.org/abs/2310.12000</link><description>&lt;p&gt;
Vecchia-Laplace&#36817;&#20284;&#27861;&#22312;&#28508;&#22312;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#20013;&#30340;&#36845;&#20195;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Iterative Methods for Vecchia-Laplace Approximations for Latent Gaussian Process Models. (arXiv:2310.12000v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12000
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#25991;&#31456;&#20171;&#32461;&#20102;&#29992;&#20110;&#28508;&#22312;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#20013;&#30340;Vecchia-Laplace&#36817;&#20284;&#27861;&#30340;&#36845;&#20195;&#26041;&#27861;&#65292;&#30456;&#27604;&#20110;&#20256;&#32479;&#30340;Cholesky&#20998;&#35299;&#26041;&#27861;&#65292;&#21487;&#20197;&#26174;&#33879;&#21152;&#24555;&#35745;&#31639;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28508;&#22312;&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#27169;&#22411;&#26159;&#28789;&#27963;&#30340;&#27010;&#29575;&#38750;&#21442;&#25968;&#20989;&#25968;&#27169;&#22411;&#12290;Vecchia&#36817;&#20284;&#26159;&#29992;&#20110;&#20811;&#26381;&#22823;&#25968;&#25454;&#35745;&#31639;&#29942;&#39048;&#30340;&#20934;&#30830;&#36817;&#20284;&#26041;&#27861;&#65292;Laplace&#36817;&#20284;&#26159;&#19968;&#31181;&#24555;&#36895;&#26041;&#27861;&#65292;&#21487;&#20197;&#36817;&#20284;&#38750;&#39640;&#26031;&#20284;&#28982;&#20989;&#25968;&#30340;&#36793;&#32536;&#20284;&#28982;&#21644;&#21518;&#39564;&#39044;&#27979;&#20998;&#24067;&#65292;&#24182;&#20855;&#26377;&#28176;&#36817;&#25910;&#25947;&#20445;&#35777;&#12290;&#28982;&#32780;&#65292;&#24403;&#19982;&#30452;&#25509;&#27714;&#35299;&#26041;&#27861;&#65288;&#22914;Cholesky&#20998;&#35299;&#65289;&#32467;&#21512;&#20351;&#29992;&#26102;&#65292;Vecchia-Laplace&#36817;&#20284;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#22686;&#38271;&#36229;&#32447;&#24615;&#22320;&#38543;&#26679;&#26412;&#22823;&#23567;&#22686;&#21152;&#12290;&#22240;&#27492;&#65292;&#19982;Vecchia-Laplace&#36817;&#20284;&#35745;&#31639;&#30456;&#20851;&#30340;&#36816;&#31639;&#22312;&#36890;&#24120;&#24773;&#20917;&#19979;&#26159;&#26368;&#20934;&#30830;&#30340;&#22823;&#22411;&#25968;&#25454;&#38598;&#26102;&#20250;&#21464;&#24471;&#38750;&#24120;&#32531;&#24930;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20960;&#31181;&#29992;&#20110;Vecchia-Laplace&#36817;&#20284;&#25512;&#26029;&#30340;&#36845;&#20195;&#26041;&#27861;&#65292;&#30456;&#27604;&#20110;&#22522;&#20110;Cholesky&#30340;&#35745;&#31639;&#65292;&#21487;&#20197;&#22823;&#22823;&#21152;&#24555;&#35745;&#31639;&#36895;&#24230;&#12290;&#25105;&#20204;&#23545;&#25105;&#20204;&#30340;&#26041;&#27861;&#36827;&#34892;&#20102;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Latent Gaussian process (GP) models are flexible probabilistic non-parametric function models. Vecchia approximations are accurate approximations for GPs to overcome computational bottlenecks for large data, and the Laplace approximation is a fast method with asymptotic convergence guarantees to approximate marginal likelihoods and posterior predictive distributions for non-Gaussian likelihoods. Unfortunately, the computational complexity of combined Vecchia-Laplace approximations grows faster than linearly in the sample size when used in combination with direct solver methods such as the Cholesky decomposition. Computations with Vecchia-Laplace approximations thus become prohibitively slow precisely when the approximations are usually the most accurate, i.e., on large data sets. In this article, we present several iterative methods for inference with Vecchia-Laplace approximations which make computations considerably faster compared to Cholesky-based calculations. We analyze our propo
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#31070;&#32463;&#32593;&#32476;&#30340;&#25554;&#20540;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#38543;&#26426;&#31639;&#27861;&#65292;&#22312;&#32473;&#23450;&#30340;&#25968;&#25454;&#38598;&#21644;&#20004;&#20010;&#31867;&#30340;&#24773;&#20917;&#19979;&#65292;&#33021;&#22815;&#20197;&#24456;&#39640;&#30340;&#27010;&#29575;&#26500;&#24314;&#19968;&#20010;&#25554;&#20540;&#30340;&#31070;&#32463;&#32593;&#32476;&#12290;&#36825;&#20123;&#32467;&#26524;&#19982;&#35757;&#32451;&#25968;&#25454;&#35268;&#27169;&#26080;&#20851;&#12290;</title><link>http://arxiv.org/abs/2310.00327</link><description>&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#30340;&#35760;&#24518;&#21270;&#65306;&#36229;&#36234;&#26368;&#22351;&#24773;&#20917;
&lt;/p&gt;
&lt;p&gt;
Memorization with neural nets: going beyond the worst case. (arXiv:2310.00327v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.00327
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#31070;&#32463;&#32593;&#32476;&#30340;&#25554;&#20540;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#38543;&#26426;&#31639;&#27861;&#65292;&#22312;&#32473;&#23450;&#30340;&#25968;&#25454;&#38598;&#21644;&#20004;&#20010;&#31867;&#30340;&#24773;&#20917;&#19979;&#65292;&#33021;&#22815;&#20197;&#24456;&#39640;&#30340;&#27010;&#29575;&#26500;&#24314;&#19968;&#20010;&#25554;&#20540;&#30340;&#31070;&#32463;&#32593;&#32476;&#12290;&#36825;&#20123;&#32467;&#26524;&#19982;&#35757;&#32451;&#25968;&#25454;&#35268;&#27169;&#26080;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23454;&#36341;&#20013;&#65292;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#36890;&#24120;&#33021;&#22815;&#36731;&#26494;&#22320;&#25554;&#20540;&#20854;&#35757;&#32451;&#25968;&#25454;&#12290;&#20026;&#20102;&#29702;&#35299;&#36825;&#19968;&#29616;&#35937;&#65292;&#35768;&#22810;&#30740;&#31350;&#37117;&#26088;&#22312;&#37327;&#21270;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#30340;&#35760;&#24518;&#33021;&#21147;&#65306;&#21363;&#22312;&#20219;&#24847;&#25918;&#32622;&#36825;&#20123;&#28857;&#24182;&#20219;&#24847;&#20998;&#37197;&#26631;&#31614;&#30340;&#24773;&#20917;&#19979;&#65292;&#26550;&#26500;&#33021;&#22815;&#25554;&#20540;&#30340;&#26368;&#22823;&#28857;&#25968;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#23454;&#38469;&#25968;&#25454;&#65292;&#20154;&#20204;&#30452;&#35273;&#22320;&#26399;&#26395;&#23384;&#22312;&#19968;&#31181;&#33391;&#24615;&#32467;&#26500;&#65292;&#20351;&#24471;&#25554;&#20540;&#22312;&#27604;&#35760;&#24518;&#33021;&#21147;&#24314;&#35758;&#30340;&#36739;&#23567;&#32593;&#32476;&#23610;&#23544;&#19978;&#24050;&#32463;&#21457;&#29983;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#37319;&#29992;&#23454;&#20363;&#29305;&#23450;&#30340;&#35266;&#28857;&#26469;&#30740;&#31350;&#25554;&#20540;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#38543;&#26426;&#31639;&#27861;&#65292;&#23427;&#21487;&#20197;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#20869;&#32473;&#23450;&#19968;&#20010;&#22266;&#23450;&#30340;&#26377;&#38480;&#25968;&#25454;&#38598;&#21644;&#20004;&#20010;&#31867;&#30340;&#24773;&#20917;&#19979;&#65292;&#20197;&#24456;&#39640;&#30340;&#27010;&#29575;&#26500;&#24314;&#20986;&#19968;&#20010;&#25554;&#20540;&#19977;&#23618;&#31070;&#32463;&#32593;&#32476;&#12290;&#25152;&#38656;&#30340;&#21442;&#25968;&#25968;&#37327;&#19982;&#36825;&#20004;&#20010;&#31867;&#30340;&#20960;&#20309;&#29305;&#24615;&#21450;&#20854;&#30456;&#20114;&#25490;&#21015;&#26377;&#20851;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#19982;&#35757;&#32451;&#25968;&#25454;&#35268;&#27169;&#26080;&#20851;&#30340;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
In practice, deep neural networks are often able to easily interpolate their training data. To understand this phenomenon, many works have aimed to quantify the memorization capacity of a neural network architecture: the largest number of points such that the architecture can interpolate any placement of these points with any assignment of labels. For real-world data, however, one intuitively expects the presence of a benign structure so that interpolation already occurs at a smaller network size than suggested by memorization capacity. In this paper, we investigate interpolation by adopting an instance-specific viewpoint. We introduce a simple randomized algorithm that, given a fixed finite dataset with two classes, with high probability constructs an interpolating three-layer neural network in polynomial time. The required number of parameters is linked to geometric properties of the two classes and their mutual arrangement. As a result, we obtain guarantees that are independent of t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#35780;&#20998;&#24046;&#24322;&#27969;&#27169;&#22411;(SD flow)&#65292;&#23427;&#21487;&#20197;&#26368;&#20248;&#22320;&#20943;&#23569;&#20004;&#20010;&#20998;&#24067;&#20043;&#38388;&#30340;&#25955;&#24230;&#65292;&#21516;&#26102;&#35299;&#20915;Schr&#8203;&#8203;&#246;dinger&#26725;&#38382;&#39064;&#12290;&#19982;&#21435;&#22122;&#25193;&#25955;&#27169;&#22411;&#19981;&#21516;&#65292;&#23427;&#27809;&#26377;&#23545;&#20808;&#39564;&#20998;&#24067;&#26045;&#21152;&#20219;&#20309;&#38480;&#21046;&#65292;&#22312;&#19968;&#20123;&#22522;&#20934;&#25968;&#25454;&#38598;&#20013;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2304.12906</link><description>&lt;p&gt;
&#35780;&#20998;&#24046;&#20540;&#27969;&#27169;&#22411;&#29992;&#20110;&#38544;&#24335;&#29983;&#25104;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
The Score-Difference Flow for Implicit Generative Modeling. (arXiv:2304.12906v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.12906
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#35780;&#20998;&#24046;&#24322;&#27969;&#27169;&#22411;(SD flow)&#65292;&#23427;&#21487;&#20197;&#26368;&#20248;&#22320;&#20943;&#23569;&#20004;&#20010;&#20998;&#24067;&#20043;&#38388;&#30340;&#25955;&#24230;&#65292;&#21516;&#26102;&#35299;&#20915;Schr&#8203;&#8203;&#246;dinger&#26725;&#38382;&#39064;&#12290;&#19982;&#21435;&#22122;&#25193;&#25955;&#27169;&#22411;&#19981;&#21516;&#65292;&#23427;&#27809;&#26377;&#23545;&#20808;&#39564;&#20998;&#24067;&#26045;&#21152;&#20219;&#20309;&#38480;&#21046;&#65292;&#22312;&#19968;&#20123;&#22522;&#20934;&#25968;&#25454;&#38598;&#20013;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38544;&#24335;&#29983;&#25104;&#24314;&#27169;(IGM)&#26088;&#22312;&#29983;&#25104;&#31526;&#21512;&#30446;&#26631;&#25968;&#25454;&#20998;&#24067;&#29305;&#24449;&#30340;&#21512;&#25104;&#25968;&#25454;&#26679;&#26412;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;(&#20363;&#22914;&#35780;&#20998;&#21305;&#37197;&#32593;&#32476;&#12289;&#25193;&#25955;&#27169;&#22411;)&#20174;&#36890;&#36807;&#29615;&#22659;&#31354;&#38388;&#20013;&#30340;&#21160;&#24577;&#25200;&#21160;&#25110;&#27969;&#23558;&#21512;&#25104;&#28304;&#25968;&#25454;&#25512;&#21521;&#30446;&#26631;&#20998;&#24067;&#30340;&#35282;&#24230;&#35299;&#20915;&#20102;IGM&#38382;&#39064;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#20219;&#24847;&#30446;&#26631;&#21644;&#28304;&#20998;&#24067;&#20043;&#38388;&#30340;&#35780;&#20998;&#24046;&#24322;(SD)&#20316;&#20026;&#27969;&#65292;&#23427;&#21487;&#20197;&#26368;&#20248;&#22320;&#20943;&#23569;&#23427;&#20204;&#20043;&#38388;&#30340;Kullback-Leibler&#25955;&#24230;&#65292;&#21516;&#26102;&#35299;&#20915;Schr&#8203;&#8203;&#246;dinger&#26725;&#38382;&#39064;&#12290;&#25105;&#20204;&#23558;SD&#27969;&#24212;&#29992;&#20110;&#26041;&#20415;&#30340;&#20195;&#29702;&#20998;&#24067;&#65292;&#24403;&#19988;&#20165;&#24403;&#21407;&#22987;&#20998;&#24067;&#23545;&#40784;&#26102;&#65292;&#23427;&#20204;&#26159;&#23545;&#40784;&#30340;&#12290;&#25105;&#20204;&#22312;&#26576;&#20123;&#26465;&#20214;&#19979;&#23637;&#31034;&#20102;&#36825;&#31181;&#20844;&#24335;&#19982;&#21435;&#22122;&#25193;&#25955;&#27169;&#22411;&#30340;&#24418;&#24335;&#19968;&#33268;&#24615;&#12290;&#28982;&#32780;&#65292;&#19982;&#25193;&#25955;&#27169;&#22411;&#19981;&#21516;&#65292;SD&#27969;&#27809;&#26377;&#23545;&#20808;&#39564;&#20998;&#24067;&#26045;&#21152;&#20219;&#20309;&#38480;&#21046;&#12290;&#25105;&#20204;&#36824;&#34920;&#26126;&#65292;&#22312;&#26080;&#38480;&#36776;&#21035;&#22120;&#33021;&#21147;&#30340;&#26497;&#38480;&#19979;&#65292;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#30340;&#35757;&#32451;&#21253;&#21547;SD&#27969;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;SD&#27969;&#22312;&#20960;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#20248;&#20110;&#20808;&#21069;&#30340;&#26368;&#26032;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
Implicit generative modeling (IGM) aims to produce samples of synthetic data matching the characteristics of a target data distribution. Recent work (e.g. score-matching networks, diffusion models) has approached the IGM problem from the perspective of pushing synthetic source data toward the target distribution via dynamical perturbations or flows in the ambient space. We introduce the score difference (SD) between arbitrary target and source distributions as a flow that optimally reduces the Kullback-Leibler divergence between them while also solving the Schr\"odinger bridge problem. We apply the SD flow to convenient proxy distributions, which are aligned if and only if the original distributions are aligned. We demonstrate the formal equivalence of this formulation to denoising diffusion models under certain conditions. However, unlike diffusion models, SD flow places no restrictions on the prior distribution. We also show that the training of generative adversarial networks includ
&lt;/p&gt;</description></item></channel></rss>