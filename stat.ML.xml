<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#21452;&#22240;&#26524;&#26368;&#20248;&#20256;&#36755;&#38382;&#39064;&#30340;&#25311;&#21512;&#20540;&#36845;&#20195;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#20445;&#35777;&#31934;&#24230;&#30340;&#21516;&#26102;&#20855;&#26377;&#33391;&#22909;&#30340;&#21487;&#25193;&#23637;&#24615;&#65292;&#25968;&#20540;&#23454;&#39564;&#32467;&#26524;&#20063;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.12658</link><description>&lt;p&gt;
&#25311;&#21512;&#20540;&#36845;&#20195;&#26041;&#27861;&#27714;&#35299;&#36866;&#24212;&#32467;&#26500;&#21452;&#22240;&#26524;&#26368;&#20248;&#20256;&#36755;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Fitted Value Iteration Methods for Bicausal Optimal Transport. (arXiv:2306.12658v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.12658
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#21452;&#22240;&#26524;&#26368;&#20248;&#20256;&#36755;&#38382;&#39064;&#30340;&#25311;&#21512;&#20540;&#36845;&#20195;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#20445;&#35777;&#31934;&#24230;&#30340;&#21516;&#26102;&#20855;&#26377;&#33391;&#22909;&#30340;&#21487;&#25193;&#23637;&#24615;&#65292;&#25968;&#20540;&#23454;&#39564;&#32467;&#26524;&#20063;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#25311;&#21512;&#20540;&#36845;&#20195;&#26041;&#27861;(FVI)&#29992;&#20110;&#35745;&#31639;&#20855;&#26377;&#36866;&#24212;&#32467;&#26500;&#30340;&#21452;&#22240;&#26524;&#26368;&#20248;&#20256;&#36755;(OT)&#12290;&#22522;&#20110;&#21160;&#24577;&#35268;&#21010;&#30340;&#24418;&#24335;&#21270;&#34920;&#36848;&#65292;FVI&#37319;&#29992;&#20989;&#25968;&#31867;&#29992;&#20110;&#36817;&#20284;&#21452;&#22240;&#26524;OT&#20013;&#30340;&#20540;&#20989;&#25968;&#12290;&#22312;&#21487;&#38598;&#20013;&#26465;&#20214;&#21644;&#36817;&#20284;&#23436;&#22791;&#24615;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#20351;&#29992;&#65288;&#23616;&#37096;&#65289;Rademacher&#22797;&#26434;&#24230;&#35777;&#26126;&#20102;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#28145;&#24230;&#22810;&#23618;&#31070;&#32463;&#32593;&#32476;&#20855;&#26377;&#36866;&#24403;&#32467;&#26500;&#65292;&#28385;&#36275;&#26679;&#26412;&#22797;&#26434;&#24230;&#35777;&#26126;&#25152;&#38656;&#30340;&#20851;&#38190;&#20551;&#35774;&#26465;&#20214;&#12290;&#25968;&#20540;&#23454;&#39564;&#34920;&#26126;&#65292;FVI&#22312;&#26102;&#38388;&#36328;&#24230;&#22686;&#21152;&#26102;&#20248;&#20110;&#32447;&#24615;&#35268;&#21010;&#21644;&#36866;&#24212;&#24615;Sinkhorn&#26041;&#27861;&#65292;&#22312;&#20445;&#25345;&#21487;&#25509;&#21463;&#31934;&#24230;&#30340;&#21516;&#26102;&#20855;&#26377;&#24456;&#22909;&#30340;&#21487;&#25193;&#23637;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We develop a fitted value iteration (FVI) method to compute bicausal optimal transport (OT) where couplings have an adapted structure. Based on the dynamic programming formulation, FVI adopts a function class to approximate the value functions in bicausal OT. Under the concentrability condition and approximate completeness assumption, we prove the sample complexity using (local) Rademacher complexity. Furthermore, we demonstrate that multilayer neural networks with appropriate structures satisfy the crucial assumptions required in sample complexity proofs. Numerical experiments reveal that FVI outperforms linear programming and adapted Sinkhorn methods in scalability as the time horizon increases, while still maintaining acceptable accuracy.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;QATS&#30340;&#26032;&#26041;&#27861;&#65292;&#29992;&#20110;&#39640;&#25928;&#35299;&#30721;&#38544;&#34255;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#24207;&#21015;&#12290;&#23427;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#20026;&#22810;&#23545;&#25968;&#21644;&#31435;&#26041;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#20855;&#26377;&#30456;&#23545;&#36739;&#23569;&#29366;&#24577;&#30340;&#22823;&#22411;HMM&#12290;</title><link>http://arxiv.org/abs/2305.18578</link><description>&lt;p&gt;
&#24555;&#36895;&#33258;&#36866;&#24212;&#19977;&#20803;&#20998;&#21106;&#65306;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#30340;&#26377;&#25928;&#35299;&#30721;&#31243;&#24207;&#12290;
&lt;/p&gt;
&lt;p&gt;
Quick Adaptive Ternary Segmentation: An Efficient Decoding Procedure For Hidden Markov Models. (arXiv:2305.18578v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18578
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;QATS&#30340;&#26032;&#26041;&#27861;&#65292;&#29992;&#20110;&#39640;&#25928;&#35299;&#30721;&#38544;&#34255;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#24207;&#21015;&#12290;&#23427;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#20026;&#22810;&#23545;&#25968;&#21644;&#31435;&#26041;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#20855;&#26377;&#30456;&#23545;&#36739;&#23569;&#29366;&#24577;&#30340;&#22823;&#22411;HMM&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#65288;HMM&#65289;&#20197;&#19981;&#21487;&#35266;&#23519;&#30340;&#65288;&#38544;&#34255;&#30340;&#65289;&#39532;&#23572;&#21487;&#22827;&#38142;&#21644;&#21487;&#35266;&#27979;&#30340;&#36807;&#31243;&#20026;&#29305;&#24449;&#65292;&#21518;&#32773;&#26159;&#38544;&#34255;&#38142;&#30340;&#22122;&#22768;&#29256;&#26412;&#12290;&#20174;&#22024;&#26434;&#30340;&#35266;&#27979;&#20013;&#35299;&#30721;&#21407;&#22987;&#20449;&#21495;&#65288;&#21363;&#38544;&#34255;&#38142;&#65289;&#26159;&#20960;&#20046;&#25152;&#26377;&#22522;&#20110;HMM&#30340;&#25968;&#25454;&#20998;&#26512;&#30340;&#20027;&#35201;&#30446;&#26631;&#12290;&#29616;&#26377;&#30340;&#35299;&#30721;&#31639;&#27861;&#65292;&#22914;&#32500;&#29305;&#27604;&#31639;&#27861;&#65292;&#22312;&#35266;&#27979;&#24207;&#21015;&#38271;&#24230;&#26368;&#22810;&#32447;&#24615;&#30340;&#24773;&#20917;&#19979;&#20855;&#26377;&#35745;&#31639;&#22797;&#26434;&#24230;&#65292;&#24182;&#19988;&#22312;&#39532;&#23572;&#21487;&#22827;&#38142;&#29366;&#24577;&#31354;&#38388;&#30340;&#22823;&#23567;&#20013;&#20855;&#26377;&#27425;&#20108;&#27425;&#35745;&#31639;&#22797;&#26434;&#24230;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#24555;&#36895;&#33258;&#36866;&#24212;&#19977;&#20803;&#20998;&#21106;&#65288;QATS&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#20998;&#32780;&#27835;&#20043;&#30340;&#36807;&#31243;&#65292;&#21487;&#22312;&#24207;&#21015;&#38271;&#24230;&#30340;&#22810;&#23545;&#25968;&#35745;&#31639;&#22797;&#26434;&#24230;&#21644;&#39532;&#23572;&#21487;&#22827;&#38142;&#29366;&#24577;&#31354;&#38388;&#30340;&#19977;&#27425;&#35745;&#31639;&#22797;&#26434;&#24230;&#19979;&#35299;&#30721;&#38544;&#34255;&#30340;&#24207;&#21015;&#65292;&#22240;&#27492;&#29305;&#21035;&#36866;&#29992;&#20110;&#20855;&#26377;&#30456;&#23545;&#36739;&#23569;&#29366;&#24577;&#30340;&#22823;&#35268;&#27169;HMM&#12290;&#35813;&#31243;&#24207;&#36824;&#24314;&#35758;&#19968;&#31181;&#26377;&#25928;&#30340;&#25968;&#25454;&#23384;&#20648;&#26041;&#24335;&#65292;&#21363;&#29305;&#23450;&#30340;&#32047;&#31215;&#24635;&#21644;&#12290;&#23454;&#36136;&#19978;&#65292;&#20272;&#35745;&#30340;&#29366;&#24577;&#24207;&#21015;&#25353;&#39034;&#24207;&#26368;&#22823;&#21270;&#23616;&#37096;&#20284;&#28982;&#12290;
&lt;/p&gt;
&lt;p&gt;
Hidden Markov models (HMMs) are characterized by an unobservable (hidden) Markov chain and an observable process, which is a noisy version of the hidden chain. Decoding the original signal (i.e., hidden chain) from the noisy observations is one of the main goals in nearly all HMM based data analyses. Existing decoding algorithms such as the Viterbi algorithm have computational complexity at best linear in the length of the observed sequence, and sub-quadratic in the size of the state space of the Markov chain. We present Quick Adaptive Ternary Segmentation (QATS), a divide-and-conquer procedure which decodes the hidden sequence in polylogarithmic computational complexity in the length of the sequence, and cubic in the size of the state space, hence particularly suited for large scale HMMs with relatively few states. The procedure also suggests an effective way of data storage as specific cumulative sums. In essence, the estimated sequence of states sequentially maximizes local likeliho
&lt;/p&gt;</description></item></channel></rss>