<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#22240;&#26524;&#21457;&#29616;&#20013;&#38598;&#25104;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#32479;&#35745;&#22240;&#26524;&#25552;&#31034;&#19982;&#30693;&#35782;&#22686;&#24378;&#30456;&#32467;&#21512;&#65292;&#21487;&#20197;&#20351;&#32479;&#35745;&#22240;&#26524;&#21457;&#29616;&#32467;&#26524;&#25509;&#36817;&#30495;&#23454;&#24773;&#20917;&#24182;&#36827;&#19968;&#27493;&#25913;&#36827;&#32467;&#26524;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01454</link><description>&lt;p&gt;
&#22312;&#22240;&#26524;&#21457;&#29616;&#20013;&#38598;&#25104;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;: &#19968;&#31181;&#32479;&#35745;&#22240;&#26524;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Integrating Large Language Models in Causal Discovery: A Statistical Causal Approach
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01454
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#22240;&#26524;&#21457;&#29616;&#20013;&#38598;&#25104;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#32479;&#35745;&#22240;&#26524;&#25552;&#31034;&#19982;&#30693;&#35782;&#22686;&#24378;&#30456;&#32467;&#21512;&#65292;&#21487;&#20197;&#20351;&#32479;&#35745;&#22240;&#26524;&#21457;&#29616;&#32467;&#26524;&#25509;&#36817;&#30495;&#23454;&#24773;&#20917;&#24182;&#36827;&#19968;&#27493;&#25913;&#36827;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23454;&#38469;&#30340;&#32479;&#35745;&#22240;&#26524;&#21457;&#29616;&#65288;SCD&#65289;&#20013;&#65292;&#23558;&#39046;&#22495;&#19987;&#23478;&#30693;&#35782;&#20316;&#20026;&#32422;&#26463;&#23884;&#20837;&#21040;&#31639;&#27861;&#20013;&#34987;&#24191;&#27867;&#25509;&#21463;&#65292;&#22240;&#20026;&#36825;&#23545;&#20110;&#21019;&#24314;&#19968;&#33268;&#26377;&#24847;&#20041;&#30340;&#22240;&#26524;&#27169;&#22411;&#26159;&#37325;&#35201;&#30340;&#65292;&#23613;&#31649;&#35782;&#21035;&#32972;&#26223;&#30693;&#35782;&#30340;&#25361;&#25112;&#34987;&#35748;&#21487;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#25361;&#25112;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22240;&#26524;&#25512;&#26029;&#26041;&#27861;&#65292;&#21363;&#36890;&#36807;&#23558;LLM&#30340;&#8220;&#32479;&#35745;&#22240;&#26524;&#25552;&#31034;&#65288;SCP&#65289;&#8221;&#19982;SCD&#26041;&#27861;&#21644;&#22522;&#20110;&#30693;&#35782;&#30340;&#22240;&#26524;&#25512;&#26029;&#65288;KBCI&#65289;&#30456;&#32467;&#21512;&#65292;&#23545;SCD&#36827;&#34892;&#20808;&#39564;&#30693;&#35782;&#22686;&#24378;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;GPT-4&#21487;&#20197;&#20351;LLM-KBCI&#30340;&#36755;&#20986;&#19982;&#24102;&#26377;LLM-KBCI&#30340;&#20808;&#39564;&#30693;&#35782;&#30340;SCD&#32467;&#26524;&#25509;&#36817;&#30495;&#23454;&#24773;&#20917;&#65292;&#22914;&#26524;GPT-4&#32463;&#21382;&#20102;SCP&#65292;&#37027;&#20040;SCD&#30340;&#32467;&#26524;&#36824;&#21487;&#20197;&#36827;&#19968;&#27493;&#25913;&#21892;&#12290;&#32780;&#19988;&#65292;&#21363;&#20351;LLM&#19981;&#21547;&#26377;&#25968;&#25454;&#38598;&#30340;&#20449;&#24687;&#65292;LLM&#20173;&#28982;&#21487;&#20197;&#36890;&#36807;&#20854;&#32972;&#26223;&#30693;&#35782;&#26469;&#25913;&#36827;SCD&#12290;
&lt;/p&gt;
&lt;p&gt;
In practical statistical causal discovery (SCD), embedding domain expert knowledge as constraints into the algorithm is widely accepted as significant for creating consistent meaningful causal models, despite the recognized challenges in systematic acquisition of the background knowledge. To overcome these challenges, this paper proposes a novel methodology for causal inference, in which SCD methods and knowledge based causal inference (KBCI) with a large language model (LLM) are synthesized through "statistical causal prompting (SCP)" for LLMs and prior knowledge augmentation for SCD. Experiments have revealed that GPT-4 can cause the output of the LLM-KBCI and the SCD result with prior knowledge from LLM-KBCI to approach the ground truth, and that the SCD result can be further improved, if GPT-4 undergoes SCP. Furthermore, it has been clarified that an LLM can improve SCD with its background knowledge, even if the LLM does not contain information on the dataset. The proposed approach
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#38750;&#32447;&#24615;&#27169;&#22411;&#30340;&#39044;&#27979;&#30446;&#26631;&#23548;&#21521;&#26368;&#20248;&#23454;&#39564;&#35774;&#35745;&#26041;&#27861;&#65292;&#36890;&#36807;&#26368;&#22823;&#21270;QoIs&#30340;&#26399;&#26395;&#20449;&#24687;&#22686;&#30410;&#26469;&#30830;&#23450;&#23454;&#39564;&#35774;&#35745;&#12290;</title><link>https://arxiv.org/abs/2403.18072</link><description>&lt;p&gt;
&#38750;&#32447;&#24615;&#27169;&#22411;&#30340;&#30446;&#26631;&#23548;&#21521;&#36125;&#21494;&#26031;&#26368;&#20248;&#23454;&#39564;&#35774;&#35745;&#19982;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Goal-Oriented Bayesian Optimal Experimental Design for Nonlinear Models using Markov Chain Monte Carlo
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18072
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#38750;&#32447;&#24615;&#27169;&#22411;&#30340;&#39044;&#27979;&#30446;&#26631;&#23548;&#21521;&#26368;&#20248;&#23454;&#39564;&#35774;&#35745;&#26041;&#27861;&#65292;&#36890;&#36807;&#26368;&#22823;&#21270;QoIs&#30340;&#26399;&#26395;&#20449;&#24687;&#22686;&#30410;&#26469;&#30830;&#23450;&#23454;&#39564;&#35774;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#20248;&#23454;&#39564;&#35774;&#35745;&#65288;OED&#65289;&#25552;&#20379;&#20102;&#19968;&#31181;&#31995;&#32479;&#21270;&#30340;&#26041;&#27861;&#26469;&#37327;&#21270;&#21644;&#26368;&#22823;&#21270;&#23454;&#39564;&#25968;&#25454;&#30340;&#20215;&#20540;&#12290;&#22312;&#36125;&#21494;&#26031;&#26041;&#27861;&#19979;&#65292;&#20256;&#32479;&#30340;OED&#20250;&#26368;&#22823;&#21270;&#23545;&#27169;&#22411;&#21442;&#25968;&#30340;&#26399;&#26395;&#20449;&#24687;&#22686;&#30410;&#65288;EIG&#65289;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#36890;&#24120;&#24863;&#20852;&#36259;&#30340;&#19981;&#26159;&#21442;&#25968;&#26412;&#36523;&#65292;&#32780;&#26159;&#20381;&#36182;&#20110;&#21442;&#25968;&#30340;&#38750;&#32447;&#24615;&#26041;&#24335;&#30340;&#39044;&#27979;&#24863;&#20852;&#36259;&#37327;&#65288;QoIs&#65289;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#36866;&#29992;&#20110;&#38750;&#32447;&#24615;&#35266;&#27979;&#21644;&#39044;&#27979;&#27169;&#22411;&#30340;&#39044;&#27979;&#30446;&#26631;&#23548;&#21521;OED&#65288;GO-OED&#65289;&#30340;&#35745;&#31639;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#23547;&#27714;&#25552;&#20379;&#23545;QoIs&#30340;&#26368;&#22823;EIG&#30340;&#23454;&#39564;&#35774;&#35745;&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#29992;&#20110;QoI EIG&#30340;&#23884;&#22871;&#33945;&#29305;&#21345;&#27931;&#20272;&#35745;&#22120;&#65292;&#20854;&#20013;&#37319;&#29992;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#36827;&#34892;&#21518;&#39564;&#37319;&#26679;&#65292;&#21033;&#29992;&#26680;&#23494;&#24230;&#20272;&#35745;&#26469;&#35780;&#20272;&#21518;&#39564;&#39044;&#27979;&#23494;&#24230;&#21450;&#20854;&#19982;&#20808;&#39564;&#39044;&#27979;&#20043;&#38388;&#30340;Kullback-Leibler&#25955;&#24230;&#12290;GO-OED&#35774;&#35745;&#36890;&#36807;&#22312;&#35774;&#35745;&#31354;&#38388;&#20013;&#26368;&#22823;&#21270;EIG&#26469;&#33719;&#24471;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18072v1 Announce Type: cross  Abstract: Optimal experimental design (OED) provides a systematic approach to quantify and maximize the value of experimental data. Under a Bayesian approach, conventional OED maximizes the expected information gain (EIG) on model parameters. However, we are often interested in not the parameters themselves, but predictive quantities of interest (QoIs) that depend on the parameters in a nonlinear manner. We present a computational framework of predictive goal-oriented OED (GO-OED) suitable for nonlinear observation and prediction models, which seeks the experimental design providing the greatest EIG on the QoIs. In particular, we propose a nested Monte Carlo estimator for the QoI EIG, featuring Markov chain Monte Carlo for posterior sampling and kernel density estimation for evaluating the posterior-predictive density and its Kullback-Leibler divergence from the prior-predictive. The GO-OED design is then found by maximizing the EIG over the des
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#25552;&#20986;&#30340;&#20004;&#38454;&#27573;&#8220;&#30417;&#30563;&#24494;&#35843;+&#20154;&#31867;&#27604;&#36739;&#8221;&#26694;&#26550;&#65292;&#26412;&#25991;&#30740;&#31350;&#20102;&#22914;&#20309;&#26377;&#25928;&#21033;&#29992;&#20154;&#31867;&#27604;&#36739;&#26469;&#25913;&#21892;AI&#27169;&#22411;&#30340;&#23545;&#40784;&#65292;&#29305;&#21035;&#26159;&#22312;&#38754;&#23545;&#22024;&#26434;&#25968;&#25454;&#21644;&#39640;&#32500;&#27169;&#22411;&#26102;&#12290;</title><link>https://arxiv.org/abs/2403.10771</link><description>&lt;p&gt;
&#19968;&#31181;&#22522;&#20110;&#27010;&#29575;&#30340;&#20154;&#31867;&#27604;&#36739;&#23545;&#40784;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Probabilistic Approach for Alignment with Human Comparisons
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10771
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#25552;&#20986;&#30340;&#20004;&#38454;&#27573;&#8220;&#30417;&#30563;&#24494;&#35843;+&#20154;&#31867;&#27604;&#36739;&#8221;&#26694;&#26550;&#65292;&#26412;&#25991;&#30740;&#31350;&#20102;&#22914;&#20309;&#26377;&#25928;&#21033;&#29992;&#20154;&#31867;&#27604;&#36739;&#26469;&#25913;&#21892;AI&#27169;&#22411;&#30340;&#23545;&#40784;&#65292;&#29305;&#21035;&#26159;&#22312;&#38754;&#23545;&#22024;&#26434;&#25968;&#25454;&#21644;&#39640;&#32500;&#27169;&#22411;&#26102;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19968;&#20010;&#22686;&#38271;&#30340;&#36235;&#21183;&#26159;&#23558;&#20154;&#31867;&#30693;&#35782;&#25972;&#21512;&#21040;&#23398;&#20064;&#26694;&#26550;&#20013;&#65292;&#21033;&#29992;&#24494;&#22937;&#30340;&#20154;&#31867;&#21453;&#39304;&#26469;&#23436;&#21892;AI&#27169;&#22411;&#12290;&#23613;&#31649;&#21462;&#24471;&#20102;&#36825;&#20123;&#36827;&#23637;&#65292;&#20294;&#23578;&#26410;&#24320;&#21457;&#20986;&#25551;&#36848;&#20154;&#31867;&#27604;&#36739;&#20309;&#26102;&#25913;&#21892;&#20256;&#32479;&#30417;&#30563;&#24494;&#35843;&#36807;&#31243;&#30340;&#29305;&#23450;&#26465;&#20214;&#30340;&#20840;&#38754;&#29702;&#35770;&#26694;&#26550;&#12290;&#20026;&#24357;&#34917;&#36825;&#19968;&#24046;&#36317;&#65292;&#26412;&#25991;&#30740;&#31350;&#20102;&#26377;&#25928;&#21033;&#29992;&#20154;&#31867;&#27604;&#36739;&#26469;&#35299;&#20915;&#30001;&#22024;&#26434;&#25968;&#25454;&#21644;&#39640;&#32500;&#27169;&#22411;&#24341;&#36215;&#30340;&#38480;&#21046;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#23558;&#26426;&#22120;&#23398;&#20064;&#19982;&#20154;&#31867;&#21453;&#39304;&#36890;&#36807;&#27010;&#29575;&#20108;&#20998;&#26041;&#27861;&#32852;&#31995;&#36215;&#26469;&#30340;&#20004;&#38454;&#27573;&#8220;&#30417;&#30563;&#24494;&#35843;+&#20154;&#31867;&#27604;&#36739;&#8221;&#65288;SFT+HC&#65289;&#26694;&#26550;&#12290;&#36825;&#20004;&#38454;&#27573;&#26694;&#26550;&#39318;&#20808;&#36890;&#36807;SFT&#36807;&#31243;&#20174;&#24102;&#26377;&#22122;&#22768;&#26631;&#35760;&#30340;&#25968;&#25454;&#20013;&#23398;&#20064;&#20302;&#32500;&#34920;&#31034;&#65292;&#28982;&#21518;&#21033;&#29992;&#20154;&#31867;&#27604;&#36739;&#26469;&#25913;&#36827;&#27169;&#22411;&#23545;&#40784;&#12290;&#20026;&#20102;&#26816;&#39564;&#23545;&#40784;&#38454;&#27573;&#30340;&#25928;&#21147;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#27010;&#24565;&#65292;&#31216;&#20026;&#8220;&#26631;&#31614;&#22122;&#22768;&#21040;&#19968;&#33268;&#24615;&#8221;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10771v1 Announce Type: new  Abstract: A growing trend involves integrating human knowledge into learning frameworks, leveraging subtle human feedback to refine AI models. Despite these advances, no comprehensive theoretical framework describing the specific conditions under which human comparisons improve the traditional supervised fine-tuning process has been developed. To bridge this gap, this paper studies the effective use of human comparisons to address limitations arising from noisy data and high-dimensional models. We propose a two-stage "Supervised Fine Tuning+Human Comparison" (SFT+HC) framework connecting machine learning with human feedback through a probabilistic bisection approach. The two-stage framework first learns low-dimensional representations from noisy-labeled data via an SFT procedure, and then uses human comparisons to improve the model alignment. To examine the efficacy of the alignment phase, we introduce a novel concept termed the "label-noise-to-co
&lt;/p&gt;</description></item><item><title>&#28145;&#39532;&#36420;&#39640;&#26031;&#36807;&#31243;Deep-HGP&#26159;&#19968;&#31181;&#31616;&#21333;&#30340;&#20808;&#39564;&#65292;&#37319;&#29992;&#28145;&#39640;&#26031;&#36807;&#31243;&#24182;&#20801;&#35768;&#25968;&#25454;&#39537;&#21160;&#36873;&#25321;&#20851;&#38190;&#38271;&#24230;&#23610;&#24230;&#21442;&#25968;&#65292;&#23545;&#20110;&#38750;&#21442;&#25968;&#22238;&#24402;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#24615;&#33021;&#65292;&#23454;&#29616;&#20102;&#23545;&#26410;&#30693;&#30495;&#23454;&#22238;&#24402;&#26354;&#32447;&#30340;&#20248;&#21270;&#22238;&#22797;&#65292;&#20855;&#26377;&#33258;&#36866;&#24212;&#30340;&#25910;&#25947;&#36895;&#29575;&#12290;</title><link>https://arxiv.org/abs/2403.01737</link><description>&lt;p&gt;
&#28145;&#39532;&#36420;&#39640;&#26031;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Deep Horseshoe Gaussian Processes
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.01737
&lt;/p&gt;
&lt;p&gt;
&#28145;&#39532;&#36420;&#39640;&#26031;&#36807;&#31243;Deep-HGP&#26159;&#19968;&#31181;&#31616;&#21333;&#30340;&#20808;&#39564;&#65292;&#37319;&#29992;&#28145;&#39640;&#26031;&#36807;&#31243;&#24182;&#20801;&#35768;&#25968;&#25454;&#39537;&#21160;&#36873;&#25321;&#20851;&#38190;&#38271;&#24230;&#23610;&#24230;&#21442;&#25968;&#65292;&#23545;&#20110;&#38750;&#21442;&#25968;&#22238;&#24402;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#24615;&#33021;&#65292;&#23454;&#29616;&#20102;&#23545;&#26410;&#30693;&#30495;&#23454;&#22238;&#24402;&#26354;&#32447;&#30340;&#20248;&#21270;&#22238;&#22797;&#65292;&#20855;&#26377;&#33258;&#36866;&#24212;&#30340;&#25910;&#25947;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#25552;&#20986;&#28145;&#39640;&#26031;&#36807;&#31243;&#20316;&#20026;&#19968;&#31181;&#33258;&#28982;&#23545;&#35937;&#65292;&#31867;&#20284;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65292;&#21487;&#33021;&#25311;&#21512;&#29616;&#20195;&#25968;&#25454;&#26679;&#26412;&#20013;&#23384;&#22312;&#30340;&#22797;&#26434;&#29305;&#24449;&#65292;&#22914;&#32452;&#21512;&#32467;&#26500;&#12290;&#37319;&#29992;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#26041;&#27861;&#65292;&#33258;&#28982;&#22320;&#21033;&#29992;&#28145;&#39640;&#26031;&#36807;&#31243;&#20316;&#20026;&#20808;&#39564;&#20998;&#24067;&#65292;&#24182;&#23558;&#30456;&#24212;&#30340;&#21518;&#39564;&#20998;&#24067;&#29992;&#20110;&#32479;&#35745;&#25512;&#26029;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;&#28145;&#39532;&#36420;&#39640;&#26031;&#36807;&#31243;Deep-HGP&#65292;&#36825;&#26159;&#19968;&#31181;&#22522;&#20110;&#24102;&#26377;&#24179;&#26041;&#25351;&#25968;&#26680;&#30340;&#28145;&#39640;&#26031;&#36807;&#31243;&#30340;&#26032;&#31616;&#21333;&#20808;&#39564;&#65292;&#29305;&#21035;&#26159;&#20351;&#24471;&#21487;&#20197;&#23545;&#20851;&#38190;&#38271;&#24230;&#23610;&#24230;&#21442;&#25968;&#36827;&#34892;&#25968;&#25454;&#39537;&#21160;&#36873;&#25321;&#12290;&#23545;&#20110;&#38543;&#26426;&#35774;&#35745;&#30340;&#38750;&#21442;&#25968;&#22238;&#24402;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#30456;&#24212;&#30340;&#35843;&#33410;&#21518;&#39564;&#20998;&#24067;&#20197;&#19968;&#31181;&#33258;&#36866;&#24212;&#26041;&#24335;&#65292;&#26368;&#20248;&#22320;&#22312;&#20108;&#27425;&#25439;&#22833;&#30340;&#24847;&#20041;&#19979;&#24674;&#22797;&#26410;&#30693;&#30340;&#30495;&#22238;&#24402;&#26354;&#32447;&#65292;&#26368;&#22810;&#21482;&#26377;&#19968;&#20010;&#23545;&#25968;&#22240;&#23376;&#12290;&#25910;&#25947;&#36895;&#29575;&#21516;&#26102;&#23545;&#22238;&#24402;&#30340;&#24179;&#28369;&#24230;&#21644;&#35774;&#35745;&#32500;&#24230;&#33258;&#36866;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01737v1 Announce Type: cross  Abstract: Deep Gaussian processes have recently been proposed as natural objects to fit, similarly to deep neural networks, possibly complex features present in modern data samples, such as compositional structures. Adopting a Bayesian nonparametric approach, it is natural to use deep Gaussian processes as prior distributions, and use the corresponding posterior distributions for statistical inference. We introduce the deep Horseshoe Gaussian process Deep-HGP, a new simple prior based on deep Gaussian processes with a squared-exponential kernel, that in particular enables data-driven choices of the key lengthscale parameters. For nonparametric regression with random design, we show that the associated tempered posterior distribution recovers the unknown true regression curve optimally in terms of quadratic loss, up to a logarithmic factor, in an adaptive way. The convergence rates are simultaneously adaptive to both the smoothness of the regress
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#20272;&#35745;&#26041;&#27861;&#65292;&#36890;&#36807;&#21152;&#26435;&#28378;&#21160;&#39564;&#35777;&#36807;&#31243;&#26469;&#25552;&#39640;&#22522;&#26412;&#20272;&#35745;&#22120;&#30340;&#33258;&#36866;&#24212;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#30340;&#37325;&#35201;&#24615;&#21644;&#25935;&#24863;&#24615;</title><link>http://arxiv.org/abs/2310.12140</link><description>&lt;p&gt;
&#22312;&#32447;&#20272;&#35745;&#19982;&#28378;&#21160;&#39564;&#35777;&#65306;&#36866;&#24212;&#24615;&#38750;&#21442;&#25968;&#20272;&#35745;&#19982;&#25968;&#25454;&#27969;
&lt;/p&gt;
&lt;p&gt;
Online Estimation with Rolling Validation: Adaptive Nonparametric Estimation with Stream Data. (arXiv:2310.12140v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12140
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#20272;&#35745;&#26041;&#27861;&#65292;&#36890;&#36807;&#21152;&#26435;&#28378;&#21160;&#39564;&#35777;&#36807;&#31243;&#26469;&#25552;&#39640;&#22522;&#26412;&#20272;&#35745;&#22120;&#30340;&#33258;&#36866;&#24212;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#30340;&#37325;&#35201;&#24615;&#21644;&#25935;&#24863;&#24615;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#20854;&#39640;&#25928;&#35745;&#31639;&#21644;&#31454;&#20105;&#24615;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#22312;&#32447;&#38750;&#21442;&#25968;&#20272;&#35745;&#22120;&#36234;&#26469;&#36234;&#21463;&#27426;&#36814;&#12290;&#19968;&#20010;&#37325;&#35201;&#30340;&#20363;&#23376;&#26159;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#21464;&#20307;&#12290;&#36825;&#20123;&#31639;&#27861;&#36890;&#24120;&#19968;&#27425;&#21482;&#21462;&#19968;&#20010;&#26679;&#26412;&#28857;&#65292;&#24182;&#31435;&#21363;&#26356;&#26032;&#24863;&#20852;&#36259;&#30340;&#21442;&#25968;&#20272;&#35745;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#36825;&#20123;&#22312;&#32447;&#31639;&#27861;&#30340;&#27169;&#22411;&#36873;&#25321;&#21644;&#36229;&#21442;&#25968;&#35843;&#25972;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21152;&#26435;&#28378;&#21160;&#39564;&#35777;&#36807;&#31243;&#65292;&#19968;&#31181;&#22312;&#32447;&#30340;&#30041;&#19968;&#20132;&#21449;&#39564;&#35777;&#21464;&#20307;&#65292;&#23545;&#20110;&#35768;&#22810;&#20856;&#22411;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#20272;&#35745;&#22120;&#26469;&#35828;&#65292;&#39069;&#22806;&#30340;&#35745;&#31639;&#25104;&#26412;&#26368;&#23567;&#12290;&#31867;&#20284;&#20110;&#25209;&#37327;&#20132;&#21449;&#39564;&#35777;&#65292;&#23427;&#21487;&#20197;&#25552;&#21319;&#22522;&#26412;&#20272;&#35745;&#22120;&#30340;&#33258;&#36866;&#24212;&#25910;&#25947;&#36895;&#24230;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#20998;&#26512;&#24456;&#31616;&#21333;&#65292;&#20027;&#35201;&#20381;&#36182;&#20110;&#19968;&#20123;&#19968;&#33324;&#30340;&#32479;&#35745;&#31283;&#23450;&#24615;&#20551;&#35774;&#12290;&#27169;&#25311;&#30740;&#31350;&#24378;&#35843;&#20102;&#28378;&#21160;&#39564;&#35777;&#20013;&#21457;&#25955;&#26435;&#37325;&#22312;&#23454;&#36341;&#20013;&#30340;&#37325;&#35201;&#24615;&#65292;&#24182;&#35777;&#26126;&#20102;&#21363;&#20351;&#21482;&#26377;&#19968;&#20010;&#24456;&#23567;&#30340;&#20559;&#24046;&#65292;&#23427;&#30340;&#25935;&#24863;&#24615;&#20063;&#24456;&#39640;
&lt;/p&gt;
&lt;p&gt;
Online nonparametric estimators are gaining popularity due to their efficient computation and competitive generalization abilities. An important example includes variants of stochastic gradient descent. These algorithms often take one sample point at a time and instantly update the parameter estimate of interest. In this work we consider model selection and hyperparameter tuning for such online algorithms. We propose a weighted rolling-validation procedure, an online variant of leave-one-out cross-validation, that costs minimal extra computation for many typical stochastic gradient descent estimators. Similar to batch cross-validation, it can boost base estimators to achieve a better, adaptive convergence rate. Our theoretical analysis is straightforward, relying mainly on some general statistical stability assumptions. The simulation study underscores the significance of diverging weights in rolling validation in practice and demonstrates its sensitivity even when there is only a slim
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#33021;&#37327;&#23548;&#21521;&#30340;&#26041;&#27861;&#29992;&#20110;&#36817;&#20284;&#35745;&#31639;&#20219;&#24847;OT&#25104;&#26412;&#20989;&#25968;&#30340;&#36830;&#32493;&#29109;OT&#24052;&#27663;&#20013;&#24515;&#65292;&#35813;&#26041;&#27861;&#20855;&#26377;&#20248;&#36234;&#30340;&#24615;&#33021;&#65292;&#24182;&#19988;&#33021;&#19982;&#22522;&#20110;&#33021;&#37327;&#30340;&#27169;&#22411;&#65288;EBMs&#65289;&#23398;&#20064;&#36807;&#31243;&#26080;&#32541;&#36830;&#25509;&#12290;</title><link>http://arxiv.org/abs/2310.01105</link><description>&lt;p&gt;
&#22522;&#20110;&#33021;&#37327;&#23548;&#21521;&#30340;&#36830;&#32493;&#29109;&#24052;&#27663;&#20013;&#24515;&#20272;&#35745;&#26041;&#27861;&#21450;&#20854;&#22312;&#19968;&#33324;&#25104;&#26412;&#38382;&#39064;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Energy-Guided Continuous Entropic Barycenter Estimation for General Costs. (arXiv:2310.01105v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.01105
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#33021;&#37327;&#23548;&#21521;&#30340;&#26041;&#27861;&#29992;&#20110;&#36817;&#20284;&#35745;&#31639;&#20219;&#24847;OT&#25104;&#26412;&#20989;&#25968;&#30340;&#36830;&#32493;&#29109;OT&#24052;&#27663;&#20013;&#24515;&#65292;&#35813;&#26041;&#27861;&#20855;&#26377;&#20248;&#36234;&#30340;&#24615;&#33021;&#65292;&#24182;&#19988;&#33021;&#19982;&#22522;&#20110;&#33021;&#37327;&#30340;&#27169;&#22411;&#65288;EBMs&#65289;&#23398;&#20064;&#36807;&#31243;&#26080;&#32541;&#36830;&#25509;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20248;&#21270;&#36755;&#36816;&#65288;OT&#65289;&#24052;&#27663;&#20013;&#24515;&#26159;&#19968;&#31181;&#22312;&#25429;&#25417;&#27010;&#29575;&#20998;&#24067;&#20960;&#20309;&#29305;&#24615;&#30340;&#21516;&#26102;&#23545;&#20854;&#36827;&#34892;&#24179;&#22343;&#30340;&#25968;&#23398;&#26041;&#27861;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#36817;&#20284;&#35745;&#31639;&#20219;&#24847;OT&#25104;&#26412;&#20989;&#25968;&#30340;&#36830;&#32493;&#29109;OT&#24052;&#27663;&#20013;&#24515;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#26368;&#36817;&#22312;&#26426;&#22120;&#23398;&#20064;&#31038;&#21306;&#20013;&#21463;&#21040;&#20851;&#27880;&#30340;&#22522;&#20110;&#24369;OT&#30340;&#36830;&#32493;&#29109;&#26368;&#20248;&#36755;&#36816;&#38382;&#39064;&#30340;&#23545;&#20598;&#37325;&#26500;&#12290;&#38500;&#20102;&#21019;&#26032;&#24615;&#20043;&#22806;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#36824;&#20855;&#26377;&#20197;&#19979;&#33509;&#24178;&#20248;&#21183;&#29305;&#28857;&#65306;&#65288;i&#65289;&#25105;&#20204;&#24314;&#31435;&#20102;&#23545;&#24674;&#22797;&#35299;&#30340;&#36136;&#37327;&#30028;&#38480;&#65307;&#65288;ii&#65289;&#35813;&#26041;&#27861;&#19982;&#22522;&#20110;&#33021;&#37327;&#30340;&#27169;&#22411;&#65288;EBMs&#65289;&#23398;&#20064;&#36807;&#31243;&#26080;&#32541;&#36830;&#25509;&#65292;&#21487;&#20197;&#20351;&#29992;&#32463;&#36807;&#33391;&#22909;&#35843;&#25972;&#30340;&#31639;&#27861;&#35299;&#20915;&#24863;&#20852;&#36259;&#30340;&#38382;&#39064;&#65307;&#65288;iii&#65289;&#23427;&#25552;&#20379;&#20102;&#19968;&#31181;&#30452;&#35266;&#30340;&#20248;&#21270;&#26041;&#26696;&#65292;&#36991;&#20813;&#20351;&#29992;&#26497;&#23567;-&#26497;&#22823;&#12289;&#24378;&#21270;&#31561;&#22797;&#26434;&#25216;&#24039;&#12290;&#20026;&#20102;&#39564;&#35777;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;s
&lt;/p&gt;
&lt;p&gt;
Optimal transport (OT) barycenters are a mathematically grounded way of averaging probability distributions while capturing their geometric properties. In short, the barycenter task is to take the average of a collection of probability distributions w.r.t. given OT discrepancies. We propose a novel algorithm for approximating the continuous Entropic OT (EOT) barycenter for arbitrary OT cost functions. Our approach is built upon the dual reformulation of the EOT problem based on weak OT, which has recently gained the attention of the ML community. Beyond its novelty, our method enjoys several advantageous properties: (i) we establish quality bounds for the recovered solution; (ii) this approach seemlessly interconnects with the Energy-Based Models (EBMs) learning procedure enabling the use of well-tuned algorithms for the problem of interest; (iii) it provides an intuitive optimization scheme avoiding min-max, reinforce and other intricate technical tricks. For validation, we consider s
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#21517;&#20026;&#23454;&#20363;&#33258;&#36866;&#24212;&#32858;&#31867;&#65288;IAC&#65289;&#65292;&#23427;&#33021;&#22815;&#22312;&#26631;&#35760;&#38543;&#26426;&#22359;&#27169;&#22411;&#65288;LSBM&#65289;&#20013;&#24674;&#22797;&#38544;&#34255;&#30340;&#32676;&#38598;&#12290;IAC&#21253;&#25324;&#19968;&#27425;&#35889;&#32858;&#31867;&#21644;&#19968;&#20010;&#36845;&#20195;&#30340;&#22522;&#20110;&#20284;&#28982;&#30340;&#31751;&#20998;&#37197;&#25913;&#36827;&#65292;&#19981;&#38656;&#35201;&#20219;&#20309;&#27169;&#22411;&#21442;&#25968;&#65292;&#26159;&#39640;&#25928;&#30340;&#12290;</title><link>http://arxiv.org/abs/2306.12968</link><description>&lt;p&gt;
&#26631;&#35760;&#38543;&#26426;&#22359;&#27169;&#22411;&#20013;&#30340;&#26368;&#20248;&#31751;&#24674;&#22797;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Instance-Optimal Cluster Recovery in the Labeled Stochastic Block Model. (arXiv:2306.12968v1 [cs.SI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.12968
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#21517;&#20026;&#23454;&#20363;&#33258;&#36866;&#24212;&#32858;&#31867;&#65288;IAC&#65289;&#65292;&#23427;&#33021;&#22815;&#22312;&#26631;&#35760;&#38543;&#26426;&#22359;&#27169;&#22411;&#65288;LSBM&#65289;&#20013;&#24674;&#22797;&#38544;&#34255;&#30340;&#32676;&#38598;&#12290;IAC&#21253;&#25324;&#19968;&#27425;&#35889;&#32858;&#31867;&#21644;&#19968;&#20010;&#36845;&#20195;&#30340;&#22522;&#20110;&#20284;&#28982;&#30340;&#31751;&#20998;&#37197;&#25913;&#36827;&#65292;&#19981;&#38656;&#35201;&#20219;&#20309;&#27169;&#22411;&#21442;&#25968;&#65292;&#26159;&#39640;&#25928;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#22312;&#26377;&#38480;&#25968;&#37327;&#30340;&#31751;&#30340;&#24773;&#20917;&#19979;&#65292;&#29992;&#26631;&#35760;&#38543;&#26426;&#22359;&#27169;&#22411;&#65288;LSBM&#65289;&#24674;&#22797;&#38544;&#34255;&#30340;&#31038;&#32676;&#65292;&#20854;&#20013;&#31751;&#22823;&#23567;&#38543;&#30528;&#29289;&#21697;&#24635;&#25968;$n$&#30340;&#22686;&#38271;&#32780;&#32447;&#24615;&#22686;&#38271;&#12290;&#22312;LSBM&#20013;&#65292;&#20026;&#27599;&#23545;&#29289;&#21697;&#65288;&#29420;&#31435;&#22320;&#65289;&#35266;&#27979;&#21040;&#19968;&#20010;&#26631;&#31614;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#35774;&#35745;&#19968;&#31181;&#26377;&#25928;&#30340;&#31639;&#27861;&#65292;&#21033;&#29992;&#35266;&#27979;&#21040;&#30340;&#26631;&#31614;&#26469;&#24674;&#22797;&#31751;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#37325;&#26032;&#23457;&#35270;&#20102;&#20851;&#20110;&#26399;&#26395;&#34987;&#20219;&#20309;&#32858;&#31867;&#31639;&#27861;&#35823;&#20998;&#31867;&#30340;&#29289;&#21697;&#25968;&#37327;&#30340;&#23454;&#20363;&#29305;&#23450;&#19979;&#30028;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#23454;&#20363;&#33258;&#36866;&#24212;&#32858;&#31867;&#65288;IAC&#65289;&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#22312;&#26399;&#26395;&#21644;&#39640;&#27010;&#29575;&#19979;&#37117;&#33021;&#21305;&#37197;&#36825;&#20123;&#19979;&#30028;&#34920;&#29616;&#30340;&#31639;&#27861;&#12290;IAC&#30001;&#19968;&#27425;&#35889;&#32858;&#31867;&#31639;&#27861;&#21644;&#19968;&#20010;&#36845;&#20195;&#30340;&#22522;&#20110;&#20284;&#28982;&#30340;&#31751;&#20998;&#37197;&#25913;&#36827;&#32452;&#25104;&#12290;&#36825;&#31181;&#26041;&#27861;&#22522;&#20110;&#23454;&#20363;&#29305;&#23450;&#30340;&#19979;&#30028;&#65292;&#19981;&#38656;&#35201;&#20219;&#20309;&#27169;&#22411;&#21442;&#25968;&#65292;&#21253;&#25324;&#31751;&#30340;&#25968;&#37327;&#12290;&#36890;&#36807;&#20165;&#25191;&#34892;&#19968;&#27425;&#35889;&#32858;&#31867;&#65292;IAC&#22312;&#35745;&#31639;&#21644;&#23384;&#20648;&#26041;&#38754;&#37117;&#26159;&#39640;&#25928;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of recovering hidden communities in the Labeled Stochastic Block Model (LSBM) with a finite number of clusters, where cluster sizes grow linearly with the total number $n$ of items. In the LSBM, a label is (independently) observed for each pair of items. Our objective is to devise an efficient algorithm that recovers clusters using the observed labels. To this end, we revisit instance-specific lower bounds on the expected number of misclassified items satisfied by any clustering algorithm. We present Instance-Adaptive Clustering (IAC), the first algorithm whose performance matches these lower bounds both in expectation and with high probability. IAC consists of a one-time spectral clustering algorithm followed by an iterative likelihood-based cluster assignment improvement. This approach is based on the instance-specific lower bound and does not require any model parameters, including the number of clusters. By performing the spectral clustering only once, IAC m
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#21151;&#33021;&#24615;&#36755;&#20837;&#31070;&#32463;&#32593;&#32476;&#65292;&#21487;&#20197;&#22312;&#24102;&#26435;&#37325;&#31354;&#38388;&#19978;&#23436;&#25104;&#20840;&#23616;&#20989;&#25968;&#36924;&#36817;&#12290;&#36825;&#19968;&#26041;&#27861;&#36866;&#29992;&#20110;&#36830;&#32493;&#20989;&#25968;&#30340;&#25512;&#24191;&#65292;&#36824;&#21487;&#29992;&#20110;&#36335;&#24452;&#31354;&#38388;&#20989;&#25968;&#30340;&#36924;&#36817;&#65292;&#21516;&#26102;&#20063;&#21487;&#20197;&#36924;&#36817;&#32447;&#24615;&#20989;&#25968;&#31614;&#21517;&#12290;</title><link>http://arxiv.org/abs/2306.03303</link><description>&lt;p&gt;
&#24102;&#26435;&#37325;&#31354;&#38388;&#19978;&#21151;&#33021;&#24615;&#36755;&#20837;&#26144;&#23556;&#30340;&#20840;&#23616;&#26222;&#36866;&#36924;&#36817;
&lt;/p&gt;
&lt;p&gt;
Global universal approximation of functional input maps on weighted spaces. (arXiv:2306.03303v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.03303
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#21151;&#33021;&#24615;&#36755;&#20837;&#31070;&#32463;&#32593;&#32476;&#65292;&#21487;&#20197;&#22312;&#24102;&#26435;&#37325;&#31354;&#38388;&#19978;&#23436;&#25104;&#20840;&#23616;&#20989;&#25968;&#36924;&#36817;&#12290;&#36825;&#19968;&#26041;&#27861;&#36866;&#29992;&#20110;&#36830;&#32493;&#20989;&#25968;&#30340;&#25512;&#24191;&#65292;&#36824;&#21487;&#29992;&#20110;&#36335;&#24452;&#31354;&#38388;&#20989;&#25968;&#30340;&#36924;&#36817;&#65292;&#21516;&#26102;&#20063;&#21487;&#20197;&#36924;&#36817;&#32447;&#24615;&#20989;&#25968;&#31614;&#21517;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#25152;&#35859;&#30340;&#21151;&#33021;&#24615;&#36755;&#20837;&#31070;&#32463;&#32593;&#32476;&#65292;&#23450;&#20041;&#22312;&#21487;&#33021;&#26159;&#26080;&#38480;&#32500;&#24102;&#26435;&#37325;&#31354;&#38388;&#19978;&#65292;&#20854;&#20540;&#20063;&#22312;&#21487;&#33021;&#26159;&#26080;&#38480;&#32500;&#30340;&#36755;&#20986;&#31354;&#38388;&#20013;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#20351;&#29992;&#19968;&#20010;&#21152;&#24615;&#26063;&#20316;&#20026;&#38544;&#34255;&#23618;&#26144;&#23556;&#65292;&#20197;&#21450;&#19968;&#20010;&#38750;&#32447;&#24615;&#28608;&#27963;&#20989;&#25968;&#24212;&#29992;&#20110;&#27599;&#20010;&#38544;&#34255;&#23618;&#12290;&#20381;&#38752;&#24102;&#26435;&#37325;&#31354;&#38388;&#19978;&#30340;Stone-Weierstrass&#23450;&#29702;&#65292;&#25105;&#20204;&#21487;&#20197;&#35777;&#26126;&#36830;&#32493;&#20989;&#25968;&#30340;&#25512;&#24191;&#30340;&#20840;&#23616;&#26222;&#36866;&#36924;&#36817;&#32467;&#26524;&#65292;&#36229;&#36234;&#20102;&#24120;&#35268;&#32039;&#38598;&#36924;&#36817;&#12290;&#36825;&#29305;&#21035;&#36866;&#29992;&#20110;&#36890;&#36807;&#21151;&#33021;&#24615;&#36755;&#20837;&#31070;&#32463;&#32593;&#32476;&#36924;&#36817;&#65288;&#38750;&#20808;&#35265;&#20043;&#26126;&#30340;&#65289;&#36335;&#24452;&#31354;&#38388;&#20989;&#25968;&#12290;&#20316;&#20026;&#24102;&#26435;Stone-Weierstrass&#23450;&#29702;&#30340;&#36827;&#19968;&#27493;&#24212;&#29992;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#32447;&#24615;&#20989;&#25968;&#31614;&#21517;&#30340;&#20840;&#23616;&#26222;&#36866;&#36924;&#36817;&#32467;&#26524;&#12290;&#25105;&#20204;&#36824;&#22312;&#36825;&#20010;&#35774;&#32622;&#20013;&#24341;&#20837;&#20102;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#30340;&#35266;&#28857;&#65292;&#24182;&#23637;&#31034;&#20102;&#31614;&#21517;&#20869;&#26680;&#30340;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#26159;&#26576;&#20123;&#39640;&#26031;&#36807;&#31243;&#30340;Cameron-Martin&#31354;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce so-called functional input neural networks defined on a possibly infinite dimensional weighted space with values also in a possibly infinite dimensional output space. To this end, we use an additive family as hidden layer maps and a non-linear activation function applied to each hidden layer. Relying on Stone-Weierstrass theorems on weighted spaces, we can prove a global universal approximation result for generalizations of continuous functions going beyond the usual approximation on compact sets. This then applies in particular to approximation of (non-anticipative) path space functionals via functional input neural networks. As a further application of the weighted Stone-Weierstrass theorem we prove a global universal approximation result for linear functions of the signature. We also introduce the viewpoint of Gaussian process regression in this setting and show that the reproducing kernel Hilbert space of the signature kernels are Cameron-Martin spaces of certain Gauss
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20840;&#38754;&#31283;&#20581;&#30340;&#25968;&#25454;&#39537;&#21160;&#20844;&#24335;&#65292;&#33021;&#22815;&#21516;&#26102;&#20445;&#25252;&#19977;&#20010;&#36807;&#25311;&#21512;&#30340;&#28304;&#22836;&#65306;&#26377;&#38480;&#26679;&#26412;&#25968;&#25454;&#30340;&#32479;&#35745;&#35823;&#24046;&#12289;&#25968;&#25454;&#28857;&#30340;&#26377;&#38480;&#31934;&#24230;&#27979;&#37327;&#24341;&#36215;&#30340;&#25968;&#25454;&#22122;&#22768;&#65292;&#20197;&#21450;&#34987;&#30772;&#22351;&#30340;&#37096;&#20998;&#25968;&#25454;&#12290;</title><link>http://arxiv.org/abs/2207.09560</link><description>&lt;p&gt;
&#20840;&#38754;&#31283;&#20581;&#30340;&#25968;&#25454;&#39537;&#21160;&#20915;&#31574;
&lt;/p&gt;
&lt;p&gt;
Holistic Robust Data-Driven Decisions. (arXiv:2207.09560v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.09560
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20840;&#38754;&#31283;&#20581;&#30340;&#25968;&#25454;&#39537;&#21160;&#20844;&#24335;&#65292;&#33021;&#22815;&#21516;&#26102;&#20445;&#25252;&#19977;&#20010;&#36807;&#25311;&#21512;&#30340;&#28304;&#22836;&#65306;&#26377;&#38480;&#26679;&#26412;&#25968;&#25454;&#30340;&#32479;&#35745;&#35823;&#24046;&#12289;&#25968;&#25454;&#28857;&#30340;&#26377;&#38480;&#31934;&#24230;&#27979;&#37327;&#24341;&#36215;&#30340;&#25968;&#25454;&#22122;&#22768;&#65292;&#20197;&#21450;&#34987;&#30772;&#22351;&#30340;&#37096;&#20998;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35774;&#35745;&#20855;&#26377;&#33391;&#22909;&#26679;&#26412;&#22806;&#24615;&#33021;&#30340;&#26426;&#22120;&#23398;&#20064;&#21644;&#20915;&#31574;&#30340;&#25968;&#25454;&#39537;&#21160;&#20844;&#24335;&#26159;&#19968;&#20010;&#20851;&#38190;&#30340;&#25361;&#25112;&#12290;&#22909;&#30340;&#26679;&#26412;&#20869;&#24615;&#33021;&#19981;&#19968;&#23450;&#33021;&#20445;&#35777;&#22909;&#30340;&#26679;&#26412;&#22806;&#24615;&#33021;&#65292;&#36825;&#34987;&#26222;&#36941;&#35748;&#20026;&#26159;&#36807;&#25311;&#21512;&#38382;&#39064;&#12290;&#23454;&#38469;&#30340;&#36807;&#25311;&#21512;&#36890;&#24120;&#19981;&#33021;&#24402;&#22240;&#20110;&#21333;&#19968;&#21407;&#22240;&#65292;&#32780;&#26159;&#30001;&#22810;&#20010;&#22240;&#32032;&#21516;&#26102;&#24341;&#36215;&#30340;&#12290;&#25105;&#20204;&#22312;&#36825;&#37324;&#32771;&#34385;&#20102;&#19977;&#20010;&#36807;&#25311;&#21512;&#30340;&#28304;&#22836;&#65306;&#65288;&#19968;&#65289;&#32479;&#35745;&#35823;&#24046;&#65292;&#30001;&#20110;&#20351;&#29992;&#26377;&#38480;&#30340;&#26679;&#26412;&#25968;&#25454;&#32780;&#20135;&#29983;&#30340;&#35823;&#24046;&#65292;&#65288;&#20108;&#65289;&#25968;&#25454;&#22122;&#22768;&#65292;&#24403;&#25968;&#25454;&#28857;&#21482;&#29992;&#26377;&#38480;&#31934;&#24230;&#27979;&#37327;&#26102;&#20135;&#29983;&#30340;&#22122;&#22768;&#65292;&#65288;&#19977;&#65289;&#25968;&#25454;&#38169;&#35823;&#65292;&#21363;&#20840;&#37096;&#25968;&#25454;&#20013;&#26377;&#19968;&#23567;&#37096;&#20998;&#25968;&#25454;&#34987;&#23436;&#20840;&#30772;&#22351;&#12290;&#25105;&#20204;&#35748;&#20026;&#65292;&#23613;&#31649;&#29616;&#26377;&#30340;&#25968;&#25454;&#39537;&#21160;&#20844;&#24335;&#22312;&#21333;&#29420;&#22788;&#29702;&#36825;&#19977;&#20010;&#28304;&#22836;&#26102;&#21487;&#33021;&#26159;&#31283;&#20581;&#30340;&#65292;&#20294;&#23427;&#20204;&#19981;&#33021;&#21516;&#26102;&#25552;&#20379;&#23545;&#25152;&#26377;&#36807;&#25311;&#21512;&#28304;&#22836;&#30340;&#20840;&#38754;&#20445;&#25252;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#25968;&#25454;&#39537;&#21160;&#20844;&#24335;&#65292;&#21487;&#20197;&#20445;&#35777;&#36825;&#31181;&#20840;&#38754;&#20445;&#25252;&#12290;
&lt;/p&gt;
&lt;p&gt;
The design of data-driven formulations for machine learning and decision-making with good out-of-sample performance is a key challenge. The observation that good in-sample performance does not guarantee good out-of-sample performance is generally known as overfitting. Practical overfitting can typically not be attributed to a single cause but instead is caused by several factors all at once. We consider here three overfitting sources: (i) statistical error as a result of working with finite sample data, (ii) data noise which occurs when the data points are measured only with finite precision, and finally (iii) data misspecification in which a small fraction of all data may be wholly corrupted. We argue that although existing data-driven formulations may be robust against one of these three sources in isolation they do not provide holistic protection against all overfitting sources simultaneously. We design a novel data-driven formulation which does guarantee such holistic protection an
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33258;&#22238;&#24402;&#27169;&#22411;&#65292;&#29992;&#20110;&#20998;&#26512;&#22810;&#20803;&#20998;&#24067;&#26102;&#38388;&#24207;&#21015;&#12290;&#24182;&#19988;&#22312;Wasserstein&#31354;&#38388;&#20013;&#24314;&#27169;&#20102;&#38543;&#26426;&#23545;&#35937;&#65292;&#25552;&#20379;&#20102;&#35813;&#27169;&#22411;&#30340;&#35299;&#30340;&#23384;&#22312;&#24615;&#21644;&#19968;&#33268;&#20272;&#35745;&#22120;&#12290;&#27492;&#26041;&#27861;&#21487;&#20197;&#24212;&#29992;&#20110;&#24180;&#40836;&#20998;&#24067;&#21644;&#33258;&#34892;&#36710;&#20849;&#20139;&#32593;&#32476;&#30340;&#35266;&#23519;&#25968;&#25454;&#12290;</title><link>http://arxiv.org/abs/2207.05442</link><description>&lt;p&gt;
Wasserstein&#22810;&#20803;&#33258;&#22238;&#24402;&#27169;&#22411;&#29992;&#20110;&#24314;&#27169;&#20998;&#24067;&#26102;&#38388;&#24207;&#21015;&#21450;&#20854;&#22312;&#22270;&#24418;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Wasserstein multivariate auto-regressive models for modeling distributional time series and its application in graph learning. (arXiv:2207.05442v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.05442
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33258;&#22238;&#24402;&#27169;&#22411;&#65292;&#29992;&#20110;&#20998;&#26512;&#22810;&#20803;&#20998;&#24067;&#26102;&#38388;&#24207;&#21015;&#12290;&#24182;&#19988;&#22312;Wasserstein&#31354;&#38388;&#20013;&#24314;&#27169;&#20102;&#38543;&#26426;&#23545;&#35937;&#65292;&#25552;&#20379;&#20102;&#35813;&#27169;&#22411;&#30340;&#35299;&#30340;&#23384;&#22312;&#24615;&#21644;&#19968;&#33268;&#20272;&#35745;&#22120;&#12290;&#27492;&#26041;&#27861;&#21487;&#20197;&#24212;&#29992;&#20110;&#24180;&#40836;&#20998;&#24067;&#21644;&#33258;&#34892;&#36710;&#20849;&#20139;&#32593;&#32476;&#30340;&#35266;&#23519;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33258;&#22238;&#24402;&#27169;&#22411;&#65292;&#29992;&#20110;&#32479;&#35745;&#20998;&#26512;&#22810;&#20803;&#20998;&#24067;&#26102;&#38388;&#24207;&#21015;&#12290;&#24863;&#20852;&#36259;&#30340;&#25968;&#25454;&#21253;&#25324;&#19968;&#32452;&#22312;&#23454;&#32447;&#26377;&#30028;&#38388;&#38548;&#19978;&#25903;&#25345;&#30340;&#27010;&#29575;&#27979;&#24230;&#30340;&#22810;&#20010;&#31995;&#21015;&#65292;&#24182;&#19988;&#34987;&#19981;&#21516;&#26102;&#38388;&#30636;&#38388;&#25152;&#32034;&#24341;&#12290;&#27010;&#29575;&#27979;&#24230;&#34987;&#24314;&#27169;&#20026;Wasserstein&#31354;&#38388;&#20013;&#30340;&#38543;&#26426;&#23545;&#35937;&#12290;&#25105;&#20204;&#36890;&#36807;&#22312;Lebesgue&#27979;&#24230;&#30340;&#20999;&#31354;&#38388;&#20013;&#24314;&#31435;&#33258;&#22238;&#24402;&#27169;&#22411;&#65292;&#39318;&#20808;&#23545;&#25152;&#26377;&#21407;&#22987;&#27979;&#24230;&#36827;&#34892;&#23621;&#20013;&#22788;&#29702;&#65292;&#20197;&#20415;&#23427;&#20204;&#30340;Fr&#233;chet&#24179;&#22343;&#20540;&#25104;&#20026;Lebesgue&#27979;&#24230;&#12290;&#21033;&#29992;&#36845;&#20195;&#38543;&#26426;&#20989;&#25968;&#31995;&#32479;&#30340;&#29702;&#35770;&#65292;&#25552;&#20379;&#20102;&#36825;&#26679;&#19968;&#20010;&#27169;&#22411;&#30340;&#35299;&#30340;&#23384;&#22312;&#24615;&#12289;&#21807;&#19968;&#24615;&#21644;&#24179;&#31283;&#24615;&#30340;&#32467;&#26524;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#27169;&#22411;&#31995;&#25968;&#30340;&#19968;&#33268;&#20272;&#35745;&#22120;&#12290;&#38500;&#20102;&#23545;&#27169;&#25311;&#25968;&#25454;&#30340;&#20998;&#26512;&#65292;&#25105;&#20204;&#36824;&#20351;&#29992;&#20004;&#20010;&#23454;&#38469;&#25968;&#25454;&#38598;&#36827;&#34892;&#20102;&#27169;&#22411;&#28436;&#31034;&#65306;&#19968;&#20010;&#26159;&#19981;&#21516;&#22269;&#23478;&#24180;&#40836;&#20998;&#24067;&#30340;&#35266;&#23519;&#25968;&#25454;&#38598;&#65292;&#21478;&#19968;&#20010;&#26159;&#24052;&#40654;&#33258;&#34892;&#36710;&#20849;&#20139;&#32593;&#32476;&#30340;&#35266;&#23519;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a new auto-regressive model for the statistical analysis of multivariate distributional time series. The data of interest consist of a collection of multiple series of probability measures supported over a bounded interval of the real line, and that are indexed by distinct time instants. The probability measures are modelled as random objects in the Wasserstein space. We establish the auto-regressive model in the tangent space at the Lebesgue measure by first centering all the raw measures so that their Fr\'echet means turn to be the Lebesgue measure. Using the theory of iterated random function systems, results on the existence, uniqueness and stationarity of the solution of such a model are provided. We also propose a consistent estimator for the model coefficient. In addition to the analysis of simulated data, the proposed model is illustrated with two real data sets made of observations from age distribution in different countries and bike sharing network in Paris. Final
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#23618;&#30456;&#20851;&#32858;&#31867;&#26041;&#27861;&#65292;&#21487;&#24212;&#29992;&#20110;&#27491;&#36127;&#37197;&#23545;&#19981;&#30456;&#20284;&#24230;&#65292;&#24182;&#30740;&#31350;&#20102;&#20351;&#29992;&#27492;&#26041;&#27861;&#36827;&#34892;&#26080;&#30417;&#30563;&#34920;&#24449;&#23398;&#20064;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2002.07756</link><description>&lt;p&gt;
&#20998;&#23618;&#30456;&#20851;&#32858;&#31867;&#21644;&#32500;&#25345;&#26641;&#32467;&#26500;&#23884;&#20837;
&lt;/p&gt;
&lt;p&gt;
Hierarchical Correlation Clustering and Tree Preserving Embedding. (arXiv:2002.07756v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2002.07756
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#23618;&#30456;&#20851;&#32858;&#31867;&#26041;&#27861;&#65292;&#21487;&#24212;&#29992;&#20110;&#27491;&#36127;&#37197;&#23545;&#19981;&#30456;&#20284;&#24230;&#65292;&#24182;&#30740;&#31350;&#20102;&#20351;&#29992;&#27492;&#26041;&#27861;&#36827;&#34892;&#26080;&#30417;&#30563;&#34920;&#24449;&#23398;&#20064;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#23618;&#30456;&#20851;&#32858;&#31867;&#26041;&#27861;&#65292;&#25193;&#23637;&#20102;&#33879;&#21517;&#30340;&#30456;&#20851;&#32858;&#31867;&#26041;&#27861;&#65292;&#21487;&#20197;&#20135;&#29983;&#36866;&#29992;&#20110;&#27491;&#36127;&#37197;&#23545;&#19981;&#30456;&#20284;&#24230;&#30340;&#20998;&#23618;&#32858;&#31867;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20351;&#29992;&#36825;&#31181;&#20998;&#23618;&#30456;&#20851;&#32858;&#31867;&#30340;&#26080;&#30417;&#30563;&#34920;&#24449;&#23398;&#20064;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#39318;&#20808;&#30740;&#31350;&#23558;&#30456;&#24212;&#30340;&#20998;&#23618;&#23884;&#20837;&#29992;&#20110;&#32500;&#25345;&#26641;&#32467;&#26500;&#23884;&#20837;&#21644;&#29305;&#24449;&#25552;&#21462;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#26368;&#23567;&#26368;&#22823;&#36317;&#31163;&#24230;&#37327;&#25193;&#23637;&#21040;&#30456;&#20851;&#32858;&#31867;&#30340;&#26041;&#27861;&#65292;&#20316;&#20026;&#21478;&#19968;&#31181;&#34920;&#24449;&#23398;&#20064;&#33539;&#24335;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a hierarchical correlation clustering method that extends the well-known correlation clustering to produce hierarchical clusters applicable to both positive and negative pairwise dissimilarities. Then, in the following, we study unsupervised representation learning with such hierarchical correlation clustering. For this purpose, we first investigate embedding the respective hierarchy to be used for tree-preserving embedding and feature extraction. Thereafter, we study the extension of minimax distance measures to correlation clustering, as another representation learning paradigm. Finally, we demonstrate the performance of our methods on several datasets.
&lt;/p&gt;</description></item></channel></rss>