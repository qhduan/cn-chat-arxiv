<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#25913;&#36827;&#30340;&#35889;&#32858;&#31867;&#31639;&#27861;&#22312;&#22810;&#23618;&#32593;&#32476;&#20013;&#23454;&#29616;&#20102;&#26356;&#22909;&#30340;&#31038;&#21306;&#26816;&#27979;&#24615;&#33021;&#65292;&#24182;&#35777;&#26126;&#22810;&#23618;&#32593;&#32476;&#23545;&#31038;&#21306;&#26816;&#27979;&#26377;&#20248;&#21183;&#12290;</title><link>https://arxiv.org/abs/2403.12540</link><description>&lt;p&gt;
&#22810;&#23618;&#32593;&#32476;&#20013;&#22522;&#20110;&#35889;&#26041;&#27861;&#30340;&#31038;&#21306;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Community detection by spectral methods in multi-layer networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12540
&lt;/p&gt;
&lt;p&gt;
&#25913;&#36827;&#30340;&#35889;&#32858;&#31867;&#31639;&#27861;&#22312;&#22810;&#23618;&#32593;&#32476;&#20013;&#23454;&#29616;&#20102;&#26356;&#22909;&#30340;&#31038;&#21306;&#26816;&#27979;&#24615;&#33021;&#65292;&#24182;&#35777;&#26126;&#22810;&#23618;&#32593;&#32476;&#23545;&#31038;&#21306;&#26816;&#27979;&#26377;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#23618;&#32593;&#32476;&#20013;&#30340;&#31038;&#21306;&#26816;&#27979;&#26159;&#32593;&#32476;&#20998;&#26512;&#20013;&#19968;&#20010;&#20851;&#38190;&#38382;&#39064;&#12290;&#26412;&#25991;&#20998;&#26512;&#20102;&#20004;&#31181;&#35889;&#32858;&#31867;&#31639;&#27861;&#22312;&#22810;&#23618;&#24230;&#26657;&#27491;&#38543;&#26426;&#22359;&#27169;&#22411;&#65288;MLDCSBM&#65289;&#26694;&#26550;&#19979;&#36827;&#34892;&#31038;&#21306;&#26816;&#27979;&#30340;&#24615;&#33021;&#12290;&#19968;&#31181;&#31639;&#27861;&#22522;&#20110;&#37051;&#25509;&#30697;&#38453;&#30340;&#21644;&#65292;&#21478;&#19968;&#31181;&#21033;&#29992;&#20102;&#21435;&#20559;&#21644;&#30340;&#24179;&#26041;&#37051;&#25509;&#30697;&#38453;&#30340;&#21644;&#12290;&#25105;&#20204;&#22312;&#32593;&#32476;&#35268;&#27169;&#21644;/&#25110;&#23618;&#25968;&#22686;&#21152;&#26102;&#24314;&#31435;&#20102;&#36825;&#20123;&#26041;&#27861;&#22312;MLDCSBM&#19979;&#36827;&#34892;&#31038;&#21306;&#26816;&#27979;&#30340;&#19968;&#33268;&#24615;&#32467;&#26524;&#12290;&#25105;&#20204;&#30340;&#23450;&#29702;&#23637;&#31034;&#20102;&#21033;&#29992;&#22810;&#23618;&#36827;&#34892;&#31038;&#21306;&#26816;&#27979;&#30340;&#20248;&#21183;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#20998;&#26512;&#34920;&#26126;&#65292;&#21033;&#29992;&#21435;&#20559;&#21644;&#30340;&#24179;&#26041;&#37051;&#25509;&#30697;&#38453;&#30340;&#35889;&#32858;&#31867;&#36890;&#24120;&#20248;&#20110;&#21033;&#29992;&#37051;&#25509;&#30697;&#38453;&#30340;&#35889;&#32858;&#31867;&#12290;&#25968;&#20540;&#27169;&#25311;&#35777;&#23454;&#20102;&#25105;&#20204;&#30340;&#31639;&#27861;&#65292;&#37319;&#29992;&#20102;&#21435;&#20559;&#21644;&#30340;&#24179;&#26041;&#37051;&#25509;&#30697;&#38453;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12540v1 Announce Type: cross  Abstract: Community detection in multi-layer networks is a crucial problem in network analysis. In this paper, we analyze the performance of two spectral clustering algorithms for community detection within the multi-layer degree-corrected stochastic block model (MLDCSBM) framework. One algorithm is based on the sum of adjacency matrices, while the other utilizes the debiased sum of squared adjacency matrices. We establish consistency results for community detection using these methods under MLDCSBM as the size of the network and/or the number of layers increases. Our theorems demonstrate the advantages of utilizing multiple layers for community detection. Moreover, our analysis indicates that spectral clustering with the debiased sum of squared adjacency matrices is generally superior to spectral clustering with the sum of adjacency matrices. Numerical simulations confirm that our algorithm, employing the debiased sum of squared adjacency matri
&lt;/p&gt;</description></item><item><title>&#22312;&#35813;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#26391;&#20043;&#20961;&#25193;&#25955;&#21644;&#26410;&#35843;&#25972;&#26391;&#20043;&#20961;&#31639;&#27861;&#20013;&#38543;&#26426;&#21464;&#37327;&#29420;&#31435;&#21270;&#36895;&#29575;&#30340;&#25910;&#25947;&#24615;&#65292;&#35777;&#26126;&#20102;&#22312;&#30446;&#26631;&#20989;&#25968;&#24378;&#23545;&#25968;&#20985;&#21644;&#24179;&#28369;&#30340;&#24773;&#20917;&#19979;&#65292;&#20114;&#20449;&#24687;&#20250;&#20197;&#25351;&#25968;&#36895;&#29575;&#25910;&#25947;&#20110;$0$&#12290;</title><link>https://arxiv.org/abs/2402.17067</link><description>&lt;p&gt;
&#20851;&#20110;&#26391;&#20043;&#20961;&#25193;&#25955;&#21644;&#26410;&#35843;&#25972;&#26391;&#20043;&#20961;&#31639;&#27861;&#20013;&#29420;&#31435;&#26679;&#26412;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Independent Samples Along the Langevin Diffusion and the Unadjusted Langevin Algorithm
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17067
&lt;/p&gt;
&lt;p&gt;
&#22312;&#35813;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#26391;&#20043;&#20961;&#25193;&#25955;&#21644;&#26410;&#35843;&#25972;&#26391;&#20043;&#20961;&#31639;&#27861;&#20013;&#38543;&#26426;&#21464;&#37327;&#29420;&#31435;&#21270;&#36895;&#29575;&#30340;&#25910;&#25947;&#24615;&#65292;&#35777;&#26126;&#20102;&#22312;&#30446;&#26631;&#20989;&#25968;&#24378;&#23545;&#25968;&#20985;&#21644;&#24179;&#28369;&#30340;&#24773;&#20917;&#19979;&#65292;&#20114;&#20449;&#24687;&#20250;&#20197;&#25351;&#25968;&#36895;&#29575;&#25910;&#25947;&#20110;$0$&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#39532;&#23572;&#21487;&#22827;&#38142;&#20013;&#21021;&#22987;&#21644;&#24403;&#21069;&#38543;&#26426;&#21464;&#37327;&#29420;&#31435;&#21270;&#30340;&#36895;&#29575;&#65292;&#37325;&#28857;&#20851;&#27880;&#36830;&#32493;&#26102;&#38388;&#20013;&#30340;&#26391;&#20043;&#20961;&#25193;&#25955;&#21644;&#31163;&#25955;&#26102;&#38388;&#20013;&#30340;&#26410;&#35843;&#25972;&#26391;&#20043;&#20961;&#31639;&#27861;&#65288;ULA&#65289;&#12290;&#25105;&#20204;&#36890;&#36807;&#23427;&#20204;&#30340;&#20114;&#20449;&#24687;&#24230;&#37327;&#38543;&#26426;&#21464;&#37327;&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#12290;&#23545;&#20110;&#26391;&#20043;&#20961;&#25193;&#25955;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#24403;&#30446;&#26631;&#20989;&#25968;&#24378;&#23545;&#25968;&#20985;&#26102;&#65292;&#20114;&#20449;&#24687;&#20197;&#25351;&#25968;&#36895;&#29575;&#25910;&#25947;&#20110;$0$&#65292;&#24403;&#30446;&#26631;&#20989;&#25968;&#24369;&#23545;&#25968;&#20985;&#26102;&#65292;&#20197;&#22810;&#39033;&#24335;&#36895;&#29575;&#25910;&#25947;&#12290;&#36825;&#20123;&#36895;&#29575;&#31867;&#20284;&#20110;&#22312;&#31867;&#20284;&#26465;&#20214;&#19979;&#26391;&#20043;&#20961;&#25193;&#25955;&#30340;&#28151;&#21512;&#26102;&#38388;&#12290;&#23545;&#20110;ULA&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#24403;&#30446;&#26631;&#20989;&#25968;&#24378;&#23545;&#25968;&#20985;&#19988;&#20809;&#28369;&#26102;&#65292;&#20114;&#20449;&#24687;&#20197;&#25351;&#25968;&#36895;&#29575;&#25910;&#25947;&#20110;$0$&#12290;&#25105;&#20204;&#36890;&#36807;&#21457;&#23637;&#36825;&#20123;&#39532;&#23572;&#21487;&#22827;&#38142;&#30340;&#20114;&#20449;&#24687;&#29256;&#26412;&#30340;&#28151;&#21512;&#26102;&#38388;&#20998;&#26512;&#26469;&#35777;&#26126;&#25105;&#20204;&#30340;&#32467;&#26524;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#22522;&#20110;&#26391;&#20043;&#20961;&#25193;&#25955;&#30340;&#24378;&#25968;&#25454;&#22788;&#29702;&#19981;&#31561;&#24335;&#30340;&#26367;&#20195;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17067v1 Announce Type: cross  Abstract: We study the rate at which the initial and current random variables become independent along a Markov chain, focusing on the Langevin diffusion in continuous time and the Unadjusted Langevin Algorithm (ULA) in discrete time. We measure the dependence between random variables via their mutual information. For the Langevin diffusion, we show the mutual information converges to $0$ exponentially fast when the target is strongly log-concave, and at a polynomial rate when the target is weakly log-concave. These rates are analogous to the mixing time of the Langevin diffusion under similar assumptions. For the ULA, we show the mutual information converges to $0$ exponentially fast when the target is strongly log-concave and smooth. We prove our results by developing the mutual version of the mixing time analyses of these Markov chains. We also provide alternative proofs based on strong data processing inequalities for the Langevin diffusion 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#19968;&#31181;&#26041;&#27861;&#65292;&#36890;&#36807;&#20923;&#32467;&#38543;&#26426;&#23376;&#38598;&#30340;&#21021;&#22987;&#26435;&#37325;&#26469;&#20943;&#23569;&#24378;&#22823;&#30340;&#24425;&#31080;&#31080;&#35777;&#65288;SLT&#65289;&#25628;&#32034;&#31354;&#38388;&#65292;&#20174;&#32780;&#29420;&#31435;&#20110;&#25152;&#38656;SLT&#31232;&#30095;&#24615;&#38477;&#20302;&#20102;SLT&#25628;&#32034;&#31354;&#38388;&#65292;&#20445;&#35777;&#20102;SLT&#22312;&#36825;&#31181;&#20943;&#23569;&#25628;&#32034;&#31354;&#38388;&#20013;&#30340;&#23384;&#22312;&#12290;</title><link>https://arxiv.org/abs/2402.14029</link><description>&lt;p&gt;
&#20923;&#32467;&#32593;&#32476;&#20013;&#30340;&#37096;&#20998;&#25628;&#32034;&#36275;&#20197;&#25214;&#21040;&#24378;&#22823;&#30340;&#24425;&#31080;&#31080;&#35777;
&lt;/p&gt;
&lt;p&gt;
Partial Search in a Frozen Network is Enough to Find a Strong Lottery Ticket
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14029
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#19968;&#31181;&#26041;&#27861;&#65292;&#36890;&#36807;&#20923;&#32467;&#38543;&#26426;&#23376;&#38598;&#30340;&#21021;&#22987;&#26435;&#37325;&#26469;&#20943;&#23569;&#24378;&#22823;&#30340;&#24425;&#31080;&#31080;&#35777;&#65288;SLT&#65289;&#25628;&#32034;&#31354;&#38388;&#65292;&#20174;&#32780;&#29420;&#31435;&#20110;&#25152;&#38656;SLT&#31232;&#30095;&#24615;&#38477;&#20302;&#20102;SLT&#25628;&#32034;&#31354;&#38388;&#65292;&#20445;&#35777;&#20102;SLT&#22312;&#36825;&#31181;&#20943;&#23569;&#25628;&#32034;&#31354;&#38388;&#20013;&#30340;&#23384;&#22312;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14029v1 &#20844;&#21578;&#31867;&#22411;&#65306;&#36328;&#36234; &#25688;&#35201;&#65306;&#38543;&#26426;&#21021;&#22987;&#21270;&#30340;&#31264;&#23494;&#32593;&#32476;&#21253;&#21547;&#21487;&#20197;&#22312;&#19981;&#36827;&#34892;&#26435;&#37325;&#23398;&#20064;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#39640;&#20934;&#30830;&#24230;&#30340;&#23376;&#32593;&#32476;--&#24378;&#22823;&#30340;&#24425;&#31080;&#31080;&#35777;&#65288;SLTs&#65289;&#12290;&#26368;&#36817;&#65292;Gadhikar&#31561;&#20154;&#65288;2023&#24180;&#65289;&#22312;&#29702;&#35770;&#21644;&#23454;&#39564;&#35777;&#26126;&#65292;SLTs&#20063;&#21487;&#20197;&#22312;&#38543;&#26426;&#20462;&#21098;&#30340;&#28304;&#32593;&#32476;&#20013;&#25214;&#21040;&#65292;&#20174;&#32780;&#20943;&#23569;SLT&#30340;&#25628;&#32034;&#31354;&#38388;&#12290;&#28982;&#32780;&#65292;&#36825;&#38480;&#21046;&#20102;&#23545;&#29978;&#33267;&#27604;&#28304;&#32593;&#32476;&#26356;&#31232;&#30095;&#30340;SLTs&#30340;&#25628;&#32034;&#65292;&#23548;&#33268;&#30001;&#20110;&#24847;&#22806;&#30340;&#39640;&#31232;&#30095;&#24615;&#32780;&#20934;&#30830;&#24230;&#36739;&#24046;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#29420;&#31435;&#20110;&#25152;&#38656;SLT&#31232;&#30095;&#24615;&#30340;&#20219;&#24847;&#27604;&#29575;&#20943;&#23569;SLT&#25628;&#32034;&#31354;&#38388;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#20923;&#32467;&#19968;&#37096;&#20998;&#21021;&#22987;&#26435;&#37325;&#30340;&#38543;&#26426;&#23376;&#38598;&#65292;&#23558;&#20854;&#25490;&#38500;&#22312;&#25628;&#32034;&#31354;&#38388;&#20043;&#22806;--&#21363;&#65292;&#36890;&#36807;&#27704;&#20037;&#20462;&#21098;&#23427;&#20204;&#25110;&#23558;&#23427;&#20204;&#38145;&#23450;&#20026;SLT&#30340;&#22266;&#23450;&#37096;&#20998;&#12290;&#20107;&#23454;&#19978;&#65292;&#36890;&#36807;&#25105;&#20204;&#19982;&#38543;&#26426;&#20923;&#32467;&#21464;&#37327;&#30340;&#23376;&#38598;&#21644;&#36924;&#36817;&#65292;&#22312;&#36825;&#31181;&#20943;&#23569;&#30340;&#25628;&#32034;&#31354;&#38388;&#20013;&#65292;SLT&#30340;&#23384;&#22312;&#22312;&#29702;&#35770;&#19978;&#26159;&#24471;&#21040;&#20445;&#35777;&#30340;&#12290;&#38500;&#27492;&#20043;&#22806;&#65292;&#36824;&#21487;&#20197;&#20943;&#23569;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14029v1 Announce Type: cross  Abstract: Randomly initialized dense networks contain subnetworks that achieve high accuracy without weight learning -- strong lottery tickets (SLTs). Recently, Gadhikar et al. (2023) demonstrated theoretically and experimentally that SLTs can also be found within a randomly pruned source network, thus reducing the SLT search space. However, this limits the search to SLTs that are even sparser than the source, leading to worse accuracy due to unintentionally high sparsity. This paper proposes a method that reduces the SLT search space by an arbitrary ratio that is independent of the desired SLT sparsity. A random subset of the initial weights is excluded from the search space by freezing it -- i.e., by either permanently pruning them or locking them as a fixed part of the SLT. Indeed, the SLT existence in such a reduced search space is theoretically guaranteed by our subset-sum approximation with randomly frozen variables. In addition to reducin
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21033;&#29992;&#22823;&#20559;&#24046;&#29702;&#35770;&#65292;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#20989;&#25968;&#30340;&#24179;&#28369;&#27169;&#22411;&#29305;&#24449;&#25551;&#36848;&#26041;&#27861;&#65292;&#35299;&#37322;&#20102;&#20026;&#20160;&#20040;&#19968;&#20123;&#25554;&#20540;&#22120;&#26377;&#24456;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#20197;&#21450;&#29616;&#20195;&#23398;&#20064;&#25216;&#26415;&#20026;&#20160;&#20040;&#33021;&#22815;&#25214;&#21040;&#23427;&#20204;&#12290;</title><link>http://arxiv.org/abs/2306.10947</link><description>&lt;p&gt;
&#20351;&#29992;&#36895;&#29575;&#20989;&#25968;&#29702;&#35299;&#25554;&#20540;&#21306;&#38388;&#30340;&#27867;&#21270;
&lt;/p&gt;
&lt;p&gt;
Understanding Generalization in the Interpolation Regime using the Rate Function. (arXiv:2306.10947v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10947
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21033;&#29992;&#22823;&#20559;&#24046;&#29702;&#35770;&#65292;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#20989;&#25968;&#30340;&#24179;&#28369;&#27169;&#22411;&#29305;&#24449;&#25551;&#36848;&#26041;&#27861;&#65292;&#35299;&#37322;&#20102;&#20026;&#20160;&#20040;&#19968;&#20123;&#25554;&#20540;&#22120;&#26377;&#24456;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#20197;&#21450;&#29616;&#20195;&#23398;&#20064;&#25216;&#26415;&#20026;&#20160;&#20040;&#33021;&#22815;&#25214;&#21040;&#23427;&#20204;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22522;&#20110;&#22823;&#20559;&#24046;&#29702;&#35770;&#30340;&#22522;&#26412;&#21407;&#29702;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#27169;&#22411;&#24179;&#28369;&#24230;&#30340;&#26032;&#29305;&#24449;&#25551;&#36848;&#26041;&#27861;&#12290;&#19982;&#20197;&#24448;&#30340;&#24037;&#20316;&#19981;&#21516;&#65292;&#20197;&#24448;&#30340;&#24037;&#20316;&#36890;&#24120;&#29992;&#23454;&#25968;&#20540;&#65288;&#22914;&#26435;&#37325;&#33539;&#25968;&#65289;&#26469;&#34920;&#24449;&#27169;&#22411;&#30340;&#24179;&#28369;&#24230;&#65292;&#25105;&#20204;&#34920;&#26126;&#21487;&#20197;&#29992;&#31616;&#21333;&#30340;&#23454;&#20540;&#20989;&#25968;&#26469;&#25551;&#36848;&#24179;&#28369;&#24230;&#12290;&#22522;&#20110;&#27169;&#22411;&#24179;&#28369;&#24230;&#30340;&#36825;&#19968;&#27010;&#24565;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#29702;&#35770;&#35299;&#37322;&#65292;&#20026;&#20160;&#20040;&#19968;&#20123;&#25554;&#20540;&#22120;&#34920;&#29616;&#20986;&#38750;&#24120;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#20197;&#21450;&#20026;&#20160;&#20040;&#24191;&#27867;&#20351;&#29992;&#30340;&#29616;&#20195;&#23398;&#20064;&#25216;&#26415;&#65288;&#22914;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65292;$\ell_2$-&#35268;&#33539;&#21270;&#65292;&#25968;&#25454;&#22686;&#24378;&#65292;&#19981;&#21464;&#30340;&#26550;&#26500;&#21644;&#36229;&#21442;&#25968;&#21270;&#65289;&#33021;&#22815;&#25214;&#21040;&#23427;&#20204;&#12290;&#25105;&#20204;&#24471;&#20986;&#30340;&#32467;&#35770;&#26159;&#65292;&#25152;&#26377;&#36825;&#20123;&#26041;&#27861;&#37117;&#25552;&#20379;&#20102;&#20114;&#34917;&#30340;&#36807;&#31243;&#65292;&#36825;&#20123;&#36807;&#31243;&#20351;&#20248;&#21270;&#22120;&#20559;&#21521;&#20110;&#26356;&#24179;&#28369;&#30340;&#25554;&#20540;&#22120;&#65292;&#32780;&#26681;&#25454;&#36825;&#31181;&#29702;&#35770;&#20998;&#26512;&#65292;&#26356;&#24179;&#28369;&#30340;&#25554;&#20540;&#22120;&#26159;&#20855;&#26377;&#26356;&#22909;&#30340;&#27867;&#21270;&#35823;&#24046;&#30340;&#25554;&#20540;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we present a novel characterization of the smoothness of a model based on basic principles of Large Deviation Theory. In contrast to prior work, where the smoothness of a model is normally characterized by a real value (e.g., the weights' norm), we show that smoothness can be described by a simple real-valued function. Based on this concept of smoothness, we propose an unifying theoretical explanation of why some interpolators generalize remarkably well and why a wide range of modern learning techniques (i.e., stochastic gradient descent, $\ell_2$-norm regularization, data augmentation, invariant architectures, and overparameterization) are able to find them. The emergent conclusion is that all these methods provide complimentary procedures that bias the optimizer to smoother interpolators, which, according to this theoretical analysis, are the ones with better generalization error.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#27169;&#22411;&#26469;&#25551;&#36848;&#22312;&#21327;&#20316;&#23398;&#20064;&#20013;&#31454;&#20105;&#23545;&#25163;&#30340;&#19981;&#35802;&#23454;&#34892;&#20026;&#65292;&#25552;&#20986;&#20102;&#26426;&#21046;&#26469;&#28608;&#21169;&#35802;&#23454;&#27807;&#36890;&#65292;&#24182;&#30830;&#20445;&#23398;&#20064;&#36136;&#37327;&#19982;&#20840;&#38754;&#21512;&#20316;&#30456;&#24403;&#12290;</title><link>http://arxiv.org/abs/2305.16272</link><description>&lt;p&gt;
&#22312;&#21327;&#21516;&#23398;&#20064;&#21644;&#20248;&#21270;&#20013;&#28608;&#21169;&#31454;&#20105;&#23545;&#25163;&#35802;&#23454;&#34892;&#20026;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Incentivizing Honesty among Competitors in Collaborative Learning and Optimization. (arXiv:2305.16272v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16272
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#27169;&#22411;&#26469;&#25551;&#36848;&#22312;&#21327;&#20316;&#23398;&#20064;&#20013;&#31454;&#20105;&#23545;&#25163;&#30340;&#19981;&#35802;&#23454;&#34892;&#20026;&#65292;&#25552;&#20986;&#20102;&#26426;&#21046;&#26469;&#28608;&#21169;&#35802;&#23454;&#27807;&#36890;&#65292;&#24182;&#30830;&#20445;&#23398;&#20064;&#36136;&#37327;&#19982;&#20840;&#38754;&#21512;&#20316;&#30456;&#24403;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21327;&#21516;&#23398;&#20064;&#25216;&#26415;&#33021;&#22815;&#35753;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#35757;&#32451;&#27604;&#20165;&#21033;&#29992;&#21333;&#19968;&#25968;&#25454;&#28304;&#30340;&#27169;&#22411;&#25928;&#26524;&#26356;&#22909;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#65292;&#28508;&#22312;&#30340;&#21442;&#19982;&#32773;&#26159;&#19979;&#28216;&#20219;&#21153;&#20013;&#30340;&#31454;&#20105;&#23545;&#25163;&#65292;&#22914;&#27599;&#20010;&#37117;&#24076;&#26395;&#36890;&#36807;&#25552;&#20379;&#26368;&#20339;&#25512;&#33616;&#26469;&#21560;&#24341;&#23458;&#25143;&#30340;&#20844;&#21496;&#12290;&#36825;&#21487;&#33021;&#20250;&#28608;&#21169;&#19981;&#35802;&#23454;&#30340;&#26356;&#26032;&#65292;&#25439;&#23475;&#20854;&#20182;&#21442;&#19982;&#32773;&#30340;&#27169;&#22411;&#65292;&#20174;&#32780;&#21487;&#33021;&#30772;&#22351;&#21327;&#20316;&#30340;&#22909;&#22788;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#21046;&#23450;&#20102;&#19968;&#20010;&#27169;&#22411;&#26469;&#25551;&#36848;&#36825;&#31181;&#20132;&#20114;&#65292;&#24182;&#22312;&#35813;&#26694;&#26550;&#20869;&#30740;&#31350;&#20102;&#20004;&#20010;&#23398;&#20064;&#20219;&#21153;&#65306;&#21333;&#36718;&#22343;&#20540;&#20272;&#35745;&#21644;&#24378;&#20984;&#30446;&#26631;&#30340;&#22810;&#36718; SGD&#12290;&#23545;&#20110;&#19968;&#31867;&#33258;&#28982;&#30340;&#21442;&#19982;&#32773;&#34892;&#20026;&#65292;&#25105;&#20204;&#21457;&#29616;&#29702;&#24615;&#30340;&#23458;&#25143;&#20250;&#34987;&#28608;&#21169;&#24378;&#28872;&#22320;&#25805;&#32437;&#20182;&#20204;&#30340;&#26356;&#26032;&#65292;&#20174;&#32780;&#38450;&#27490;&#23398;&#20064;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#26426;&#21046;&#26469;&#28608;&#21169;&#35802;&#23454;&#27807;&#36890;&#65292;&#24182;&#30830;&#20445;&#23398;&#20064;&#36136;&#37327;&#19982;&#20840;&#38754;&#21512;&#20316;&#30456;&#24403;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#36825;&#19968;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
Collaborative learning techniques have the potential to enable training machine learning models that are superior to models trained on a single entity's data. However, in many cases, potential participants in such collaborative schemes are competitors on a downstream task, such as firms that each aim to attract customers by providing the best recommendations. This can incentivize dishonest updates that damage other participants' models, potentially undermining the benefits of collaboration. In this work, we formulate a game that models such interactions and study two learning tasks within this framework: single-round mean estimation and multi-round SGD on strongly-convex objectives. For a natural class of player actions, we show that rational clients are incentivized to strongly manipulate their updates, preventing learning. We then propose mechanisms that incentivize honest communication and ensure learning quality comparable to full cooperation. Lastly, we empirically demonstrate the
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32593;&#32476;&#32467;&#26500;&#30340;&#23616;&#37096;&#33258;&#36866;&#24212;&#32467;&#26500;&#23398;&#20064;&#31639;&#27861;&#65292;&#21487;&#23558;LD&#32593;&#32476;&#25968;&#25454;&#21644;&#22810;&#20010;&#26679;&#26412;&#30340;&#36741;&#21161;&#25968;&#25454;&#25972;&#21512;&#36215;&#26469;&#65292;&#36890;&#36807;&#25968;&#25454;&#39537;&#21160;&#30340;&#26435;&#37325;&#20998;&#37197;&#26041;&#27861;&#23454;&#29616;&#23545;&#22810;&#37325;&#26816;&#39564;&#30340;&#25511;&#21046;&#65292;&#24182;&#22312;&#32593;&#32476;&#25968;&#25454;&#20855;&#26377;&#20449;&#24687;&#37327;&#26102;&#20855;&#26377;&#26356;&#39640;&#30340;&#21151;&#25928;&#12290;</title><link>http://arxiv.org/abs/2203.11461</link><description>&lt;p&gt;
&#22522;&#20110;&#32593;&#32476;&#32467;&#26500;&#30340;&#23616;&#37096;&#33258;&#36866;&#24212;&#22810;&#37325;&#26816;&#39564;&#31639;&#27861;&#65292;&#21450;&#20854;&#22312;&#20840;&#22522;&#22240;&#32452;&#20851;&#32852;&#30740;&#31350;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Locally Adaptive Algorithms for Multiple Testing with Network Structure, with Application to Genome-Wide Association Studies. (arXiv:2203.11461v4 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.11461
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32593;&#32476;&#32467;&#26500;&#30340;&#23616;&#37096;&#33258;&#36866;&#24212;&#32467;&#26500;&#23398;&#20064;&#31639;&#27861;&#65292;&#21487;&#23558;LD&#32593;&#32476;&#25968;&#25454;&#21644;&#22810;&#20010;&#26679;&#26412;&#30340;&#36741;&#21161;&#25968;&#25454;&#25972;&#21512;&#36215;&#26469;&#65292;&#36890;&#36807;&#25968;&#25454;&#39537;&#21160;&#30340;&#26435;&#37325;&#20998;&#37197;&#26041;&#27861;&#23454;&#29616;&#23545;&#22810;&#37325;&#26816;&#39564;&#30340;&#25511;&#21046;&#65292;&#24182;&#22312;&#32593;&#32476;&#25968;&#25454;&#20855;&#26377;&#20449;&#24687;&#37327;&#26102;&#20855;&#26377;&#26356;&#39640;&#30340;&#21151;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38142;&#25509;&#20998;&#26512;&#22312;&#20840;&#22522;&#22240;&#32452;&#20851;&#32852;&#30740;&#31350;&#20013;&#36215;&#30528;&#37325;&#35201;&#20316;&#29992;&#65292;&#29305;&#21035;&#26159;&#22312;&#25581;&#31034;&#19982;&#30142;&#30149;&#34920;&#22411;&#30456;&#20851;&#30340;&#36830;&#38145;&#19981;&#24179;&#34913;&#65288;LD&#65289;&#30340;SNP&#20849;&#21516;&#24433;&#21709;&#26041;&#38754;&#12290;&#28982;&#32780;&#65292;LD&#32593;&#32476;&#25968;&#25454;&#30340;&#28508;&#21147;&#22312;&#25991;&#29486;&#20013;&#24448;&#24448;&#34987;&#24573;&#35270;&#25110;&#26410;&#20805;&#20998;&#21033;&#29992;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#23616;&#37096;&#33258;&#36866;&#24212;&#32467;&#26500;&#23398;&#20064;&#31639;&#27861;&#65288;LASLA&#65289;&#65292;&#20026;&#25972;&#21512;&#32593;&#32476;&#25968;&#25454;&#25110;&#26469;&#33258;&#30456;&#20851;&#28304;&#22495;&#30340;&#22810;&#20010;&#26679;&#26412;&#30340;&#36741;&#21161;&#25968;&#25454;&#25552;&#20379;&#20102;&#19968;&#20010;&#26377;&#21407;&#21017;&#19988;&#36890;&#29992;&#30340;&#26694;&#26550;&#65307;&#21487;&#33021;&#20855;&#26377;&#19981;&#21516;&#30340;&#32500;&#24230;/&#32467;&#26500;&#21644;&#19981;&#21516;&#30340;&#20154;&#32676;&#12290;LASLA&#37319;&#29992;$p$&#20540;&#21152;&#26435;&#26041;&#27861;&#65292;&#21033;&#29992;&#32467;&#26500;&#27934;&#23519;&#21147;&#20026;&#21508;&#20010;&#26816;&#39564;&#28857;&#20998;&#37197;&#25968;&#25454;&#39537;&#21160;&#30340;&#26435;&#37325;&#12290;&#29702;&#35770;&#20998;&#26512;&#34920;&#26126;&#65292;&#24403;&#20027;&#35201;&#32479;&#35745;&#37327;&#29420;&#31435;&#25110;&#24369;&#30456;&#20851;&#26102;&#65292;LASLA&#21487;&#20197;&#28176;&#36817;&#22320;&#25511;&#21046;FDR&#65292;&#24182;&#22312;&#32593;&#32476;&#25968;&#25454;&#20855;&#26377;&#20449;&#24687;&#37327;&#26102;&#23454;&#29616;&#26356;&#39640;&#30340;&#21151;&#25928;&#12290;&#36890;&#36807;&#21508;&#31181;&#21512;&#25104;&#23454;&#39564;&#21644;&#19968;&#20010;&#24212;&#29992;&#26696;&#20363;&#65292;&#23637;&#31034;&#20102;LASLA&#30340;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Linkage analysis has provided valuable insights to the GWAS studies, particularly in revealing that SNPs in linkage disequilibrium (LD) can jointly influence disease phenotypes. However, the potential of LD network data has often been overlooked or underutilized in the literature. In this paper, we propose a locally adaptive structure learning algorithm (LASLA) that provides a principled and generic framework for incorporating network data or multiple samples of auxiliary data from related source domains; possibly in different dimensions/structures and from diverse populations. LASLA employs a $p$-value weighting approach, utilizing structural insights to assign data-driven weights to individual test points. Theoretical analysis shows that LASLA can asymptotically control FDR with independent or weakly dependent primary statistics, and achieve higher power when the network data is informative. Efficiency again of LASLA is illustrated through various synthetic experiments and an applica
&lt;/p&gt;</description></item></channel></rss>