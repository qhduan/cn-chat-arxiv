<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#32479;&#35745;&#27169;&#22411;&#30340;&#26032;&#23481;&#37327;&#27979;&#37327;2sED&#65292;&#21487;&#20197;&#21487;&#38752;&#22320;&#38480;&#21046;&#27867;&#21270;&#35823;&#24046;&#65292;&#24182;&#19988;&#19982;&#35757;&#32451;&#35823;&#24046;&#20855;&#26377;&#24456;&#22909;&#30340;&#30456;&#20851;&#24615;&#12290;&#27492;&#22806;&#65292;&#23545;&#20110;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#36890;&#36807;&#36880;&#23618;&#36845;&#20195;&#30340;&#26041;&#27861;&#26377;&#25928;&#22320;&#36817;&#20284;2sED&#65292;&#20174;&#32780;&#22788;&#29702;&#22823;&#37327;&#21442;&#25968;&#30340;&#24773;&#20917;&#12290;</title><link>http://arxiv.org/abs/2401.09184</link><description>&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#20004;&#23610;&#24230;&#22797;&#26434;&#24230;&#27979;&#37327;
&lt;/p&gt;
&lt;p&gt;
A Two-Scale Complexity Measure for Deep Learning Models. (arXiv:2401.09184v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.09184
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#32479;&#35745;&#27169;&#22411;&#30340;&#26032;&#23481;&#37327;&#27979;&#37327;2sED&#65292;&#21487;&#20197;&#21487;&#38752;&#22320;&#38480;&#21046;&#27867;&#21270;&#35823;&#24046;&#65292;&#24182;&#19988;&#19982;&#35757;&#32451;&#35823;&#24046;&#20855;&#26377;&#24456;&#22909;&#30340;&#30456;&#20851;&#24615;&#12290;&#27492;&#22806;&#65292;&#23545;&#20110;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#36890;&#36807;&#36880;&#23618;&#36845;&#20195;&#30340;&#26041;&#27861;&#26377;&#25928;&#22320;&#36817;&#20284;2sED&#65292;&#20174;&#32780;&#22788;&#29702;&#22823;&#37327;&#21442;&#25968;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#26377;&#25928;&#32500;&#24230;&#30340;&#32479;&#35745;&#27169;&#22411;&#26032;&#23481;&#37327;&#27979;&#37327;2sED&#12290;&#36825;&#20010;&#26032;&#30340;&#25968;&#37327;&#22312;&#23545;&#27169;&#22411;&#36827;&#34892;&#28201;&#21644;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;&#21487;&#20197;&#21487;&#38752;&#22320;&#38480;&#21046;&#27867;&#21270;&#35823;&#24046;&#12290;&#27492;&#22806;&#65292;&#23545;&#20110;&#26631;&#20934;&#25968;&#25454;&#38598;&#21644;&#27969;&#34892;&#30340;&#27169;&#22411;&#26550;&#26500;&#30340;&#27169;&#25311;&#32467;&#26524;&#34920;&#26126;&#65292;2sED&#19982;&#35757;&#32451;&#35823;&#24046;&#20855;&#26377;&#24456;&#22909;&#30340;&#30456;&#20851;&#24615;&#12290;&#23545;&#20110;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#36890;&#36807;&#36880;&#23618;&#36845;&#20195;&#30340;&#26041;&#27861;&#26377;&#25928;&#22320;&#20174;&#19979;&#26041;&#36817;&#20284;2sED&#65292;&#20174;&#32780;&#35299;&#20915;&#20855;&#26377;&#22823;&#37327;&#21442;&#25968;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#12290;&#27169;&#25311;&#32467;&#26524;&#34920;&#26126;&#65292;&#36825;&#31181;&#36817;&#20284;&#23545;&#19981;&#21516;&#30340;&#31361;&#20986;&#27169;&#22411;&#21644;&#25968;&#25454;&#38598;&#37117;&#24456;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a novel capacity measure 2sED for statistical models based on the effective dimension. The new quantity provably bounds the generalization error under mild assumptions on the model. Furthermore, simulations on standard data sets and popular model architectures show that 2sED correlates well with the training error. For Markovian models, we show how to efficiently approximate 2sED from below through a layerwise iterative approach, which allows us to tackle deep learning models with a large number of parameters. Simulation results suggest that the approximation is good for different prominent models and data sets.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21442;&#25968;&#65292;&#24179;&#34913;&#32676;&#20307;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#65288;BGATE&#65289;&#65292;&#29992;&#20110;&#35299;&#37322;&#22788;&#29702;&#22312;&#32676;&#20307;&#38388;&#30340;&#25928;&#24212;&#24046;&#24322;&#65292;&#35813;&#21442;&#25968;&#22522;&#20110;&#22240;&#26524;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#23545;&#31163;&#25955;&#22788;&#29702;&#36827;&#34892;&#20272;&#35745;&#12290;&#36890;&#36807;&#27604;&#36739;&#20004;&#20010;BGATE&#30340;&#24046;&#24322;&#65292;&#33021;&#26356;&#22909;&#22320;&#20998;&#26512;&#22788;&#29702;&#30340;&#24322;&#36136;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.08290</link><description>&lt;p&gt;
&#22240;&#26524;&#26426;&#22120;&#23398;&#20064;&#29992;&#20110;&#20013;&#20171;&#25928;&#24212;&#12290; (arXiv:2401.08290v1 [econ.EM])
&lt;/p&gt;
&lt;p&gt;
Causal Machine Learning for Moderation Effects. (arXiv:2401.08290v1 [econ.EM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.08290
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21442;&#25968;&#65292;&#24179;&#34913;&#32676;&#20307;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#65288;BGATE&#65289;&#65292;&#29992;&#20110;&#35299;&#37322;&#22788;&#29702;&#22312;&#32676;&#20307;&#38388;&#30340;&#25928;&#24212;&#24046;&#24322;&#65292;&#35813;&#21442;&#25968;&#22522;&#20110;&#22240;&#26524;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#23545;&#31163;&#25955;&#22788;&#29702;&#36827;&#34892;&#20272;&#35745;&#12290;&#36890;&#36807;&#27604;&#36739;&#20004;&#20010;BGATE&#30340;&#24046;&#24322;&#65292;&#33021;&#26356;&#22909;&#22320;&#20998;&#26512;&#22788;&#29702;&#30340;&#24322;&#36136;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#20219;&#20309;&#20915;&#31574;&#32773;&#26469;&#35828;&#65292;&#20102;&#35299;&#20915;&#31574;&#65288;&#22788;&#29702;&#65289;&#23545;&#25972;&#20307;&#21644;&#23376;&#32676;&#30340;&#24433;&#21709;&#26159;&#38750;&#24120;&#26377;&#20215;&#20540;&#30340;&#12290;&#22240;&#26524;&#26426;&#22120;&#23398;&#20064;&#26368;&#36817;&#25552;&#20379;&#20102;&#29992;&#20110;&#20272;&#35745;&#32676;&#20307;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#65288;GATE&#65289;&#30340;&#24037;&#20855;&#65292;&#20197;&#26356;&#22909;&#22320;&#29702;&#35299;&#22788;&#29702;&#30340;&#24322;&#36136;&#24615;&#12290;&#26412;&#25991;&#35299;&#20915;&#20102;&#22312;&#32771;&#34385;&#20854;&#20182;&#21327;&#21464;&#37327;&#21464;&#21270;&#30340;&#24773;&#20917;&#19979;&#35299;&#37322;&#32676;&#20307;&#38388;&#22788;&#29702;&#25928;&#24212;&#24046;&#24322;&#30340;&#38590;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#21442;&#25968;&#65292;&#21363;&#24179;&#34913;&#32676;&#20307;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#65288;BGATE&#65289;&#65292;&#23427;&#34913;&#37327;&#20102;&#20855;&#26377;&#29305;&#23450;&#20998;&#24067;&#30340;&#20808;&#39564;&#30830;&#23450;&#21327;&#21464;&#37327;&#30340;GATE&#12290;&#36890;&#36807;&#27604;&#36739;&#20004;&#20010;BGATE&#30340;&#24046;&#24322;&#65292;&#25105;&#20204;&#21487;&#20197;&#26356;&#26377;&#24847;&#20041;&#22320;&#20998;&#26512;&#24322;&#36136;&#24615;&#65292;&#32780;&#19981;&#20165;&#20165;&#27604;&#36739;&#20004;&#20010;GATE&#12290;&#36825;&#20010;&#21442;&#25968;&#30340;&#20272;&#35745;&#31574;&#30053;&#26159;&#22522;&#20110;&#26080;&#28151;&#28102;&#35774;&#32622;&#20013;&#31163;&#25955;&#22788;&#29702;&#30340;&#21452;&#37325;/&#21435;&#20559;&#26426;&#22120;&#23398;&#20064;&#65292;&#35813;&#20272;&#35745;&#37327;&#22312;&#26631;&#20934;&#26465;&#20214;&#19979;&#34920;&#29616;&#20026;$\sqrt{N}$&#19968;&#33268;&#24615;&#21644;&#28176;&#36817;&#27491;&#24577;&#24615;&#12290;&#28155;&#21152;&#39069;&#22806;&#30340;&#26631;&#35782;
&lt;/p&gt;
&lt;p&gt;
It is valuable for any decision maker to know the impact of decisions (treatments) on average and for subgroups. The causal machine learning literature has recently provided tools for estimating group average treatment effects (GATE) to understand treatment heterogeneity better. This paper addresses the challenge of interpreting such differences in treatment effects between groups while accounting for variations in other covariates. We propose a new parameter, the balanced group average treatment effect (BGATE), which measures a GATE with a specific distribution of a priori-determined covariates. By taking the difference of two BGATEs, we can analyse heterogeneity more meaningfully than by comparing two GATEs. The estimation strategy for this parameter is based on double/debiased machine learning for discrete treatments in an unconfoundedness setting, and the estimator is shown to be $\sqrt{N}$-consistent and asymptotically normal under standard conditions. Adding additional identifyin
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20108;&#20803;&#32467;&#26524;&#25552;&#21319;&#24314;&#27169;&#36716;&#25442;&#26041;&#27861;&#65292;&#21033;&#29992;&#20102;&#38646;&#32467;&#26524;&#26679;&#26412;&#30340;&#20449;&#24687;&#24182;&#19988;&#26131;&#20110;&#20351;&#29992;&#12290; (arXiv:2310.05549v1 [stat.ML])</title><link>http://arxiv.org/abs/2310.05549</link><description>&lt;p&gt;
&#19968;&#20010;&#26032;&#30340;&#20108;&#20803;&#32467;&#26524;&#25552;&#21319;&#24314;&#27169;&#36716;&#25442;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A New Transformation Approach for Uplift Modeling with Binary Outcome. (arXiv:2310.05549v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.05549
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20108;&#20803;&#32467;&#26524;&#25552;&#21319;&#24314;&#27169;&#36716;&#25442;&#26041;&#27861;&#65292;&#21033;&#29992;&#20102;&#38646;&#32467;&#26524;&#26679;&#26412;&#30340;&#20449;&#24687;&#24182;&#19988;&#26131;&#20110;&#20351;&#29992;&#12290; (arXiv:2310.05549v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25552;&#21319;&#24314;&#27169;&#22312;&#24066;&#22330;&#33829;&#38144;&#21644;&#23458;&#25143;&#20445;&#30041;&#31561;&#39046;&#22495;&#20013;&#24471;&#21040;&#20102;&#26377;&#25928;&#24212;&#29992;&#65292;&#29992;&#20110;&#38024;&#23545;&#37027;&#20123;&#30001;&#20110;&#27963;&#21160;&#25110;&#27835;&#30103;&#26356;&#26377;&#21487;&#33021;&#20135;&#29983;&#21453;&#24212;&#30340;&#23458;&#25143;&#12290;&#26412;&#25991;&#35774;&#35745;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20108;&#20803;&#32467;&#26524;&#36716;&#25442;&#26041;&#27861;&#65292;&#35299;&#38145;&#20102;&#38646;&#32467;&#26524;&#26679;&#26412;&#30340;&#20840;&#37096;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
Uplift modeling has been used effectively in fields such as marketing and customer retention, to target those customers who are more likely to respond due to the campaign or treatment. Essentially, it is a machine learning technique that predicts the gain from performing some action with respect to not taking it. A popular class of uplift models is the transformation approach that redefines the target variable with the original treatment indicator. These transformation approaches only need to train and predict the difference in outcomes directly. The main drawback of these approaches is that in general it does not use the information in the treatment indicator beyond the construction of the transformed outcome and usually is not efficient. In this paper, we design a novel transformed outcome for the case of the binary target variable and unlock the full value of the samples with zero outcome. From a practical perspective, our new approach is flexible and easy to use. Experimental resul
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#35777;&#26126;&#20102;&#23558;&#28040;&#24687;&#20256;&#36882;&#31070;&#32463;&#32593;&#32476;&#24212;&#29992;&#20110;&#31232;&#30095;&#22270;&#30340;&#33410;&#28857;&#20998;&#31867;&#20219;&#21153;&#26159;&#28176;&#36817;&#26412;&#22320;&#36125;&#21494;&#26031;&#26368;&#20248;&#30340;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#23454;&#29616;&#26368;&#20248;&#20998;&#31867;&#22120;&#30340;&#31639;&#27861;&#65292;&#24182;&#23558;&#26368;&#20248;&#20998;&#31867;&#22120;&#30340;&#24615;&#33021;&#29702;&#35770;&#19978;&#19982;&#29616;&#26377;&#23398;&#20064;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;</title><link>http://arxiv.org/abs/2305.10391</link><description>&lt;p&gt;
&#31232;&#30095;&#22270;&#30340;&#28040;&#24687;&#20256;&#36882;&#26550;&#26500;&#30340;&#26368;&#20248;&#24615;
&lt;/p&gt;
&lt;p&gt;
Optimality of Message-Passing Architectures for Sparse Graphs. (arXiv:2305.10391v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.10391
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35777;&#26126;&#20102;&#23558;&#28040;&#24687;&#20256;&#36882;&#31070;&#32463;&#32593;&#32476;&#24212;&#29992;&#20110;&#31232;&#30095;&#22270;&#30340;&#33410;&#28857;&#20998;&#31867;&#20219;&#21153;&#26159;&#28176;&#36817;&#26412;&#22320;&#36125;&#21494;&#26031;&#26368;&#20248;&#30340;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#23454;&#29616;&#26368;&#20248;&#20998;&#31867;&#22120;&#30340;&#31639;&#27861;&#65292;&#24182;&#23558;&#26368;&#20248;&#20998;&#31867;&#22120;&#30340;&#24615;&#33021;&#29702;&#35770;&#19978;&#19982;&#29616;&#26377;&#23398;&#20064;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#29305;&#24449;&#35013;&#39280;&#22270;&#19978;&#30340;&#33410;&#28857;&#20998;&#31867;&#38382;&#39064;&#65292;&#22312;&#31232;&#30095;&#35774;&#32622;&#19979;&#65292;&#21363;&#33410;&#28857;&#30340;&#39044;&#26399;&#24230;&#25968;&#20026;&#33410;&#28857;&#25968;&#30340;O(1)&#26102;&#12290;&#36825;&#26679;&#30340;&#22270;&#36890;&#24120;&#34987;&#31216;&#20026;&#26412;&#22320;&#26641;&#29366;&#22270;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#21483;&#20570;&#28176;&#36817;&#26412;&#22320;&#36125;&#21494;&#26031;&#26368;&#20248;&#24615;&#30340;&#33410;&#28857;&#20998;&#31867;&#20219;&#21153;&#30340;&#36125;&#21494;&#26031;&#26368;&#20248;&#24615;&#27010;&#24565;&#65292;&#24182;&#26681;&#25454;&#36825;&#20010;&#26631;&#20934;&#35745;&#31639;&#20102;&#20855;&#26377;&#20219;&#24847;&#33410;&#28857;&#29305;&#24449;&#21644;&#36793;&#36830;&#25509;&#20998;&#24067;&#30340;&#30456;&#24403;&#19968;&#33324;&#30340;&#32479;&#35745;&#25968;&#25454;&#27169;&#22411;&#30340;&#26368;&#20248;&#20998;&#31867;&#22120;&#12290;&#35813;&#26368;&#20248;&#20998;&#31867;&#22120;&#21487;&#20197;&#20351;&#29992;&#28040;&#24687;&#20256;&#36882;&#22270;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#23454;&#29616;&#12290;&#28982;&#21518;&#25105;&#20204;&#35745;&#31639;&#20102;&#35813;&#20998;&#31867;&#22120;&#30340;&#27867;&#21270;&#35823;&#24046;&#65292;&#24182;&#22312;&#19968;&#20010;&#24050;&#32463;&#30740;&#31350;&#20805;&#20998;&#30340;&#32479;&#35745;&#27169;&#22411;&#19978;&#20174;&#29702;&#35770;&#19978;&#19982;&#29616;&#26377;&#30340;&#23398;&#20064;&#26041;&#27861;&#36827;&#34892;&#27604;&#36739;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#22312;&#20302;&#22270;&#20449;&#21495;&#30340;&#24773;&#20917;&#19979;&#65292;&#26368;&#20339;&#28040;&#24687;&#20256;&#36882;&#26550;&#26500;&#25554;&#20540;&#20110;&#26631;&#20934;MLP&#21644;&#19968;&#31181;&#20856;&#22411;&#30340;c&#26550;&#26500;&#20043;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the node classification problem on feature-decorated graphs in the sparse setting, i.e., when the expected degree of a node is $O(1)$ in the number of nodes. Such graphs are typically known to be locally tree-like. We introduce a notion of Bayes optimality for node classification tasks, called asymptotic local Bayes optimality, and compute the optimal classifier according to this criterion for a fairly general statistical data model with arbitrary distributions of the node features and edge connectivity. The optimal classifier is implementable using a message-passing graph neural network architecture. We then compute the generalization error of this classifier and compare its performance against existing learning methods theoretically on a well-studied statistical model with naturally identifiable signal-to-noise ratios (SNRs) in the data. We find that the optimal message-passing architecture interpolates between a standard MLP in the regime of low graph signal and a typical c
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#35299;&#37322;&#40657;&#31665;&#39044;&#27979;&#31639;&#27861;&#34892;&#20026;&#30340;&#22240;&#26524;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#22240;&#26524;&#22270;&#34920;&#31034;&#26469;&#25552;&#20379;&#22240;&#26524;&#35299;&#37322;&#65292;&#24357;&#34917;&#20102;&#29616;&#26377;&#26041;&#27861;&#30340;&#32570;&#28857;&#65292;&#21363;&#35299;&#37322;&#21333;&#20803;&#26356;&#21152;&#21487;&#35299;&#37322;&#19988;&#32771;&#34385;&#20102;&#23439;&#35266;&#32423;&#29305;&#24449;&#21644;&#26410;&#27979;&#37327;&#30340;&#28151;&#28102;&#12290;</title><link>http://arxiv.org/abs/2006.02482</link><description>&lt;p&gt;
&#29992;&#22240;&#26524;&#23398;&#20064;&#35299;&#37322;&#40657;&#31665;&#39044;&#27979;&#31639;&#27861;&#30340;&#34892;&#20026;
&lt;/p&gt;
&lt;p&gt;
Explaining the Behavior of Black-Box Prediction Algorithms with Causal Learning. (arXiv:2006.02482v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2006.02482
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#35299;&#37322;&#40657;&#31665;&#39044;&#27979;&#31639;&#27861;&#34892;&#20026;&#30340;&#22240;&#26524;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#22240;&#26524;&#22270;&#34920;&#31034;&#26469;&#25552;&#20379;&#22240;&#26524;&#35299;&#37322;&#65292;&#24357;&#34917;&#20102;&#29616;&#26377;&#26041;&#27861;&#30340;&#32570;&#28857;&#65292;&#21363;&#35299;&#37322;&#21333;&#20803;&#26356;&#21152;&#21487;&#35299;&#37322;&#19988;&#32771;&#34385;&#20102;&#23439;&#35266;&#32423;&#29305;&#24449;&#21644;&#26410;&#27979;&#37327;&#30340;&#28151;&#28102;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#26524;&#23398;&#26041;&#27861;&#22312;&#35299;&#37322;&#40657;&#31665;&#39044;&#27979;&#27169;&#22411;&#65288;&#20363;&#22914;&#22522;&#20110;&#22270;&#20687;&#20687;&#32032;&#25968;&#25454;&#35757;&#32451;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65289;&#26041;&#38754;&#36234;&#26469;&#36234;&#21463;&#27426;&#36814;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#26041;&#27861;&#23384;&#22312;&#20004;&#20010;&#37325;&#35201;&#32570;&#28857;&#65306;&#65288;i&#65289;&#8220;&#35299;&#37322;&#21333;&#20803;&#8221;&#26159;&#30456;&#20851;&#39044;&#27979;&#27169;&#22411;&#30340;&#24494;&#35266;&#32423;&#36755;&#20837;&#65292;&#20363;&#22914;&#22270;&#20687;&#20687;&#32032;&#65292;&#32780;&#19981;&#26159;&#26356;&#26377;&#29992;&#20110;&#29702;&#35299;&#22914;&#20309;&#21487;&#33021;&#25913;&#21464;&#31639;&#27861;&#34892;&#20026;&#30340;&#21487;&#35299;&#37322;&#30340;&#23439;&#35266;&#32423;&#29305;&#24449;&#65307;&#65288;ii&#65289;&#29616;&#26377;&#26041;&#27861;&#20551;&#35774;&#29305;&#24449;&#19982;&#30446;&#26631;&#27169;&#22411;&#39044;&#27979;&#20043;&#38388;&#19981;&#23384;&#22312;&#26410;&#27979;&#37327;&#30340;&#28151;&#28102;&#65292;&#36825;&#22312;&#35299;&#37322;&#21333;&#20803;&#26159;&#23439;&#35266;&#32423;&#21464;&#37327;&#26102;&#19981;&#25104;&#31435;&#12290;&#25105;&#20204;&#20851;&#27880;&#30340;&#26159;&#22312;&#20998;&#26512;&#20154;&#21592;&#26080;&#27861;&#35775;&#38382;&#30446;&#26631;&#39044;&#27979;&#31639;&#27861;&#20869;&#37096;&#24037;&#20316;&#21407;&#29702;&#30340;&#37325;&#35201;&#24773;&#20917;&#65292;&#32780;&#21482;&#33021;&#26681;&#25454;&#29305;&#23450;&#36755;&#20837;&#26597;&#35810;&#27169;&#22411;&#36755;&#20986;&#30340;&#33021;&#21147;&#12290;&#20026;&#20102;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#25552;&#20379;&#22240;&#26524;&#35299;&#37322;&#65292;&#25105;&#20204;&#25552;&#20986;&#23398;&#20064;&#22240;&#26524;&#22270;&#34920;&#31034;&#65292;&#20801;&#35768;&#26356;&#22909;&#22320;&#29702;&#35299;&#31639;&#27861;&#30340;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;
Causal approaches to post-hoc explainability for black-box prediction models (e.g., deep neural networks trained on image pixel data) have become increasingly popular. However, existing approaches have two important shortcomings: (i) the "explanatory units" are micro-level inputs into the relevant prediction model, e.g., image pixels, rather than interpretable macro-level features that are more useful for understanding how to possibly change the algorithm's behavior, and (ii) existing approaches assume there exists no unmeasured confounding between features and target model predictions, which fails to hold when the explanatory units are macro-level variables. Our focus is on the important setting where the analyst has no access to the inner workings of the target prediction algorithm, rather only the ability to query the output of the model in response to a particular input. To provide causal explanations in such a setting, we propose to learn causal graphical representations that allo
&lt;/p&gt;</description></item></channel></rss>