<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#19968;&#31181;&#23884;&#22871;APT&#26041;&#27861;&#26469;&#35299;&#20915;&#39034;&#24207;&#31070;&#32463;&#21518;&#39564;&#20272;&#35745;&#20013;&#30340;&#23884;&#22871;&#26399;&#26395;&#35745;&#31639;&#38382;&#39064;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#25910;&#25947;&#24615;&#20998;&#26512;&#12290;</title><link>http://arxiv.org/abs/2401.16776</link><description>&lt;p&gt;
&#21033;&#29992;&#23884;&#22871;MLMC&#23545;&#20855;&#26377;&#38590;&#20197;&#22788;&#29702;&#30340;&#20284;&#28982;&#20989;&#25968;&#30340;&#39034;&#24207;&#31070;&#32463;&#21518;&#39564;&#20272;&#35745;&#36827;&#34892;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Leveraging Nested MLMC for Sequential Neural Posterior Estimation with Intractable Likelihoods. (arXiv:2401.16776v1 [stat.CO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.16776
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#19968;&#31181;&#23884;&#22871;APT&#26041;&#27861;&#26469;&#35299;&#20915;&#39034;&#24207;&#31070;&#32463;&#21518;&#39564;&#20272;&#35745;&#20013;&#30340;&#23884;&#22871;&#26399;&#26395;&#35745;&#31639;&#38382;&#39064;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#25910;&#25947;&#24615;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#25552;&#20986;&#20102;&#39034;&#24207;&#31070;&#32463;&#21518;&#39564;&#20272;&#35745;&#65288;SNPE&#65289;&#25216;&#26415;&#65292;&#29992;&#20110;&#22788;&#29702;&#20855;&#26377;&#38590;&#20197;&#22788;&#29702;&#30340;&#20284;&#28982;&#20989;&#25968;&#30340;&#22522;&#20110;&#27169;&#25311;&#30340;&#27169;&#22411;&#12290;&#23427;&#20204;&#33268;&#21147;&#20110;&#36890;&#36807;&#20351;&#29992;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#26465;&#20214;&#23494;&#24230;&#20272;&#35745;&#22120;&#33258;&#36866;&#24212;&#22320;&#29983;&#25104;&#30340;&#27169;&#25311;&#26469;&#23398;&#20064;&#21518;&#39564;&#12290;&#20316;&#20026;&#19968;&#31181;SNPE&#25216;&#26415;&#65292;Greenberg&#31561;&#20154;&#65288;2019&#65289;&#25552;&#20986;&#30340;&#33258;&#21160;&#21518;&#39564;&#21464;&#25442;&#65288;APT&#65289;&#26041;&#27861;&#34920;&#29616;&#20986;&#33394;&#65292;&#24182;&#21487;&#24212;&#29992;&#20110;&#39640;&#32500;&#25968;&#25454;&#12290;&#28982;&#32780;&#65292;APT&#26041;&#27861;&#21253;&#21547;&#35745;&#31639;&#38590;&#20197;&#22788;&#29702;&#30340;&#24402;&#19968;&#21270;&#24120;&#25968;&#30340;&#23545;&#25968;&#30340;&#26399;&#26395;&#65292;&#21363;&#23884;&#22871;&#26399;&#26395;&#12290;&#23613;&#31649;&#21407;&#23376;APT&#36890;&#36807;&#31163;&#25955;&#21270;&#24402;&#19968;&#21270;&#24120;&#25968;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#20294;&#20998;&#26512;&#23398;&#20064;&#30340;&#25910;&#25947;&#24615;&#20173;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#23884;&#22871;APT&#26041;&#27861;&#26469;&#20272;&#35745;&#30456;&#20851;&#30340;&#23884;&#22871;&#26399;&#26395;&#12290;&#36825;&#26377;&#21161;&#20110;&#24314;&#31435;&#25910;&#25947;&#24615;&#20998;&#26512;&#12290;&#30001;&#20110;&#25439;&#22833;&#20989;&#25968;&#21450;&#20854;&#26799;&#24230;&#30340;&#23884;&#22871;&#20272;&#35745;&#26159;&#26377;&#20559;&#30340;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;
&lt;/p&gt;
&lt;p&gt;
Sequential neural posterior estimation (SNPE) techniques have been recently proposed for dealing with simulation-based models with intractable likelihoods. They are devoted to learning the posterior from adaptively proposed simulations using neural network-based conditional density estimators. As a SNPE technique, the automatic posterior transformation (APT) method proposed by Greenberg et al. (2019) performs notably and scales to high dimensional data. However, the APT method bears the computation of an expectation of the logarithm of an intractable normalizing constant, i.e., a nested expectation. Although atomic APT was proposed to solve this by discretizing the normalizing constant, it remains challenging to analyze the convergence of learning. In this paper, we propose a nested APT method to estimate the involved nested expectation instead. This facilitates establishing the convergence analysis. Since the nested estimators for the loss function and its gradient are biased, we make
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#21033;&#29992;&#28145;&#24230;&#23398;&#20064;&#25216;&#26415;&#22312;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#24773;&#20917;&#19979;&#26816;&#27979;&#21644;&#20998;&#31867;&#33041;&#32959;&#30244;&#65292;&#24182;&#35299;&#20915;&#20102;&#22312;&#32597;&#35265;&#24773;&#20917;&#19979;&#30340;&#32959;&#30244;&#26816;&#27979;&#38382;&#39064;&#12290;&#30740;&#31350;&#20351;&#29992;&#20102;&#26469;&#33258;&#22269;&#23478;&#33041;&#26144;&#23556;&#23454;&#39564;&#23460;&#30340;&#25968;&#25454;&#38598;&#65292;&#36890;&#36807;&#20462;&#25913;&#26679;&#26412;&#25968;&#37327;&#21644;&#24739;&#32773;&#20998;&#24067;&#65292;&#20351;&#27169;&#22411;&#33021;&#22815;&#24212;&#23545;&#30495;&#23454;&#19990;&#30028;&#22330;&#26223;&#20013;&#30340;&#24322;&#24120;&#24773;&#20917;&#12290;</title><link>http://arxiv.org/abs/2401.03302</link><description>&lt;p&gt;
&#34892;&#21160;&#20013;&#30340;&#29616;&#23454;&#20027;&#20041;&#65306;&#20351;&#29992;YOLOv8&#21644;DeiT&#20174;&#21307;&#23398;&#22270;&#20687;&#20013;&#35786;&#26029;&#33041;&#32959;&#30244;&#30340;&#24322;&#24120;&#24863;&#30693;
&lt;/p&gt;
&lt;p&gt;
Realism in Action: Anomaly-Aware Diagnosis of Brain Tumors from Medical Images Using YOLOv8 and DeiT. (arXiv:2401.03302v1 [eess.IV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.03302
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21033;&#29992;&#28145;&#24230;&#23398;&#20064;&#25216;&#26415;&#22312;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#24773;&#20917;&#19979;&#26816;&#27979;&#21644;&#20998;&#31867;&#33041;&#32959;&#30244;&#65292;&#24182;&#35299;&#20915;&#20102;&#22312;&#32597;&#35265;&#24773;&#20917;&#19979;&#30340;&#32959;&#30244;&#26816;&#27979;&#38382;&#39064;&#12290;&#30740;&#31350;&#20351;&#29992;&#20102;&#26469;&#33258;&#22269;&#23478;&#33041;&#26144;&#23556;&#23454;&#39564;&#23460;&#30340;&#25968;&#25454;&#38598;&#65292;&#36890;&#36807;&#20462;&#25913;&#26679;&#26412;&#25968;&#37327;&#21644;&#24739;&#32773;&#20998;&#24067;&#65292;&#20351;&#27169;&#22411;&#33021;&#22815;&#24212;&#23545;&#30495;&#23454;&#19990;&#30028;&#22330;&#26223;&#20013;&#30340;&#24322;&#24120;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21307;&#23398;&#31185;&#23398;&#39046;&#22495;&#65292;&#30001;&#20110;&#33041;&#32959;&#30244;&#22312;&#24739;&#32773;&#20013;&#30340;&#32597;&#35265;&#31243;&#24230;&#65292;&#21487;&#38752;&#22320;&#26816;&#27979;&#21644;&#20998;&#31867;&#33041;&#32959;&#30244;&#20173;&#28982;&#26159;&#19968;&#20010;&#33392;&#24040;&#30340;&#25361;&#25112;&#12290;&#22240;&#27492;&#65292;&#22312;&#24322;&#24120;&#24773;&#20917;&#19979;&#26816;&#27979;&#32959;&#30244;&#30340;&#33021;&#21147;&#23545;&#20110;&#30830;&#20445;&#21450;&#26102;&#24178;&#39044;&#21644;&#25913;&#21892;&#24739;&#32773;&#32467;&#26524;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#30740;&#31350;&#21033;&#29992;&#28145;&#24230;&#23398;&#20064;&#25216;&#26415;&#22312;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#24773;&#20917;&#19979;&#26816;&#27979;&#21644;&#20998;&#31867;&#33041;&#32959;&#30244;&#12290;&#26469;&#33258;&#22269;&#23478;&#33041;&#26144;&#23556;&#23454;&#39564;&#23460;&#65288;NBML&#65289;&#30340;&#31934;&#36873;&#25968;&#25454;&#38598;&#21253;&#25324;81&#21517;&#24739;&#32773;&#65292;&#20854;&#20013;&#21253;&#25324;30&#20363;&#32959;&#30244;&#30149;&#20363;&#21644;51&#20363;&#27491;&#24120;&#30149;&#20363;&#12290;&#26816;&#27979;&#21644;&#20998;&#31867;&#27969;&#31243;&#34987;&#20998;&#20026;&#20004;&#20010;&#36830;&#32493;&#30340;&#20219;&#21153;&#12290;&#26816;&#27979;&#38454;&#27573;&#21253;&#25324;&#20840;&#38754;&#30340;&#25968;&#25454;&#20998;&#26512;&#21644;&#39044;&#22788;&#29702;&#65292;&#20197;&#20462;&#25913;&#22270;&#20687;&#26679;&#26412;&#21644;&#27599;&#20010;&#31867;&#21035;&#30340;&#24739;&#32773;&#25968;&#37327;&#65292;&#20197;&#31526;&#21512;&#30495;&#23454;&#19990;&#30028;&#22330;&#26223;&#20013;&#30340;&#24322;&#24120;&#20998;&#24067;&#65288;9&#20010;&#27491;&#24120;&#26679;&#26412;&#23545;&#24212;1&#20010;&#32959;&#30244;&#26679;&#26412;&#65289;&#12290;&#27492;&#22806;&#65292;&#22312;&#27979;&#35797;&#20013;&#38500;&#20102;&#24120;&#35265;&#30340;&#35780;&#20272;&#25351;&#26631;&#22806;&#65292;&#25105;&#20204;&#36824;&#37319;&#29992;&#20102;... [&#25688;&#35201;&#38271;&#24230;&#24050;&#36798;&#21040;&#19978;&#38480;]
&lt;/p&gt;
&lt;p&gt;
In the field of medical sciences, reliable detection and classification of brain tumors from images remains a formidable challenge due to the rarity of tumors within the population of patients. Therefore, the ability to detect tumors in anomaly scenarios is paramount for ensuring timely interventions and improved patient outcomes. This study addresses the issue by leveraging deep learning (DL) techniques to detect and classify brain tumors in challenging situations. The curated data set from the National Brain Mapping Lab (NBML) comprises 81 patients, including 30 Tumor cases and 51 Normal cases. The detection and classification pipelines are separated into two consecutive tasks. The detection phase involved comprehensive data analysis and pre-processing to modify the number of image samples and the number of patients of each class to anomaly distribution (9 Normal per 1 Tumor) to comply with real world scenarios. Next, in addition to common evaluation metrics for the testing, we emplo
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39640;&#32500;&#27969;&#24418;&#30340;SOFAR&#25512;&#26029;&#65288;SOFARI&#65289;&#26041;&#27861;&#65292;&#36890;&#36807;&#32467;&#21512;Neyman&#36817;&#27491;&#20132;&#25512;&#26029;&#21644;SVD&#32422;&#26463;&#30340;Stiefel&#27969;&#24418;&#32467;&#26500;&#65292;&#23454;&#29616;&#20102;&#23545;&#22810;&#20219;&#21153;&#23398;&#20064;&#20013;&#28508;&#22312;&#22240;&#23376;&#30697;&#38453;&#30340;&#20934;&#30830;&#25512;&#26029;&#12290;</title><link>http://arxiv.org/abs/2309.15032</link><description>&lt;p&gt;
SOFARI:&#22522;&#20110;&#39640;&#32500;&#27969;&#24418;&#30340;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
SOFARI: High-Dimensional Manifold-Based Inference. (arXiv:2309.15032v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.15032
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39640;&#32500;&#27969;&#24418;&#30340;SOFAR&#25512;&#26029;&#65288;SOFARI&#65289;&#26041;&#27861;&#65292;&#36890;&#36807;&#32467;&#21512;Neyman&#36817;&#27491;&#20132;&#25512;&#26029;&#21644;SVD&#32422;&#26463;&#30340;Stiefel&#27969;&#24418;&#32467;&#26500;&#65292;&#23454;&#29616;&#20102;&#23545;&#22810;&#20219;&#21153;&#23398;&#20064;&#20013;&#28508;&#22312;&#22240;&#23376;&#30697;&#38453;&#30340;&#20934;&#30830;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#20219;&#21153;&#23398;&#20064;&#26159;&#19968;&#31181;&#24191;&#27867;&#20351;&#29992;&#30340;&#25216;&#26415;&#65292;&#29992;&#20110;&#20174;&#21508;&#31181;&#20219;&#21153;&#20013;&#25552;&#21462;&#20449;&#24687;&#12290;&#26368;&#36817;&#65292;&#22522;&#20110;&#31995;&#25968;&#30697;&#38453;&#20013;&#30340;&#31232;&#30095;&#22855;&#24322;&#20540;&#20998;&#35299;&#65288;SVD&#65289;&#30340;&#31232;&#30095;&#27491;&#20132;&#22240;&#23376;&#22238;&#24402;&#65288;SOFAR&#65289;&#26694;&#26550;&#34987;&#24341;&#20837;&#21040;&#21487;&#35299;&#37322;&#30340;&#22810;&#20219;&#21153;&#23398;&#20064;&#20013;&#65292;&#21487;&#20197;&#21457;&#29616;&#19981;&#21516;&#23618;&#27425;&#20043;&#38388;&#26377;&#24847;&#20041;&#30340;&#28508;&#22312;&#29305;&#24449;-&#21709;&#24212;&#20851;&#32852;&#32593;&#32476;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#31232;&#30095;SVD&#32422;&#26463;&#30340;&#27491;&#20132;&#24615;&#32422;&#26463;&#65292;&#23545;&#28508;&#22312;&#22240;&#23376;&#30697;&#38453;&#36827;&#34892;&#31934;&#30830;&#25512;&#26029;&#20173;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#31216;&#20026;&#22522;&#20110;&#39640;&#32500;&#27969;&#24418;&#30340;SOFAR&#25512;&#26029;&#65288;SOFARI&#65289;&#65292;&#20511;&#37492;&#20102;Neyman&#36817;&#27491;&#20132;&#25512;&#26029;&#65292;&#24182;&#32467;&#21512;&#20102;SVD&#32422;&#26463;&#25152;&#26045;&#21152;&#30340;Stiefel&#27969;&#24418;&#32467;&#26500;&#12290;&#36890;&#36807;&#21033;&#29992;&#28508;&#22312;&#30340;Stiefel&#27969;&#24418;&#32467;&#26500;&#65292;SOFARI&#20026;&#28508;&#22312;&#24038;&#22240;&#23376;&#21521;&#37327;&#21644;&#22855;&#24322;&#20540;&#25552;&#20379;&#20102;&#20559;&#24046;&#26657;&#27491;&#30340;&#20272;&#35745;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multi-task learning is a widely used technique for harnessing information from various tasks. Recently, the sparse orthogonal factor regression (SOFAR) framework, based on the sparse singular value decomposition (SVD) within the coefficient matrix, was introduced for interpretable multi-task learning, enabling the discovery of meaningful latent feature-response association networks across different layers. However, conducting precise inference on the latent factor matrices has remained challenging due to orthogonality constraints inherited from the sparse SVD constraint. In this paper, we suggest a novel approach called high-dimensional manifold-based SOFAR inference (SOFARI), drawing on the Neyman near-orthogonality inference while incorporating the Stiefel manifold structure imposed by the SVD constraints. By leveraging the underlying Stiefel manifold structure, SOFARI provides bias-corrected estimators for both latent left factor vectors and singular values, for which we show to enj
&lt;/p&gt;</description></item></channel></rss>