<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#25552;&#20986;&#19968;&#31181;&#20351;&#29992;Concrete&#20998;&#24067;&#20316;&#20026;&#27010;&#29575;&#21333;&#32431;&#24418;&#19978;&#30340;&#27010;&#29575;&#27169;&#22411;&#30340;&#20445;&#25345;&#31934;&#24230;&#30340;&#26657;&#20934;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20854;&#22312;&#20132;&#21449;&#29109;&#25439;&#22833;&#19978;&#35757;&#32451;&#30340;DNN&#27169;&#22411;&#20855;&#26377;&#26368;&#20248;&#24615;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#26679;&#26412;&#29983;&#25104;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.13765</link><description>&lt;p&gt;
&#36890;&#36807;&#27010;&#29575;&#21333;&#32431;&#24418;&#19978;&#30340;&#32479;&#35745;&#24314;&#27169;&#23454;&#29616;&#20445;&#25345;&#31934;&#24230;&#30340;&#26657;&#20934;
&lt;/p&gt;
&lt;p&gt;
Accuracy-Preserving Calibration via Statistical Modeling on Probability Simplex
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13765
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#19968;&#31181;&#20351;&#29992;Concrete&#20998;&#24067;&#20316;&#20026;&#27010;&#29575;&#21333;&#32431;&#24418;&#19978;&#30340;&#27010;&#29575;&#27169;&#22411;&#30340;&#20445;&#25345;&#31934;&#24230;&#30340;&#26657;&#20934;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20854;&#22312;&#20132;&#21449;&#29109;&#25439;&#22833;&#19978;&#35757;&#32451;&#30340;DNN&#27169;&#22411;&#20855;&#26377;&#26368;&#20248;&#24615;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#26679;&#26412;&#29983;&#25104;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNNs&#65289;&#30340;&#20998;&#31867;&#27169;&#22411;&#24517;&#39035;&#36827;&#34892;&#26657;&#20934;&#65292;&#20197;&#35780;&#20272;&#39044;&#27979;&#32467;&#26524;&#30340;&#21487;&#38752;&#24615;&#12290;&#19968;&#20123;&#26368;&#36817;&#30340;&#26657;&#20934;&#26041;&#27861;&#37319;&#29992;&#20102;&#27010;&#29575;&#21333;&#32431;&#24418;&#19978;&#30340;&#27010;&#29575;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26657;&#20934;&#26041;&#27861;&#26080;&#27861;&#20445;&#25345;&#39044;&#35757;&#32451;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#65292;&#21363;&#20351;&#36825;&#20123;&#27169;&#22411;&#20855;&#26377;&#24456;&#39640;&#30340;&#20998;&#31867;&#20934;&#30830;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;Concrete&#20998;&#24067;&#20316;&#20026;&#27010;&#29575;&#21333;&#32431;&#24418;&#19978;&#30340;&#27010;&#29575;&#27169;&#22411;&#30340;&#20445;&#25345;&#31934;&#24230;&#30340;&#26657;&#20934;&#26041;&#27861;&#12290;&#25105;&#20204;&#22312;&#29702;&#35770;&#19978;&#35777;&#26126;&#65292;&#22312;&#20132;&#21449;&#29109;&#25439;&#22833;&#19978;&#35757;&#32451;&#30340;DNN&#27169;&#22411;&#20855;&#26377;Concrete&#20998;&#24067;&#21442;&#25968;&#30340;&#26368;&#20248;&#24615;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#21512;&#25104;&#29983;&#25104;&#26679;&#26412;&#65292;&#29992;&#20110;&#22312;&#27010;&#29575;&#21333;&#32431;&#24418;&#19978;&#35757;&#32451;&#27010;&#29575;&#27169;&#22411;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#31934;&#24230;&#20445;&#25345;&#26657;&#20934;&#20219;&#21153;&#19978;&#21487;&#20197;&#20248;&#20110;&#20197;&#24448;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#22522;&#20934;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13765v1 Announce Type: new  Abstract: Classification models based on deep neural networks (DNNs) must be calibrated to measure the reliability of predictions. Some recent calibration methods have employed a probabilistic model on the probability simplex. However, these calibration methods cannot preserve the accuracy of pre-trained models, even those with a high classification accuracy. We propose an accuracy-preserving calibration method using the Concrete distribution as the probabilistic model on the probability simplex. We theoretically prove that a DNN model trained on cross-entropy loss has optimality as the parameter of the Concrete distribution. We also propose an efficient method that synthetically generates samples for training probabilistic models on the probability simplex. We demonstrate that the proposed method can outperform previous methods in accuracy-preserving calibration tasks using benchmarks.
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31209;&#30340;&#22810;&#37325;&#26816;&#39564;&#20462;&#27491;&#26041;&#27861;&#65292;&#33021;&#22815;&#26377;&#25928;&#21033;&#29992;&#27491;&#30456;&#20851;&#30340;&#32479;&#35745;&#20551;&#35774;&#26816;&#39564;&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#65292;&#24182;&#22312;&#23384;&#22312;&#27491;&#30456;&#20851;&#20381;&#36182;&#24773;&#20917;&#19979;&#20248;&#20110;Bonferroni&#20462;&#27491;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#23588;&#20854;&#36866;&#29992;&#20110;&#24182;&#34892;&#32622;&#25442;&#26816;&#39564;&#65292;&#22312;&#20445;&#35777;FWER&#25511;&#21046;&#30340;&#21516;&#26102;&#20445;&#25345;&#39640;&#32479;&#35745;&#21151;&#25928;&#12290;</title><link>http://arxiv.org/abs/2311.10900</link><description>&lt;p&gt;
&#19968;&#31181;&#22522;&#20110;&#31209;&#30340;&#22810;&#37325;&#26816;&#39564;&#27491;&#30456;&#20851;&#20381;&#36182;&#30340;&#24378;&#22823;&#20462;&#27491;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A powerful rank-based correction to multiple testing under positive dependency. (arXiv:2311.10900v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.10900
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31209;&#30340;&#22810;&#37325;&#26816;&#39564;&#20462;&#27491;&#26041;&#27861;&#65292;&#33021;&#22815;&#26377;&#25928;&#21033;&#29992;&#27491;&#30456;&#20851;&#30340;&#32479;&#35745;&#20551;&#35774;&#26816;&#39564;&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#65292;&#24182;&#22312;&#23384;&#22312;&#27491;&#30456;&#20851;&#20381;&#36182;&#24773;&#20917;&#19979;&#20248;&#20110;Bonferroni&#20462;&#27491;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#23588;&#20854;&#36866;&#29992;&#20110;&#24182;&#34892;&#32622;&#25442;&#26816;&#39564;&#65292;&#22312;&#20445;&#35777;FWER&#25511;&#21046;&#30340;&#21516;&#26102;&#20445;&#25345;&#39640;&#32479;&#35745;&#21151;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#33021;&#22815;&#39640;&#25928;&#21033;&#29992;&#21487;&#33021;&#30456;&#20851;&#30340;&#32479;&#35745;&#20551;&#35774;&#26816;&#39564;&#20043;&#38388;&#27491;&#30456;&#20851;&#24615;&#30340;&#23478;&#26063;&#35823;&#24046;&#29575;(FWER)&#25511;&#21046;&#30340;&#26032;&#22411;&#22810;&#37325;&#20551;&#35774;&#26816;&#39564;&#20462;&#27491;&#31639;&#27861;$\texttt{max-rank}$&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#27010;&#24565;&#19978;&#24456;&#30452;&#35266;&#65292;&#20381;&#36182;&#20110;&#22312;&#35745;&#31639;&#30340;&#32479;&#35745;&#26816;&#39564;&#30340;&#31209;&#22495;&#20351;&#29992;$\max$&#31639;&#23376;&#12290;&#36890;&#36807;&#29702;&#35770;&#21644;&#32463;&#39564;&#30340;&#27604;&#36739;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#23384;&#22312;&#27491;&#30456;&#20851;&#20381;&#36182;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20248;&#20110;&#32463;&#24120;&#20351;&#29992;&#30340;Bonferroni&#20462;&#27491;&#65292;&#32780;&#22312;&#19981;&#23384;&#22312;&#27491;&#30456;&#20851;&#20381;&#36182;&#30340;&#24773;&#20917;&#19979;&#31561;&#25928;&#12290;&#25105;&#20204;&#30340;&#20248;&#21183;&#38543;&#30528;&#27979;&#35797;&#25968;&#37327;&#30340;&#22686;&#21152;&#32780;&#22686;&#21152;&#65292;&#21516;&#26102;&#22312;&#20445;&#35777;FWER&#25511;&#21046;&#30340;&#24773;&#20917;&#19979;&#20445;&#25345;&#39640;&#32479;&#35745;&#21151;&#25928;&#12290;&#25105;&#20204;&#29305;&#21035;&#23558;&#25105;&#20204;&#30340;&#31639;&#27861;&#24212;&#29992;&#20110;&#24182;&#34892;&#32622;&#25442;&#26816;&#39564;&#30340;&#32972;&#26223;&#20013;&#65292;&#36825;&#26159;&#22312;&#25105;&#20204;&#20027;&#35201;&#24212;&#29992;&#30340;&#19968;&#31181;&#22797;&#26434;&#39044;&#27979;&#22330;&#26223;&#20013;&#20135;&#29983;&#30340;&#24773;&#20917;&#19979;&#12290;
&lt;/p&gt;
&lt;p&gt;
We develop a novel multiple hypothesis testing correction with family-wise error rate (FWER) control that efficiently exploits positive dependencies between potentially correlated statistical hypothesis tests. Our proposed algorithm $\texttt{max-rank}$ is conceptually straight-forward, relying on the use of a $\max$-operator in the rank domain of computed test statistics. We compare our approach to the frequently employed Bonferroni correction, theoretically and empirically demonstrating its superiority over Bonferroni in the case of existing positive dependency, and its equivalence otherwise. Our advantage over Bonferroni increases as the number of tests rises, and we maintain high statistical power whilst ensuring FWER control. We specifically frame our algorithm in the context of parallel permutation testing, a scenario that arises in our primary application of conformal prediction, a recently popularized approach for quantifying uncertainty in complex predictive settings.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#32771;&#34385;&#20102;&#20855;&#26377;&#26410;&#35266;&#27979;&#28151;&#28102;&#22240;&#32032;&#30340;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#38382;&#39064;&#65292;&#22312;&#32467;&#26524;&#26159;&#30830;&#23450;&#24615;&#29983;&#25104;&#30340;&#24773;&#20917;&#19979;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#21333;&#19968;&#20195;&#29702;&#21464;&#37327;&#30340;&#20869;&#26680;&#26041;&#27861;&#65292;&#36890;&#36807;&#20004;&#38454;&#27573;&#22238;&#24402;&#21644;&#26368;&#22823;&#30697;&#32422;&#26463;&#30340;&#26041;&#27861;&#21487;&#20197;&#19968;&#33268;&#20272;&#35745;&#22240;&#26524;&#25928;&#24212;&#65292;&#24182;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#25104;&#21151;&#24674;&#22797;&#20102;&#22240;&#26524;&#25928;&#24212;&#12290;</title><link>http://arxiv.org/abs/2308.04585</link><description>&lt;p&gt;
&#20915;&#23450;&#24615;&#28151;&#28102;&#19979;&#30340;&#20869;&#26680;&#21333;&#19968;&#20195;&#29702;&#25511;&#21046;
&lt;/p&gt;
&lt;p&gt;
Kernel Single Proxy Control for Deterministic Confounding. (arXiv:2308.04585v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.04585
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#32771;&#34385;&#20102;&#20855;&#26377;&#26410;&#35266;&#27979;&#28151;&#28102;&#22240;&#32032;&#30340;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#38382;&#39064;&#65292;&#22312;&#32467;&#26524;&#26159;&#30830;&#23450;&#24615;&#29983;&#25104;&#30340;&#24773;&#20917;&#19979;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#21333;&#19968;&#20195;&#29702;&#21464;&#37327;&#30340;&#20869;&#26680;&#26041;&#27861;&#65292;&#36890;&#36807;&#20004;&#38454;&#27573;&#22238;&#24402;&#21644;&#26368;&#22823;&#30697;&#32422;&#26463;&#30340;&#26041;&#27861;&#21487;&#20197;&#19968;&#33268;&#20272;&#35745;&#22240;&#26524;&#25928;&#24212;&#65292;&#24182;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#25104;&#21151;&#24674;&#22797;&#20102;&#22240;&#26524;&#25928;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20855;&#26377;&#26410;&#35266;&#27979;&#28151;&#28102;&#22240;&#32032;&#30340;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#38382;&#39064;&#65292;&#20854;&#20013;&#25105;&#20204;&#35266;&#27979;&#21040;&#19982;&#28151;&#28102;&#22240;&#32032;&#30456;&#20851;&#30340;&#20195;&#29702;&#21464;&#37327;&#12290;&#23613;&#31649;&#20195;&#29702;&#22240;&#26524;&#23398;&#20064;&#65288;PCL&#65289;&#20351;&#29992;&#20004;&#20010;&#20195;&#29702;&#21464;&#37327;&#26469;&#24674;&#22797;&#30495;&#23454;&#30340;&#22240;&#26524;&#25928;&#24212;&#65292;&#25105;&#20204;&#35777;&#26126;&#22914;&#26524;&#32467;&#26524;&#26159;&#30830;&#23450;&#24615;&#29983;&#25104;&#30340;&#65292;&#21017;&#20351;&#29992;&#21333;&#20010;&#20195;&#29702;&#21464;&#37327;&#23601;&#36275;&#20197;&#36827;&#34892;&#22240;&#26524;&#20272;&#35745;&#65292;&#24182;&#27010;&#25324;&#20102;&#25511;&#21046;&#32467;&#26524;&#26657;&#20934;&#27861;&#65288;COCA&#65289;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#22522;&#20110;&#20869;&#26680;&#30340;&#26041;&#27861;&#65306;&#19968;&#31181;&#22522;&#20110;&#20004;&#38454;&#27573;&#22238;&#24402;&#26041;&#27861;&#65292;&#21478;&#19968;&#31181;&#22522;&#20110;&#26368;&#22823;&#30697;&#32422;&#26463;&#26041;&#27861;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#20004;&#31181;&#26041;&#27861;&#37117;&#21487;&#20197;&#19968;&#33268;&#22320;&#20272;&#35745;&#22240;&#26524;&#25928;&#24212;&#65292;&#24182;&#36890;&#36807;&#21512;&#25104;&#25968;&#25454;&#38598;&#30340;&#23454;&#35777;&#23454;&#39564;&#25104;&#21151;&#22320;&#24674;&#22797;&#20102;&#22240;&#26524;&#25928;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of causal effect estimation with an unobserved confounder, where we observe a proxy variable that is associated with the confounder. Although Proxy Causal Learning (PCL) uses two proxy variables to recover the true causal effect, we show that a single proxy variable is sufficient for causal estimation if the outcome is generated deterministically, generalizing Control Outcome Calibration Approach (COCA). We propose two kernel-based methods for this setting: the first based on the two-stage regression approach, and the second based on a maximum moment restriction approach. We prove that both approaches can consistently estimate the causal effect, and we empirically demonstrate that we can successfully recover the causal effect on a synthetic dataset.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#20844;&#24179;&#26694;&#26550;&#8212;&#8212;&#32771;&#34385;&#25919;&#31574;&#20248;&#21270;&#21738;&#20010;&#25928;&#29992;&#65292;&#23450;&#20041;&#20102;&#20449;&#24687;&#20215;&#20540;&#20844;&#24179;&#65292;&#25552;&#20986;&#19981;&#24212;&#20351;&#29992;&#19981;&#28385;&#36275;&#36825;&#19968;&#26631;&#20934;&#30340;&#23454;&#29992;&#31243;&#24207;&#65292;&#24182;&#25506;&#35752;&#20102;&#20462;&#25913;&#23454;&#29992;&#31243;&#24207;&#20197;&#28385;&#36275;&#27492;&#20844;&#24179;&#26631;&#20934;&#21487;&#33021;&#23545;&#26368;&#20248;&#25919;&#31574;&#20135;&#29983;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2306.00636</link><description>&lt;p&gt;
&#19981;&#20844;&#24179;&#30340;&#23454;&#29992;&#31243;&#24207;&#21450;&#20854;&#25913;&#36827;&#30340;&#31532;&#19968;&#27493;
&lt;/p&gt;
&lt;p&gt;
Unfair Utilities and First Steps Towards Improving Them. (arXiv:2306.00636v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00636
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#20844;&#24179;&#26694;&#26550;&#8212;&#8212;&#32771;&#34385;&#25919;&#31574;&#20248;&#21270;&#21738;&#20010;&#25928;&#29992;&#65292;&#23450;&#20041;&#20102;&#20449;&#24687;&#20215;&#20540;&#20844;&#24179;&#65292;&#25552;&#20986;&#19981;&#24212;&#20351;&#29992;&#19981;&#28385;&#36275;&#36825;&#19968;&#26631;&#20934;&#30340;&#23454;&#29992;&#31243;&#24207;&#65292;&#24182;&#25506;&#35752;&#20102;&#20462;&#25913;&#23454;&#29992;&#31243;&#24207;&#20197;&#28385;&#36275;&#27492;&#20844;&#24179;&#26631;&#20934;&#21487;&#33021;&#23545;&#26368;&#20248;&#25919;&#31574;&#20135;&#29983;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#20844;&#24179;&#26631;&#20934;&#23545;&#25919;&#31574;&#25110;&#39044;&#27979;&#22120;&#30340;&#36873;&#25321;&#36827;&#34892;&#38480;&#21046;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#19981;&#21516;&#30340;&#24605;&#32771;&#20844;&#24179;&#30340;&#26694;&#26550;&#65306;&#25105;&#20204;&#32771;&#34385;&#25919;&#31574;&#27491;&#22312;&#20248;&#21270;&#21738;&#20010;&#25928;&#29992;&#65292;&#32780;&#19981;&#26159;&#38480;&#21046;&#25919;&#31574;&#25110;&#39044;&#27979;&#22120;&#30340;&#36873;&#25321;&#12290;&#25105;&#20204;&#23450;&#20041;&#20102;&#20449;&#24687;&#20215;&#20540;&#20844;&#24179;&#65292;&#24182;&#24314;&#35758;&#19981;&#20351;&#29992;&#19981;&#28385;&#36275;&#27492;&#26631;&#20934;&#30340;&#23454;&#29992;&#31243;&#24207;&#12290;&#25105;&#20204;&#25551;&#36848;&#20102;&#22914;&#20309;&#20462;&#25913;&#23454;&#29992;&#31243;&#24207;&#20197;&#28385;&#36275;&#36825;&#31181;&#20844;&#24179;&#26631;&#20934;&#65292;&#24182;&#35752;&#35770;&#20102;&#36825;&#21487;&#33021;&#23545;&#30456;&#24212;&#30340;&#26368;&#20248;&#25919;&#31574;&#20135;&#29983;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many fairness criteria constrain the policy or choice of predictors. In this work, we propose a different framework for thinking about fairness: Instead of constraining the policy or choice of predictors, we consider which utility a policy is optimizing for. We define value of information fairness and propose to not use utilities that do not satisfy this criterion. We describe how to modify a utility to satisfy this fairness criterion and discuss the consequences this might have on the corresponding optimal policies.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#31350;&#20102;&#36807;&#24230;&#21442;&#25968;&#21270;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#20559;&#35265;&#65292;&#21457;&#29616;&#22312;ReLU&#32593;&#32476;&#20013;&#28155;&#21152;&#32447;&#24615;&#23618;&#26377;&#21161;&#20110;&#36924;&#36817;&#20855;&#26377;&#20302;&#31209;&#32447;&#24615;&#31639;&#23376;&#21644;&#20302;&#34920;&#31034;&#25104;&#26412;&#20989;&#25968;&#32452;&#25104;&#30340;&#20989;&#25968;&#65292;&#20174;&#32780;&#24471;&#21040;&#19968;&#20010;&#19982;&#20302;&#32500;&#23376;&#31354;&#38388;&#22402;&#30452;&#26041;&#21521;&#36817;&#20046;&#24658;&#23450;&#30340;&#25554;&#20540;&#20989;&#25968;&#12290;</title><link>http://arxiv.org/abs/2305.15598</link><description>&lt;p&gt;
&#32447;&#24615;&#31070;&#32463;&#32593;&#32476;&#23618;&#20419;&#36827;&#23398;&#20064;&#21333;&#25351;&#25968;&#21644;&#22810;&#25351;&#25968;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Linear Neural Network Layers Promote Learning Single- and Multiple-Index Models. (arXiv:2305.15598v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15598
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#31350;&#20102;&#36807;&#24230;&#21442;&#25968;&#21270;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#20559;&#35265;&#65292;&#21457;&#29616;&#22312;ReLU&#32593;&#32476;&#20013;&#28155;&#21152;&#32447;&#24615;&#23618;&#26377;&#21161;&#20110;&#36924;&#36817;&#20855;&#26377;&#20302;&#31209;&#32447;&#24615;&#31639;&#23376;&#21644;&#20302;&#34920;&#31034;&#25104;&#26412;&#20989;&#25968;&#32452;&#25104;&#30340;&#20989;&#25968;&#65292;&#20174;&#32780;&#24471;&#21040;&#19968;&#20010;&#19982;&#20302;&#32500;&#23376;&#31354;&#38388;&#22402;&#30452;&#26041;&#21521;&#36817;&#20046;&#24658;&#23450;&#30340;&#25554;&#20540;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#31350;&#20102;&#28145;&#24230;&#22823;&#20110;&#20004;&#23618;&#30340;&#36807;&#24230;&#21442;&#25968;&#21270;&#31070;&#32463;&#32593;&#32476;&#30340;&#38544;&#21547;&#20559;&#35265;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#32771;&#34385;&#20102;&#19968;&#31867;&#28145;&#24230;&#19981;&#21516;&#20294;&#23481;&#37327;&#30456;&#21516;&#30340;&#32593;&#32476;&#65292;&#23427;&#20204;&#20855;&#26377;&#19981;&#21516;&#30340;&#26174;&#24335;&#23450;&#20041;&#30340;&#34920;&#31034;&#25104;&#26412;&#12290;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#35825;&#23548;&#30340;&#20989;&#25968;&#30340;&#34920;&#31034;&#25104;&#26412;&#26159;&#32593;&#32476;&#34920;&#31034;&#35813;&#20989;&#25968;&#25152;&#38656;&#30340;&#24179;&#26041;&#26435;&#37325;&#20043;&#21644;&#30340;&#26368;&#23567;&#20540;&#65307;&#23427;&#21453;&#26144;&#20102;&#19982;&#35813;&#26550;&#26500;&#30456;&#20851;&#30340;&#20989;&#25968;&#31354;&#38388;&#20559;&#24046;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#23558;&#32447;&#24615;&#23618;&#28155;&#21152;&#21040;ReLU&#32593;&#32476;&#20250;&#20135;&#29983;&#19968;&#20010;&#34920;&#31034;&#25104;&#26412;&#65292;&#36825;&#26377;&#21033;&#20110;&#20351;&#29992;&#20004;&#23618;&#32593;&#32476;&#26469;&#36924;&#36817;&#30001;&#20302;&#31209;&#32447;&#24615;&#31639;&#23376;&#21644;&#20855;&#26377;&#20302;&#34920;&#31034;&#25104;&#26412;&#30340;&#20989;&#25968;&#32452;&#25104;&#30340;&#20989;&#25968;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#20197;&#26368;&#23567;&#30340;&#34920;&#31034;&#25104;&#26412;&#25311;&#21512;&#35757;&#32451;&#25968;&#25454;&#20250;&#24471;&#21040;&#19968;&#20010;&#19982;&#20302;&#32500;&#23376;&#31354;&#38388;&#22402;&#30452;&#26041;&#21521;&#36817;&#20046;&#24658;&#23450;&#30340;&#25554;&#20540;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper explores the implicit bias of overparameterized neural networks of depth greater than two layers. Our framework considers a family of networks of varying depths that all have the same capacity but different implicitly defined representation costs. The representation cost of a function induced by a neural network architecture is the minimum sum of squared weights needed for the network to represent the function; it reflects the function space bias associated with the architecture. Our results show that adding linear layers to a ReLU network yields a representation cost that favors functions that can be approximated by a low-rank linear operator composed with a function with low representation cost using a two-layer network. Specifically, using a neural network to fit training data with minimum representation cost yields an interpolating function that is nearly constant in directions orthogonal to a low-dimensional subspace. This means that the learned network will approximate
&lt;/p&gt;</description></item></channel></rss>