<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#30452;&#25509;&#28508;&#22312;&#27169;&#22411;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#32447;&#24615;&#20108;&#27425;&#39640;&#26031;&#25511;&#21046;&#38382;&#39064;&#65292;&#33021;&#22815;&#22312;&#26377;&#38480;&#26679;&#26412;&#19979;&#25214;&#21040;&#36817;&#20284;&#26368;&#20248;&#29366;&#24577;&#34920;&#31034;&#20989;&#25968;&#21644;&#25511;&#21046;&#22120;&#12290;</title><link>https://arxiv.org/abs/2212.14511</link><description>&lt;p&gt;
&#30452;&#25509;&#28508;&#22312;&#27169;&#22411;&#23398;&#20064;&#33021;&#22815;&#35299;&#20915;&#32447;&#24615;&#20108;&#27425;&#39640;&#26031;&#25511;&#21046;&#38382;&#39064;&#21527;&#65311;
&lt;/p&gt;
&lt;p&gt;
Can Direct Latent Model Learning Solve Linear Quadratic Gaussian Control?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2212.14511
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#30452;&#25509;&#28508;&#22312;&#27169;&#22411;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#32447;&#24615;&#20108;&#27425;&#39640;&#26031;&#25511;&#21046;&#38382;&#39064;&#65292;&#33021;&#22815;&#22312;&#26377;&#38480;&#26679;&#26412;&#19979;&#25214;&#21040;&#36817;&#20284;&#26368;&#20248;&#29366;&#24577;&#34920;&#31034;&#20989;&#25968;&#21644;&#25511;&#21046;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#20174;&#28508;&#22312;&#39640;&#32500;&#35266;&#27979;&#20013;&#23398;&#20064;&#29366;&#24577;&#34920;&#31034;&#30340;&#20219;&#21153;&#65292;&#30446;&#26631;&#26159;&#25511;&#21046;&#26410;&#30693;&#30340;&#37096;&#20998;&#21487;&#35266;&#23519;&#31995;&#32479;&#12290;&#25105;&#20204;&#37319;&#29992;&#30452;&#25509;&#28508;&#22312;&#27169;&#22411;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#39044;&#27979;&#19982;&#35268;&#21010;&#30452;&#25509;&#30456;&#20851;&#30340;&#25968;&#37327;&#65288;&#20363;&#22914;&#25104;&#26412;&#65289;&#26469;&#23398;&#20064;&#28508;&#22312;&#29366;&#24577;&#31354;&#38388;&#20013;&#30340;&#21160;&#24577;&#27169;&#22411;&#65292;&#32780;&#26080;&#38656;&#37325;&#24314;&#35266;&#27979;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#19987;&#27880;&#20110;&#19968;&#31181;&#30452;&#35266;&#30340;&#22522;&#20110;&#25104;&#26412;&#39537;&#21160;&#30340;&#29366;&#24577;&#34920;&#31034;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#32447;&#24615;&#20108;&#27425;&#39640;&#26031;&#65288;LQG&#65289;&#25511;&#21046;&#38382;&#39064;&#65292;&#36825;&#26159;&#26368;&#22522;&#26412;&#30340;&#37096;&#20998;&#21487;&#35266;&#23519;&#25511;&#21046;&#38382;&#39064;&#20043;&#19968;&#12290;&#20316;&#20026;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#22312;&#26377;&#38480;&#26679;&#26412;&#19979;&#25214;&#21040;&#36817;&#20284;&#26368;&#20248;&#29366;&#24577;&#34920;&#31034;&#20989;&#25968;&#21644;&#20351;&#29992;&#30452;&#25509;&#23398;&#20064;&#30340;&#28508;&#22312;&#27169;&#22411;&#25214;&#21040;&#36817;&#20284;&#26368;&#20248;&#25511;&#21046;&#22120;&#30340;&#20445;&#35777;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#23613;&#31649;&#20197;&#21069;&#30340;&#30456;&#20851;&#24037;&#20316;&#21462;&#24471;&#20102;&#21508;&#31181;&#32463;&#39564;&#25104;&#21151;&#65292;&#20294;&#22312;&#36825;&#39033;&#24037;&#20316;&#20043;&#21069;&#65292;&#23578;&#19981;&#28165;&#26970;&#36825;&#31181;&#22522;&#20110;&#25104;&#26412;&#39537;&#21160;&#30340;&#28508;&#22312;&#27169;&#22411;&#23398;&#20064;&#26041;&#27861;&#26159;&#21542;&#20855;&#26377;&#26377;&#38480;&#26679;&#26412;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2212.14511v2 Announce Type: replace  Abstract: We study the task of learning state representations from potentially high-dimensional observations, with the goal of controlling an unknown partially observable system. We pursue a direct latent model learning approach, where a dynamic model in some latent state space is learned by predicting quantities directly related to planning (e.g., costs) without reconstructing the observations. In particular, we focus on an intuitive cost-driven state representation learning method for solving Linear Quadratic Gaussian (LQG) control, one of the most fundamental partially observable control problems. As our main results, we establish finite-sample guarantees of finding a near-optimal state representation function and a near-optimal controller using the directly learned latent model. To the best of our knowledge, despite various empirical successes, prior to this work it was unclear if such a cost-driven latent model learner enjoys finite-sampl
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#38543;&#26426;&#36924;&#36817;&#20013;&#30340;&#35760;&#24518;&#35781;&#21650;&#38382;&#39064;&#65292;&#24182;&#25506;&#35752;&#20102;&#22312;&#19981;&#21516;&#24773;&#20917;&#19979;&#30340;&#32467;&#26524;&#12290;&#22312;&#20855;&#26377;&#20960;&#20309;&#36941;&#21382;&#39532;&#23572;&#21487;&#22827;&#25200;&#21160;&#30340;&#24773;&#20917;&#19979;&#65292;&#30446;&#26631;&#20559;&#24046;&#19968;&#33324;&#38750;&#38646;&#12290;&#27492;&#22806;&#65292;&#24403;&#21442;&#25968;&#20272;&#35745;&#20351;&#29992;&#24179;&#22343;&#27861;&#26102;&#65292;&#20272;&#35745;&#20540;&#25910;&#25947;&#21040;&#28176;&#36817;&#26080;&#20559;&#65292;&#19988;&#20855;&#26377;&#36817;&#20284;&#26368;&#20248;&#30340;&#28176;&#36817;&#21327;&#26041;&#24046;&#12290;</title><link>http://arxiv.org/abs/2309.02944</link><description>&lt;p&gt;
&#38543;&#26426;&#36924;&#36817;&#20013;&#30340;&#35760;&#24518;&#35781;&#21650;&#65306;&#25193;&#23637;&#29256;&#26412;
&lt;/p&gt;
&lt;p&gt;
The Curse of Memory in Stochastic Approximation: Extended Version. (arXiv:2309.02944v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.02944
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38543;&#26426;&#36924;&#36817;&#20013;&#30340;&#35760;&#24518;&#35781;&#21650;&#38382;&#39064;&#65292;&#24182;&#25506;&#35752;&#20102;&#22312;&#19981;&#21516;&#24773;&#20917;&#19979;&#30340;&#32467;&#26524;&#12290;&#22312;&#20855;&#26377;&#20960;&#20309;&#36941;&#21382;&#39532;&#23572;&#21487;&#22827;&#25200;&#21160;&#30340;&#24773;&#20917;&#19979;&#65292;&#30446;&#26631;&#20559;&#24046;&#19968;&#33324;&#38750;&#38646;&#12290;&#27492;&#22806;&#65292;&#24403;&#21442;&#25968;&#20272;&#35745;&#20351;&#29992;&#24179;&#22343;&#27861;&#26102;&#65292;&#20272;&#35745;&#20540;&#25910;&#25947;&#21040;&#28176;&#36817;&#26080;&#20559;&#65292;&#19988;&#20855;&#26377;&#36817;&#20284;&#26368;&#20248;&#30340;&#28176;&#36817;&#21327;&#26041;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#36866;&#24212;&#25511;&#21046;&#30340;&#26368;&#26089;&#30340;&#26085;&#23376;&#20197;&#26469;&#65292;&#38543;&#26426;&#36924;&#36817;&#65288;SA&#65289;&#30340;&#29702;&#35770;&#21644;&#24212;&#29992;&#22312;&#25511;&#21046;&#31995;&#32479;&#30340;&#31038;&#21306;&#20013;&#24471;&#21040;&#20102;&#24555;&#36895;&#21457;&#23637;&#12290;&#26412;&#25991;&#20197;&#26032;&#30340;&#35270;&#35282;&#37325;&#26032;&#23457;&#35270;&#20102;&#36825;&#20010;&#20027;&#39064;&#65292;&#21463;&#21040;&#26368;&#36817;&#30340;&#32467;&#26524;&#30340;&#21551;&#21457;&#65292;&#35813;&#32467;&#26524;&#35777;&#26126;&#20351;&#29992;&#65288;&#36275;&#22815;&#23567;&#30340;&#65289;&#24658;&#23450;&#27493;&#38271;&#945;&gt;0&#30340;SA&#20855;&#26377;&#38750;&#20961;&#30340;&#24615;&#33021;&#12290;&#22914;&#26524;&#37319;&#29992;&#24179;&#22343;&#27861;&#33719;&#21462;&#26368;&#32456;&#30340;&#21442;&#25968;&#20272;&#35745;&#65292;&#21017;&#20272;&#35745;&#20540;&#22312;&#28176;&#36817;&#26080;&#20559;&#21644;&#36817;&#20284;&#26368;&#20248;&#30340;&#28176;&#36817;&#21327;&#26041;&#24046;&#19979;&#25910;&#25947;&#12290;&#36825;&#20123;&#32467;&#26524;&#26159;&#38024;&#23545;&#20855;&#26377;&#29420;&#31435;&#21516;&#20998;&#24067;&#31995;&#25968;&#30340;&#38543;&#26426;&#32447;&#24615;SA&#36882;&#24402;&#33719;&#24471;&#30340;&#12290;&#26412;&#25991;&#22312;&#26356;&#24120;&#35265;&#30340;&#20960;&#20309;&#36941;&#21382;&#39532;&#23572;&#21487;&#22827;&#25200;&#21160;&#30340;&#24773;&#20917;&#19979;&#33719;&#24471;&#20102;&#38750;&#24120;&#19981;&#21516;&#30340;&#32467;&#35770;&#65306;&#65288;i&#65289;&#22312;&#38750;&#32447;&#24615;SA&#30340;&#24773;&#20917;&#19979;&#65292;&#35782;&#21035;&#20986;&#20102;&#8220;&#30446;&#26631;&#20559;&#24046;&#8221;&#65292;&#24182;&#19988;&#19968;&#33324;&#19978;&#19981;&#20026;&#38646;&#12290;&#20854;&#20313;&#30340;&#32467;&#26524;&#26159;&#38024;&#23545;&#32447;&#24615;SA&#36882;&#24402;&#24314;&#31435;&#30340;&#65306;&#65288;ii&#65289;&#21452;&#21464;&#37327;&#21442;&#25968;&#25200;&#21160;&#36807;&#31243;&#22312;&#25299;&#25169;&#24847;&#20041;&#19978;&#20855;&#26377;&#20960;&#20309;&#36941;&#21382;&#24615;&#65307;&#65288;iii&#65289;&#20559;&#24046;&#30340;&#34920;&#31034;&#20855;&#26377;&#31616;&#21333;&#30340;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;
Theory and application of stochastic approximation (SA) has grown within the control systems community since the earliest days of adaptive control. This paper takes a new look at the topic, motivated by recent results establishing remarkable performance of SA with (sufficiently small) constant step-size $\alpha&gt;0$. If averaging is implemented to obtain the final parameter estimate, then the estimates are asymptotically unbiased with nearly optimal asymptotic covariance. These results have been obtained for random linear SA recursions with i.i.d.\ coefficients. This paper obtains very different conclusions in the more common case of geometrically ergodic Markovian disturbance: (i) The \textit{target bias} is identified, even in the case of non-linear SA, and is in general non-zero. The remaining results are established for linear SA recursions: (ii) the bivariate parameter-disturbance process is geometrically ergodic in a topological sense; (iii) the representation for bias has a simple
&lt;/p&gt;</description></item></channel></rss>