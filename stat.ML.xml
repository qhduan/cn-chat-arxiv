<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21516;&#26102;&#21033;&#29992;&#27491;&#25968;&#25454;-&#26080;&#26631;&#31614;&#23398;&#20064;&#21644;&#26377;&#26465;&#20214;&#29983;&#25104;&#30340;&#35757;&#32451;&#26694;&#26550;&#65292;&#20197;&#21450;&#39069;&#22806;&#26080;&#26631;&#31614;&#25968;&#25454;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#20351;&#29992;&#19968;&#20010;&#23545;&#22122;&#22768;&#26631;&#31614;&#20855;&#26377;&#40065;&#26834;&#24615;&#30340;&#20998;&#31867;&#22120;&#22122;&#22768;&#19981;&#21464;&#26377;&#26465;&#20214;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#26469;&#25552;&#39640;PU&#20998;&#31867;&#22120;&#30340;&#24615;&#33021;&#65292;&#24182;&#21033;&#29992;PU&#20998;&#31867;&#22120;&#39044;&#27979;&#30340;&#26631;&#31614;&#21644;&#39069;&#22806;&#25968;&#25454;&#26469;&#24110;&#21161;&#29983;&#25104;&#12290;&#23454;&#39564;&#32467;&#26524;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>https://arxiv.org/abs/2006.07841</link><description>&lt;p&gt;
&#21516;&#26102;&#36827;&#34892;&#27491;&#25968;&#25454;-&#26080;&#26631;&#31614;&#23398;&#20064;&#21644;&#26377;&#26465;&#20214;&#29983;&#25104;&#65292;&#21033;&#29992;&#39069;&#22806;&#25968;&#25454;&#26469;&#20998;&#31867;&#21644;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
Classify and Generate Reciprocally: Simultaneous Positive-Unlabelled Learning and Conditional Generation with Extra Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2006.07841
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21516;&#26102;&#21033;&#29992;&#27491;&#25968;&#25454;-&#26080;&#26631;&#31614;&#23398;&#20064;&#21644;&#26377;&#26465;&#20214;&#29983;&#25104;&#30340;&#35757;&#32451;&#26694;&#26550;&#65292;&#20197;&#21450;&#39069;&#22806;&#26080;&#26631;&#31614;&#25968;&#25454;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#20351;&#29992;&#19968;&#20010;&#23545;&#22122;&#22768;&#26631;&#31614;&#20855;&#26377;&#40065;&#26834;&#24615;&#30340;&#20998;&#31867;&#22120;&#22122;&#22768;&#19981;&#21464;&#26377;&#26465;&#20214;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#26469;&#25552;&#39640;PU&#20998;&#31867;&#22120;&#30340;&#24615;&#33021;&#65292;&#24182;&#21033;&#29992;PU&#20998;&#31867;&#22120;&#39044;&#27979;&#30340;&#26631;&#31614;&#21644;&#39069;&#22806;&#25968;&#25454;&#26469;&#24110;&#21161;&#29983;&#25104;&#12290;&#23454;&#39564;&#32467;&#26524;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#20013;&#65292;&#26631;&#35760;&#31867;&#21035;&#25968;&#25454;&#30340;&#31232;&#32570;&#24615;&#26159;&#19968;&#20010;&#26222;&#36941;&#23384;&#22312;&#30340;&#29942;&#39048;&#12290;&#34429;&#28982;&#23384;&#22312;&#20016;&#23500;&#30340;&#26080;&#26631;&#31614;&#25968;&#25454;&#24182;&#25552;&#20379;&#28508;&#22312;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#20294;&#21033;&#29992;&#23427;&#20204;&#26159;&#38750;&#24120;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#26412;&#25991;&#36890;&#36807;&#21516;&#26102;&#21033;&#29992;&#27491;&#25968;&#25454;-&#26080;&#26631;&#31614;&#65288;Positive-Unlabeled&#65292;PU&#65289;&#20998;&#31867;&#21644;&#26377;&#26465;&#20214;&#29983;&#25104;&#65292;&#20197;&#21450;&#39069;&#22806;&#30340;&#26080;&#26631;&#31614;&#25968;&#25454;&#65292;&#35299;&#20915;&#20102;&#36825;&#20010;&#38382;&#39064;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#35757;&#32451;&#26694;&#26550;&#65292;&#20351;&#24471;&#22312;&#38754;&#23545;&#39069;&#22806;&#25968;&#25454;&#65288;&#23588;&#20854;&#26159;&#20998;&#24067;&#22806;&#30340;&#26080;&#26631;&#31614;&#25968;&#25454;&#65289;&#26102;&#65292;&#21516;&#26102;&#36827;&#34892;PU&#20998;&#31867;&#21644;&#26377;&#26465;&#20214;&#29983;&#25104;&#25104;&#20026;&#21487;&#33021;&#65292;&#36890;&#36807;&#25506;&#32034;&#23427;&#20204;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#65306;1&#65289;&#36890;&#36807;&#19968;&#20010;&#23545;&#22122;&#22768;&#26631;&#31614;&#20855;&#26377;&#40065;&#26834;&#24615;&#30340;&#26032;&#22411;&#20998;&#31867;&#22120;&#22122;&#22768;&#19981;&#21464;&#26377;&#26465;&#20214;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;Classifier-Noise-Invariant Conditional GAN&#65292;CNI-CGAN&#65289;&#26469;&#25552;&#39640;PU&#20998;&#31867;&#22120;&#30340;&#24615;&#33021;&#65292;2&#65289;&#21033;&#29992;PU&#20998;&#31867;&#22120;&#39044;&#27979;&#30340;&#26631;&#31614;&#21644;&#39069;&#22806;&#25968;&#25454;&#26469;&#24110;&#21161;&#29983;&#25104;&#12290;&#20174;&#29702;&#35770;&#19978;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;CNI-CGAN&#30340;&#26368;&#20248;&#26465;&#20214;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#36890;&#36807;&#24191;&#27867;&#30340;&#35780;&#20272;&#26469;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
The scarcity of class-labeled data is a ubiquitous bottleneck in many machine learning problems. While abundant unlabeled data typically exist and provide a potential solution, it is highly challenging to exploit them. In this paper, we address this problem by leveraging Positive-Unlabeled~(PU) classification and the conditional generation with extra unlabeled data \emph{simultaneously}. In particular, we present a novel training framework to jointly target both PU classification and conditional generation when exposed to extra data, especially out-of-distribution unlabeled data, by exploring the interplay between them: 1) enhancing the performance of PU classifiers with the assistance of a novel Classifier-Noise-Invariant Conditional GAN~(CNI-CGAN) that is robust to noisy labels, 2) leveraging extra data with predicted labels from a PU classifier to help the generation. Theoretically, we prove the optimal condition of CNI-CGAN, and experimentally, we conducted extensive evaluations on
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;ARMOR_D&#26469;&#21152;&#24378;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#23545;&#25239;&#40065;&#26834;&#24615;&#65292;&#35813;&#26041;&#27861;&#22522;&#20110;&#26368;&#20248;&#20256;&#36755;&#27491;&#21017;&#21270;&#24046;&#24322;&#65292;&#36890;&#36807;&#22312;&#20998;&#24067;&#30340;&#37051;&#22495;&#19978;&#36827;&#34892;&#26368;&#22823;&#21270;&#26399;&#26395;&#25439;&#22833;&#26469;&#23454;&#29616;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;ARMOR_D&#26041;&#27861;&#22312;&#24694;&#24847;&#36719;&#20214;&#26816;&#27979;&#21644;&#22270;&#20687;&#35782;&#21035;&#24212;&#29992;&#20013;&#33021;&#22815;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#65292;&#22312;&#23545;&#25239;&#25915;&#20987;&#19979;&#30340;&#40065;&#26834;&#24615;&#26041;&#38754;&#20855;&#26377;&#36739;&#22909;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2309.03791</link><description>&lt;p&gt;
&#20351;&#29992;&#26368;&#20248;&#20256;&#36755;&#27491;&#21017;&#21270;&#24046;&#24322;&#26469;&#25552;&#39640;&#23545;&#25239;&#24615;&#40065;&#26834;&#28145;&#24230;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Adversarially Robust Deep Learning with Optimal-Transport-Regularized Divergences. (arXiv:2309.03791v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.03791
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;ARMOR_D&#26469;&#21152;&#24378;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#23545;&#25239;&#40065;&#26834;&#24615;&#65292;&#35813;&#26041;&#27861;&#22522;&#20110;&#26368;&#20248;&#20256;&#36755;&#27491;&#21017;&#21270;&#24046;&#24322;&#65292;&#36890;&#36807;&#22312;&#20998;&#24067;&#30340;&#37051;&#22495;&#19978;&#36827;&#34892;&#26368;&#22823;&#21270;&#26399;&#26395;&#25439;&#22833;&#26469;&#23454;&#29616;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;ARMOR_D&#26041;&#27861;&#22312;&#24694;&#24847;&#36719;&#20214;&#26816;&#27979;&#21644;&#22270;&#20687;&#35782;&#21035;&#24212;&#29992;&#20013;&#33021;&#22815;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#65292;&#22312;&#23545;&#25239;&#25915;&#20987;&#19979;&#30340;&#40065;&#26834;&#24615;&#26041;&#38754;&#20855;&#26377;&#36739;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;ARMOR_D&#26041;&#27861;&#20316;&#20026;&#22686;&#24378;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#23545;&#25239;&#24615;&#40065;&#26834;&#24615;&#30340;&#21019;&#26032;&#26041;&#27861;&#12290;&#36825;&#20123;&#26041;&#27861;&#22522;&#20110;&#19968;&#31181;&#26032;&#30340;&#26368;&#20248;&#20256;&#36755;&#27491;&#21017;&#21270;&#24046;&#24322;&#31867;&#65292;&#36890;&#36807;&#20449;&#24687;&#24046;&#24322;&#21644;&#26368;&#20248;&#20256;&#36755;&#25104;&#26412;&#20043;&#38388;&#30340;infimal&#21367;&#31215;&#26500;&#24314;&#12290;&#25105;&#20204;&#20351;&#29992;&#36825;&#20123;&#26041;&#27861;&#26469;&#22686;&#24378;&#23545;&#25239;&#24615;&#40065;&#26834;&#24615;&#65292;&#36890;&#36807;&#22312;&#20998;&#24067;&#30340;&#37051;&#22495;&#19978;&#26368;&#22823;&#21270;&#26399;&#26395;&#25439;&#22833;&#65292;&#36825;&#34987;&#31216;&#20026;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#25216;&#26415;&#12290;&#20316;&#20026;&#26500;&#24314;&#23545;&#25239;&#26679;&#26412;&#30340;&#24037;&#20855;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20801;&#35768;&#26679;&#26412;&#26681;&#25454;&#26368;&#20248;&#20256;&#36755;&#25104;&#26412;&#36827;&#34892;&#20256;&#36755;&#65292;&#24182;&#26681;&#25454;&#20449;&#24687;&#24046;&#24322;&#36827;&#34892;&#37325;&#26032;&#21152;&#26435;&#12290;&#25105;&#20204;&#22312;&#24694;&#24847;&#36719;&#20214;&#26816;&#27979;&#21644;&#22270;&#20687;&#35782;&#21035;&#24212;&#29992;&#19978;&#35777;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#21457;&#29616;&#22312;&#22686;&#24378;&#23545;&#25239;&#25915;&#20987;&#40065;&#26834;&#24615;&#26041;&#38754;&#65292;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#23427;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;ARMOR_D&#22312;FGSM&#25915;&#20987;&#19979;&#30340;robustified&#20934;&#30830;&#29575;&#36798;&#21040;98.29%&#65292;&#22312;&#20854;&#20182;&#25915;&#20987;&#19979;&#36798;&#21040;98.18%&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce the $ARMOR_D$ methods as novel approaches to enhancing the adversarial robustness of deep learning models. These methods are based on a new class of optimal-transport-regularized divergences, constructed via an infimal convolution between an information divergence and an optimal-transport (OT) cost. We use these as tools to enhance adversarial robustness by maximizing the expected loss over a neighborhood of distributions, a technique known as distributionally robust optimization. Viewed as a tool for constructing adversarial samples, our method allows samples to be both transported, according to the OT cost, and re-weighted, according to the information divergence. We demonstrate the effectiveness of our method on malware detection and image recognition applications and find that, to our knowledge, it outperforms existing methods at enhancing the robustness against adversarial attacks. $ARMOR_D$ yields the robustified accuracy of $98.29\%$ against $FGSM$ and $98.18\%$ aga
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#21387;&#32553;&#23545;&#20998;&#24067;&#24335;&#21644;&#32852;&#37030;&#23398;&#20064;&#20013;&#38543;&#26426;&#26799;&#24230;&#31639;&#27861;&#30340;&#24433;&#21709;&#65292;&#36890;&#36807;&#27604;&#36739;&#19981;&#21516;&#30340;&#26080;&#20559;&#21387;&#32553;&#25805;&#20316;&#31526;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#36229;&#36234;&#20102;&#32463;&#20856;&#30340;&#26368;&#22351;&#24773;&#20917;&#20998;&#26512;&#12290;&#38024;&#23545;&#26368;&#23567;&#20108;&#20056;&#22238;&#24402;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#38543;&#26426;&#36924;&#36817;&#31639;&#27861;&#65292;&#24182;&#32771;&#34385;&#20102;&#38543;&#26426;&#22330;&#30340;&#19968;&#33324;&#20551;&#35774;&#21644;&#22122;&#22768;&#21327;&#26041;&#24046;&#30340;&#38480;&#21046;&#65292;&#20197;&#20998;&#26512;&#21508;&#31181;&#38543;&#26426;&#21270;&#26426;&#21046;&#12290;</title><link>http://arxiv.org/abs/2308.01358</link><description>&lt;p&gt;
&#21387;&#32553;&#21644;&#20998;&#24067;&#24335;&#26368;&#23567;&#20108;&#20056;&#22238;&#24402;&#65306;&#25910;&#25947;&#36895;&#24230;&#21450;&#20854;&#22312;&#32852;&#37030;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Compressed and distributed least-squares regression: convergence rates with applications to Federated Learning. (arXiv:2308.01358v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.01358
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#21387;&#32553;&#23545;&#20998;&#24067;&#24335;&#21644;&#32852;&#37030;&#23398;&#20064;&#20013;&#38543;&#26426;&#26799;&#24230;&#31639;&#27861;&#30340;&#24433;&#21709;&#65292;&#36890;&#36807;&#27604;&#36739;&#19981;&#21516;&#30340;&#26080;&#20559;&#21387;&#32553;&#25805;&#20316;&#31526;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#36229;&#36234;&#20102;&#32463;&#20856;&#30340;&#26368;&#22351;&#24773;&#20917;&#20998;&#26512;&#12290;&#38024;&#23545;&#26368;&#23567;&#20108;&#20056;&#22238;&#24402;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#38543;&#26426;&#36924;&#36817;&#31639;&#27861;&#65292;&#24182;&#32771;&#34385;&#20102;&#38543;&#26426;&#22330;&#30340;&#19968;&#33324;&#20551;&#35774;&#21644;&#22122;&#22768;&#21327;&#26041;&#24046;&#30340;&#38480;&#21046;&#65292;&#20197;&#20998;&#26512;&#21508;&#31181;&#38543;&#26426;&#21270;&#26426;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#24191;&#27867;&#24212;&#29992;&#30340;&#20998;&#24067;&#24335;&#21644;&#32852;&#37030;&#23398;&#20064;&#20013;&#65292;&#21387;&#32553;&#23545;&#38543;&#26426;&#26799;&#24230;&#31639;&#27861;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#24378;&#35843;&#20102;&#20960;&#31181;&#26080;&#20559;&#21387;&#32553;&#25805;&#20316;&#31526;&#20043;&#38388;&#30340;&#25910;&#25947;&#36895;&#24230;&#24046;&#24322;&#65292;&#36825;&#20123;&#25805;&#20316;&#31526;&#37117;&#28385;&#36275;&#30456;&#21516;&#30340;&#26041;&#24046;&#26465;&#20214;&#65292;&#20174;&#32780;&#36229;&#36234;&#20102;&#32463;&#20856;&#30340;&#26368;&#22351;&#24773;&#20917;&#20998;&#26512;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#19987;&#27880;&#20110;&#26368;&#23567;&#20108;&#20056;&#22238;&#24402;&#65288;LSR&#65289;&#30340;&#24773;&#20917;&#65292;&#24182;&#20998;&#26512;&#20102;&#19968;&#20010;&#20381;&#36182;&#20110;&#38543;&#26426;&#22330;&#30340;&#26368;&#23567;&#20108;&#20056;&#22238;&#24402;&#30340;&#38543;&#26426;&#36924;&#36817;&#31639;&#27861;&#12290;&#25105;&#20204;&#23545;&#38543;&#26426;&#22330;&#30340;&#19968;&#33324;&#24615;&#20551;&#35774;&#36827;&#34892;&#20102;&#35814;&#32454;&#20998;&#26512;&#65288;&#29305;&#21035;&#26159;&#26399;&#26395;&#30340;H&#246;lder&#27491;&#21017;&#24615;&#65289;&#24182;&#23545;&#22122;&#22768;&#21327;&#26041;&#24046;&#36827;&#34892;&#20102;&#38480;&#21046;&#65292;&#20197;&#20415;&#20998;&#26512;&#21508;&#31181;&#38543;&#26426;&#21270;&#26426;&#21046;&#65292;&#21253;&#25324;&#21387;&#32553;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23558;&#32467;&#26524;&#25193;&#23637;&#21040;&#32852;&#37030;&#23398;&#20064;&#30340;&#24773;&#20917;&#19979;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#24378;&#35843;&#20102;&#23545;&#21152;&#24615;&#22122;&#22768;&#30340;&#21327;&#26041;&#24046;&#120226;&#120224;&#120237;&#120232;&#120224;&#23545;&#25910;&#25947;&#24615;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we investigate the impact of compression on stochastic gradient algorithms for machine learning, a technique widely used in distributed and federated learning. We underline differences in terms of convergence rates between several unbiased compression operators, that all satisfy the same condition on their variance, thus going beyond the classical worst-case analysis. To do so, we focus on the case of least-squares regression (LSR) and analyze a general stochastic approximation algorithm for minimizing quadratic functions relying on a random field. We consider weak assumptions on the random field, tailored to the analysis (specifically, expected H\"older regularity), and on the noise covariance, enabling the analysis of various randomizing mechanisms, including compression. We then extend our results to the case of federated learning.  More formally, we highlight the impact on the convergence of the covariance $\mathfrak{C}_{\mathrm{ania}}$ of the additive noise induced 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20851;&#20110;&#26680;&#23725;&#22238;&#24402;&#30340;&#21327;&#21464;&#37327;&#36716;&#31227;&#31574;&#30053;&#65292;&#36890;&#36807;&#20351;&#29992;&#20266;&#26631;&#31614;&#36827;&#34892;&#27169;&#22411;&#36873;&#25321;&#65292;&#33021;&#22815;&#36866;&#24212;&#19981;&#21516;&#29305;&#24449;&#20998;&#24067;&#19979;&#30340;&#23398;&#20064;&#65292;&#23454;&#29616;&#22343;&#26041;&#35823;&#24046;&#26368;&#23567;&#21270;&#12290;</title><link>http://arxiv.org/abs/2302.10160</link><description>&lt;p&gt;
&#26680;&#23725;&#22238;&#24402;&#19979;&#20266;&#26631;&#31614;&#30340;&#21327;&#21464;&#37327;&#36716;&#31227;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Pseudo-Labeling for Kernel Ridge Regression under Covariate Shift. (arXiv:2302.10160v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.10160
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20851;&#20110;&#26680;&#23725;&#22238;&#24402;&#30340;&#21327;&#21464;&#37327;&#36716;&#31227;&#31574;&#30053;&#65292;&#36890;&#36807;&#20351;&#29992;&#20266;&#26631;&#31614;&#36827;&#34892;&#27169;&#22411;&#36873;&#25321;&#65292;&#33021;&#22815;&#36866;&#24212;&#19981;&#21516;&#29305;&#24449;&#20998;&#24067;&#19979;&#30340;&#23398;&#20064;&#65292;&#23454;&#29616;&#22343;&#26041;&#35823;&#24046;&#26368;&#23567;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#24182;&#20998;&#26512;&#20102;&#19968;&#31181;&#22522;&#20110;&#21327;&#21464;&#37327;&#36716;&#31227;&#30340;&#26680;&#23725;&#22238;&#24402;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#22312;&#30446;&#26631;&#20998;&#24067;&#19978;&#23398;&#20064;&#19968;&#20010;&#22343;&#26041;&#35823;&#24046;&#26368;&#23567;&#30340;&#22238;&#24402;&#20989;&#25968;&#65292;&#22522;&#20110;&#20174;&#30446;&#26631;&#20998;&#24067;&#37319;&#26679;&#30340;&#26410;&#26631;&#35760;&#25968;&#25454;&#21644;&#21487;&#33021;&#20855;&#26377;&#19981;&#21516;&#29305;&#24449;&#20998;&#24067;&#30340;&#24050;&#26631;&#35760;&#25968;&#25454;&#12290;&#25105;&#20204;&#23558;&#24050;&#26631;&#35760;&#25968;&#25454;&#20998;&#25104;&#20004;&#20010;&#23376;&#38598;&#65292;&#24182;&#20998;&#21035;&#36827;&#34892;&#26680;&#23725;&#22238;&#24402;&#65292;&#20197;&#33719;&#24471;&#20505;&#36873;&#27169;&#22411;&#38598;&#21512;&#21644;&#19968;&#20010;&#22635;&#20805;&#27169;&#22411;&#12290;&#25105;&#20204;&#20351;&#29992;&#21518;&#32773;&#22635;&#20805;&#32570;&#22833;&#30340;&#26631;&#31614;&#65292;&#28982;&#21518;&#30456;&#24212;&#22320;&#36873;&#25321;&#26368;&#20339;&#30340;&#20505;&#36873;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#38750;&#28176;&#36817;&#24615;&#36807;&#37327;&#39118;&#38505;&#30028;&#34920;&#26126;&#65292;&#22312;&#30456;&#24403;&#19968;&#33324;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30340;&#20272;&#35745;&#22120;&#33021;&#22815;&#36866;&#24212;&#30446;&#26631;&#20998;&#24067;&#20197;&#21450;&#21327;&#21464;&#37327;&#36716;&#31227;&#30340;&#32467;&#26500;&#12290;&#23427;&#33021;&#22815;&#23454;&#29616;&#28176;&#36817;&#27491;&#24577;&#35823;&#24046;&#29575;&#30452;&#21040;&#23545;&#25968;&#22240;&#23376;&#30340;&#26368;&#23567;&#26497;&#38480;&#20248;&#21270;&#12290;&#22312;&#27169;&#22411;&#36873;&#25321;&#20013;&#20351;&#29992;&#20266;&#26631;&#31614;&#19981;&#20250;&#20135;&#29983;&#20027;&#35201;&#36127;&#38754;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
We develop and analyze a principled approach to kernel ridge regression under covariate shift. The goal is to learn a regression function with small mean squared error over a target distribution, based on unlabeled data from there and labeled data that may have a different feature distribution. We propose to split the labeled data into two subsets and conduct kernel ridge regression on them separately to obtain a collection of candidate models and an imputation model. We use the latter to fill the missing labels and then select the best candidate model accordingly. Our non-asymptotic excess risk bounds show that in quite general scenarios, our estimator adapts to the structure of the target distribution as well as the covariate shift. It achieves the minimax optimal error rate up to a logarithmic factor. The use of pseudo-labels in model selection does not have major negative impacts.
&lt;/p&gt;</description></item></channel></rss>