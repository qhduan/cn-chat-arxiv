<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#36890;&#36807;&#23558;&#26080;&#22870;&#21169;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#24341;&#20837;&#21040;&#22312;&#32447;&#26426;&#21046;&#35774;&#35745;&#38382;&#39064;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#33021;&#22815;&#22312;&#26410;&#30693;&#29615;&#22659;&#20013;&#23398;&#20064;&#21160;&#24577;VCG&#26426;&#21046;&#19988;&#20855;&#26377;&#19978;&#30028;&#20026;$\tilde{\mathcal{O}}(T^{2/3})$&#30340;&#36951;&#25022;&#20445;&#35777;&#30340;&#26032;&#39062;&#23398;&#20064;&#31639;&#27861;&#12290;</title><link>https://arxiv.org/abs/2202.12797</link><description>&lt;p&gt;
&#22312;&#26410;&#30693;&#29615;&#22659;&#20013;&#23398;&#20064;&#21160;&#24577;&#26426;&#21046;&#65306;&#19968;&#31181;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Learning Dynamic Mechanisms in Unknown Environments: A Reinforcement Learning Approach
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2202.12797
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23558;&#26080;&#22870;&#21169;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#24341;&#20837;&#21040;&#22312;&#32447;&#26426;&#21046;&#35774;&#35745;&#38382;&#39064;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#33021;&#22815;&#22312;&#26410;&#30693;&#29615;&#22659;&#20013;&#23398;&#20064;&#21160;&#24577;VCG&#26426;&#21046;&#19988;&#20855;&#26377;&#19978;&#30028;&#20026;$\tilde{\mathcal{O}}(T^{2/3})$&#30340;&#36951;&#25022;&#20445;&#35777;&#30340;&#26032;&#39062;&#23398;&#20064;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21160;&#24577;&#26426;&#21046;&#35774;&#35745;&#30740;&#31350;&#20102;&#26426;&#21046;&#35774;&#35745;&#32773;&#22312;&#26102;&#21464;&#29615;&#22659;&#20013;&#24212;&#35813;&#22914;&#20309;&#22312;&#20195;&#29702;&#20043;&#38388;&#20998;&#37197;&#36164;&#28304;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#31181;&#38382;&#39064;&#65292;&#21363;&#20195;&#29702;&#26681;&#25454;&#26410;&#30693;&#30340;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;(MDP)&#19982;&#26426;&#21046;&#35774;&#35745;&#32773;&#20114;&#21160;&#65292;&#22312;&#36825;&#20010;&#36807;&#31243;&#20013;&#20195;&#29702;&#30340;&#22870;&#21169;&#21644;&#26426;&#21046;&#35774;&#35745;&#32773;&#30340;&#29366;&#24577;&#26681;&#25454;&#19968;&#20010;&#24102;&#26377;&#26410;&#30693;&#22870;&#21169;&#20989;&#25968;&#21644;&#36716;&#31227;&#26680;&#30340;&#24773;&#33410;MDP&#28436;&#21270;&#12290;&#25105;&#20204;&#20851;&#27880;&#22312;&#32447;&#35774;&#32622;&#19979;&#30340;&#32447;&#24615;&#20989;&#25968;&#36817;&#20284;&#65292;&#24182;&#25552;&#20986;&#20102;&#26032;&#39062;&#30340;&#23398;&#20064;&#31639;&#27861;&#65292;&#22312;&#22810;&#36718;&#20114;&#21160;&#20013;&#24674;&#22797;&#21160;&#24577;Vickrey-Clarke-Grove(VCG)&#26426;&#21046;&#12290;&#25105;&#20204;&#26041;&#27861;&#30340;&#19968;&#20010;&#20851;&#38190;&#36129;&#29486;&#26159;&#23558;&#26080;&#22870;&#21169;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;(RL)&#32467;&#21512;&#36827;&#26469;&#65292;&#20197;&#24110;&#21161;&#22312;&#20016;&#23500;&#30340;&#31574;&#30053;&#31354;&#38388;&#20013;&#36827;&#34892;&#25506;&#32034;&#65292;&#20174;&#32780;&#20272;&#35745;&#21160;&#24577;VCG&#26426;&#21046;&#20013;&#30340;&#20215;&#26684;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#30340;&#36951;&#25022;&#19978;&#30028;&#20026;$\tilde{\mathcal{O}}(T^{2/3})$&#65292;&#24182;&#36827;&#19968;&#27493;&#35774;&#35745;&#20102;&#19968;&#20010;&#19979;&#30028;&#65292;&#20197;&#23637;&#31034;&#25105;&#20204;&#26041;&#27861;&#30340;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2202.12797v2 Announce Type: replace  Abstract: Dynamic mechanism design studies how mechanism designers should allocate resources among agents in a time-varying environment. We consider the problem where the agents interact with the mechanism designer according to an unknown Markov Decision Process (MDP), where agent rewards and the mechanism designer's state evolve according to an episodic MDP with unknown reward functions and transition kernels. We focus on the online setting with linear function approximation and propose novel learning algorithms to recover the dynamic Vickrey-Clarke-Grove (VCG) mechanism over multiple rounds of interaction. A key contribution of our approach is incorporating reward-free online Reinforcement Learning (RL) to aid exploration over a rich policy space to estimate prices in the dynamic VCG mechanism. We show that the regret of our proposed method is upper bounded by $\tilde{\mathcal{O}}(T^{2/3})$ and further devise a lower bound to show that our a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31354;&#38388;&#26497;&#31471;&#20540;&#27169;&#22411;&#65292;&#36890;&#36807;&#38598;&#25104;&#22312;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#30340;&#32467;&#26500;&#20013;&#65292;&#21487;&#20197;&#28789;&#27963;&#12289;&#39640;&#25928;&#22320;&#27169;&#25311;&#20855;&#26377;&#38750;&#24179;&#31283;&#30456;&#20851;&#24615;&#30340;&#26497;&#31471;&#20107;&#20214;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#22312;&#26102;&#38388;&#25928;&#29575;&#21644;&#24615;&#33021;&#19978;&#65292;&#30456;&#23545;&#20110;&#20256;&#32479;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#21644;&#35768;&#22810;&#20855;&#26377;&#24179;&#31283;&#30456;&#20851;&#24615;&#30340;&#31354;&#38388;&#26497;&#31471;&#20540;&#27169;&#22411;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20855;&#26377;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2307.08079</link><description>&lt;p&gt;
&#36890;&#36807;&#21464;&#20998;&#33258;&#21160; &#32534;&#30721;&#22120;&#23454;&#29616;&#28789;&#27963;&#39640;&#25928;&#30340;&#31354;&#38388;&#26497;&#31471;&#20540;&#27169;&#25311;
&lt;/p&gt;
&lt;p&gt;
Flexible and efficient spatial extremes emulation via variational autoencoders. (arXiv:2307.08079v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.08079
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31354;&#38388;&#26497;&#31471;&#20540;&#27169;&#22411;&#65292;&#36890;&#36807;&#38598;&#25104;&#22312;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#30340;&#32467;&#26500;&#20013;&#65292;&#21487;&#20197;&#28789;&#27963;&#12289;&#39640;&#25928;&#22320;&#27169;&#25311;&#20855;&#26377;&#38750;&#24179;&#31283;&#30456;&#20851;&#24615;&#30340;&#26497;&#31471;&#20107;&#20214;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#22312;&#26102;&#38388;&#25928;&#29575;&#21644;&#24615;&#33021;&#19978;&#65292;&#30456;&#23545;&#20110;&#20256;&#32479;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#21644;&#35768;&#22810;&#20855;&#26377;&#24179;&#31283;&#30456;&#20851;&#24615;&#30340;&#31354;&#38388;&#26497;&#31471;&#20540;&#27169;&#22411;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20855;&#26377;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#29616;&#23454;&#19990;&#30028;&#30340;&#36807;&#31243;&#20855;&#26377;&#22797;&#26434;&#30340;&#23614;&#20381;&#36182;&#32467;&#26500;&#65292;&#36825;&#31181;&#32467;&#26500;&#26080;&#27861;&#20351;&#29992;&#20256;&#32479;&#30340;&#39640;&#26031;&#36807;&#31243;&#26469;&#25551;&#36848;&#12290;&#26356;&#28789;&#27963;&#30340;&#31354;&#38388;&#26497;&#31471;&#20540;&#27169;&#22411;&#65292; &#22914;&#39640;&#26031;&#23610;&#24230;&#28151;&#21512;&#27169;&#22411;&#21644;&#21333;&#31449;&#28857;&#35843;&#33410;&#27169;&#22411;&#65292;&#20855;&#26377;&#21560;&#24341;&#20154;&#30340;&#26497;&#31471;&#20381;&#36182;&#24615;&#36136;&#65292;&#20294;&#24448;&#24448;&#38590;&#20197;&#25311;&#21512;&#21644;&#27169;&#25311;&#12290;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31354;&#38388;&#26497;&#31471;&#20540;&#27169;&#22411;&#65292;&#20855;&#26377;&#28789;&#27963;&#21644;&#38750;&#24179;&#31283;&#30340;&#30456;&#20851;&#24615;&#23646;&#24615;&#65292;&#24182;&#23558;&#20854;&#38598;&#25104;&#21040;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120; (extVAE) &#30340;&#32534;&#30721;-&#35299;&#30721;&#32467;&#26500;&#20013;&#12290; extVAE &#21487;&#20197;&#20316;&#20026;&#19968;&#20010;&#26102;&#31354;&#27169;&#25311;&#22120;&#65292;&#23545;&#28508;&#22312;&#30340;&#26426;&#21046;&#27169;&#22411;&#36755;&#20986;&#29366;&#24577;&#30340;&#20998;&#24067;&#36827;&#34892;&#24314;&#27169;&#65292;&#24182;&#20135;&#29983;&#20855;&#26377;&#19982;&#36755;&#20837;&#30456;&#21516;&#23646;&#24615;&#30340;&#36755;&#20986;&#65292;&#23588;&#20854;&#26159;&#22312;&#23614;&#37096;&#21306;&#22495;&#12290;&#36890;&#36807;&#24191;&#27867;&#30340;&#27169;&#25311;&#30740;&#31350;&#65292;&#25105;&#20204;&#35777;&#26126;&#25105;&#20204;&#30340;extVAE&#27604;&#20256;&#32479;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#26356;&#39640;&#25928;&#65292;&#24182;&#19988;&#22312;&#20855;&#26377; &#24179;&#31283;&#30456;&#20851;&#24615;&#32467;&#26500;&#30340;&#35768;&#22810;&#31354;&#38388;&#26497;&#31471;&#20540;&#27169;&#22411;&#20013;&#34920;&#29616; &#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many real-world processes have complex tail dependence structures that cannot be characterized using classical Gaussian processes. More flexible spatial extremes models such as Gaussian scale mixtures and single-station conditioning models exhibit appealing extremal dependence properties but are often exceedingly prohibitive to fit and simulate from. In this paper, we develop a new spatial extremes model that has flexible and non-stationary dependence properties, and we integrate it in the encoding-decoding structure of a variational autoencoder (extVAE). The extVAE can be used as a spatio-temporal emulator that characterizes the distribution of potential mechanistic model output states and produces outputs that have the same properties as the inputs, especially in the tail. Through extensive simulation studies, we show that our extVAE is vastly more time-efficient than traditional Bayesian inference while also outperforming many spatial extremes models with a stationary dependence str
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#22411;&#25193;&#25955;&#26144;&#23556;&#31890;&#23376;&#31995;&#32479;(DMPS)&#65292;&#21487;&#20197;&#29992;&#20110;&#39640;&#25928;&#29983;&#25104;&#24314;&#27169;&#65292;&#23454;&#39564;&#34920;&#26126;&#22312;&#21253;&#21547;&#27969;&#24418;&#32467;&#26500;&#30340;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#20102;&#27604;&#20854;&#20182;&#26041;&#27861;&#26356;&#22909;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2304.00200</link><description>&lt;p&gt;
&#22522;&#20110;&#25193;&#25955;&#26144;&#23556;&#30340;&#31890;&#23376;&#31995;&#32479;&#29992;&#20110;&#29983;&#25104;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Diffusion map particle systems for generative modeling. (arXiv:2304.00200v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.00200
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#22411;&#25193;&#25955;&#26144;&#23556;&#31890;&#23376;&#31995;&#32479;(DMPS)&#65292;&#21487;&#20197;&#29992;&#20110;&#39640;&#25928;&#29983;&#25104;&#24314;&#27169;&#65292;&#23454;&#39564;&#34920;&#26126;&#22312;&#21253;&#21547;&#27969;&#24418;&#32467;&#26500;&#30340;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#20102;&#27604;&#20854;&#20182;&#26041;&#27861;&#26356;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#25193;&#25955;&#26144;&#23556;&#31890;&#23376;&#31995;&#32479;(DMPS)&#65292;&#29992;&#20110;&#29983;&#25104;&#24314;&#27169;&#65292;&#35813;&#26041;&#27861;&#22522;&#20110;&#25193;&#25955;&#26144;&#23556;&#21644;Laplacian&#35843;&#25972;&#30340;Wasserstein&#26799;&#24230;&#19979;&#38477;&#65288;LAWGD&#65289;&#12290;&#25193;&#25955;&#26144;&#23556;&#34987;&#29992;&#26469;&#20174;&#26679;&#26412;&#20013;&#36817;&#20284;Langevin&#25193;&#25955;&#36807;&#31243;&#30340;&#29983;&#25104;&#22120;&#65292;&#20174;&#32780;&#23398;&#20064;&#28508;&#22312;&#30340;&#25968;&#25454;&#29983;&#25104;&#27969;&#24418;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;LAWGD&#33021;&#22815;&#22312;&#21512;&#36866;&#30340;&#26680;&#20989;&#25968;&#36873;&#25321;&#19979;&#39640;&#25928;&#22320;&#20174;&#30446;&#26631;&#20998;&#24067;&#20013;&#25277;&#26679;&#65292;&#25105;&#20204;&#22312;&#36825;&#37324;&#36890;&#36807;&#25193;&#25955;&#26144;&#23556;&#35745;&#31639;&#29983;&#25104;&#22120;&#30340;&#35889;&#36924;&#36817;&#26469;&#26500;&#36896;&#26680;&#20989;&#25968;&#12290;&#25968;&#20540;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#21253;&#25324;&#20855;&#26377;&#27969;&#24418;&#32467;&#26500;&#30340;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a novel diffusion map particle system (DMPS) for generative modeling, based on diffusion maps and Laplacian-adjusted Wasserstein gradient descent (LAWGD). Diffusion maps are used to approximate the generator of the Langevin diffusion process from samples, and hence to learn the underlying data-generating manifold. On the other hand, LAWGD enables efficient sampling from the target distribution given a suitable choice of kernel, which we construct here via a spectral approximation of the generator, computed with diffusion maps. Numerical experiments show that our method outperforms others on synthetic datasets, including examples with manifold structure.
&lt;/p&gt;</description></item></channel></rss>