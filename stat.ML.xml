<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#35757;&#32451;&#28145;&#24230;&#40784;&#27425;&#31070;&#32463;&#32593;&#32476;&#26102;&#26799;&#24230;&#27969;&#21160;&#21147;&#23398;&#30340;&#21160;&#24577;&#24615;&#65292;&#21457;&#29616;&#22312;&#36275;&#22815;&#23567;&#30340;&#21021;&#22987;&#21270;&#19979;&#65292;&#31070;&#32463;&#32593;&#32476;&#30340;&#26435;&#37325;&#22312;&#35757;&#32451;&#26089;&#26399;&#38454;&#27573;&#20445;&#25345;&#36739;&#23567;&#35268;&#33539;&#65292;&#24182;&#19988;&#27839;&#30528;&#31070;&#32463;&#30456;&#20851;&#20989;&#25968;&#30340;KKT&#28857;&#26041;&#21521;&#36817;&#20284;&#25910;&#25947;&#12290;</title><link>https://arxiv.org/abs/2403.08121</link><description>&lt;p&gt;
&#26089;&#26399;&#26041;&#21521;&#24615;&#25910;&#25947;&#22312;&#28145;&#24230;&#40784;&#27425;&#31070;&#32463;&#32593;&#32476;&#20013;&#36827;&#34892;&#23567;&#21021;&#22987;&#21270;&#26102;&#30340;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Early Directional Convergence in Deep Homogeneous Neural Networks for Small Initializations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.08121
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#35757;&#32451;&#28145;&#24230;&#40784;&#27425;&#31070;&#32463;&#32593;&#32476;&#26102;&#26799;&#24230;&#27969;&#21160;&#21147;&#23398;&#30340;&#21160;&#24577;&#24615;&#65292;&#21457;&#29616;&#22312;&#36275;&#22815;&#23567;&#30340;&#21021;&#22987;&#21270;&#19979;&#65292;&#31070;&#32463;&#32593;&#32476;&#30340;&#26435;&#37325;&#22312;&#35757;&#32451;&#26089;&#26399;&#38454;&#27573;&#20445;&#25345;&#36739;&#23567;&#35268;&#33539;&#65292;&#24182;&#19988;&#27839;&#30528;&#31070;&#32463;&#30456;&#20851;&#20989;&#25968;&#30340;KKT&#28857;&#26041;&#21521;&#36817;&#20284;&#25910;&#25947;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#35757;&#32451;&#28145;&#24230;&#40784;&#27425;&#31070;&#32463;&#32593;&#32476;&#26102;&#26799;&#24230;&#27969;&#21160;&#21147;&#23398;&#30340;&#21160;&#24577;&#24615;&#65292;&#36825;&#20123;&#32593;&#32476;&#20174;&#23567;&#21021;&#22987;&#21270;&#24320;&#22987;&#12290;&#26412;&#25991;&#32771;&#34385;&#21040;&#20855;&#26377;&#23616;&#37096;Lipschitz&#26799;&#24230;&#21644;&#38454;&#25968;&#20005;&#26684;&#22823;&#20110;&#20004;&#30340;&#31070;&#32463;&#32593;&#32476;&#12290;&#25991;&#31456;&#35777;&#26126;&#20102;&#23545;&#20110;&#36275;&#22815;&#23567;&#30340;&#21021;&#22987;&#21270;&#65292;&#22312;&#35757;&#32451;&#30340;&#26089;&#26399;&#38454;&#27573;&#65292;&#31070;&#32463;&#32593;&#32476;&#30340;&#26435;&#37325;&#20445;&#25345;&#35268;&#33539;&#36739;&#23567;&#65292;&#24182;&#19988;&#22312;Karush-Kuhn-Tucker (KKT)&#28857;&#22788;&#36817;&#20284;&#27839;&#30528;&#31070;&#32463;&#30456;&#20851;&#20989;&#25968;&#30340;&#26041;&#21521;&#25910;&#25947;&#12290;&#27492;&#22806;&#65292;&#23545;&#20110;&#24179;&#26041;&#25439;&#22833;&#24182;&#22312;&#31070;&#32463;&#32593;&#32476;&#26435;&#37325;&#19978;&#36827;&#34892;&#21487;&#20998;&#31163;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;&#36824;&#23637;&#31034;&#20102;&#22312;&#25439;&#22833;&#20989;&#25968;&#30340;&#26576;&#20123;&#38797;&#28857;&#38468;&#36817;&#26799;&#24230;&#27969;&#21160;&#21160;&#24577;&#30340;&#31867;&#20284;&#26041;&#21521;&#24615;&#25910;&#25947;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.08121v1 Announce Type: new  Abstract: This paper studies the gradient flow dynamics that arise when training deep homogeneous neural networks, starting with small initializations. The present work considers neural networks that are assumed to have locally Lipschitz gradients and an order of homogeneity strictly greater than two. This paper demonstrates that for sufficiently small initializations, during the early stages of training, the weights of the neural network remain small in norm and approximately converge in direction along the Karush-Kuhn-Tucker (KKT) points of the neural correlation function introduced in [1]. Additionally, for square loss and under a separability assumption on the weights of neural networks, a similar directional convergence of gradient flow dynamics is shown near certain saddle points of the loss function.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;Brenier&#30340;&#26497;&#20998;&#35299;&#23450;&#29702;&#30340;&#31070;&#32463;&#23454;&#29616;&#65292;&#25506;&#35752;&#20102;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#65292;&#24182;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#21270;&#28508;&#22312;&#20989;&#25968;$u$&#65292;&#20174;&#26368;&#26032;&#31070;&#32463;&#26368;&#20248;&#36755;&#36816;&#39046;&#22495;&#30340;&#36827;&#23637;&#20013;&#27762;&#21462;&#28789;&#24863;&#12290;</title><link>https://arxiv.org/abs/2403.03071</link><description>&lt;p&gt;
&#35770;Brenier&#30340;&#26497;&#20998;&#35299;&#30340;&#31070;&#32463;&#23454;&#29616;
&lt;/p&gt;
&lt;p&gt;
On a Neural Implementation of Brenier's Polar Factorization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03071
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;Brenier&#30340;&#26497;&#20998;&#35299;&#23450;&#29702;&#30340;&#31070;&#32463;&#23454;&#29616;&#65292;&#25506;&#35752;&#20102;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#65292;&#24182;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#21270;&#28508;&#22312;&#20989;&#25968;$u$&#65292;&#20174;&#26368;&#26032;&#31070;&#32463;&#26368;&#20248;&#36755;&#36816;&#39046;&#22495;&#30340;&#36827;&#23637;&#20013;&#27762;&#21462;&#28789;&#24863;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;1991&#24180;&#65292;Brenier&#35777;&#26126;&#20102;&#19968;&#20010;&#23450;&#29702;&#65292;&#23558;$QR$&#20998;&#35299;&#65288;&#20998;&#20026;&#21322;&#27491;&#23450;&#30697;&#38453;$\times$&#37193;&#30697;&#38453;&#65289;&#25512;&#24191;&#21040;&#20219;&#24847;&#30690;&#37327;&#22330;$F:\mathbb{R}^d\rightarrow \mathbb{R}^d$&#12290;&#36825;&#20010;&#34987;&#31216;&#20026;&#26497;&#20998;&#35299;&#23450;&#29702;&#30340;&#23450;&#29702;&#34920;&#26126;&#65292;&#20219;&#24847;&#22330;$F$&#37117;&#21487;&#20197;&#34920;&#31034;&#20026;&#20984;&#20989;&#25968;$u$&#30340;&#26799;&#24230;&#19982;&#20445;&#27979;&#24230;&#26144;&#23556;$M$&#30340;&#22797;&#21512;&#65292;&#21363;$F=\nabla u \circ M$&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#36825;&#19968;&#20855;&#26377;&#28145;&#36828;&#29702;&#35770;&#24847;&#20041;&#30340;&#32467;&#26524;&#30340;&#23454;&#38469;&#23454;&#29616;&#65292;&#24182;&#25506;&#35752;&#20102;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#21487;&#33021;&#30340;&#24212;&#29992;&#12290;&#35813;&#23450;&#29702;&#19982;&#26368;&#20248;&#36755;&#36816;&#65288;OT&#65289;&#29702;&#35770;&#23494;&#20999;&#30456;&#20851;&#65292;&#25105;&#20204;&#20511;&#37492;&#20102;&#31070;&#32463;&#26368;&#20248;&#36755;&#36816;&#39046;&#22495;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#23558;&#28508;&#22312;&#20989;&#25968;$u$&#21442;&#25968;&#21270;&#20026;&#36755;&#20837;&#20984;&#31070;&#32463;&#32593;&#32476;&#12290;&#26144;&#23556;$M$&#21487;&#20197;&#36890;&#36807;&#20351;&#29992;$u^*$&#65292;&#21363;$u$&#30340;&#20984;&#20849;&#36717;&#65292;&#36880;&#28857;&#35745;&#31639;&#24471;&#21040;&#65292;&#21363;$M=\nabla u^* \circ F$&#65292;&#25110;&#32773;&#20316;&#20026;&#36741;&#21161;&#32593;&#32476;&#23398;&#20064;&#24471;&#21040;&#12290;&#22240;&#20026;$M$&#22312;&#22522;&#22240;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03071v1 Announce Type: cross  Abstract: In 1991, Brenier proved a theorem that generalizes the $QR$ decomposition for square matrices -- factored as PSD $\times$ unitary -- to any vector field $F:\mathbb{R}^d\rightarrow \mathbb{R}^d$. The theorem, known as the polar factorization theorem, states that any field $F$ can be recovered as the composition of the gradient of a convex function $u$ with a measure-preserving map $M$, namely $F=\nabla u \circ M$. We propose a practical implementation of this far-reaching theoretical result, and explore possible uses within machine learning. The theorem is closely related to optimal transport (OT) theory, and we borrow from recent advances in the field of neural optimal transport to parameterize the potential $u$ as an input convex neural network. The map $M$ can be either evaluated pointwise using $u^*$, the convex conjugate of $u$, through the identity $M=\nabla u^* \circ F$, or learned as an auxiliary network. Because $M$ is, in gene
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23545;&#20110;&#20855;&#26377;&#20559;&#24577;&#26799;&#24230;&#21644;&#33258;&#36866;&#24212;&#27493;&#38271;&#30340;SGD&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#38750;&#28176;&#36827;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;Adagrad&#21644;RMSProp&#31639;&#27861;&#22312;&#25910;&#25947;&#36895;&#24230;&#19978;&#19982;&#26080;&#20559;&#24773;&#20917;&#30456;&#20284;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#32467;&#26524;&#39564;&#35777;&#20102;&#25910;&#25947;&#32467;&#26524;&#65292;&#23637;&#31034;&#20102;&#22914;&#20309;&#38477;&#20302;&#20559;&#24046;&#30340;&#24433;&#21709;&#12290;</title><link>https://arxiv.org/abs/2402.02857</link><description>&lt;p&gt;
&#20559;&#24577;&#33258;&#36866;&#24212;&#38543;&#26426;&#36924;&#36817;&#30340;&#38750;&#28176;&#36827;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Non-asymptotic Analysis of Biased Adaptive Stochastic Approximation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02857
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;&#20110;&#20855;&#26377;&#20559;&#24577;&#26799;&#24230;&#21644;&#33258;&#36866;&#24212;&#27493;&#38271;&#30340;SGD&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#38750;&#28176;&#36827;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;Adagrad&#21644;RMSProp&#31639;&#27861;&#22312;&#25910;&#25947;&#36895;&#24230;&#19978;&#19982;&#26080;&#20559;&#24773;&#20917;&#30456;&#20284;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#32467;&#26524;&#39564;&#35777;&#20102;&#25910;&#25947;&#32467;&#26524;&#65292;&#23637;&#31034;&#20102;&#22914;&#20309;&#38477;&#20302;&#20559;&#24046;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#36866;&#24212;&#27493;&#38271;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#29616;&#22312;&#24191;&#27867;&#29992;&#20110;&#35757;&#32451;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#12290;&#22823;&#22810;&#25968;&#29702;&#35770;&#32467;&#26524;&#20551;&#35774;&#21487;&#20197;&#33719;&#24471;&#26080;&#20559;&#30340;&#26799;&#24230;&#20272;&#35745;&#22120;&#65292;&#28982;&#32780;&#22312;&#19968;&#20123;&#26368;&#36817;&#30340;&#28145;&#24230;&#23398;&#20064;&#21644;&#24378;&#21270;&#23398;&#20064;&#24212;&#29992;&#20013;&#65292;&#20351;&#29992;&#20102;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#65292;&#21364;&#26080;&#27861;&#28385;&#36275;&#36825;&#19968;&#20551;&#35774;&#12290;&#26412;&#25991;&#23545;&#20855;&#26377;&#20559;&#24577;&#26799;&#24230;&#21644;&#33258;&#36866;&#24212;&#27493;&#38271;&#30340;SGD&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#38750;&#28176;&#36827;&#24615;&#20998;&#26512;&#65292;&#38024;&#23545;&#20984;&#21644;&#38750;&#20984;&#24179;&#28369;&#20989;&#25968;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#21253;&#25324;&#26102;&#21464;&#20559;&#24046;&#65292;&#24182;&#24378;&#35843;&#25511;&#21046;&#20559;&#24046;&#21644;&#22343;&#26041;&#35823;&#24046;&#65288;MSE&#65289;&#26799;&#24230;&#20272;&#35745;&#30340;&#37325;&#35201;&#24615;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20351;&#29992;&#20559;&#24577;&#26799;&#24230;&#30340;Adagrad&#21644;RMSProp&#31639;&#27861;&#23545;&#20110;&#38750;&#20984;&#24179;&#28369;&#20989;&#25968;&#30340;&#25910;&#25947;&#36895;&#24230;&#19982;&#25991;&#29486;&#20013;&#26080;&#20559;&#24773;&#20917;&#19979;&#30340;&#32467;&#26524;&#30456;&#20284;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#20351;&#29992;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65288;VAE&#65289;&#30340;&#23454;&#39564;&#32467;&#26524;&#65292;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#25910;&#25947;&#32467;&#26524;&#65292;&#24182;&#23637;&#31034;&#20102;&#22914;&#20309;&#36890;&#36807;&#36866;&#24403;&#30340;&#26041;&#27861;&#38477;&#20302;&#20559;&#24046;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stochastic Gradient Descent (SGD) with adaptive steps is now widely used for training deep neural networks. Most theoretical results assume access to unbiased gradient estimators, which is not the case in several recent deep learning and reinforcement learning applications that use Monte Carlo methods. This paper provides a comprehensive non-asymptotic analysis of SGD with biased gradients and adaptive steps for convex and non-convex smooth functions. Our study incorporates time-dependent bias and emphasizes the importance of controlling the bias and Mean Squared Error (MSE) of the gradient estimator. In particular, we establish that Adagrad and RMSProp with biased gradients converge to critical points for smooth non-convex functions at a rate similar to existing results in the literature for the unbiased case. Finally, we provide experimental results using Variational Autoenconders (VAE) that illustrate our convergence results and show how the effect of bias can be reduced by appropri
&lt;/p&gt;</description></item><item><title>&#23884;&#22871;&#38543;&#26426;&#22359;&#27169;&#22411;&#65288;NSBM&#65289;&#33021;&#22815;&#21516;&#26102;&#23545;&#32593;&#32476;&#21644;&#33410;&#28857;&#36827;&#34892;&#32858;&#31867;&#65292;&#20855;&#26377;&#22788;&#29702;&#26080;&#26631;&#31614;&#32593;&#32476;&#12289;&#24314;&#27169;&#24322;&#36136;&#31038;&#32676;&#20197;&#21450;&#33258;&#21160;&#36873;&#25321;&#32858;&#31867;&#25968;&#37327;&#30340;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2307.09210</link><description>&lt;p&gt;
&#23884;&#22871;&#38543;&#26426;&#22359;&#27169;&#22411;&#29992;&#20110;&#21516;&#26102;&#23545;&#32593;&#32476;&#21644;&#33410;&#28857;&#36827;&#34892;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Nested stochastic block model for simultaneously clustering networks and nodes. (arXiv:2307.09210v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.09210
&lt;/p&gt;
&lt;p&gt;
&#23884;&#22871;&#38543;&#26426;&#22359;&#27169;&#22411;&#65288;NSBM&#65289;&#33021;&#22815;&#21516;&#26102;&#23545;&#32593;&#32476;&#21644;&#33410;&#28857;&#36827;&#34892;&#32858;&#31867;&#65292;&#20855;&#26377;&#22788;&#29702;&#26080;&#26631;&#31614;&#32593;&#32476;&#12289;&#24314;&#27169;&#24322;&#36136;&#31038;&#32676;&#20197;&#21450;&#33258;&#21160;&#36873;&#25321;&#32858;&#31867;&#25968;&#37327;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#23884;&#22871;&#38543;&#26426;&#22359;&#27169;&#22411;&#65288;NSBM&#65289;&#65292;&#29992;&#20110;&#23545;&#19968;&#32452;&#32593;&#32476;&#36827;&#34892;&#32858;&#31867;&#65292;&#21516;&#26102;&#26816;&#27979;&#27599;&#20010;&#32593;&#32476;&#20013;&#30340;&#31038;&#32676;&#12290;NSBM&#20855;&#26377;&#20960;&#20010;&#21560;&#24341;&#20154;&#30340;&#29305;&#28857;&#65292;&#21253;&#25324;&#33021;&#22815;&#22788;&#29702;&#20855;&#26377;&#28508;&#22312;&#19981;&#21516;&#33410;&#28857;&#38598;&#30340;&#26080;&#26631;&#31614;&#32593;&#32476;&#65292;&#28789;&#27963;&#22320;&#24314;&#27169;&#24322;&#36136;&#31038;&#32676;&#65292;&#20197;&#21450;&#33258;&#21160;&#36873;&#25321;&#32593;&#32476;&#31867;&#21035;&#21644;&#27599;&#20010;&#32593;&#32476;&#20869;&#31038;&#32676;&#25968;&#37327;&#30340;&#33021;&#21147;&#12290;&#36890;&#36807;&#36125;&#21494;&#26031;&#27169;&#22411;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#65292;&#24182;&#23558;&#23884;&#22871;&#29380;&#21033;&#20811;&#38647;&#36807;&#31243;&#65288;NDP&#65289;&#20316;&#20026;&#20808;&#39564;&#65292;&#20197;&#32852;&#21512;&#24314;&#27169;&#32593;&#32476;&#38388;&#21644;&#32593;&#32476;&#20869;&#30340;&#32858;&#31867;&#12290;&#32593;&#32476;&#25968;&#25454;&#24341;&#20837;&#30340;&#20381;&#36182;&#24615;&#32473;NDP&#24102;&#26469;&#20102;&#38750;&#24179;&#20961;&#30340;&#25361;&#25112;&#65292;&#29305;&#21035;&#26159;&#22312;&#24320;&#21457;&#39640;&#25928;&#30340;&#37319;&#26679;&#22120;&#26041;&#38754;&#12290;&#23545;&#20110;&#21518;&#39564;&#25512;&#26029;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20960;&#31181;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#31639;&#27861;&#65292;&#21253;&#25324;&#26631;&#20934;&#30340;Gibbs&#37319;&#26679;&#22120;&#65292;&#31616;&#21270;Gibbs&#37319;&#26679;&#22120;&#21644;&#20004;&#31181;&#29992;&#20110;&#36820;&#22238;&#20004;&#20010;&#32423;&#21035;&#32858;&#31867;&#32467;&#26524;&#30340;&#38459;&#22622;Gibbs&#37319;&#26679;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce the nested stochastic block model (NSBM) to cluster a collection of networks while simultaneously detecting communities within each network. NSBM has several appealing features including the ability to work on unlabeled networks with potentially different node sets, the flexibility to model heterogeneous communities, and the means to automatically select the number of classes for the networks and the number of communities within each network. This is accomplished via a Bayesian model, with a novel application of the nested Dirichlet process (NDP) as a prior to jointly model the between-network and within-network clusters. The dependency introduced by the network data creates nontrivial challenges for the NDP, especially in the development of efficient samplers. For posterior inference, we propose several Markov chain Monte Carlo algorithms including a standard Gibbs sampler, a collapsed Gibbs sampler, and two blocked Gibbs samplers that ultimately return two levels of clus
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;&#20013;&#22810;&#26679;&#25237;&#24433;&#38598;&#21512;&#30340;&#29702;&#35770;&#29305;&#24615;&#65292;&#25552;&#20986;&#20102;&#20351;&#29992;&#38598;&#21512;&#24046;&#24322;&#24230;&#37327;&#30340;&#31639;&#27861;&#65292;&#20197;&#20419;&#36827;&#21487;&#38752;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/2306.07124</link><description>&lt;p&gt;
&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;&#30340;&#22810;&#26679;&#25237;&#24433;&#38598;&#21512;
&lt;/p&gt;
&lt;p&gt;
Diverse Projection Ensembles for Distributional Reinforcement Learning. (arXiv:2306.07124v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07124
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;&#20013;&#22810;&#26679;&#25237;&#24433;&#38598;&#21512;&#30340;&#29702;&#35770;&#29305;&#24615;&#65292;&#25552;&#20986;&#20102;&#20351;&#29992;&#38598;&#21512;&#24046;&#24322;&#24230;&#37327;&#30340;&#31639;&#27861;&#65292;&#20197;&#20419;&#36827;&#21487;&#38752;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19982;&#20256;&#32479;&#30340;&#24378;&#21270;&#23398;&#20064;&#19981;&#21516;&#65292;&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#26088;&#22312;&#23398;&#20064;&#22238;&#25253;&#30340;&#20998;&#24067;&#32780;&#19981;&#26159;&#20854;&#26399;&#26395;&#20540;&#12290;&#30001;&#20110;&#22238;&#25253;&#20998;&#24067;&#30340;&#24615;&#36136;&#36890;&#24120;&#26159;&#26410;&#30693;&#30340;&#25110;&#36807;&#20110;&#22797;&#26434;&#65292;&#22240;&#27492;&#36890;&#24120;&#37319;&#29992;&#23558;&#26410;&#32422;&#26463;&#30340;&#20998;&#24067;&#25237;&#24433;&#21040;&#21487;&#34920;&#31034;&#30340;&#21442;&#25968;&#20998;&#24067;&#38598;&#21512;&#20013;&#30340;&#26041;&#27861;&#36827;&#34892;&#36924;&#36817;&#12290;&#25105;&#20204;&#35748;&#20026;&#65292;&#24403;&#23558;&#36825;&#31181;&#25237;&#24433;&#27493;&#39588;&#19982;&#31070;&#32463;&#32593;&#32476;&#21644;&#26799;&#24230;&#19979;&#38477;&#30456;&#32467;&#21512;&#26102;&#65292;&#36825;&#31181;&#25237;&#24433;&#27493;&#39588;&#20250;&#20135;&#29983;&#24378;&#28872;&#30340;&#24402;&#32435;&#20559;&#35265;&#65292;&#20174;&#32780;&#28145;&#21051;&#24433;&#21709;&#23398;&#20064;&#27169;&#22411;&#30340;&#27867;&#21270;&#34892;&#20026;&#12290;&#20026;&#20102;&#36890;&#36807;&#22810;&#26679;&#24615;&#20419;&#36827;&#21487;&#38752;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#65292;&#26412;&#25991;&#30740;&#31350;&#20102;&#20998;&#24067;&#24335;&#38598;&#21512;&#20013;&#22810;&#20010;&#19981;&#21516;&#30340;&#25237;&#24433;&#21644;&#34920;&#31034;&#30340;&#32452;&#21512;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#36825;&#31181;&#25237;&#24433;&#38598;&#21512;&#30340;&#29702;&#35770;&#29305;&#24615;&#65292;&#24182;&#25512;&#23548;&#20986;&#19968;&#31181;&#20351;&#29992;&#38598;&#21512;&#24046;&#24322;&#24230;&#37327;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In contrast to classical reinforcement learning, distributional reinforcement learning algorithms aim to learn the distribution of returns rather than their expected value. Since the nature of the return distribution is generally unknown a priori or arbitrarily complex, a common approach finds approximations within a set of representable, parametric distributions. Typically, this involves a projection of the unconstrained distribution onto the set of simplified distributions. We argue that this projection step entails a strong inductive bias when coupled with neural networks and gradient descent, thereby profoundly impacting the generalization behavior of learned models. In order to facilitate reliable uncertainty estimation through diversity, this work studies the combination of several different projections and representations in a distributional ensemble. We establish theoretical properties of such projection ensembles and derive an algorithm that uses ensemble disagreement, measure
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20869;&#37096;&#34920;&#24449;&#30340;Vecchia&#39640;&#26031;&#36807;&#31243;&#38598;&#25104;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#23558;&#26631;&#20934;&#39640;&#26031;&#36807;&#31243;&#19982;DNN&#30456;&#32467;&#21512;&#65292;&#29983;&#25104;&#19968;&#31181;&#19981;&#20165;&#33021;&#22815;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#65292;&#32780;&#19988;&#33021;&#22815;&#25552;&#20379;&#26356;&#20934;&#30830;&#21644;&#26356;&#31283;&#20581;&#30340;&#39044;&#27979;&#30340;&#28145;&#24230;Vecchia&#38598;&#21512;&#12290;</title><link>http://arxiv.org/abs/2305.17063</link><description>&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20869;&#37096;&#34920;&#24449;&#19978;&#30340;Vecchia&#39640;&#26031;&#36807;&#31243;&#38598;&#25104;
&lt;/p&gt;
&lt;p&gt;
Vecchia Gaussian Process Ensembles on Internal Representations of Deep Neural Networks. (arXiv:2305.17063v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17063
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20869;&#37096;&#34920;&#24449;&#30340;Vecchia&#39640;&#26031;&#36807;&#31243;&#38598;&#25104;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#23558;&#26631;&#20934;&#39640;&#26031;&#36807;&#31243;&#19982;DNN&#30456;&#32467;&#21512;&#65292;&#29983;&#25104;&#19968;&#31181;&#19981;&#20165;&#33021;&#22815;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#65292;&#32780;&#19988;&#33021;&#22815;&#25552;&#20379;&#26356;&#20934;&#30830;&#21644;&#26356;&#31283;&#20581;&#30340;&#39044;&#27979;&#30340;&#28145;&#24230;Vecchia&#38598;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#22238;&#24402;&#20219;&#21153;&#65292;&#26631;&#20934;&#39640;&#26031;&#36807;&#31243;(GPs)&#25552;&#20379;&#20102;&#33258;&#28982;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#32780;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;(DNNs)&#25797;&#38271;&#34920;&#24449;&#23398;&#20064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#28151;&#21512;&#26041;&#27861;&#65292;&#23558;&#36825;&#20004;&#31181;&#26041;&#27861;&#21327;&#21516;&#32452;&#21512;&#36215;&#26469;&#65292;&#24418;&#25104;&#19968;&#20010;&#22522;&#20110;DNN&#30340;&#38544;&#34255;&#23618;&#36755;&#20986;&#26500;&#24314;&#30340;GP&#38598;&#21512;&#12290;&#36890;&#36807;&#21033;&#29992;&#26368;&#36817;&#37051;&#26465;&#20214;&#29420;&#31435;&#30340;Vecchia&#36817;&#20284;&#23454;&#29616;&#20102;GP&#30340;&#21487;&#25193;&#23637;&#24615;&#12290;&#29983;&#25104;&#30340;&#28145;&#24230;Vecchia&#38598;&#21512;&#19981;&#20165;&#36171;&#20104;DNN&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#36824;&#21487;&#20197;&#25552;&#20379;&#26356;&#20934;&#30830;&#21644;&#26356;&#31283;&#20581;&#30340;&#39044;&#27979;&#12290;&#25105;&#20204;&#22312;&#20960;&#20010;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#27169;&#22411;&#30340;&#25928;&#29992;&#65292;&#24182;&#36827;&#34892;&#20102;&#23454;&#39564;&#20197;&#20102;&#35299;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#20869;&#37096;&#26426;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
For regression tasks, standard Gaussian processes (GPs) provide natural uncertainty quantification, while deep neural networks (DNNs) excel at representation learning. We propose to synergistically combine these two approaches in a hybrid method consisting of an ensemble of GPs built on the output of hidden layers of a DNN. GP scalability is achieved via Vecchia approximations that exploit nearest-neighbor conditional independence. The resulting deep Vecchia ensemble not only imbues the DNN with uncertainty quantification but can also provide more accurate and robust predictions. We demonstrate the utility of our model on several datasets and carry out experiments to understand the inner workings of the proposed method.
&lt;/p&gt;</description></item></channel></rss>