<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#35813;&#35770;&#25991;&#36890;&#36807;&#22522;&#20110;&#21306;&#22495;&#31283;&#23450;&#24615;&#30340;&#26041;&#27861;&#65292;&#25512;&#23548;&#20986;&#20102;&#38543;&#26426;&#26862;&#26519;&#39044;&#27979;&#30340;&#39640;&#26031;&#36924;&#36817;&#30028;&#38480;&#65292;&#24182;&#24314;&#31435;&#20102;&#36866;&#29992;&#20110;&#21508;&#31181;&#30456;&#20851;&#32479;&#35745;&#38382;&#39064;&#30340;&#27010;&#29575;&#32467;&#26524;&#12290;</title><link>https://arxiv.org/abs/2403.09960</link><description>&lt;p&gt;
&#36890;&#36807;&#22522;&#20110;&#21306;&#22495;&#31283;&#23450;&#24615;&#30340;&#22810;&#20803;&#39640;&#26031;&#36924;&#36817;&#25913;&#36827;&#38543;&#26426;&#26862;&#26519;
&lt;/p&gt;
&lt;p&gt;
Multivariate Gaussian Approximation for Random Forest via Region-based Stabilization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.09960
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#36890;&#36807;&#22522;&#20110;&#21306;&#22495;&#31283;&#23450;&#24615;&#30340;&#26041;&#27861;&#65292;&#25512;&#23548;&#20986;&#20102;&#38543;&#26426;&#26862;&#26519;&#39044;&#27979;&#30340;&#39640;&#26031;&#36924;&#36817;&#30028;&#38480;&#65292;&#24182;&#24314;&#31435;&#20102;&#36866;&#29992;&#20110;&#21508;&#31181;&#30456;&#20851;&#32479;&#35745;&#38382;&#39064;&#30340;&#27010;&#29575;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;&#32473;&#23450;&#30001;&#27850;&#26494;&#36807;&#31243;&#20135;&#29983;&#30340;&#19968;&#32452;&#35757;&#32451;&#28857;&#30340;&#24773;&#20917;&#19979;&#65292;&#25512;&#23548;&#20102;&#38543;&#26426;&#26862;&#26519;&#39044;&#27979;&#30340;&#39640;&#26031;&#36924;&#36817;&#30028;&#38480;&#65292;&#20551;&#35774;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#23384;&#22312;&#30456;&#24403;&#28201;&#21644;&#30340;&#27491;&#21017;&#24615;&#20551;&#35774;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#19968;&#20010;&#20851;&#38190;&#35266;&#23519;&#65306;&#38543;&#26426;&#26862;&#26519;&#30340;&#39044;&#27979;&#28385;&#36275;&#19968;&#23450;&#30340;&#31216;&#20026;&#22522;&#20110;&#21306;&#22495;&#31283;&#23450;&#24615;&#30340;&#20960;&#20309;&#23646;&#24615;&#12290;&#22312;&#20026;&#38543;&#26426;&#26862;&#26519;&#24320;&#21457;&#32467;&#26524;&#30340;&#36807;&#31243;&#20013;&#65292;&#25105;&#20204;&#36824;&#20026;&#22522;&#20110;&#21306;&#22495;&#31283;&#23450;&#30340;&#27850;&#26494;&#36807;&#31243;&#30340;&#19968;&#33324;&#27867;&#20989;&#24314;&#31435;&#20102;&#19968;&#20010;&#27010;&#29575;&#32467;&#26524;&#65292;&#36825;&#21487;&#33021;&#26159;&#29420;&#31435;&#24863;&#20852;&#36259;&#30340;&#12290;&#36825;&#19968;&#26222;&#36941;&#32467;&#26524;&#21033;&#29992;&#20102;Malliavin-Stein&#26041;&#27861;&#65292;&#24182;&#19988;&#21487;&#33021;&#36866;&#29992;&#20110;&#21508;&#31181;&#30456;&#20851;&#30340;&#32479;&#35745;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.09960v1 Announce Type: cross  Abstract: We derive Gaussian approximation bounds for random forest predictions based on a set of training points given by a Poisson process, under fairly mild regularity assumptions on the data generating process. Our approach is based on the key observation that the random forest predictions satisfy a certain geometric property called region-based stabilization. In the process of developing our results for the random forest, we also establish a probabilistic result, which might be of independent interest, on multivariate Gaussian approximation bounds for general functionals of Poisson process that are region-based stabilizing. This general result makes use of the Malliavin-Stein method, and is potentially applicable to various related statistical problems.
&lt;/p&gt;</description></item><item><title>&#37319;&#29992;&#32467;&#26500;&#19981;&#21487;&#30693;&#30340;&#32479;&#35745;&#19979;&#30028;&#26694;&#26550;&#65292;&#35777;&#26126;&#20102;&#21452;&#31283;&#20581;&#20272;&#35745;&#22120;&#22312;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#65288;ATE&#65289;&#21644;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#26041;&#38754;&#30340;&#32479;&#35745;&#26368;&#20248;&#24615;</title><link>https://arxiv.org/abs/2402.14264</link><description>&lt;p&gt;
&#21452;&#31283;&#20581;&#23398;&#20064;&#22312;&#22788;&#29702;&#25928;&#24212;&#20272;&#35745;&#20013;&#30340;&#32467;&#26500;&#19981;&#21487;&#30693;&#24615;&#26368;&#20248;&#24615;
&lt;/p&gt;
&lt;p&gt;
Structure-agnostic Optimality of Doubly Robust Learning for Treatment Effect Estimation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14264
&lt;/p&gt;
&lt;p&gt;
&#37319;&#29992;&#32467;&#26500;&#19981;&#21487;&#30693;&#30340;&#32479;&#35745;&#19979;&#30028;&#26694;&#26550;&#65292;&#35777;&#26126;&#20102;&#21452;&#31283;&#20581;&#20272;&#35745;&#22120;&#22312;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#65288;ATE&#65289;&#21644;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#26041;&#38754;&#30340;&#32479;&#35745;&#26368;&#20248;&#24615;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#20272;&#35745;&#26159;&#22240;&#26524;&#25512;&#26029;&#20013;&#26368;&#26680;&#24515;&#30340;&#38382;&#39064;&#65292;&#24212;&#29992;&#24191;&#27867;&#12290;&#34429;&#28982;&#25991;&#29486;&#20013;&#25552;&#20986;&#20102;&#35768;&#22810;&#20272;&#35745;&#31574;&#30053;&#65292;&#26368;&#36817;&#36824;&#32435;&#20837;&#20102;&#36890;&#29992;&#30340;&#26426;&#22120;&#23398;&#20064;&#20272;&#35745;&#22120;&#65292;&#20294;&#36825;&#20123;&#26041;&#27861;&#30340;&#32479;&#35745;&#26368;&#20248;&#24615;&#20173;&#28982;&#26159;&#19968;&#20010;&#24320;&#25918;&#30340;&#30740;&#31350;&#39046;&#22495;&#12290;&#26412;&#25991;&#37319;&#29992;&#26368;&#36817;&#24341;&#20837;&#30340;&#32479;&#35745;&#19979;&#30028;&#32467;&#26500;&#19981;&#21487;&#30693;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#23545;&#24178;&#25200;&#20989;&#25968;&#27809;&#26377;&#32467;&#26500;&#24615;&#36136;&#20551;&#35774;&#65292;&#38500;&#20102;&#35775;&#38382;&#40657;&#30418;&#20272;&#35745;&#22120;&#20197;&#36798;&#21040;&#23567;&#35823;&#24046;&#65307;&#24403;&#21482;&#24895;&#24847;&#32771;&#34385;&#20351;&#29992;&#38750;&#21442;&#25968;&#22238;&#24402;&#21644;&#20998;&#31867;&#31070;&#35861;&#20316;&#20026;&#40657;&#30418;&#23376;&#36807;&#31243;&#30340;&#20272;&#35745;&#31574;&#30053;&#26102;&#65292;&#36825;&#19968;&#28857;&#23588;&#20854;&#21560;&#24341;&#20154;&#12290;&#22312;&#36825;&#20010;&#26694;&#26550;&#20869;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#21452;&#31283;&#20581;&#20272;&#35745;&#22120;&#23545;&#20110;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#65288;ATE&#65289;&#21644;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#30340;&#32479;&#35745;&#26368;&#20248;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14264v1 Announce Type: cross  Abstract: Average treatment effect estimation is the most central problem in causal inference with application to numerous disciplines. While many estimation strategies have been proposed in the literature, recently also incorporating generic machine learning estimators, the statistical optimality of these methods has still remained an open area of investigation. In this paper, we adopt the recently introduced structure-agnostic framework of statistical lower bounds, which poses no structural properties on the nuisance functions other than access to black-box estimators that attain small errors; which is particularly appealing when one is only willing to consider estimation strategies that use non-parametric regression and classification oracles as a black-box sub-process. Within this framework, we prove the statistical optimality of the celebrated and widely used doubly robust estimators for both the Average Treatment Effect (ATE) and the Avera
&lt;/p&gt;</description></item><item><title>&#21487;&#23481;&#35768;&#39044;&#27979;&#35268;&#21010;&#65288;CPP&#65289;&#26159;&#19968;&#31181;&#35299;&#20915;&#21463;&#20219;&#24847;&#38543;&#26426;&#21442;&#25968;&#24433;&#21709;&#30340;&#20248;&#21270;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#26679;&#26412;&#21644;&#37327;&#23376;&#24341;&#29702;&#23558;&#26426;&#36935;&#21463;&#38480;&#20248;&#21270;&#65288;CCO&#65289;&#38382;&#39064;&#36716;&#21270;&#20026;&#30830;&#23450;&#24615;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#20855;&#22791;&#36793;&#38469;&#27010;&#29575;&#21487;&#34892;&#24615;&#20445;&#35777;&#12290;</title><link>https://arxiv.org/abs/2402.07407</link><description>&lt;p&gt;
&#21487;&#23481;&#35768;&#39044;&#27979;&#35268;&#21010;&#29992;&#20110;&#26426;&#36935;&#21463;&#38480;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Conformal Predictive Programming for Chance Constrained Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07407
&lt;/p&gt;
&lt;p&gt;
&#21487;&#23481;&#35768;&#39044;&#27979;&#35268;&#21010;&#65288;CPP&#65289;&#26159;&#19968;&#31181;&#35299;&#20915;&#21463;&#20219;&#24847;&#38543;&#26426;&#21442;&#25968;&#24433;&#21709;&#30340;&#20248;&#21270;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#26679;&#26412;&#21644;&#37327;&#23376;&#24341;&#29702;&#23558;&#26426;&#36935;&#21463;&#38480;&#20248;&#21270;&#65288;CCO&#65289;&#38382;&#39064;&#36716;&#21270;&#20026;&#30830;&#23450;&#24615;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#20855;&#22791;&#36793;&#38469;&#27010;&#29575;&#21487;&#34892;&#24615;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23545;&#39044;&#27979;&#35268;&#21010;&#65288;CP&#65289;&#30340;&#36827;&#23637;&#30340;&#28608;&#21169;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#21487;&#23481;&#35768;&#39044;&#27979;&#35268;&#21010;&#65288;CPP&#65289;&#65292;&#19968;&#31181;&#35299;&#20915;&#26426;&#36935;&#21463;&#38480;&#20248;&#21270;&#65288;CCO&#65289;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#21363;&#21463;&#20219;&#24847;&#38543;&#26426;&#21442;&#25968;&#24433;&#21709;&#30340;&#38750;&#32447;&#24615;&#32422;&#26463;&#20989;&#25968;&#30340;&#20248;&#21270;&#38382;&#39064;&#12290;CPP&#21033;&#29992;&#36825;&#20123;&#38543;&#26426;&#21442;&#25968;&#30340;&#26679;&#26412;&#20197;&#21450;&#37327;&#23376;&#24341;&#29702;&#65288;CP&#30340;&#26680;&#24515;&#65289;&#23558;CCO&#38382;&#39064;&#36716;&#21270;&#20026;&#30830;&#23450;&#24615;&#20248;&#21270;&#38382;&#39064;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#65306;&#65288;1&#65289;&#23558;&#37327;&#23376;&#34920;&#31034;&#20026;&#32447;&#24615;&#35268;&#21010;&#20197;&#21450;&#20854;KKT&#26465;&#20214;&#65288;CPP-KKT&#65289;&#65307;&#65288;2&#65289;&#20351;&#29992;&#28151;&#21512;&#25972;&#25968;&#35268;&#21010;&#65288;CPP-MIP&#65289;&#26469;&#21576;&#29616;CPP&#30340;&#20004;&#31181;&#26131;&#20110;&#22788;&#29702;&#30340;&#25913;&#36827;&#12290;CPP&#20855;&#22791;&#23545;CCO&#38382;&#39064;&#36827;&#34892;&#36793;&#38469;&#27010;&#29575;&#21487;&#34892;&#24615;&#20445;&#35777;&#65292;&#36825;&#19982;&#29616;&#26377;&#26041;&#27861;&#65288;&#20363;&#22914;&#26679;&#26412;&#36924;&#36817;&#21644;&#22330;&#26223;&#26041;&#27861;&#65289;&#22312;&#27010;&#24565;&#19978;&#26377;&#25152;&#19981;&#21516;&#12290;&#23613;&#31649;&#25105;&#20204;&#25506;&#35752;&#20102;&#19982;&#26679;&#26412;&#36924;&#36817;&#26041;&#27861;&#30340;&#31639;&#27861;&#30456;&#20284;&#20043;&#22788;&#65292;&#20294;&#25105;&#20204;&#24378;&#35843;CPP&#30340;&#20248;&#21183;&#22312;&#20110;&#26131;&#20110;&#25193;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;
Motivated by the advances in conformal prediction (CP), we propose conformal predictive programming (CPP), an approach to solve chance constrained optimization (CCO) problems, i.e., optimization problems with nonlinear constraint functions affected by arbitrary random parameters. CPP utilizes samples from these random parameters along with the quantile lemma -- which is central to CP -- to transform the CCO problem into a deterministic optimization problem. We then present two tractable reformulations of CPP by: (1) writing the quantile as a linear program along with its KKT conditions (CPP-KKT), and (2) using mixed integer programming (CPP-MIP). CPP comes with marginal probabilistic feasibility guarantees for the CCO problem that are conceptually different from existing approaches, e.g., the sample approximation and the scenario approach. While we explore algorithmic similarities with the sample approximation approach, we emphasize that the strength of CPP is that it can easily be ext
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#40065;&#26834;&#24615;&#36801;&#31227;&#23398;&#20064;&#26041;&#27861;TAB&#27169;&#22411;&#65292;&#36890;&#36807;&#34913;&#37327;&#30446;&#26631;&#19982;&#28304;&#22238;&#24402;&#20989;&#25968;&#20043;&#38388;&#30340;&#27169;&#31946;&#24230;&#27700;&#24179;&#26469;&#25913;&#21892;&#20998;&#31867;&#20219;&#21153;&#65292;&#24182;&#36991;&#20813;&#36127;&#36801;&#31227;&#12290;&#36890;&#36807;&#23454;&#39564;&#39564;&#35777;&#65292;TAB&#27169;&#22411;&#22312;&#38750;&#21442;&#25968;&#20998;&#31867;&#21644;&#36923;&#36753;&#22238;&#24402;&#20219;&#21153;&#19978;&#34920;&#29616;&#20986;&#20102;&#20248;&#36234;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.04606</link><description>&lt;p&gt;
&#20855;&#26377;&#19981;&#21487;&#38752;&#28304;&#25968;&#25454;&#30340;&#40065;&#26834;&#24615;&#36801;&#31227;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Robust Transfer Learning with Unreliable Source Data. (arXiv:2310.04606v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.04606
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#40065;&#26834;&#24615;&#36801;&#31227;&#23398;&#20064;&#26041;&#27861;TAB&#27169;&#22411;&#65292;&#36890;&#36807;&#34913;&#37327;&#30446;&#26631;&#19982;&#28304;&#22238;&#24402;&#20989;&#25968;&#20043;&#38388;&#30340;&#27169;&#31946;&#24230;&#27700;&#24179;&#26469;&#25913;&#21892;&#20998;&#31867;&#20219;&#21153;&#65292;&#24182;&#36991;&#20813;&#36127;&#36801;&#31227;&#12290;&#36890;&#36807;&#23454;&#39564;&#39564;&#35777;&#65292;TAB&#27169;&#22411;&#22312;&#38750;&#21442;&#25968;&#20998;&#31867;&#21644;&#36923;&#36753;&#22238;&#24402;&#20219;&#21153;&#19978;&#34920;&#29616;&#20986;&#20102;&#20248;&#36234;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#40065;&#26834;&#24615;&#36801;&#31227;&#23398;&#20064;&#20013;&#30340;&#36125;&#21494;&#26031;&#20998;&#31867;&#22120;&#30340;&#27169;&#31946;&#24615;&#21644;&#30446;&#26631;&#19982;&#28304;&#20998;&#24067;&#20043;&#38388;&#30340;&#24369;&#21487;&#36716;&#31227;&#20449;&#21495;&#25152;&#24102;&#26469;&#30340;&#25361;&#25112;&#36827;&#34892;&#20102;&#30740;&#31350;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#37327;&#65292;&#31216;&#20026;&#8220;&#27169;&#31946;&#24230;&#27700;&#24179;&#8221;&#65292;&#29992;&#20110;&#34913;&#37327;&#30446;&#26631;&#19982;&#28304;&#22238;&#24402;&#20989;&#25968;&#20043;&#38388;&#30340;&#24046;&#24322;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#36801;&#31227;&#23398;&#20064;&#26041;&#27861;&#65292;&#24182;&#24314;&#31435;&#20102;&#19968;&#20010;&#19968;&#33324;&#23450;&#29702;&#65292;&#35828;&#26126;&#20102;&#36825;&#20010;&#26032;&#37327;&#19982;&#23398;&#20064;&#30340;&#36801;&#31227;&#24615;&#22312;&#39118;&#38505;&#25913;&#21892;&#26041;&#38754;&#30340;&#20851;&#31995;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#8220;&#36793;&#30028;&#21608;&#22260;&#36716;&#31227;&#8221;(Transfer Around Boundary, TAB)&#27169;&#22411;&#36890;&#36807;&#22312;&#30446;&#26631;&#25968;&#25454;&#21644;&#28304;&#25968;&#25454;&#24615;&#33021;&#20043;&#38388;&#36827;&#34892;&#24179;&#34913;&#30340;&#38408;&#20540;&#65292;&#26082;&#39640;&#25928;&#21448;&#40065;&#26834;&#65292;&#33021;&#22815;&#25913;&#21892;&#20998;&#31867;&#24182;&#36991;&#20813;&#36127;&#36801;&#31227;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;TAB&#27169;&#22411;&#22312;&#38750;&#21442;&#25968;&#20998;&#31867;&#21644;&#36923;&#36753;&#22238;&#24402;&#20219;&#21153;&#19978;&#30340;&#26377;&#25928;&#24615;&#65292;&#36798;&#21040;&#20102;&#26368;&#20248;&#30340;&#19978;&#30028;&#65292;&#21482;&#26377;&#23545;&#25968;&#22240;&#23376;&#30340;&#24046;&#36317;&#12290;&#36890;&#36807;&#20223;&#30495;&#30740;&#31350;&#36827;&#19968;&#27493;&#25903;&#25345;&#20102;TAB&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper addresses challenges in robust transfer learning stemming from ambiguity in Bayes classifiers and weak transferable signals between the target and source distribution. We introduce a novel quantity called the ''ambiguity level'' that measures the discrepancy between the target and source regression functions, propose a simple transfer learning procedure, and establish a general theorem that shows how this new quantity is related to the transferability of learning in terms of risk improvements. Our proposed ''Transfer Around Boundary'' (TAB) model, with a threshold balancing the performance of target and source data, is shown to be both efficient and robust, improving classification while avoiding negative transfer. Moreover, we demonstrate the effectiveness of the TAB model on non-parametric classification and logistic regression tasks, achieving upper bounds which are optimal up to logarithmic factors. Simulation studies lend further support to the effectiveness of TAB. We 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25968;&#25454;&#30340;&#29305;&#24449;&#21521;&#37327;&#30340;&#20808;&#39564;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#38750;&#31232;&#30095;&#36229;&#21442;&#25968;&#32447;&#24615;&#27169;&#22411;&#12290;&#20174;&#23548;&#20986;&#30340;&#21518;&#39564;&#20998;&#24067;&#25910;&#32553;&#29575;&#21644;&#24320;&#21457;&#30340;&#25130;&#26029;&#39640;&#26031;&#36817;&#20284;&#20004;&#20010;&#26041;&#38754;&#26469;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#21487;&#20197;&#35299;&#20915;&#20043;&#21069;&#30340;&#20808;&#39564;&#31232;&#30095;&#24615;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2305.15754</link><description>&lt;p&gt;
&#38750;&#31232;&#30095;&#36229;&#21442;&#25968;&#32447;&#24615;&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Bayesian Analysis for Over-parameterized Linear Model without Sparsity. (arXiv:2305.15754v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15754
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25968;&#25454;&#30340;&#29305;&#24449;&#21521;&#37327;&#30340;&#20808;&#39564;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#38750;&#31232;&#30095;&#36229;&#21442;&#25968;&#32447;&#24615;&#27169;&#22411;&#12290;&#20174;&#23548;&#20986;&#30340;&#21518;&#39564;&#20998;&#24067;&#25910;&#32553;&#29575;&#21644;&#24320;&#21457;&#30340;&#25130;&#26029;&#39640;&#26031;&#36817;&#20284;&#20004;&#20010;&#26041;&#38754;&#26469;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#21487;&#20197;&#35299;&#20915;&#20043;&#21069;&#30340;&#20808;&#39564;&#31232;&#30095;&#24615;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#39640;&#32500;&#36125;&#21494;&#26031;&#32479;&#35745;&#23398;&#20013;&#65292;&#21457;&#23637;&#20102;&#35768;&#22810;&#26041;&#27861;&#65292;&#21253;&#25324;&#35768;&#22810;&#20808;&#39564;&#20998;&#24067;&#65292;&#23427;&#20204;&#23548;&#33268;&#20272;&#35745;&#21442;&#25968;&#30340;&#31232;&#30095;&#24615;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#20808;&#39564;&#22312;&#22788;&#29702;&#25968;&#25454;&#30340;&#35889;&#29305;&#24449;&#21521;&#37327;&#32467;&#26500;&#26041;&#38754;&#26377;&#23616;&#38480;&#24615;&#65292;&#22240;&#27492;&#19981;&#36866;&#29992;&#20110;&#20998;&#26512;&#26368;&#36817;&#21457;&#23637;&#30340;&#19981;&#20551;&#35774;&#31232;&#30095;&#24615;&#30340;&#39640;&#32500;&#32447;&#24615;&#27169;&#22411;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36125;&#21494;&#26031;&#26041;&#27861;&#65292;&#23427;&#20351;&#29992;&#19968;&#20010;&#20381;&#36182;&#20110;&#25968;&#25454;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#29305;&#24449;&#21521;&#37327;&#30340;&#20808;&#39564;&#65292;&#20294;&#19981;&#20250;&#24341;&#36215;&#21442;&#25968;&#30340;&#31232;&#30095;&#24615;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#23548;&#20986;&#30340;&#21518;&#39564;&#20998;&#24067;&#30340;&#25910;&#32553;&#29575;&#65292;&#24182;&#24320;&#21457;&#20102;&#21518;&#39564;&#20998;&#24067;&#30340;&#25130;&#26029;&#39640;&#26031;&#36817;&#20284;&#12290;&#21069;&#32773;&#35777;&#26126;&#20102;&#21518;&#39564;&#20272;&#35745;&#30340;&#25928;&#29575;&#65292;&#32780;&#21518;&#32773;&#21017;&#20351;&#29992;Bernstein-von Mises&#31867;&#22411;&#26041;&#27861;&#26469;&#37327;&#21270;&#21442;&#25968;&#19981;&#30830;&#23450;&#24615;&#12290;&#36825;&#20123;&#32467;&#26524;&#34920;&#26126;&#65292;&#20219;&#20309;&#33021;&#22815;&#22788;&#29702;&#35889;&#29305;&#24449;&#21521;&#37327;&#30340;&#36125;&#21494;&#26031;&#26041;&#27861;&#65292;&#37117;&#21487;&#20197;&#29992;&#20110;&#38750;&#31232;&#30095;&#36229;&#21442;&#25968;&#32447;&#24615;&#27169;&#22411;&#20998;&#26512;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#20808;&#21069;&#30340;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
In high-dimensional Bayesian statistics, several methods have been developed, including many prior distributions that lead to the sparsity of estimated parameters. However, such priors have limitations in handling the spectral eigenvector structure of data, and as a result, they are ill-suited for analyzing over-parameterized models (high-dimensional linear models that do not assume sparsity) that have been developed in recent years. This paper introduces a Bayesian approach that uses a prior dependent on the eigenvectors of data covariance matrices, but does not induce the sparsity of parameters. We also provide contraction rates of derived posterior distributions and develop a truncated Gaussian approximation of the posterior distribution. The former demonstrates the efficiency of posterior estimation, while the latter enables quantification of parameter uncertainty using a Bernstein-von Mises-type approach. These results indicate that any Bayesian method that can handle the spectrum
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#30340;&#24494;&#27491;&#21017; Langevin Monte Carlo &#26041;&#27861;&#33021;&#22815;&#39640;&#25928;&#22320;&#37319;&#26679; $\exp[-S(\x)]$ &#20998;&#24067;&#65292;&#21516;&#26102;&#20855;&#26377;&#26080;&#20559;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.18221</link><description>&lt;p&gt;
&#24494;&#27491;&#21017; Langevin Monte Carlo
&lt;/p&gt;
&lt;p&gt;
Microcanonical Langevin Monte Carlo. (arXiv:2303.18221v1 [hep-lat])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.18221
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#30340;&#24494;&#27491;&#21017; Langevin Monte Carlo &#26041;&#27861;&#33021;&#22815;&#39640;&#25928;&#22320;&#37319;&#26679; $\exp[-S(\x)]$ &#20998;&#24067;&#65292;&#21516;&#26102;&#20855;&#26377;&#26080;&#20559;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#29992;&#20110;&#20197;&#21487;&#29992;&#28176;&#21464; $ \nabla S(\x)$ &#30340;&#24418;&#24335;&#37319;&#26679;&#33258;&#19968;&#20219;&#24847;&#20998;&#24067; $ \exp[-S(\x)]$&#65292;&#35813;&#26041;&#27861;&#34987;&#21046;&#23450;&#20026;&#20445;&#25345;&#33021;&#37327;&#30340;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#65288;SDE&#65289;&#12290;&#25105;&#20204;&#25512;&#23548;&#20986; Fokker-Planck &#26041;&#31243;&#65292;&#24182;&#35777;&#26126;&#30830;&#23450;&#24615;&#28418;&#31227;&#21644;&#38543;&#26426;&#25193;&#25955;&#20998;&#21035;&#20445;&#25345;&#24179;&#31283;&#20998;&#24067;&#12290;&#36825;&#24847;&#21619;&#30528;&#28418;&#31227;&#25193;&#25955;&#31163;&#25955;&#21270;&#26041;&#26696;&#26080;&#20559;&#65292;&#32780;&#26631;&#20934; Langevin &#21160;&#21147;&#23398;&#21017;&#19981;&#26159;&#12290;&#25105;&#20204;&#23558;&#35813;&#26041;&#27861;&#24212;&#29992;&#20110; $\phi^4$ &#26230;&#26684;&#22330;&#35770;&#65292;&#23637;&#31034;&#20102;&#32467;&#26524;&#19982;&#26631;&#20934;&#37319;&#26679;&#26041;&#27861;&#19968;&#33268;&#65292;&#20294;&#27604;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#37319;&#26679;&#22120;&#25928;&#29575;&#26174;&#33879;&#25552;&#39640;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a method for sampling from an arbitrary distribution $\exp[-S(\x)]$ with an available gradient $\nabla S(\x)$, formulated as an energy-preserving stochastic differential equation (SDE). We derive the Fokker-Planck equation and show that both the deterministic drift and the stochastic diffusion separately preserve the stationary distribution. This implies that the drift-diffusion discretization schemes are bias-free, in contrast to the standard Langevin dynamics. We apply the method to the $\phi^4$ lattice field theory, showing the results agree with the standard sampling methods but with significantly higher efficiency compared to the current state-of-the-art samplers.
&lt;/p&gt;</description></item></channel></rss>