<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#24471;&#20998;&#21305;&#37197;&#23454;&#29616;&#26368;&#20339;&#20984;$M$-&#20272;&#35745;&#30340;&#26041;&#27861;&#65292;&#22312;&#32447;&#24615;&#22238;&#24402;&#20013;&#33021;&#22815;&#36798;&#21040;&#26368;&#20339;&#30340;&#28176;&#36817;&#26041;&#24046;&#65292;&#24182;&#19988;&#22312;&#35745;&#31639;&#19978;&#39640;&#25928;&#65292;&#35777;&#26126;&#20855;&#26377;&#25152;&#26377;&#20984;$M$-&#20272;&#35745;&#20013;&#26368;&#23567;&#30340;&#28176;&#36817;&#21327;&#26041;&#24046;&#12290;</title><link>https://arxiv.org/abs/2403.16688</link><description>&lt;p&gt;
&#36890;&#36807;&#24471;&#20998;&#21305;&#37197;&#23454;&#29616;&#26368;&#20339;&#20984;$M$-&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Optimal convex $M$-estimation via score matching
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.16688
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#24471;&#20998;&#21305;&#37197;&#23454;&#29616;&#26368;&#20339;&#20984;$M$-&#20272;&#35745;&#30340;&#26041;&#27861;&#65292;&#22312;&#32447;&#24615;&#22238;&#24402;&#20013;&#33021;&#22815;&#36798;&#21040;&#26368;&#20339;&#30340;&#28176;&#36817;&#26041;&#24046;&#65292;&#24182;&#19988;&#22312;&#35745;&#31639;&#19978;&#39640;&#25928;&#65292;&#35777;&#26126;&#20855;&#26377;&#25152;&#26377;&#20984;$M$-&#20272;&#35745;&#20013;&#26368;&#23567;&#30340;&#28176;&#36817;&#21327;&#26041;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32447;&#24615;&#22238;&#24402;&#30340;&#32972;&#26223;&#19979;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#25968;&#25454;&#39537;&#21160;&#30340;&#20984;&#25439;&#22833;&#20989;&#25968;&#65292;&#36890;&#36807;&#35813;&#20989;&#25968;&#36827;&#34892;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#21487;&#20197;&#22312;&#22238;&#24402;&#31995;&#25968;&#30340;&#19979;&#28216;&#20272;&#35745;&#20013;&#23454;&#29616;&#26368;&#20339;&#30340;&#28176;&#36817;&#26041;&#24046;&#12290;&#25105;&#20204;&#30340;&#21322;&#21442;&#25968;&#26041;&#27861;&#26088;&#22312;&#26368;&#20339;&#36924;&#36817;&#22122;&#22768;&#20998;&#24067;&#23545;&#25968;&#23494;&#24230;&#30340;&#23548;&#25968;&#12290;&#22312;&#24635;&#20307;&#23618;&#38754;&#19978;&#65292;&#36825;&#20010;&#25311;&#21512;&#36807;&#31243;&#26159;&#23545;&#24471;&#20998;&#21305;&#37197;&#30340;&#38750;&#21442;&#25968;&#25299;&#23637;&#65292;&#23545;&#24212;&#20110;&#26681;&#25454;Fisher&#25955;&#24230;&#36827;&#34892;&#22122;&#22768;&#20998;&#24067;&#30340;&#23545;&#25968;&#20985;&#26144;&#23556;&#12290;&#35813;&#36807;&#31243;&#22312;&#35745;&#31639;&#19978;&#26159;&#39640;&#25928;&#30340;&#65292;&#25105;&#20204;&#35777;&#26126;&#25105;&#20204;&#30340;&#31243;&#24207;&#36798;&#21040;&#20102;&#25152;&#26377;&#20984;$M$-&#20272;&#35745;&#20013;&#26368;&#23567;&#30340;&#28176;&#36817;&#21327;&#26041;&#24046;&#12290;&#20316;&#20026;&#38750;&#23545;&#25968;&#20985;&#35774;&#32622;&#30340;&#19968;&#20010;&#20363;&#23376;&#65292;&#23545;&#20110;&#26607;&#35199;&#35823;&#24046;&#65292;&#26368;&#20339;&#20984;&#25439;&#22833;&#20989;&#25968;&#31867;&#20284;&#20110;Huber&#20989;&#25968;&#65292;&#24182;&#19988;&#25105;&#20204;&#30340;&#36807;&#31243;&#30456;&#23545;&#20110;oracle&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#22120;&#23454;&#29616;&#20102;&#22823;&#20110;0.87&#30340;&#28176;&#36817;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.16688v1 Announce Type: cross  Abstract: In the context of linear regression, we construct a data-driven convex loss function with respect to which empirical risk minimisation yields optimal asymptotic variance in the downstream estimation of the regression coefficients. Our semiparametric approach targets the best decreasing approximation of the derivative of the log-density of the noise distribution. At the population level, this fitting process is a nonparametric extension of score matching, corresponding to a log-concave projection of the noise distribution with respect to the Fisher divergence. The procedure is computationally efficient, and we prove that our procedure attains the minimal asymptotic covariance among all convex $M$-estimators. As an example of a non-log-concave setting, for Cauchy errors, the optimal convex loss function is Huber-like, and our procedure yields an asymptotic efficiency greater than 0.87 relative to the oracle maximum likelihood estimator o
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#24191;&#20041;&#26368;&#20339;&#21452;&#36194;&#32447;&#24615;&#32972;&#26223;&#24378;&#21270;&#22411;&#36172;&#21338;&#26426;&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#27425;&#20248;&#24615;&#24046;&#36317;&#21463;&#21040;&#19979;&#30028;&#38480;&#21046;&#26102;&#36951;&#25022;&#20026;$O(\log(T))$&#12290;&#21516;&#26102;&#24341;&#20837;&#20102;&#36793;&#32536;&#26465;&#20214;&#26469;&#25551;&#36848;&#27425;&#20248;&#24615;&#24046;&#36317;&#23545;&#38382;&#39064;&#38590;&#24230;&#30340;&#24433;&#21709;&#12290;</title><link>https://arxiv.org/abs/2403.03219</link><description>&lt;p&gt;
LC-Tsalis-INF: &#24191;&#20041;&#26368;&#20339;&#21452;&#36194;&#32447;&#24615;&#32972;&#26223;&#24378;&#21270;&#22411;&#36172;&#21338;&#26426;
&lt;/p&gt;
&lt;p&gt;
LC-Tsalis-INF: Generalized Best-of-Both-Worlds Linear Contextual Bandits
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03219
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#24191;&#20041;&#26368;&#20339;&#21452;&#36194;&#32447;&#24615;&#32972;&#26223;&#24378;&#21270;&#22411;&#36172;&#21338;&#26426;&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#27425;&#20248;&#24615;&#24046;&#36317;&#21463;&#21040;&#19979;&#30028;&#38480;&#21046;&#26102;&#36951;&#25022;&#20026;$O(\log(T))$&#12290;&#21516;&#26102;&#24341;&#20837;&#20102;&#36793;&#32536;&#26465;&#20214;&#26469;&#25551;&#36848;&#27425;&#20248;&#24615;&#24046;&#36317;&#23545;&#38382;&#39064;&#38590;&#24230;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#32771;&#34385;&#20855;&#26377;&#29420;&#31435;&#21516;&#20998;&#24067;&#65288;i.i.d.&#65289;&#32972;&#26223;&#30340;&#32447;&#24615;&#32972;&#26223;&#24378;&#21270;&#22411;&#36172;&#21338;&#26426;&#38382;&#39064;&#12290;&#22312;&#36825;&#20010;&#38382;&#39064;&#20013;&#65292;&#29616;&#26377;&#30740;&#31350;&#25552;&#20986;&#20102;&#26368;&#20339;&#21452;&#36194;&#65288;BoBW&#65289;&#31639;&#27861;&#65292;&#20854;&#36951;&#25022;&#22312;&#38543;&#26426;&#21306;&#22495;&#20013;&#28385;&#36275;$O(\log^2(T))$&#65292;&#20854;&#20013;$T$&#20026;&#22238;&#21512;&#25968;&#65292;&#20854;&#27425;&#20248;&#24615;&#24046;&#36317;&#30001;&#27491;&#24120;&#25968;&#19979;&#30028;&#65292;&#21516;&#26102;&#22312;&#23545;&#25239;&#24615;&#21306;&#22495;&#20013;&#28385;&#36275;$O(\sqrt{T})$&#12290;&#28982;&#32780;&#65292;&#23545;$T$&#30340;&#20381;&#36182;&#20173;&#26377;&#25913;&#36827;&#31354;&#38388;&#65292;&#24182;&#19988;&#27425;&#20248;&#24615;&#24046;&#36317;&#30340;&#20551;&#35774;&#21487;&#20197;&#25918;&#23485;&#12290;&#38024;&#23545;&#36825;&#20010;&#38382;&#39064;&#65292;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#31639;&#27861;&#65292;&#24403;&#27425;&#20248;&#24615;&#24046;&#36317;&#21463;&#21040;&#19979;&#30028;&#38480;&#21046;&#26102;&#65292;&#20854;&#36951;&#25022;&#28385;&#36275;$O(\log(T))$&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#36793;&#32536;&#26465;&#20214;&#65292;&#21363;&#23545;&#27425;&#20248;&#24615;&#24046;&#36317;&#30340;&#19968;&#20010;&#26356;&#28201;&#21644;&#30340;&#20551;&#35774;&#12290;&#35813;&#26465;&#20214;&#20351;&#29992;&#21442;&#25968;$\beta \in (0, \infty]$&#34920;&#24449;&#19982;&#27425;&#20248;&#24615;&#24046;&#36317;&#30456;&#20851;&#30340;&#38382;&#39064;&#38590;&#24230;&#12290;&#28982;&#21518;&#25105;&#20204;&#35777;&#26126;&#35813;&#31639;&#27861;&#30340;&#36951;&#25022;&#28385;&#36275;$O\left(\
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03219v1 Announce Type: new  Abstract: This study considers the linear contextual bandit problem with independent and identically distributed (i.i.d.) contexts. In this problem, existing studies have proposed Best-of-Both-Worlds (BoBW) algorithms whose regrets satisfy $O(\log^2(T))$ for the number of rounds $T$ in a stochastic regime with a suboptimality gap lower-bounded by a positive constant, while satisfying $O(\sqrt{T})$ in an adversarial regime. However, the dependency on $T$ has room for improvement, and the suboptimality-gap assumption can be relaxed. For this issue, this study proposes an algorithm whose regret satisfies $O(\log(T))$ in the setting when the suboptimality gap is lower-bounded. Furthermore, we introduce a margin condition, a milder assumption on the suboptimality gap. That condition characterizes the problem difficulty linked to the suboptimality gap using a parameter $\beta \in (0, \infty]$. We then show that the algorithm's regret satisfies $O\left(\
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24046;&#20998;&#38544;&#31169;&#26426;&#21046;"Cluster-DP"&#65292;&#23427;&#22312;&#20445;&#35777;&#38544;&#31169;&#30340;&#21516;&#26102;&#21033;&#29992;&#25968;&#25454;&#30340;&#32858;&#31867;&#32467;&#26500;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#26356;&#24378;&#30340;&#38544;&#31169;&#20445;&#35777;&#21644;&#36739;&#20302;&#30340;&#26041;&#24046;&#65292;&#21487;&#20197;&#29992;&#20110;&#36827;&#34892;&#22240;&#26524;&#20998;&#26512;&#12290;</title><link>http://arxiv.org/abs/2308.00957</link><description>&lt;p&gt;
&#20855;&#26377;&#24046;&#20998;&#38544;&#31169;(&#20998;&#32452;)&#32467;&#26524;&#30340;&#22240;&#26524;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Causal Inference with Differentially Private (Clustered) Outcomes. (arXiv:2308.00957v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.00957
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24046;&#20998;&#38544;&#31169;&#26426;&#21046;"Cluster-DP"&#65292;&#23427;&#22312;&#20445;&#35777;&#38544;&#31169;&#30340;&#21516;&#26102;&#21033;&#29992;&#25968;&#25454;&#30340;&#32858;&#31867;&#32467;&#26500;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#26356;&#24378;&#30340;&#38544;&#31169;&#20445;&#35777;&#21644;&#36739;&#20302;&#30340;&#26041;&#24046;&#65292;&#21487;&#20197;&#29992;&#20110;&#36827;&#34892;&#22240;&#26524;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#38543;&#26426;&#23454;&#39564;&#20013;&#20272;&#35745;&#22240;&#26524;&#25928;&#24212;&#21482;&#26377;&#22312;&#21442;&#19982;&#32773;&#21516;&#24847;&#36879;&#38706;&#20182;&#20204;&#21487;&#33021;&#25935;&#24863;&#30340;&#21709;&#24212;&#26102;&#25165;&#21487;&#34892;&#12290;&#22312;&#30830;&#20445;&#38544;&#31169;&#30340;&#35768;&#22810;&#26041;&#27861;&#20013;&#65292;&#26631;&#31614;&#24046;&#20998;&#38544;&#31169;&#26159;&#19968;&#31181;&#24191;&#27867;&#20351;&#29992;&#30340;&#31639;&#27861;&#38544;&#31169;&#20445;&#35777;&#24230;&#37327;&#65292;&#21487;&#20197;&#40723;&#21169;&#21442;&#19982;&#32773;&#20998;&#20139;&#21709;&#24212;&#32780;&#19981;&#20250;&#38754;&#20020;&#21435;&#21311;&#21517;&#21270;&#30340;&#39118;&#38505;&#12290;&#35768;&#22810;&#24046;&#20998;&#38544;&#31169;&#26426;&#21046;&#20250;&#21521;&#21407;&#22987;&#25968;&#25454;&#38598;&#20013;&#27880;&#20837;&#22122;&#38899;&#26469;&#23454;&#29616;&#36825;&#31181;&#38544;&#31169;&#20445;&#35777;&#65292;&#36825;&#20250;&#22686;&#21152;&#22823;&#22810;&#25968;&#32479;&#35745;&#20272;&#35745;&#37327;&#30340;&#26041;&#24046;&#65292;&#20351;&#24471;&#31934;&#30830;&#27979;&#37327;&#22240;&#26524;&#25928;&#24212;&#21464;&#24471;&#22256;&#38590;&#65306;&#20174;&#24046;&#20998;&#38544;&#31169;&#25968;&#25454;&#36827;&#34892;&#22240;&#26524;&#20998;&#26512;&#23384;&#22312;&#30528;&#22266;&#26377;&#30340;&#38544;&#31169;-&#26041;&#24046;&#26435;&#34913;&#12290;&#20026;&#20102;&#23454;&#29616;&#26356;&#24378;&#38544;&#31169;&#20445;&#35777;&#30340;&#36739;&#20302;&#26041;&#24046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24046;&#20998;&#38544;&#31169;&#26426;&#21046;"Cluster-DP"&#65292;&#23427;&#21033;&#29992;&#25968;&#25454;&#30340;&#20219;&#20309;&#32473;&#23450;&#30340;&#32858;&#31867;&#32467;&#26500;&#65292;&#21516;&#26102;&#20173;&#28982;&#20801;&#35768;&#23545;&#22240;&#26524;&#25928;&#24212;&#36827;&#34892;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
Estimating causal effects from randomized experiments is only feasible if participants agree to reveal their potentially sensitive responses. Of the many ways of ensuring privacy, label differential privacy is a widely used measure of an algorithm's privacy guarantee, which might encourage participants to share responses without running the risk of de-anonymization. Many differentially private mechanisms inject noise into the original data-set to achieve this privacy guarantee, which increases the variance of most statistical estimators and makes the precise measurement of causal effects difficult: there exists a fundamental privacy-variance trade-off to performing causal analyses from differentially private data. With the aim of achieving lower variance for stronger privacy guarantees, we suggest a new differential privacy mechanism, "Cluster-DP", which leverages any given cluster structure of the data while still allowing for the estimation of causal effects. We show that, depending 
&lt;/p&gt;</description></item></channel></rss>