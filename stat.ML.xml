<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#35813;&#35770;&#25991;&#20998;&#26512;&#20102;&#20998;&#24067;&#24335;&#26102;&#38388;&#24046;&#20998;&#30340;&#32479;&#35745;&#25928;&#29575;&#21644;&#26377;&#38480;&#26679;&#26412;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2403.05811</link><description>&lt;p&gt;
&#20998;&#24067;&#24335;&#26102;&#38388;&#24046;&#20998;&#30340;&#32479;&#35745;&#25928;&#29575;
&lt;/p&gt;
&lt;p&gt;
Statistical Efficiency of Distributional Temporal Difference
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.05811
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20998;&#26512;&#20102;&#20998;&#24067;&#24335;&#26102;&#38388;&#24046;&#20998;&#30340;&#32479;&#35745;&#25928;&#29575;&#21644;&#26377;&#38480;&#26679;&#26412;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;(DRL)&#20851;&#27880;&#30340;&#26159;&#36820;&#22238;&#30340;&#23436;&#25972;&#20998;&#24067;&#65292;&#32780;&#19981;&#20165;&#20165;&#26159;&#22343;&#20540;&#65292;&#22312;&#21508;&#20010;&#39046;&#22495;&#21462;&#24471;&#20102;&#32463;&#39564;&#25104;&#21151;&#12290;&#39046;&#22495;DRL&#20013;&#30340;&#26680;&#24515;&#20219;&#21153;&#20043;&#19968;&#26159;&#20998;&#24067;&#24335;&#31574;&#30053;&#35780;&#20272;&#65292;&#28041;&#21450;&#20272;&#35745;&#32473;&#23450;&#31574;&#30053;pi&#30340;&#36820;&#22238;&#20998;&#24067;&#951;^pi&#12290;&#30456;&#24212;&#22320;&#25552;&#20986;&#20102;&#20998;&#24067;&#26102;&#38388;&#24046;&#20998;(TD)&#31639;&#27861;&#65292;&#36825;&#26159;&#32463;&#20856;RL&#25991;&#29486;&#20013;&#26102;&#38388;&#24046;&#20998;&#31639;&#27861;&#30340;&#24310;&#20280;&#12290;&#22312;&#34920;&#26684;&#26696;&#20363;&#20013;&#65292;citet{rowland2018analysis}&#21644;citet{rowland2023analysis}&#20998;&#21035;&#35777;&#26126;&#20102;&#20004;&#20010;&#20998;&#24067;&#24335;TD&#23454;&#20363;&#21363;&#20998;&#31867;&#26102;&#38388;&#24046;&#20998;&#31639;&#27861;(CTD)&#21644;&#20998;&#20301;&#25968;&#26102;&#38388;&#24046;&#20998;&#31639;&#27861;(QTD)&#30340;&#28176;&#36817;&#25910;&#25947;&#12290;&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#20998;&#26512;&#20102;&#20998;&#24067;&#24335;TD&#30340;&#26377;&#38480;&#26679;&#26412;&#24615;&#33021;&#12290;&#20026;&#20102;&#20419;&#36827;&#29702;&#35770;&#20998;&#26512;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#38750;&#21442;&#25968;&#30340; dis
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.05811v1 Announce Type: cross  Abstract: Distributional reinforcement learning (DRL), which cares about the full distribution of returns instead of just the mean, has achieved empirical success in various domains. One of the core tasks in the field of DRL is distributional policy evaluation, which involves estimating the return distribution $\eta^\pi$ for a given policy $\pi$. A distributional temporal difference (TD) algorithm has been accordingly proposed, which is an extension of the temporal difference algorithm in the classic RL literature. In the tabular case, \citet{rowland2018analysis} and \citet{rowland2023analysis} proved the asymptotic convergence of two instances of distributional TD, namely categorical temporal difference algorithm (CTD) and quantile temporal difference algorithm (QTD), respectively. In this paper, we go a step further and analyze the finite-sample performance of distributional TD. To facilitate theoretical analysis, we propose non-parametric dis
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#20351;&#29992;Moreau&#21253;&#32476;&#26469;&#23545;&#27979;&#24230;f-&#24046;&#24322;&#36827;&#34892;&#27491;&#21017;&#21270;&#30340;&#26041;&#27861;&#65292;&#24182;&#21033;&#29992;&#35813;&#26041;&#27861;&#20998;&#26512;&#20102;Wasserstein&#26799;&#24230;&#27969;&#12290;</title><link>https://arxiv.org/abs/2402.04613</link><description>&lt;p&gt;
&#22312;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#30340;Moreau&#21253;&#32476;&#30340;f-&#24046;&#24322;&#30340;Wasserstein&#26799;&#24230;&#27969;
&lt;/p&gt;
&lt;p&gt;
Wasserstein Gradient Flows for Moreau Envelopes of f-Divergences in Reproducing Kernel Hilbert Spaces
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04613
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#20351;&#29992;Moreau&#21253;&#32476;&#26469;&#23545;&#27979;&#24230;f-&#24046;&#24322;&#36827;&#34892;&#27491;&#21017;&#21270;&#30340;&#26041;&#27861;&#65292;&#24182;&#21033;&#29992;&#35813;&#26041;&#27861;&#20998;&#26512;&#20102;Wasserstein&#26799;&#24230;&#27969;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22810;&#25968;&#24120;&#29992;&#30340;&#27979;&#24230;f-&#24046;&#24322;&#65292;&#20363;&#22914;Kullback-Leibler&#24046;&#24322;&#65292;&#23545;&#20110;&#25152;&#28041;&#21450;&#30340;&#27979;&#24230;&#30340;&#25903;&#25345;&#23384;&#22312;&#38480;&#21046;&#12290;&#35299;&#20915;&#21150;&#27861;&#26159;&#36890;&#36807;&#19982;&#29305;&#24449;&#26680;K&#30456;&#20851;&#30340;&#24179;&#26041;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;(MMD)&#23545;f-&#24046;&#24322;&#36827;&#34892;&#27491;&#21017;&#21270;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#25152;&#35859;&#30340;&#26680;&#22343;&#20540;&#23884;&#20837;&#26469;&#26174;&#31034;&#30456;&#24212;&#30340;&#27491;&#21017;&#21270;&#21487;&#20197;&#37325;&#20889;&#20026;&#19982;K&#30456;&#20851;&#30340;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#26576;&#20123;&#20989;&#25968;&#30340;Moreau&#21253;&#32476;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#21033;&#29992;&#20851;&#20110;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;Moreau&#21253;&#32476;&#30340;&#20247;&#25152;&#21608;&#30693;&#30340;&#32467;&#26524;&#26469;&#35777;&#26126;MMD&#27491;&#21017;&#21270;&#30340;f-&#24046;&#24322;&#21450;&#20854;&#26799;&#24230;&#30340;&#23646;&#24615;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#26469;&#20998;&#26512;&#21463;MMD&#27491;&#21017;&#21270;&#30340;f-&#24046;&#24322;&#30340;Wasserstein&#26799;&#24230;&#27969;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#32771;&#34385;&#20174;&#32463;&#39564;&#27979;&#24230;&#24320;&#22987;&#30340;Wasserstein&#26799;&#24230;&#27969;&#65292;&#24182;&#25552;&#20379;&#20351;&#29992;Tsallis-$\alpha$&#24046;&#24322;&#30340;&#27010;&#24565;&#24615;&#25968;&#20540;&#31034;&#20363;&#30340;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
Most commonly used $f$-divergences of measures, e.g., the Kullback-Leibler divergence, are subject to limitations regarding the support of the involved measures. A remedy consists of regularizing the $f$-divergence by a squared maximum mean discrepancy (MMD) associated with a characteristic kernel $K$. In this paper, we use the so-called kernel mean embedding to show that the corresponding regularization can be rewritten as the Moreau envelope of some function in the reproducing kernel Hilbert space associated with $K$. Then, we exploit well-known results on Moreau envelopes in Hilbert spaces to prove properties of the MMD-regularized $f$-divergences and, in particular, their gradients. Subsequently, we use our findings to analyze Wasserstein gradient flows of MMD-regularized $f$-divergences. Finally, we consider Wasserstein gradient flows starting from empirical measures and provide proof-of-the-concept numerical examples with Tsallis-$\alpha$ divergences.
&lt;/p&gt;</description></item></channel></rss>