<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#35813;&#30740;&#31350;&#30830;&#23450;&#20102;&#22312;&#28508;&#22312;&#38468;&#21152;&#22122;&#22768;&#27169;&#22411;&#32972;&#26223;&#19979;&#23548;&#33268;&#21487;&#35782;&#21035;&#24615;&#30340;&#20998;&#24067;&#21464;&#21270;&#31867;&#22411;&#30340;&#20805;&#20998;&#19988;&#24517;&#35201;&#26465;&#20214;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#24403;&#21482;&#26377;&#37096;&#20998;&#20998;&#24067;&#21464;&#21270;&#28385;&#36275;&#26465;&#20214;&#26102;&#30340;&#37096;&#20998;&#21487;&#35782;&#21035;&#24615;&#32467;&#26524;&#12290;</title><link>https://arxiv.org/abs/2403.15711</link><description>&lt;p&gt;
&#21487;&#35782;&#21035;&#30340;&#28508;&#22312;&#31070;&#32463;&#22240;&#26524;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Identifiable Latent Neural Causal Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.15711
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#30830;&#23450;&#20102;&#22312;&#28508;&#22312;&#38468;&#21152;&#22122;&#22768;&#27169;&#22411;&#32972;&#26223;&#19979;&#23548;&#33268;&#21487;&#35782;&#21035;&#24615;&#30340;&#20998;&#24067;&#21464;&#21270;&#31867;&#22411;&#30340;&#20805;&#20998;&#19988;&#24517;&#35201;&#26465;&#20214;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#24403;&#21482;&#26377;&#37096;&#20998;&#20998;&#24067;&#21464;&#21270;&#28385;&#36275;&#26465;&#20214;&#26102;&#30340;&#37096;&#20998;&#21487;&#35782;&#21035;&#24615;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#26524;&#34920;&#24449;&#23398;&#20064;&#26088;&#22312;&#20174;&#20302;&#32423;&#35266;&#27979;&#25968;&#25454;&#20013;&#25581;&#31034;&#28508;&#22312;&#30340;&#39640;&#32423;&#22240;&#26524;&#34920;&#24449;&#12290;&#23427;&#29305;&#21035;&#25797;&#38271;&#39044;&#27979;&#22312;&#26410;&#35265;&#20998;&#24067;&#21464;&#21270;&#19979;&#65292;&#22240;&#20026;&#36825;&#20123;&#21464;&#21270;&#36890;&#24120;&#21487;&#20197;&#35299;&#37322;&#20026;&#24178;&#39044;&#30340;&#21518;&#26524;&#12290;&#22240;&#27492;&#65292;&#21033;&#29992;{&#24050;&#35265;}&#20998;&#24067;&#21464;&#21270;&#25104;&#20026;&#24110;&#21161;&#35782;&#21035;&#22240;&#26524;&#34920;&#24449;&#30340;&#33258;&#28982;&#31574;&#30053;&#65292;&#36827;&#32780;&#26377;&#21161;&#20110;&#39044;&#27979;&#20197;&#21069;{&#26410;&#35265;}&#20998;&#24067;&#30340;&#24773;&#20917;&#12290;&#30830;&#23450;&#36825;&#20123;&#20998;&#24067;&#21464;&#21270;&#30340;&#31867;&#22411;&#65288;&#25110;&#26465;&#20214;&#65289;&#23545;&#20110;&#22240;&#26524;&#34920;&#24449;&#30340;&#21487;&#35782;&#21035;&#24615;&#33267;&#20851;&#37325;&#35201;&#12290;&#35813;&#24037;&#20316;&#24314;&#31435;&#20102;&#22312;&#28508;&#22312;&#38468;&#21152;&#22122;&#22768;&#27169;&#22411;&#32972;&#26223;&#19979;&#65292;&#34920;&#24449;&#23548;&#33268;&#21487;&#35782;&#21035;&#24615;&#30340;&#20998;&#24067;&#21464;&#21270;&#31867;&#22411;&#30340;&#20805;&#20998;&#19988;&#24517;&#35201;&#26465;&#20214;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#24403;&#21482;&#26377;&#37096;&#20998;&#20998;&#24067;&#21464;&#21270;&#28385;&#36275;&#26465;&#20214;&#26102;&#30340;&#37096;&#20998;&#21487;&#35782;&#21035;&#24615;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.15711v1 Announce Type: new  Abstract: Causal representation learning seeks to uncover latent, high-level causal representations from low-level observed data. It is particularly good at predictions under unseen distribution shifts, because these shifts can generally be interpreted as consequences of interventions. Hence leveraging {seen} distribution shifts becomes a natural strategy to help identifying causal representations, which in turn benefits predictions where distributions are previously {unseen}. Determining the types (or conditions) of such distribution shifts that do contribute to the identifiability of causal representations is critical. This work establishes a {sufficient} and {necessary} condition characterizing the types of distribution shifts for identifiability in the context of latent additive noise models. Furthermore, we present partial identifiability results when only a portion of distribution shifts meets the condition. In addition, we extend our findin
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#36716;&#31227;&#23398;&#20064;&#29615;&#22659;&#20013;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#23610;&#24230;&#34892;&#20026;&#65292;&#21457;&#29616;&#24494;&#35843;&#25968;&#25454;&#38598;&#30340;&#22823;&#23567;&#21644;&#39044;&#35757;&#32451;&#25968;&#25454;&#19982;&#19979;&#28216;&#25968;&#25454;&#30340;&#20998;&#24067;&#19968;&#33268;&#24615;&#23545;&#19979;&#28216;&#24615;&#33021;&#26377;&#26174;&#33879;&#24433;&#21709;&#12290;</title><link>https://arxiv.org/abs/2402.04177</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#19979;&#28216;&#20219;&#21153;&#24615;&#33021;&#30340;&#23610;&#24230;&#24459;
&lt;/p&gt;
&lt;p&gt;
Scaling Laws for Downstream Task Performance of Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04177
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#36716;&#31227;&#23398;&#20064;&#29615;&#22659;&#20013;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#23610;&#24230;&#34892;&#20026;&#65292;&#21457;&#29616;&#24494;&#35843;&#25968;&#25454;&#38598;&#30340;&#22823;&#23567;&#21644;&#39044;&#35757;&#32451;&#25968;&#25454;&#19982;&#19979;&#28216;&#25968;&#25454;&#30340;&#20998;&#24067;&#19968;&#33268;&#24615;&#23545;&#19979;&#28216;&#24615;&#33021;&#26377;&#26174;&#33879;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23610;&#24230;&#24459;&#25552;&#20379;&#20102;&#37325;&#35201;&#30340;&#35265;&#35299;&#65292;&#21487;&#20197;&#25351;&#23548;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#35774;&#35745;&#12290;&#29616;&#26377;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#30740;&#31350;&#39044;&#35757;&#32451;&#65288;&#19978;&#28216;&#65289;&#25439;&#22833;&#30340;&#23610;&#24230;&#24459;&#12290;&#28982;&#32780;&#65292;&#22312;&#36716;&#31227;&#23398;&#20064;&#29615;&#22659;&#20013;&#65292;LLM&#20808;&#22312;&#26080;&#30417;&#30563;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#39044;&#35757;&#32451;&#65292;&#28982;&#21518;&#22312;&#19979;&#28216;&#20219;&#21153;&#19978;&#36827;&#34892;&#24494;&#35843;&#65292;&#25105;&#20204;&#36890;&#24120;&#20063;&#20851;&#24515;&#19979;&#28216;&#24615;&#33021;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#36716;&#31227;&#23398;&#20064;&#29615;&#22659;&#20013;&#30340;&#23610;&#24230;&#34892;&#20026;&#65292;&#20854;&#20013;LLM&#34987;&#24494;&#35843;&#29992;&#20110;&#26426;&#22120;&#32763;&#35793;&#20219;&#21153;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#39044;&#35757;&#32451;&#25968;&#25454;&#30340;&#36873;&#25321;&#21644;&#22823;&#23567;&#23545;&#19979;&#28216;&#24615;&#33021;&#65288;&#32763;&#35793;&#36136;&#37327;&#65289;&#30340;&#24433;&#21709;&#65292;&#20351;&#29992;&#20102;&#20004;&#20010;&#35780;&#20215;&#25351;&#26631;&#65306;&#19979;&#28216;&#20132;&#21449;&#29109;&#21644;BLEU&#20998;&#25968;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#24494;&#35843;&#25968;&#25454;&#38598;&#30340;&#22823;&#23567;&#21644;&#39044;&#35757;&#32451;&#25968;&#25454;&#19982;&#19979;&#28216;&#25968;&#25454;&#30340;&#20998;&#24067;&#19968;&#33268;&#24615;&#26174;&#33879;&#24433;&#21709;&#23610;&#24230;&#34892;&#20026;&#12290;&#22312;&#20805;&#20998;&#19968;&#33268;&#24615;&#24773;&#20917;&#19979;&#65292;&#19979;&#28216;&#20132;&#21449;&#29109;&#21644;BLEU&#20998;&#25968;&#37117;&#20250;&#36880;&#28176;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;
Scaling laws provide important insights that can guide the design of large language models (LLMs). Existing work has primarily focused on studying scaling laws for pretraining (upstream) loss. However, in transfer learning settings, in which LLMs are pretrained on an unsupervised dataset and then finetuned on a downstream task, we often also care about the downstream performance. In this work, we study the scaling behavior in a transfer learning setting, where LLMs are finetuned for machine translation tasks. Specifically, we investigate how the choice of the pretraining data and its size affect downstream performance (translation quality) as judged by two metrics: downstream cross-entropy and BLEU score. Our experiments indicate that the size of the finetuning dataset and the distribution alignment between the pretraining and downstream data significantly influence the scaling behavior. With sufficient alignment, both downstream cross-entropy and BLEU score improve monotonically with 
&lt;/p&gt;</description></item></channel></rss>