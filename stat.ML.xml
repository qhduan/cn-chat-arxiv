<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#22270;&#24418;&#36755;&#20837;&#31354;&#38388;&#20013;&#65292;&#20998;&#31867;&#22120;&#36793;&#30028;&#30340;&#32467;&#26500;&#12290;&#36890;&#36807;&#21019;&#24314;&#19968;&#31181;&#26032;&#30340;&#19981;&#30830;&#23450;&#24615;&#24230;&#37327;&#65292;&#31216;&#20026;&#37051;&#23621;&#30456;&#20284;&#24230;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#26420;&#32032;&#36125;&#21494;&#26031;&#20998;&#31867;&#22120;&#30340;&#36793;&#30028;&#26159;&#24040;&#22823;&#19988;&#22797;&#26434;&#30340;&#32467;&#26500;&#12290;</title><link>https://arxiv.org/abs/2212.04382</link><description>&lt;p&gt;
&#20998;&#31867;&#22120;&#36793;&#30028;&#30340;&#32467;&#26500;&#65306;&#26420;&#32032;&#36125;&#21494;&#26031;&#20998;&#31867;&#22120;&#30340;&#26696;&#20363;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Structure of Classifier Boundaries: Case Study for a Naive Bayes Classifier
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2212.04382
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#22270;&#24418;&#36755;&#20837;&#31354;&#38388;&#20013;&#65292;&#20998;&#31867;&#22120;&#36793;&#30028;&#30340;&#32467;&#26500;&#12290;&#36890;&#36807;&#21019;&#24314;&#19968;&#31181;&#26032;&#30340;&#19981;&#30830;&#23450;&#24615;&#24230;&#37327;&#65292;&#31216;&#20026;&#37051;&#23621;&#30456;&#20284;&#24230;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#26420;&#32032;&#36125;&#21494;&#26031;&#20998;&#31867;&#22120;&#30340;&#36793;&#30028;&#26159;&#24040;&#22823;&#19988;&#22797;&#26434;&#30340;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#35770;&#22522;&#20110;&#27169;&#22411;&#12289;&#35757;&#32451;&#25968;&#25454;&#36824;&#26159;&#20108;&#32773;&#32452;&#21512;&#65292;&#20998;&#31867;&#22120;&#23558;&#65288;&#21487;&#33021;&#22797;&#26434;&#30340;&#65289;&#36755;&#20837;&#25968;&#25454;&#24402;&#20837;&#30456;&#23545;&#36739;&#23569;&#30340;&#36755;&#20986;&#31867;&#21035;&#20043;&#19968;&#12290;&#26412;&#25991;&#30740;&#31350;&#22312;&#36755;&#20837;&#31354;&#38388;&#20026;&#22270;&#30340;&#24773;&#20917;&#19979;&#65292;&#36793;&#30028;&#30340;&#32467;&#26500;&#8212;&#8212;&#37027;&#20123;&#34987;&#20998;&#31867;&#20026;&#19981;&#21516;&#31867;&#21035;&#30340;&#37051;&#36817;&#28857;&#8212;&#8212;&#30340;&#29305;&#24615;&#12290;&#25105;&#20204;&#30340;&#31185;&#23398;&#32972;&#26223;&#26159;&#22522;&#20110;&#27169;&#22411;&#30340;&#26420;&#32032;&#36125;&#21494;&#26031;&#20998;&#31867;&#22120;&#65292;&#29992;&#20110;&#22788;&#29702;&#30001;&#19979;&#19968;&#20195;&#27979;&#24207;&#20202;&#29983;&#25104;&#30340;DNA&#35835;&#25968;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36793;&#30028;&#26082;&#26159;&#24040;&#22823;&#30340;&#65292;&#21448;&#20855;&#26377;&#22797;&#26434;&#30340;&#32467;&#26500;&#12290;&#25105;&#20204;&#21019;&#24314;&#20102;&#19968;&#31181;&#26032;&#30340;&#19981;&#30830;&#23450;&#24615;&#24230;&#37327;&#65292;&#31216;&#20026;&#37051;&#23621;&#30456;&#20284;&#24230;&#65292;&#23427;&#23558;&#19968;&#20010;&#28857;&#30340;&#32467;&#26524;&#19982;&#20854;&#37051;&#23621;&#30340;&#32467;&#26524;&#20998;&#24067;&#36827;&#34892;&#27604;&#36739;&#12290;&#36825;&#20010;&#24230;&#37327;&#19981;&#20165;&#36861;&#36394;&#20102;&#36125;&#21494;&#26031;&#20998;&#31867;&#22120;&#30340;&#20004;&#20010;&#22266;&#26377;&#19981;&#30830;&#23450;&#24615;&#24230;&#37327;&#65292;&#36824;&#21487;&#20197;&#22312;&#27809;&#26377;&#22266;&#26377;&#19981;&#30830;&#23450;&#24615;&#24230;&#37327;&#30340;&#20998;&#31867;&#22120;&#19978;&#23454;&#29616;&#65292;&#20294;&#38656;&#35201;&#35745;&#31639;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
Whether based on models, training data or a combination, classifiers place (possibly complex) input data into one of a relatively small number of output categories. In this paper, we study the structure of the boundary--those points for which a neighbor is classified differently--in the context of an input space that is a graph, so that there is a concept of neighboring inputs, The scientific setting is a model-based naive Bayes classifier for DNA reads produced by Next Generation Sequencers. We show that the boundary is both large and complicated in structure. We create a new measure of uncertainty, called Neighbor Similarity, that compares the result for a point to the distribution of results for its neighbors. This measure not only tracks two inherent uncertainty measures for the Bayes classifier, but also can be implemented, at a computational cost, for classifiers without inherent measures of uncertainty.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#24314;&#31435;&#21516;&#26102;&#26041;&#31243;&#27169;&#22411;&#21644;&#25511;&#21046;&#20989;&#25968;&#19982;&#20998;&#24067;&#27010;&#25324;&#30340;&#26032;&#36830;&#25509;&#65292;&#35299;&#20915;&#20102;&#22312;&#23384;&#22312;&#26410;&#35266;&#23519;&#21040;&#30340;&#28151;&#28102;&#24773;&#20917;&#19979;&#65292;&#38024;&#23545;&#19981;&#21516;&#35757;&#32451;&#21644;&#27979;&#35797;&#20998;&#24067;&#30340;&#39044;&#27979;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.05805</link><description>&lt;p&gt;
&#25552;&#21319;&#25511;&#21046;&#20989;&#25968;
&lt;/p&gt;
&lt;p&gt;
Boosted Control Functions. (arXiv:2310.05805v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.05805
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#24314;&#31435;&#21516;&#26102;&#26041;&#31243;&#27169;&#22411;&#21644;&#25511;&#21046;&#20989;&#25968;&#19982;&#20998;&#24067;&#27010;&#25324;&#30340;&#26032;&#36830;&#25509;&#65292;&#35299;&#20915;&#20102;&#22312;&#23384;&#22312;&#26410;&#35266;&#23519;&#21040;&#30340;&#28151;&#28102;&#24773;&#20917;&#19979;&#65292;&#38024;&#23545;&#19981;&#21516;&#35757;&#32451;&#21644;&#27979;&#35797;&#20998;&#24067;&#30340;&#39044;&#27979;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#21644;&#22823;&#35268;&#27169;&#25968;&#25454;&#30340;&#21487;&#29992;&#24615;&#20026;&#20174;&#22823;&#37327;&#30340;&#21327;&#21464;&#37327;&#20013;&#20934;&#30830;&#39044;&#27979;&#30446;&#26631;&#25968;&#37327;&#25171;&#24320;&#20102;&#22823;&#38376;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#39044;&#27979;&#26041;&#27861;&#22312;&#35757;&#32451;&#21644;&#27979;&#35797;&#25968;&#25454;&#19981;&#21516;&#30340;&#24773;&#20917;&#19979;&#34920;&#29616;&#19981;&#20339;&#65292;&#23588;&#20854;&#26159;&#22312;&#23384;&#22312;&#38544;&#34255;&#28151;&#28102;&#30340;&#24773;&#20917;&#19979;&#12290;&#34429;&#28982;&#23545;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#65288;&#20363;&#22914;&#20202;&#22120;&#21464;&#37327;&#65289;&#24050;&#32463;&#23545;&#38544;&#34255;&#28151;&#28102;&#36827;&#34892;&#20102;&#28145;&#20837;&#30740;&#31350;&#65292;&#20294;&#23545;&#20110;&#39044;&#27979;&#20219;&#21153;&#26469;&#35828;&#24182;&#38750;&#22914;&#27492;&#12290;&#26412;&#30740;&#31350;&#26088;&#22312;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#35299;&#20915;&#22312;&#23384;&#22312;&#26410;&#35266;&#23519;&#21040;&#30340;&#28151;&#28102;&#30340;&#24773;&#20917;&#19979;&#65292;&#38024;&#23545;&#19981;&#21516;&#35757;&#32451;&#21644;&#27979;&#35797;&#20998;&#24067;&#30340;&#39044;&#27979;&#38382;&#39064;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#22312;&#26426;&#22120;&#23398;&#20064;&#30340;&#20998;&#24067;&#27010;&#25324;&#39046;&#22495;&#65292;&#20197;&#21450;&#35745;&#37327;&#32463;&#27982;&#23398;&#20013;&#30340;&#21516;&#26102;&#26041;&#31243;&#27169;&#22411;&#21644;&#25511;&#21046;&#20989;&#25968;&#20043;&#38388;&#24314;&#31435;&#20102;&#19968;&#31181;&#26032;&#30340;&#32852;&#31995;&#12290;&#25105;&#20204;&#30340;&#36129;&#29486;&#30340;&#26680;&#24515;&#26159;&#25551;&#36848;&#22312;&#19968;&#32452;&#20998;&#24067;&#36716;&#21464;&#19979;&#30340;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#30340;&#20998;&#24067;&#27010;&#25324;&#21516;&#26102;&#26041;&#31243;&#27169;&#22411;&#65288;SIMDGs&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modern machine learning methods and the availability of large-scale data opened the door to accurately predict target quantities from large sets of covariates. However, existing prediction methods can perform poorly when the training and testing data are different, especially in the presence of hidden confounding. While hidden confounding is well studied for causal effect estimation (e.g., instrumental variables), this is not the case for prediction tasks. This work aims to bridge this gap by addressing predictions under different training and testing distributions in the presence of unobserved confounding. In particular, we establish a novel connection between the field of distribution generalization from machine learning, and simultaneous equation models and control function from econometrics. Central to our contribution are simultaneous equation models for distribution generalization (SIMDGs) which describe the data-generating process under a set of distributional shifts. Within thi
&lt;/p&gt;</description></item></channel></rss>