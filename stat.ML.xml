<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#22312;&#22238;&#24402;&#35774;&#32622;&#19979;&#32473;&#20986;&#20102;Mondrian&#38543;&#26426;&#26862;&#26519;&#30340;&#20272;&#35745;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#21644;&#21435;&#20559;&#36807;&#31243;&#65292;&#20351;&#20854;&#33021;&#22815;&#36827;&#34892;&#32479;&#35745;&#25512;&#26029;&#21644;&#23454;&#29616;&#26368;&#23567;&#26497;&#22823;&#20272;&#35745;&#36895;&#29575;&#12290;</title><link>http://arxiv.org/abs/2310.09702</link><description>&lt;p&gt;
&#24102;&#26377;Mondrian&#38543;&#26426;&#26862;&#26519;&#30340;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
Inference with Mondrian Random Forests. (arXiv:2310.09702v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.09702
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22312;&#22238;&#24402;&#35774;&#32622;&#19979;&#32473;&#20986;&#20102;Mondrian&#38543;&#26426;&#26862;&#26519;&#30340;&#20272;&#35745;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#21644;&#21435;&#20559;&#36807;&#31243;&#65292;&#20351;&#20854;&#33021;&#22815;&#36827;&#34892;&#32479;&#35745;&#25512;&#26029;&#21644;&#23454;&#29616;&#26368;&#23567;&#26497;&#22823;&#20272;&#35745;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#26862;&#26519;&#26159;&#19968;&#31181;&#24120;&#29992;&#30340;&#20998;&#31867;&#21644;&#22238;&#24402;&#26041;&#27861;&#65292;&#22312;&#26368;&#36817;&#20960;&#24180;&#20013;&#25552;&#20986;&#20102;&#35768;&#22810;&#19981;&#21516;&#30340;&#21464;&#20307;&#12290;&#19968;&#20010;&#26377;&#36259;&#30340;&#20363;&#23376;&#26159;Mondrian&#38543;&#26426;&#26862;&#26519;&#65292;&#20854;&#20013;&#24213;&#23618;&#26641;&#26159;&#26681;&#25454;Mondrian&#36807;&#31243;&#26500;&#24314;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;Mondrian&#38543;&#26426;&#26862;&#26519;&#22312;&#22238;&#24402;&#35774;&#32622;&#19979;&#30340;&#20272;&#35745;&#30340;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#12290;&#24403;&#19982;&#20559;&#24046;&#34920;&#24449;&#21644;&#19968;&#33268;&#26041;&#24046;&#20272;&#35745;&#22120;&#30456;&#32467;&#21512;&#26102;&#65292;&#36825;&#20801;&#35768;&#36827;&#34892;&#28176;&#36817;&#26377;&#25928;&#30340;&#32479;&#35745;&#25512;&#26029;&#65292;&#22914;&#26500;&#24314;&#32622;&#20449;&#21306;&#38388;&#65292;&#23545;&#26410;&#30693;&#30340;&#22238;&#24402;&#20989;&#25968;&#36827;&#34892;&#25512;&#26029;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#19968;&#31181;&#21435;&#20559;&#36807;&#31243;&#65292;&#29992;&#20110;Mondrian&#38543;&#26426;&#26862;&#26519;&#65292;&#20351;&#20854;&#33021;&#22815;&#22312;&#36866;&#24403;&#30340;&#21442;&#25968;&#35843;&#25972;&#19979;&#23454;&#29616;$\beta$-H\"older&#22238;&#24402;&#20989;&#25968;&#30340;&#26368;&#23567;&#26497;&#22823;&#20272;&#35745;&#36895;&#29575;&#65292;&#23545;&#20110;&#25152;&#26377;&#30340;$\beta$&#21644;&#20219;&#24847;&#32500;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Random forests are popular methods for classification and regression, and many different variants have been proposed in recent years. One interesting example is the Mondrian random forest, in which the underlying trees are constructed according to a Mondrian process. In this paper we give a central limit theorem for the estimates made by a Mondrian random forest in the regression setting. When combined with a bias characterization and a consistent variance estimator, this allows one to perform asymptotically valid statistical inference, such as constructing confidence intervals, on the unknown regression function. We also provide a debiasing procedure for Mondrian random forests which allows them to achieve minimax-optimal estimation rates with $\beta$-H\"older regression functions, for all $\beta$ and in arbitrary dimension, assuming appropriate parameter tuning.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22806;&#37096;&#26377;&#25928;&#30340;&#20010;&#24615;&#21270;&#27835;&#30103;&#31574;&#30053;&#30340;&#23398;&#20064;&#38382;&#39064;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#26368;&#22823;&#21270;&#31119;&#21033;&#30340;&#27835;&#30103;&#31574;&#30053;&#23545;&#20110;&#23454;&#39564;&#21644;&#30446;&#26631;&#20154;&#32676;&#20043;&#38388;&#30340;&#32467;&#26524;&#20998;&#24067;&#21464;&#21270;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;&#36890;&#36807;&#24320;&#21457;&#26032;&#30340;&#26041;&#27861;&#65292;&#20316;&#32773;&#25552;&#20986;&#20102;&#23545;&#32467;&#26524;&#21644;&#29305;&#24449;&#21464;&#21270;&#20855;&#26377;&#40065;&#26834;&#24615;&#30340;&#31574;&#30053;&#23398;&#20064;&#26041;&#27861;&#65292;&#24182;&#24378;&#35843;&#23454;&#39564;&#20154;&#32676;&#20869;&#30340;&#27835;&#30103;&#25928;&#26524;&#24322;&#36136;&#24615;&#23545;&#31574;&#30053;&#26222;&#36866;&#24615;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2205.05561</link><description>&lt;p&gt;
&#22806;&#37096;&#26377;&#25928;&#30340;&#31574;&#30053;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
Externally Valid Policy Choice. (arXiv:2205.05561v2 [econ.EM] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.05561
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22806;&#37096;&#26377;&#25928;&#30340;&#20010;&#24615;&#21270;&#27835;&#30103;&#31574;&#30053;&#30340;&#23398;&#20064;&#38382;&#39064;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#26368;&#22823;&#21270;&#31119;&#21033;&#30340;&#27835;&#30103;&#31574;&#30053;&#23545;&#20110;&#23454;&#39564;&#21644;&#30446;&#26631;&#20154;&#32676;&#20043;&#38388;&#30340;&#32467;&#26524;&#20998;&#24067;&#21464;&#21270;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;&#36890;&#36807;&#24320;&#21457;&#26032;&#30340;&#26041;&#27861;&#65292;&#20316;&#32773;&#25552;&#20986;&#20102;&#23545;&#32467;&#26524;&#21644;&#29305;&#24449;&#21464;&#21270;&#20855;&#26377;&#40065;&#26834;&#24615;&#30340;&#31574;&#30053;&#23398;&#20064;&#26041;&#27861;&#65292;&#24182;&#24378;&#35843;&#23454;&#39564;&#20154;&#32676;&#20869;&#30340;&#27835;&#30103;&#25928;&#26524;&#24322;&#36136;&#24615;&#23545;&#31574;&#30053;&#26222;&#36866;&#24615;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#23398;&#20064;&#20010;&#24615;&#21270;&#27835;&#30103;&#31574;&#30053;&#30340;&#38382;&#39064;&#65292;&#36825;&#20123;&#31574;&#30053;&#26159;&#22806;&#37096;&#26377;&#25928;&#25110;&#24191;&#20041;&#21270;&#30340;&#65306;&#23427;&#20204;&#22312;&#38500;&#20102;&#23454;&#39564;&#65288;&#25110;&#35757;&#32451;&#65289;&#20154;&#32676;&#22806;&#30340;&#20854;&#20182;&#30446;&#26631;&#20154;&#32676;&#20013;&#34920;&#29616;&#33391;&#22909;&#12290;&#25105;&#20204;&#39318;&#20808;&#35777;&#26126;&#65292;&#23545;&#20110;&#23454;&#39564;&#20154;&#32676;&#32780;&#35328;&#65292;&#26368;&#22823;&#21270;&#31119;&#21033;&#30340;&#31574;&#30053;&#23545;&#20110;&#23454;&#39564;&#21644;&#30446;&#26631;&#20154;&#32676;&#20043;&#38388;&#30340;&#32467;&#26524;&#65288;&#20294;&#19981;&#26159;&#29305;&#24449;&#65289;&#20998;&#24067;&#21464;&#21270;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#26032;&#30340;&#26041;&#27861;&#26469;&#23398;&#20064;&#23545;&#32467;&#26524;&#21644;&#29305;&#24449;&#21464;&#21270;&#20855;&#26377;&#40065;&#26834;&#24615;&#30340;&#31574;&#30053;&#12290;&#22312;&#36825;&#26679;&#20570;&#26102;&#65292;&#25105;&#20204;&#24378;&#35843;&#20102;&#23454;&#39564;&#20154;&#32676;&#20869;&#30340;&#27835;&#30103;&#25928;&#26524;&#24322;&#36136;&#24615;&#22914;&#20309;&#24433;&#21709;&#31574;&#30053;&#30340;&#26222;&#36866;&#24615;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#20351;&#29992;&#23454;&#39564;&#25110;&#35266;&#23519;&#25968;&#25454;&#65288;&#20854;&#20013;&#27835;&#30103;&#26159;&#20869;&#29983;&#30340;&#65289;&#12290;&#25105;&#20204;&#30340;&#35768;&#22810;&#26041;&#27861;&#21487;&#20197;&#20351;&#29992;&#32447;&#24615;&#35268;&#21010;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of learning personalized treatment policies that are externally valid or generalizable: they perform well in other target populations besides the experimental (or training) population from which data are sampled. We first show that welfare-maximizing policies for the experimental population are robust to shifts in the distribution of outcomes (but not characteristics) between the experimental and target populations. We then develop new methods for learning policies that are robust to shifts in outcomes and characteristics. In doing so, we highlight how treatment effect heterogeneity within the experimental population affects the generalizability of policies. Our methods may be used with experimental or observational data (where treatment is endogenous). Many of our methods can be implemented with linear programming.
&lt;/p&gt;</description></item></channel></rss>