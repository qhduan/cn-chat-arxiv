<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#32467;&#26500;&#21270;&#36172;&#21338;&#26426;&#20013;&#30340;&#36125;&#21494;&#26031;&#22266;&#23450;&#39044;&#31639;&#26368;&#20339;&#33218;&#35782;&#21035;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20808;&#39564;&#20449;&#24687;&#30340;&#22266;&#23450;&#20998;&#37197;&#31639;&#27861;&#65292;&#24182;&#24341;&#20837;&#20102;&#26032;&#30340;&#35777;&#26126;&#26041;&#27861;&#65292;&#20197;&#24471;&#21040;&#26356;&#32039;&#23494;&#30340;&#22810;&#33218;BAI&#30028;&#38480;&#12290;&#35813;&#26041;&#27861;&#22312;&#21508;&#31181;&#24773;&#20917;&#19979;&#23637;&#29616;&#20986;&#19968;&#33268;&#19988;&#31283;&#20581;&#30340;&#24615;&#33021;&#65292;&#21152;&#28145;&#20102;&#25105;&#20204;&#23545;&#20110;&#35813;&#38382;&#39064;&#30340;&#29702;&#35299;&#12290;</title><link>https://arxiv.org/abs/2402.05878</link><description>&lt;p&gt;
&#22522;&#20110;&#20808;&#39564;&#20381;&#36182;&#20998;&#37197;&#30340;&#32467;&#26500;&#21270;&#36172;&#21338;&#26426;&#20013;&#36125;&#21494;&#26031;&#22266;&#23450;&#39044;&#31639;&#26368;&#20339;&#33218;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
Prior-Dependent Allocations for Bayesian Fixed-Budget Best-Arm Identification in Structured Bandits
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05878
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#32467;&#26500;&#21270;&#36172;&#21338;&#26426;&#20013;&#30340;&#36125;&#21494;&#26031;&#22266;&#23450;&#39044;&#31639;&#26368;&#20339;&#33218;&#35782;&#21035;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20808;&#39564;&#20449;&#24687;&#30340;&#22266;&#23450;&#20998;&#37197;&#31639;&#27861;&#65292;&#24182;&#24341;&#20837;&#20102;&#26032;&#30340;&#35777;&#26126;&#26041;&#27861;&#65292;&#20197;&#24471;&#21040;&#26356;&#32039;&#23494;&#30340;&#22810;&#33218;BAI&#30028;&#38480;&#12290;&#35813;&#26041;&#27861;&#22312;&#21508;&#31181;&#24773;&#20917;&#19979;&#23637;&#29616;&#20986;&#19968;&#33268;&#19988;&#31283;&#20581;&#30340;&#24615;&#33021;&#65292;&#21152;&#28145;&#20102;&#25105;&#20204;&#23545;&#20110;&#35813;&#38382;&#39064;&#30340;&#29702;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#32467;&#26500;&#21270;&#36172;&#21338;&#26426;&#20013;&#30340;&#36125;&#21494;&#26031;&#22266;&#23450;&#39044;&#31639;&#26368;&#20339;&#33218;&#35782;&#21035;&#65288;BAI&#65289;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#22522;&#20110;&#20808;&#39564;&#20449;&#24687;&#21644;&#29615;&#22659;&#32467;&#26500;&#20351;&#29992;&#22266;&#23450;&#20998;&#37197;&#12290;&#25105;&#20204;&#22312;&#22810;&#20010;&#27169;&#22411;&#20013;&#25552;&#20379;&#20102;&#23427;&#22312;&#24615;&#33021;&#19978;&#30340;&#29702;&#35770;&#30028;&#38480;&#65292;&#21253;&#25324;&#32447;&#24615;&#21644;&#20998;&#23618;BAI&#30340;&#39318;&#20010;&#20808;&#39564;&#20381;&#36182;&#19978;&#30028;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#24341;&#20837;&#20102;&#26032;&#30340;&#35777;&#26126;&#26041;&#27861;&#65292;&#30456;&#27604;&#29616;&#26377;&#26041;&#27861;&#65292;&#23427;&#33021;&#24471;&#21040;&#26356;&#32039;&#23494;&#30340;&#22810;&#33218;BAI&#30028;&#38480;&#12290;&#25105;&#20204;&#24191;&#27867;&#27604;&#36739;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#19982;&#20854;&#20182;&#22266;&#23450;&#39044;&#31639;BAI&#26041;&#27861;&#65292;&#22312;&#21508;&#31181;&#35774;&#32622;&#20013;&#23637;&#31034;&#20102;&#20854;&#19968;&#33268;&#19988;&#31283;&#20581;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#25913;&#36827;&#20102;&#23545;&#20110;&#32467;&#26500;&#21270;&#36172;&#21338;&#26426;&#20013;&#36125;&#21494;&#26031;&#22266;&#23450;&#39044;&#31639;BAI&#30340;&#29702;&#35299;&#65292;&#24182;&#31361;&#20986;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#23454;&#38469;&#22330;&#26223;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of Bayesian fixed-budget best-arm identification (BAI) in structured bandits. We propose an algorithm that uses fixed allocations based on the prior information and the structure of the environment. We provide theoretical bounds on its performance across diverse models, including the first prior-dependent upper bounds for linear and hierarchical BAI. Our key contribution is introducing new proof methods that result in tighter bounds for multi-armed BAI compared to existing methods. We extensively compare our approach to other fixed-budget BAI methods, demonstrating its consistent and robust performance in various settings. Our work improves our understanding of Bayesian fixed-budget BAI in structured bandits and highlights the effectiveness of our approach in practical scenarios.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#23545;&#22810;&#20010;&#21512;&#25104;&#25968;&#25454;&#38598;&#36827;&#34892;&#20559;&#24046;-&#26041;&#24046;&#20998;&#35299;&#65292;&#22686;&#21152;&#20102;&#23545;&#20854;&#29702;&#35770;&#29702;&#35299;&#12290;&#23454;&#39564;&#35777;&#26126;&#22810;&#20010;&#21512;&#25104;&#25968;&#25454;&#38598;&#23545;&#20110;&#39640;&#26041;&#24046;&#30340;&#19979;&#28216;&#39044;&#27979;&#22120;&#29305;&#21035;&#26377;&#30410;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#32463;&#39564;&#27861;&#21017;&#29992;&#20110;&#36873;&#25321;&#36866;&#24403;&#30340;&#21512;&#25104;&#25968;&#25454;&#38598;&#25968;&#37327;&#12290;</title><link>https://arxiv.org/abs/2402.03985</link><description>&lt;p&gt;
&#23545;&#22810;&#20010;&#21512;&#25104;&#25968;&#25454;&#38598;&#30340;&#38598;&#25104;&#36827;&#34892;&#20559;&#24046;-&#26041;&#24046;&#20998;&#35299;
&lt;/p&gt;
&lt;p&gt;
A Bias-Variance Decomposition for Ensembles over Multiple Synthetic Datasets
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03985
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#23545;&#22810;&#20010;&#21512;&#25104;&#25968;&#25454;&#38598;&#36827;&#34892;&#20559;&#24046;-&#26041;&#24046;&#20998;&#35299;&#65292;&#22686;&#21152;&#20102;&#23545;&#20854;&#29702;&#35770;&#29702;&#35299;&#12290;&#23454;&#39564;&#35777;&#26126;&#22810;&#20010;&#21512;&#25104;&#25968;&#25454;&#38598;&#23545;&#20110;&#39640;&#26041;&#24046;&#30340;&#19979;&#28216;&#39044;&#27979;&#22120;&#29305;&#21035;&#26377;&#30410;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#32463;&#39564;&#27861;&#21017;&#29992;&#20110;&#36873;&#25321;&#36866;&#24403;&#30340;&#21512;&#25104;&#25968;&#25454;&#38598;&#25968;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#24378;&#35843;&#20102;&#20026;&#30417;&#30563;&#23398;&#20064;&#29983;&#25104;&#22810;&#20010;&#21512;&#25104;&#25968;&#25454;&#38598;&#30340;&#22909;&#22788;&#65292;&#21253;&#25324;&#22686;&#21152;&#20934;&#30830;&#24615;&#12289;&#26356;&#26377;&#25928;&#30340;&#27169;&#22411;&#36873;&#25321;&#21644;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;&#36825;&#20123;&#22909;&#22788;&#22312;&#32463;&#39564;&#19978;&#26377;&#26126;&#30830;&#30340;&#25903;&#25345;&#65292;&#20294;&#23545;&#23427;&#20204;&#30340;&#29702;&#35770;&#29702;&#35299;&#30446;&#21069;&#38750;&#24120;&#26377;&#38480;&#12290;&#25105;&#20204;&#36890;&#36807;&#25512;&#23548;&#20351;&#29992;&#22810;&#20010;&#21512;&#25104;&#25968;&#25454;&#38598;&#30340;&#20960;&#31181;&#35774;&#32622;&#30340;&#20559;&#24046;-&#26041;&#24046;&#20998;&#35299;&#65292;&#26469;&#22686;&#21152;&#29702;&#35770;&#29702;&#35299;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#39044;&#27979;&#65292;&#23545;&#20110;&#39640;&#26041;&#24046;&#30340;&#19979;&#28216;&#39044;&#27979;&#22120;&#65292;&#22810;&#20010;&#21512;&#25104;&#25968;&#25454;&#38598;&#23558;&#29305;&#21035;&#26377;&#30410;&#65292;&#24182;&#20026;&#22343;&#26041;&#35823;&#24046;&#21644;Brier&#20998;&#25968;&#30340;&#24773;&#20917;&#25552;&#20379;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#32463;&#39564;&#27861;&#21017;&#26469;&#36873;&#25321;&#21512;&#36866;&#30340;&#21512;&#25104;&#25968;&#25454;&#38598;&#25968;&#37327;&#12290;&#25105;&#20204;&#36890;&#36807;&#35780;&#20272;&#19968;&#20010;&#38598;&#25104;&#22312;&#22810;&#20010;&#21512;&#25104;&#25968;&#25454;&#38598;&#21644;&#20960;&#20010;&#30495;&#23454;&#25968;&#25454;&#38598;&#20197;&#21450;&#19979;&#28216;&#39044;&#27979;&#22120;&#19978;&#30340;&#24615;&#33021;&#26469;&#30740;&#31350;&#25105;&#20204;&#30340;&#29702;&#35770;&#22312;&#23454;&#36341;&#20013;&#30340;&#25928;&#26524;&#12290;&#32467;&#26524;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#65292;&#34920;&#26126;&#25105;&#20204;&#30340;&#27934;&#23519;&#20063;&#22312;&#23454;&#36341;&#20013;&#20855;&#26377;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent studies have highlighted the benefits of generating multiple synthetic datasets for supervised learning, from increased accuracy to more effective model selection and uncertainty estimation. These benefits have clear empirical support, but the theoretical understanding of them is currently very light. We seek to increase the theoretical understanding by deriving bias-variance decompositions for several settings of using multiple synthetic datasets. Our theory predicts multiple synthetic datasets to be especially beneficial for high-variance downstream predictors, and yields a simple rule of thumb to select the appropriate number of synthetic datasets in the case of mean-squared error and Brier score. We investigate how our theory works in practice by evaluating the performance of an ensemble over many synthetic datasets for several real datasets and downstream predictors. The results follow our theory, showing that our insights are also practically relevant.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#21547;&#26377;&#25209;&#37327;&#26356;&#26032;&#21644;/&#25110;&#36817;&#20284;&#26799;&#24230;&#30340;&#21160;&#37327;&#37325;&#29699;&#27861;&#30340;&#25910;&#25947;&#24615;&#65292;&#30001;&#20110;&#37319;&#29992;&#20102;&#31616;&#21270;&#30340;&#26799;&#24230;&#35745;&#31639;&#26041;&#27861;&#65292;&#22823;&#22823;&#20943;&#23569;&#20102;&#35745;&#31639;&#28040;&#32791;&#65292;&#21516;&#26102;&#20173;&#33021;&#20445;&#35777;&#25910;&#25947;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.16241</link><description>&lt;p&gt;
&#37319;&#29992;&#25209;&#37327;&#26356;&#26032;&#21644;/&#25110;&#36817;&#20284;&#26799;&#24230;&#30340;&#21160;&#37327;&#37325;&#29699;&#27861;&#30340;&#25910;&#25947;&#24615;
&lt;/p&gt;
&lt;p&gt;
Convergence of Momentum-Based Heavy Ball Method with Batch Updating and/or Approximate Gradients. (arXiv:2303.16241v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.16241
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#21547;&#26377;&#25209;&#37327;&#26356;&#26032;&#21644;/&#25110;&#36817;&#20284;&#26799;&#24230;&#30340;&#21160;&#37327;&#37325;&#29699;&#27861;&#30340;&#25910;&#25947;&#24615;&#65292;&#30001;&#20110;&#37319;&#29992;&#20102;&#31616;&#21270;&#30340;&#26799;&#24230;&#35745;&#31639;&#26041;&#27861;&#65292;&#22823;&#22823;&#20943;&#23569;&#20102;&#35745;&#31639;&#28040;&#32791;&#65292;&#21516;&#26102;&#20173;&#33021;&#20445;&#35777;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;1964&#24180;Polyak&#24341;&#20837;&#30340;&#20984;&#20248;&#21270;&#21644;&#38750;&#20984;&#20248;&#21270;&#20013;&#24191;&#20026;&#20154;&#30693;&#30340;&#8220;&#21160;&#37327;&#37325;&#29699;&#8221;&#27861;&#65292;&#24182;&#22312;&#22810;&#31181;&#24773;&#20917;&#19979;&#30830;&#31435;&#20102;&#20854;&#25910;&#25947;&#24615;&#12290;&#24403;&#35201;&#27714;&#35299;&#21442;&#25968;&#30340;&#32500;&#24230;&#38750;&#24120;&#39640;&#26102;&#65292;&#26356;&#26032;&#19968;&#37096;&#20998;&#32780;&#19981;&#26159;&#25152;&#26377;&#21442;&#25968;&#21487;&#20197;&#25552;&#39640;&#20248;&#21270;&#25928;&#29575;&#65292;&#31216;&#20043;&#20026;&#8220;&#25209;&#37327;&#26356;&#26032;&#8221;&#65292;&#33509;&#19982;&#26799;&#24230;&#27861;&#37197;&#21512;&#20351;&#29992;&#65292;&#21017;&#29702;&#35770;&#19978;&#21482;&#38656;&#35745;&#31639;&#38656;&#35201;&#26356;&#26032;&#30340;&#21442;&#25968;&#30340;&#26799;&#24230;&#65292;&#32780;&#22312;&#23454;&#38469;&#20013;&#65292;&#36890;&#36807;&#21453;&#21521;&#20256;&#25773;&#31561;&#26041;&#27861;&#20165;&#35745;&#31639;&#37096;&#20998;&#26799;&#24230;&#24182;&#19981;&#33021;&#20943;&#23569;&#35745;&#31639;&#37327;&#12290;&#22240;&#27492;&#65292;&#20026;&#20102;&#22312;&#27599;&#19968;&#27493;&#20013;&#20943;&#23569;CPU&#20351;&#29992;&#37327;&#65292;&#21487;&#20197;&#20351;&#29992;&#19968;&#38454;&#24494;&#20998;&#25110;&#36817;&#20284;&#26799;&#24230;&#20195;&#26367;&#30495;&#23454;&#26799;&#24230;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#34920;&#26126;&#65292;&#22312;&#21508;&#31181;&#20551;&#35774;&#19979;&#65292;&#37319;&#29992;&#36817;&#20284;&#26799;&#24230;&#20449;&#24687;&#21644;/&#25110;&#25209;&#37327;&#26356;&#26032;&#30340;&#21160;&#37327;&#37325;&#29699;&#27861;&#20173;&#28982;&#21487;&#20197;&#25910;&#25947;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we study the well-known "Heavy Ball" method for convex and nonconvex optimization introduced by Polyak in 1964, and establish its convergence under a variety of situations. Traditionally, most algorthms use "full-coordinate update," that is, at each step, very component of the argument is updated. However, when the dimension of the argument is very high, it is more efficient to update some but not all components of the argument at each iteration. We refer to this as "batch updating" in this paper.  When gradient-based algorithms are used together with batch updating, in principle it is sufficient to compute only those components of the gradient for which the argument is to be updated. However, if a method such as back propagation is used to compute these components, computing only some components of gradient does not offer much savings over computing the entire gradient. Therefore, to achieve a noticeable reduction in CPU usage at each step, one can use first-order diffe
&lt;/p&gt;</description></item></channel></rss>