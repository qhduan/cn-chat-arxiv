<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#30740;&#31350;&#20102;&#23545;&#20110;&#29420;&#31435;&#20294;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#30340;&#39640;&#32500;&#22238;&#24402;&#27169;&#22411;&#65292;&#25552;&#20986;&#20102;&#22312;&#23725;&#27491;&#21017;&#21270;&#21442;&#25968;&#36235;&#36817;&#20110;&#38646;&#26102;&#39640;&#32500;&#22238;&#24402;&#20013;&#30340;&#21452;&#35895;&#29616;&#35937;&#12290;</title><link>https://arxiv.org/abs/2403.20200</link><description>&lt;p&gt;
&#23545;&#20855;&#26377;&#26041;&#24046;&#36718;&#24275;&#30340;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#30340;&#23725;&#22238;&#24402;&#36827;&#34892;&#39640;&#32500;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
High-dimensional analysis of ridge regression for non-identically distributed data with a variance profile
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.20200
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#23545;&#20110;&#29420;&#31435;&#20294;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#30340;&#39640;&#32500;&#22238;&#24402;&#27169;&#22411;&#65292;&#25552;&#20986;&#20102;&#22312;&#23725;&#27491;&#21017;&#21270;&#21442;&#25968;&#36235;&#36817;&#20110;&#38646;&#26102;&#39640;&#32500;&#22238;&#24402;&#20013;&#30340;&#21452;&#35895;&#29616;&#35937;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38024;&#23545;&#29420;&#31435;&#20294;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#65292;&#25105;&#20204;&#25552;&#20986;&#30740;&#31350;&#39640;&#32500;&#22238;&#24402;&#27169;&#22411;&#12290;&#20551;&#35774;&#35266;&#27979;&#21040;&#30340;&#39044;&#27979;&#21464;&#37327;&#38598;&#21512;&#26159;&#24102;&#26377;&#26041;&#24046;&#36718;&#24275;&#30340;&#38543;&#26426;&#30697;&#38453;&#65292;&#24182;&#19988;&#20854;&#32500;&#24230;&#20197;&#30456;&#24212;&#36895;&#29575;&#22686;&#38271;&#12290;&#22312;&#20551;&#35774;&#38543;&#26426;&#25928;&#24212;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20855;&#26377;&#36825;&#31181;&#26041;&#24046;&#36718;&#24275;&#30340;&#23725;&#20272;&#35745;&#22120;&#30340;&#32447;&#24615;&#22238;&#24402;&#30340;&#39044;&#27979;&#39118;&#38505;&#12290;&#22312;&#36825;&#31181;&#35774;&#32622;&#19979;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#35813;&#39118;&#38505;&#30340;&#30830;&#23450;&#24615;&#31561;&#20215;&#29289;&#20197;&#21450;&#23725;&#20272;&#35745;&#22120;&#30340;&#33258;&#30001;&#24230;&#12290;&#23545;&#20110;&#26576;&#20123;&#26041;&#24046;&#36718;&#24275;&#31867;&#21035;&#65292;&#25105;&#20204;&#30340;&#24037;&#20316;&#31361;&#20986;&#20102;&#22312;&#23725;&#27491;&#21017;&#21270;&#21442;&#25968;&#36235;&#20110;&#38646;&#26102;&#65292;&#39640;&#32500;&#22238;&#24402;&#20013;&#30340;&#26368;&#23567;&#27169;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#22120;&#20986;&#29616;&#21452;&#35895;&#29616;&#35937;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#19968;&#20123;&#26041;&#24046;&#36718;&#24275;f...
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.20200v1 Announce Type: cross  Abstract: High-dimensional linear regression has been thoroughly studied in the context of independent and identically distributed data. We propose to investigate high-dimensional regression models for independent but non-identically distributed data. To this end, we suppose that the set of observed predictors (or features) is a random matrix with a variance profile and with dimensions growing at a proportional rate. Assuming a random effect model, we study the predictive risk of the ridge estimator for linear regression with such a variance profile. In this setting, we provide deterministic equivalents of this risk and of the degree of freedom of the ridge estimator. For certain class of variance profile, our work highlights the emergence of the well-known double descent phenomenon in high-dimensional regression for the minimum norm least-squares estimator when the ridge regularization parameter goes to zero. We also exhibit variance profiles f
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#35299;&#26512;&#20102;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#30561;&#30496;&#38454;&#27573;&#20998;&#31867;&#27169;&#22411;&#30340;&#35774;&#35745;&#31354;&#38388;&#65292;&#25214;&#21040;&#20102;&#36866;&#29992;&#20110;&#19981;&#21516;&#36755;&#20837;&#34920;&#31034;&#30340;&#31283;&#20581;&#26550;&#26500;&#65292;&#24182;&#22312;&#30561;&#30496;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#20102;&#26174;&#33879;&#30340;&#24615;&#33021;&#25552;&#21319;&#12290;</title><link>http://arxiv.org/abs/2310.06715</link><description>&lt;p&gt;
S4Sleep: &#35299;&#26512;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#30561;&#30496;&#38454;&#27573;&#20998;&#31867;&#27169;&#22411;&#30340;&#35774;&#35745;&#31354;&#38388;
&lt;/p&gt;
&lt;p&gt;
S4Sleep: Elucidating the design space of deep-learning-based sleep stage classification models. (arXiv:2310.06715v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.06715
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35299;&#26512;&#20102;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#30561;&#30496;&#38454;&#27573;&#20998;&#31867;&#27169;&#22411;&#30340;&#35774;&#35745;&#31354;&#38388;&#65292;&#25214;&#21040;&#20102;&#36866;&#29992;&#20110;&#19981;&#21516;&#36755;&#20837;&#34920;&#31034;&#30340;&#31283;&#20581;&#26550;&#26500;&#65292;&#24182;&#22312;&#30561;&#30496;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#20102;&#26174;&#33879;&#30340;&#24615;&#33021;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#22810;&#36890;&#36947;&#30561;&#30496;&#33041;&#30005;&#22270;&#35760;&#24405;&#36827;&#34892;&#30561;&#30496;&#38454;&#27573;&#25171;&#20998;&#26159;&#19968;&#39033;&#32791;&#26102;&#19988;&#23384;&#22312;&#26174;&#33879;&#30340;&#35780;&#20998;&#20154;&#21592;&#20043;&#38388;&#24046;&#24322;&#30340;&#20219;&#21153;&#12290;&#22240;&#27492;&#65292;&#24212;&#29992;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#21487;&#20197;&#24102;&#26469;&#24456;&#22823;&#30340;&#30410;&#22788;&#12290;&#34429;&#28982;&#24050;&#32463;&#20026;&#27492;&#25552;&#20986;&#20102;&#35768;&#22810;&#31639;&#27861;&#65292;&#20294;&#26576;&#20123;&#20851;&#38190;&#30340;&#26550;&#26500;&#20915;&#31574;&#24182;&#26410;&#24471;&#21040;&#31995;&#32479;&#24615;&#30340;&#25506;&#32034;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#35814;&#32454;&#35843;&#26597;&#20102;&#24191;&#27867;&#30340;&#32534;&#30721;&#22120;-&#39044;&#27979;&#22120;&#26550;&#26500;&#33539;&#30068;&#20869;&#30340;&#36825;&#20123;&#35774;&#35745;&#36873;&#25321;&#12290;&#25105;&#20204;&#25214;&#21040;&#20102;&#36866;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#21644;&#22768;&#35889;&#22270;&#36755;&#20837;&#34920;&#31034;&#30340;&#31283;&#20581;&#26550;&#26500;&#12290;&#36825;&#20123;&#26550;&#26500;&#23558;&#32467;&#26500;&#21270;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#20316;&#20026;&#32452;&#25104;&#37096;&#20998;&#65292;&#23545;&#24191;&#27867;&#30340;SHHS&#25968;&#25454;&#38598;&#30340;&#24615;&#33021;&#36827;&#34892;&#20102;&#32479;&#35745;&#26174;&#33879;&#30340;&#25552;&#21319;&#12290;&#36825;&#20123;&#25913;&#36827;&#36890;&#36807;&#32479;&#35745;&#21644;&#31995;&#32479;&#35823;&#24046;&#20272;&#35745;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;&#25105;&#20204;&#39044;&#35745;&#65292;&#20174;&#26412;&#30740;&#31350;&#20013;&#33719;&#24471;&#30340;&#26550;&#26500;&#27934;&#23519;&#19981;&#20165;&#23545;&#26410;&#26469;&#30340;&#30561;&#30496;&#20998;&#26399;&#30740;&#31350;&#26377;&#20215;&#20540;&#65292;&#32780;&#19988;&#23545;&#25972;&#20307;&#30561;&#30496;&#30740;&#31350;&#37117;&#26377;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
Scoring sleep stages in polysomnography recordings is a time-consuming task plagued by significant inter-rater variability. Therefore, it stands to benefit from the application of machine learning algorithms. While many algorithms have been proposed for this purpose, certain critical architectural decisions have not received systematic exploration. In this study, we meticulously investigate these design choices within the broad category of encoder-predictor architectures. We identify robust architectures applicable to both time series and spectrogram input representations. These architectures incorporate structured state space models as integral components, leading to statistically significant advancements in performance on the extensive SHHS dataset. These improvements are assessed through both statistical and systematic error estimations. We anticipate that the architectural insights gained from this study will not only prove valuable for future research in sleep staging but also hol
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20855;&#26377;&#35889;&#27491;&#21017;&#21270;&#30340;&#26680;&#25311;&#21512;&#20248;&#24230;&#26816;&#39564;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#38750;&#27431;&#20960;&#37324;&#24471;&#25968;&#25454;&#12290;&#30456;&#27604;&#20043;&#21069;&#30340;&#26041;&#27861;&#65292;&#26412;&#26041;&#27861;&#22312;&#36873;&#25321;&#36866;&#24403;&#30340;&#27491;&#21017;&#21270;&#21442;&#25968;&#26102;&#33021;&#36798;&#21040;&#26368;&#23567;&#21270;&#26368;&#22823;&#39118;&#38505;&#12290;&#21516;&#26102;&#65292;&#26412;&#26041;&#27861;&#36824;&#20811;&#26381;&#20102;&#20043;&#21069;&#26041;&#27861;&#23545;&#22343;&#20540;&#20803;&#32032;&#20026;&#38646;&#21644;&#31215;&#20998;&#25805;&#20316;&#31526;&#29305;&#24449;&#20989;&#25968;&#22343;&#21248;&#26377;&#30028;&#24615;&#26465;&#20214;&#30340;&#38480;&#21046;&#65292;&#24182;&#19988;&#33021;&#22815;&#35745;&#31639;&#26356;&#22810;&#31181;&#31867;&#30340;&#26680;&#20989;&#25968;&#12290;</title><link>http://arxiv.org/abs/2308.04561</link><description>&lt;p&gt;
&#20855;&#26377;&#35889;&#27491;&#21017;&#21270;&#30340;&#26680;&#25311;&#21512;&#20248;&#24230;&#26816;&#39564;
&lt;/p&gt;
&lt;p&gt;
Spectral Regularized Kernel Goodness-of-Fit Tests. (arXiv:2308.04561v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.04561
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20855;&#26377;&#35889;&#27491;&#21017;&#21270;&#30340;&#26680;&#25311;&#21512;&#20248;&#24230;&#26816;&#39564;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#38750;&#27431;&#20960;&#37324;&#24471;&#25968;&#25454;&#12290;&#30456;&#27604;&#20043;&#21069;&#30340;&#26041;&#27861;&#65292;&#26412;&#26041;&#27861;&#22312;&#36873;&#25321;&#36866;&#24403;&#30340;&#27491;&#21017;&#21270;&#21442;&#25968;&#26102;&#33021;&#36798;&#21040;&#26368;&#23567;&#21270;&#26368;&#22823;&#39118;&#38505;&#12290;&#21516;&#26102;&#65292;&#26412;&#26041;&#27861;&#36824;&#20811;&#26381;&#20102;&#20043;&#21069;&#26041;&#27861;&#23545;&#22343;&#20540;&#20803;&#32032;&#20026;&#38646;&#21644;&#31215;&#20998;&#25805;&#20316;&#31526;&#29305;&#24449;&#20989;&#25968;&#22343;&#21248;&#26377;&#30028;&#24615;&#26465;&#20214;&#30340;&#38480;&#21046;&#65292;&#24182;&#19988;&#33021;&#22815;&#35745;&#31639;&#26356;&#22810;&#31181;&#31867;&#30340;&#26680;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#21644;&#32479;&#35745;&#24212;&#29992;&#20013;&#65292;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;(MMD)&#22240;&#20854;&#22788;&#29702;&#38750;&#27431;&#20960;&#37324;&#24471;&#25968;&#25454;&#30340;&#33021;&#21147;&#32780;&#33719;&#24471;&#20102;&#24456;&#22810;&#25104;&#21151;&#65292;&#21253;&#25324;&#38750;&#21442;&#25968;&#20551;&#35774;&#26816;&#39564;&#12290;&#26368;&#36817;&#65292;Balasubramanian&#31561;&#20154;(2021)&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;&#22522;&#20110;MMD&#30340;&#25311;&#21512;&#20248;&#24230;&#26816;&#39564;&#22312;&#36866;&#24403;&#36873;&#25321;&#27491;&#21017;&#21270;&#21442;&#25968;&#26102;&#65292;&#24182;&#19981;&#26159;&#26368;&#23567;&#21270;&#26368;&#22823;&#39118;&#38505;&#65292;&#32780;&#20854;Tikhonov&#27491;&#21017;&#21270;&#29256;&#26412;&#21017;&#26159;&#26368;&#23567;&#21270;&#26368;&#22823;&#39118;&#38505;&#30340;&#12290;&#28982;&#32780;&#65292;Balasubramanian&#31561;&#20154;(2021)&#30340;&#32467;&#26524;&#26159;&#22312;&#22343;&#20540;&#20803;&#32032;&#20026;&#38646;&#30340;&#38480;&#21046;&#24615;&#20551;&#35774;&#21644;&#31215;&#20998;&#25805;&#20316;&#31526;&#29305;&#24449;&#20989;&#25968;&#30340;&#22343;&#21248;&#26377;&#30028;&#24615;&#26465;&#20214;&#19979;&#33719;&#24471;&#30340;&#12290;&#27492;&#22806;&#65292;Balasubramanian&#31561;&#20154;(2021)&#25552;&#20986;&#30340;&#26816;&#39564;&#22312;&#35768;&#22810;&#26680;&#20989;&#25968;&#20013;&#26159;&#19981;&#21487;&#35745;&#31639;&#30340;&#65292;&#22240;&#27492;&#19981;&#23454;&#29992;&#12290;&#26412;&#25991;&#35299;&#20915;&#20102;&#36825;&#20123;&#38382;&#39064;&#65292;&#24182;&#23558;&#32467;&#26524;&#25512;&#24191;&#21040;&#21253;&#25324;Tikhonov&#27491;&#21017;&#21270;&#22312;&#20869;&#30340;&#19968;&#33324;&#35889;&#27491;&#21017;&#21270;&#26041;&#27861;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
Maximum mean discrepancy (MMD) has enjoyed a lot of success in many machine learning and statistical applications, including non-parametric hypothesis testing, because of its ability to handle non-Euclidean data. Recently, it has been demonstrated in Balasubramanian et al.(2021) that the goodness-of-fit test based on MMD is not minimax optimal while a Tikhonov regularized version of it is, for an appropriate choice of the regularization parameter. However, the results in Balasubramanian et al. (2021) are obtained under the restrictive assumptions of the mean element being zero, and the uniform boundedness condition on the eigenfunctions of the integral operator. Moreover, the test proposed in Balasubramanian et al. (2021) is not practical as it is not computable for many kernels. In this paper, we address these shortcomings and extend the results to general spectral regularizers that include Tikhonov regularization.
&lt;/p&gt;</description></item></channel></rss>