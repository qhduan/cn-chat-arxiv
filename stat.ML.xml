<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#32972;&#21253;&#32422;&#26463;&#30340;&#39640;&#32500;&#32447;&#24615;&#36172;&#33218;&#38382;&#39064;&#65292;&#21033;&#29992;&#31232;&#30095;&#32467;&#26500;&#23454;&#29616;&#25913;&#36827;&#36951;&#25022;&#12290;&#36890;&#36807;&#24320;&#21457;&#22312;&#32447;&#30828;&#38408;&#20540;&#31639;&#27861;&#21644;&#21407;&#22987;-&#23545;&#20598;&#26694;&#26550;&#32467;&#21512;&#30340;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#23545;&#29305;&#24449;&#32500;&#24230;&#30340;&#23545;&#25968;&#25913;&#36827;&#30340;&#27425;&#32447;&#24615;&#36951;&#25022;&#12290;</title><link>http://arxiv.org/abs/2311.01327</link><description>&lt;p&gt;
&#20855;&#26377;&#32972;&#21253;&#32422;&#26463;&#30340;&#39640;&#32500;&#32447;&#24615;&#36172;&#33218;&#38382;&#39064;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
High-dimensional Linear Bandits with Knapsacks. (arXiv:2311.01327v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01327
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#32972;&#21253;&#32422;&#26463;&#30340;&#39640;&#32500;&#32447;&#24615;&#36172;&#33218;&#38382;&#39064;&#65292;&#21033;&#29992;&#31232;&#30095;&#32467;&#26500;&#23454;&#29616;&#25913;&#36827;&#36951;&#25022;&#12290;&#36890;&#36807;&#24320;&#21457;&#22312;&#32447;&#30828;&#38408;&#20540;&#31639;&#27861;&#21644;&#21407;&#22987;-&#23545;&#20598;&#26694;&#26550;&#32467;&#21512;&#30340;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#23545;&#29305;&#24449;&#32500;&#24230;&#30340;&#23545;&#25968;&#25913;&#36827;&#30340;&#27425;&#32447;&#24615;&#36951;&#25022;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#29305;&#24449;&#32500;&#24230;&#36739;&#22823;&#30340;&#39640;&#32500;&#35774;&#32622;&#19979;&#30340;&#20855;&#26377;&#32972;&#21253;&#32422;&#26463;&#30340;&#19978;&#19979;&#25991;&#36172;&#33218;&#38382;&#39064;&#12290;&#27599;&#20010;&#25163;&#33218;&#25289;&#21160;&#30340;&#22870;&#21169;&#31561;&#20110;&#31232;&#30095;&#39640;&#32500;&#26435;&#37325;&#21521;&#37327;&#19982;&#24403;&#21069;&#21040;&#36798;&#30340;&#29305;&#24449;&#30340;&#20056;&#31215;&#65292;&#21152;&#19978;&#39069;&#22806;&#30340;&#38543;&#26426;&#22122;&#22768;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#22914;&#20309;&#21033;&#29992;&#36825;&#31181;&#31232;&#30095;&#32467;&#26500;&#26469;&#23454;&#29616;CBwK&#38382;&#39064;&#30340;&#25913;&#36827;&#36951;&#25022;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#39318;&#20808;&#24320;&#21457;&#20102;&#19968;&#31181;&#22312;&#32447;&#30340;&#30828;&#38408;&#20540;&#31639;&#27861;&#30340;&#21464;&#20307;&#65292;&#20197;&#22312;&#32447;&#26041;&#24335;&#36827;&#34892;&#31232;&#30095;&#20272;&#35745;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#23558;&#25105;&#20204;&#30340;&#22312;&#32447;&#20272;&#35745;&#22120;&#19982;&#21407;&#22987;-&#23545;&#20598;&#26694;&#26550;&#32467;&#21512;&#36215;&#26469;&#65292;&#22312;&#27599;&#20010;&#32972;&#21253;&#32422;&#26463;&#19978;&#20998;&#37197;&#19968;&#20010;&#23545;&#20598;&#21464;&#37327;&#65292;&#24182;&#21033;&#29992;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#26469;&#26356;&#26032;&#23545;&#20598;&#21464;&#37327;&#65292;&#20174;&#32780;&#25511;&#21046;&#32972;&#21253;&#23481;&#37327;&#30340;&#28040;&#32791;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#31181;&#38598;&#25104;&#26041;&#27861;&#20351;&#25105;&#20204;&#33021;&#22815;&#23454;&#29616;&#23545;&#29305;&#24449;&#32500;&#24230;&#30340;&#23545;&#25968;&#25913;&#36827;&#30340;&#27425;&#32447;&#24615;&#36951;&#25022;&#65292;&#20174;&#32780;&#25913;&#36827;&#20102;&#22810;&#39033;&#24335;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the contextual bandits with knapsack (CBwK) problem under the high-dimensional setting where the dimension of the feature is large. The reward of pulling each arm equals the multiplication of a sparse high-dimensional weight vector and the feature of the current arrival, with additional random noise. In this paper, we investigate how to exploit this sparsity structure to achieve improved regret for the CBwK problem. To this end, we first develop an online variant of the hard thresholding algorithm that performs the sparse estimation in an online manner. We further combine our online estimator with a primal-dual framework, where we assign a dual variable to each knapsack constraint and utilize an online learning algorithm to update the dual variable, thereby controlling the consumption of the knapsack capacity. We show that this integrated approach allows us to achieve a sublinear regret that depends logarithmically on the feature dimension, thus improving the polynomial depend
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#36890;&#36807;&#27604;&#36739;&#32806;&#21512;&#27969;&#21644;&#33258;&#22238;&#24402;&#27969;&#30340;&#19981;&#21516;&#26550;&#26500;&#21644;&#22810;&#26679;&#30446;&#26631;&#20998;&#24067;&#65292;&#21033;&#29992;&#21508;&#31181;&#27979;&#35797;&#32479;&#35745;&#37327;&#36827;&#34892;&#24615;&#33021;&#27604;&#36739;&#65292;&#20026;&#27491;&#35268;&#21270;&#27969;&#30340;&#29983;&#25104;&#27169;&#22411;&#25552;&#20379;&#20102;&#28145;&#20837;&#30340;&#30740;&#31350;&#21644;&#23454;&#35777;&#35780;&#20272;&#12290;</title><link>http://arxiv.org/abs/2302.12024</link><description>&lt;p&gt;
&#27604;&#36739;&#32806;&#21512;&#27969;&#21644;&#33258;&#22238;&#24402;&#27969;&#30340;&#40065;&#26834;&#32479;&#35745;&#26816;&#39564;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Comparative Study of Coupling and Autoregressive Flows through Robust Statistical Tests. (arXiv:2302.12024v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.12024
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#36890;&#36807;&#27604;&#36739;&#32806;&#21512;&#27969;&#21644;&#33258;&#22238;&#24402;&#27969;&#30340;&#19981;&#21516;&#26550;&#26500;&#21644;&#22810;&#26679;&#30446;&#26631;&#20998;&#24067;&#65292;&#21033;&#29992;&#21508;&#31181;&#27979;&#35797;&#32479;&#35745;&#37327;&#36827;&#34892;&#24615;&#33021;&#27604;&#36739;&#65292;&#20026;&#27491;&#35268;&#21270;&#27969;&#30340;&#29983;&#25104;&#27169;&#22411;&#25552;&#20379;&#20102;&#28145;&#20837;&#30340;&#30740;&#31350;&#21644;&#23454;&#35777;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27491;&#35268;&#21270;&#27969;&#24050;&#32463;&#25104;&#20026;&#19968;&#31181;&#24378;&#22823;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#22240;&#20026;&#23427;&#20204;&#19981;&#20165;&#33021;&#22815;&#26377;&#25928;&#22320;&#23545;&#22797;&#26434;&#30446;&#26631;&#20998;&#24067;&#36827;&#34892;&#37319;&#26679;&#65292;&#32780;&#19988;&#36824;&#36890;&#36807;&#26500;&#36896;&#25552;&#20379;&#23494;&#24230;&#20272;&#35745;&#12290;&#25105;&#20204;&#22312;&#36825;&#37324;&#25552;&#20986;&#20102;&#23545;&#32806;&#21512;&#27969;&#21644;&#33258;&#22238;&#24402;&#27969;&#36827;&#34892;&#28145;&#20837;&#27604;&#36739;&#30340;&#30740;&#31350;&#65292;&#21253;&#25324;&#20223;&#23556;&#21644;&#26377;&#29702;&#20108;&#27425;&#26679;&#26465;&#31867;&#22411;&#30340;&#22235;&#31181;&#19981;&#21516;&#26550;&#26500;&#65306;&#23454;&#20540;&#38750;&#20307;&#31215;&#20445;&#25345;&#65288;RealNVP&#65289;&#12289;&#25513;&#34109;&#33258;&#22238;&#24402;&#27969;&#65288;MAF&#65289;&#12289;&#32806;&#21512;&#26377;&#29702;&#20108;&#27425;&#26679;&#26465;&#65288;C-RQS&#65289;&#21644;&#33258;&#22238;&#24402;&#26377;&#29702;&#20108;&#27425;&#26679;&#26465;&#65288;A-RQS&#65289;&#12290;&#25105;&#20204;&#20851;&#27880;&#19968;&#32452;&#20174;4&#32500;&#21040;400&#32500;&#36882;&#22686;&#30340;&#22810;&#27169;&#24577;&#30446;&#26631;&#20998;&#24067;&#12290;&#36890;&#36807;&#20351;&#29992;&#19981;&#21516;&#30340;&#20004;&#26679;&#26412;&#27979;&#35797;&#30340;&#27979;&#35797;&#32479;&#35745;&#37327;&#36827;&#34892;&#27604;&#36739;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#24050;&#30693;&#36317;&#31163;&#24230;&#37327;&#30340;&#27979;&#35797;&#32479;&#35745;&#37327;&#65306;&#20999;&#29255;Wasserstein&#36317;&#31163;&#12289;&#32500;&#24230;&#24179;&#22343;&#19968;&#32500;Kolmogorov-Smirnov&#26816;&#39564;&#21644;&#30456;&#20851;&#30697;&#38453;&#20043;&#24046;&#30340;Frobenius&#33539;&#25968;&#12290;&#21478;&#22806;&#65292;&#25105;&#20204;&#36824;&#21253;&#25324;&#20102;&#20197;&#19979;&#20272;&#35745;&#65306;
&lt;/p&gt;
&lt;p&gt;
Normalizing Flows have emerged as a powerful brand of generative models, as they not only allow for efficient sampling of complicated target distributions, but also deliver density estimation by construction. We propose here an in-depth comparison of coupling and autoregressive flows, both of the affine and rational quadratic spline type, considering four different architectures: Real-valued Non-Volume Preserving (RealNVP), Masked Autoregressive Flow (MAF), Coupling Rational Quadratic Spline (C-RQS), and Autoregressive Rational Quadratic Spline (A-RQS). We focus on a set of multimodal target distributions of increasing dimensionality ranging from 4 to 400. The performances are compared by means of different test-statistics for two-sample tests, built from known distance measures: the sliced Wasserstein distance, the dimension-averaged one-dimensional Kolmogorov-Smirnov test, and the Frobenius norm of the difference between correlation matrices. Furthermore, we include estimations of th
&lt;/p&gt;</description></item></channel></rss>