<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#36890;&#36807;&#20984;&#32452;&#21512;&#30340;&#26041;&#27861;&#20272;&#35745;&#39640;&#32500;&#31354;&#38388;&#20013;&#19981;&#21516;&#27010;&#29575;&#20998;&#24067;&#30340;&#22810;&#32500;&#22343;&#20540;&#65292;&#24341;&#20837;&#20102;&#20004;&#31181;&#26435;&#37325;&#30830;&#23450;&#31574;&#30053;&#65306;&#19968;&#31181;&#36890;&#36807;&#27979;&#35797;&#31243;&#24207;&#35782;&#21035;&#20302;&#26041;&#24046;&#30340;&#30456;&#37051;&#22343;&#20540;&#65292;&#25552;&#20986;&#20102;&#23553;&#38381;&#24418;&#24335;&#25554;&#34917;&#20844;&#24335;&#65307;&#21478;&#19968;&#31181;&#36890;&#36807;&#26368;&#23567;&#21270;&#20108;&#27425;&#39118;&#38505;&#30340;&#19978;&#32622;&#20449;&#30028;&#30830;&#23450;&#26435;&#37325;&#65292;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#24471;&#20986;&#26041;&#27861;&#23545;&#32463;&#39564;&#22343;&#20540;&#30340;&#20108;&#27425;&#39118;&#38505;&#25913;&#36827;&#65292;&#22312;&#32500;&#24230;&#28176;&#36817;&#30340;&#35282;&#24230;&#19978;&#28176;&#36817;&#22320;&#25509;&#36817; Oracle&#65288;Minimax&#65289;&#25913;&#36827;&#12290;</title><link>https://arxiv.org/abs/2403.15038</link><description>&lt;p&gt;
&#39640;&#32500;&#24773;&#20917;&#19979;&#22810;&#20010;&#22343;&#20540;&#21521;&#37327;&#30340;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Estimation of multiple mean vectors in high dimension
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.15038
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20984;&#32452;&#21512;&#30340;&#26041;&#27861;&#20272;&#35745;&#39640;&#32500;&#31354;&#38388;&#20013;&#19981;&#21516;&#27010;&#29575;&#20998;&#24067;&#30340;&#22810;&#32500;&#22343;&#20540;&#65292;&#24341;&#20837;&#20102;&#20004;&#31181;&#26435;&#37325;&#30830;&#23450;&#31574;&#30053;&#65306;&#19968;&#31181;&#36890;&#36807;&#27979;&#35797;&#31243;&#24207;&#35782;&#21035;&#20302;&#26041;&#24046;&#30340;&#30456;&#37051;&#22343;&#20540;&#65292;&#25552;&#20986;&#20102;&#23553;&#38381;&#24418;&#24335;&#25554;&#34917;&#20844;&#24335;&#65307;&#21478;&#19968;&#31181;&#36890;&#36807;&#26368;&#23567;&#21270;&#20108;&#27425;&#39118;&#38505;&#30340;&#19978;&#32622;&#20449;&#30028;&#30830;&#23450;&#26435;&#37325;&#65292;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#24471;&#20986;&#26041;&#27861;&#23545;&#32463;&#39564;&#22343;&#20540;&#30340;&#20108;&#27425;&#39118;&#38505;&#25913;&#36827;&#65292;&#22312;&#32500;&#24230;&#28176;&#36817;&#30340;&#35282;&#24230;&#19978;&#28176;&#36817;&#22320;&#25509;&#36817; Oracle&#65288;Minimax&#65289;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#33268;&#21147;&#20110;&#22522;&#20110;&#29420;&#31435;&#26679;&#26412;&#22312;&#19968;&#20010;&#20849;&#21516;&#31354;&#38388;&#20013;&#20272;&#35745;&#26469;&#33258;&#19981;&#21516;&#27010;&#29575;&#20998;&#24067;&#30340;&#22810;&#32500;&#22343;&#20540;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#26159;&#36890;&#36807;&#23545;&#36825;&#20123;&#26679;&#26412;&#23548;&#20986;&#30340;&#32463;&#39564;&#22343;&#20540;&#36827;&#34892;&#20984;&#32452;&#21512;&#26469;&#24418;&#25104;&#20272;&#35745;&#37327;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#20004;&#31181;&#31574;&#30053;&#26469;&#25214;&#21040;&#36866;&#24403;&#30340;&#20381;&#36182;&#20110;&#25968;&#25454;&#30340;&#20984;&#32452;&#21512;&#26435;&#37325;&#65306;&#31532;&#19968;&#31181;&#21033;&#29992;&#27979;&#35797;&#31243;&#24207;&#26469;&#35782;&#21035;&#20855;&#26377;&#20302;&#26041;&#24046;&#30340;&#30456;&#37051;&#22343;&#20540;&#65292;&#20174;&#32780;&#20135;&#29983;&#20102;&#19968;&#20010;&#20851;&#20110;&#26435;&#37325;&#30340;&#23553;&#38381;&#24418;&#24335;&#25554;&#34917;&#20844;&#24335;&#65307;&#31532;&#20108;&#31181;&#36890;&#36807;&#26368;&#23567;&#21270;&#20108;&#27425;&#39118;&#38505;&#30340;&#19978;&#32622;&#20449;&#21306;&#38388;&#26469;&#30830;&#23450;&#26435;&#37325;&#12290;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#65292;&#25105;&#20204;&#35780;&#20272;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#30456;&#23545;&#20110;&#32463;&#39564;&#22343;&#20540;&#25552;&#20379;&#30340;&#20108;&#27425;&#39118;&#38505;&#25913;&#36827;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#38598;&#20013;&#22312;&#32500;&#24230;&#28176;&#36817;&#30340;&#35282;&#24230;&#19978;&#65292;&#26174;&#31034;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#25968;&#25454;&#30340;&#26377;&#25928;&#32500;&#24230;&#22686;&#21152;&#26102;&#28176;&#36817;&#22320;&#25509;&#36817;&#20110;&#19968;&#20010; Oracle&#65288;Minimax&#65289;&#25913;&#36827;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36890;&#36807;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#22343;&#20540;&#20272;&#35745;&#20013;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.15038v1 Announce Type: cross  Abstract: We endeavour to estimate numerous multi-dimensional means of various probability distributions on a common space based on independent samples. Our approach involves forming estimators through convex combinations of empirical means derived from these samples. We introduce two strategies to find appropriate data-dependent convex combination weights: a first one employing a testing procedure to identify neighbouring means with low variance, which results in a closed-form plug-in formula for the weights, and a second one determining weights via minimization of an upper confidence bound on the quadratic risk.Through theoretical analysis, we evaluate the improvement in quadratic risk offered by our methods compared to the empirical means. Our analysis focuses on a dimensional asymptotics perspective, showing that our methods asymptotically approach an oracle (minimax) improvement as the effective dimension of the data increases.We demonstrat
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#27599;&#20010;&#25968;&#25454;&#28857;&#30340;&#25104;&#21592;&#25512;&#26029;&#25915;&#20987;&#65292;&#37327;&#21270;&#20102;&#27599;&#20010;&#25968;&#25454;&#28857;&#30340;&#25104;&#21592;&#27844;&#38706;&#65292;&#24182;&#35780;&#20272;&#20102;&#20004;&#31181;&#38544;&#31169;&#38450;&#24481;&#25514;&#26045;&#30340;&#25928;&#26524;&#12290;</title><link>https://arxiv.org/abs/2402.10065</link><description>&lt;p&gt;
&#27599;&#20010;&#25968;&#25454;&#28857;&#27844;&#38706;&#24744;&#38544;&#31169;&#30340;&#31243;&#24230;&#26377;&#22810;&#22823;&#65311;&#37327;&#21270;&#27599;&#20010;&#25968;&#25454;&#28857;&#30340;&#25104;&#21592;&#27844;&#38706;
&lt;/p&gt;
&lt;p&gt;
How Much Does Each Datapoint Leak Your Privacy? Quantifying the Per-datum Membership Leakage
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10065
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#27599;&#20010;&#25968;&#25454;&#28857;&#30340;&#25104;&#21592;&#25512;&#26029;&#25915;&#20987;&#65292;&#37327;&#21270;&#20102;&#27599;&#20010;&#25968;&#25454;&#28857;&#30340;&#25104;&#21592;&#27844;&#38706;&#65292;&#24182;&#35780;&#20272;&#20102;&#20004;&#31181;&#38544;&#31169;&#38450;&#24481;&#25514;&#26045;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#27599;&#20010;&#25968;&#25454;&#28857;&#30340;&#25104;&#21592;&#25512;&#26029;&#25915;&#20987;&#65288;MIAs&#65289;&#65292;&#20854;&#20013;&#25915;&#20987;&#32773;&#26088;&#22312;&#25512;&#26029;&#20986;&#19968;&#20010;&#22266;&#23450;&#30446;&#26631;&#25968;&#25454;&#26159;&#21542;&#24050;&#21253;&#21547;&#22312;&#31639;&#27861;&#30340;&#36755;&#20837;&#25968;&#25454;&#38598;&#20013;&#65292;&#20174;&#32780;&#20405;&#29359;&#38544;&#31169;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#23450;&#20041;&#27599;&#20010;&#25968;&#25454;&#28857;&#30340;&#25104;&#21592;&#27844;&#38706;&#20026;&#26368;&#20248;&#23545;&#25163;&#36776;&#35782;&#23427;&#30340;&#20248;&#21183;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#37327;&#21270;&#20102;&#32463;&#39564;&#22343;&#20540;&#30340;&#27599;&#20010;&#25968;&#25454;&#28857;&#30340;&#25104;&#21592;&#27844;&#38706;&#65292;&#24182;&#34920;&#26126;&#23427;&#21462;&#20915;&#20110;&#30446;&#26631;&#25968;&#25454;&#28857;&#21644;&#25968;&#25454;&#29983;&#25104;&#20998;&#24067;&#20043;&#38388;&#30340;&#39532;&#27663;&#36317;&#31163;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#35780;&#20272;&#20102;&#20004;&#31181;&#38544;&#31169;&#38450;&#24481;&#25514;&#26045;&#30340;&#25928;&#26524;&#65292;&#21363;&#28155;&#21152;&#39640;&#26031;&#22122;&#22768;&#21644;&#23376;&#37319;&#26679;&#12290;&#25105;&#20204;&#20934;&#30830;&#22320;&#37327;&#21270;&#20102;&#23427;&#20204;&#37117;&#22914;&#20309;&#38477;&#20302;&#27599;&#20010;&#25968;&#25454;&#28857;&#30340;&#25104;&#21592;&#27844;&#38706;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#24314;&#31435;&#22312;&#19968;&#20010;&#32467;&#21512;&#20102;&#20284;&#28982;&#27604;&#26816;&#39564;&#30340;Edgeworth&#23637;&#24320;&#21644;Lindeberg-Feller&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#30340;&#26032;&#22411;&#35777;&#26126;&#25216;&#26415;&#19978;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#36830;&#25509;&#20102;&#29616;&#26377;&#30340;&#20284;&#28982;&#27604;&#21644;&#26631;&#37327;&#20056;&#31215;&#25915;&#20987;&#65292;&#24182;&#23545;&#36825;&#20123;&#25915;&#20987;&#36827;&#34892;&#20102;&#35770;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10065v1 Announce Type: new  Abstract: We study the per-datum Membership Inference Attacks (MIAs), where an attacker aims to infer whether a fixed target datum has been included in the input dataset of an algorithm and thus, violates privacy. First, we define the membership leakage of a datum as the advantage of the optimal adversary targeting to identify it. Then, we quantify the per-datum membership leakage for the empirical mean, and show that it depends on the Mahalanobis distance between the target datum and the data-generating distribution. We further assess the effect of two privacy defences, i.e. adding Gaussian noise and sub-sampling. We quantify exactly how both of them decrease the per-datum membership leakage. Our analysis builds on a novel proof technique that combines an Edgeworth expansion of the likelihood ratio test and a Lindeberg-Feller central limit theorem. Our analysis connects the existing likelihood ratio and scalar product attacks, and also justifies 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25551;&#36848;&#20102;CNN&#20013;&#21367;&#31215;&#29942;&#39048;&#65288;CBN&#65289;&#32467;&#26500;&#30340;&#20986;&#29616;&#65292;&#32593;&#32476;&#22312;&#21069;&#20960;&#23618;&#23558;&#36755;&#20837;&#34920;&#31034;&#36716;&#25442;&#20026;&#22312;&#23569;&#25968;&#39057;&#29575;&#21644;&#36890;&#36947;&#19978;&#21463;&#25903;&#25345;&#30340;&#34920;&#31034;&#65292;&#28982;&#21518;&#36890;&#36807;&#26368;&#21518;&#20960;&#23618;&#26144;&#23556;&#22238;&#36755;&#20986;&#12290;CBN&#31209;&#23450;&#20041;&#20102;&#20445;&#30041;&#22312;&#29942;&#39048;&#20013;&#30340;&#39057;&#29575;&#30340;&#25968;&#37327;&#21644;&#31867;&#22411;&#65292;&#24182;&#37096;&#20998;&#35777;&#26126;&#20102;&#21442;&#25968;&#33539;&#25968;&#19982;&#28145;&#24230;&#21644;CBN&#31209;&#30340;&#27604;&#20363;&#25104;&#27491;&#27604;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#32593;&#32476;&#30340;&#21442;&#25968;&#33539;&#25968;&#20381;&#36182;&#20110;&#20989;&#25968;&#30340;&#35268;&#21017;&#24615;&#12290;&#25105;&#20204;&#21457;&#29616;&#20219;&#20309;&#20855;&#26377;&#25509;&#36817;&#26368;&#20248;&#21442;&#25968;&#33539;&#25968;&#30340;&#32593;&#32476;&#37117;&#20250;&#23637;&#31034;&#20986;CBN&#32467;&#26500;&#65292;&#36825;&#35299;&#37322;&#20102;&#19979;&#37319;&#26679;&#30340;&#24120;&#35265;&#23454;&#36341;&#65307;&#25105;&#20204;&#36824;&#39564;&#35777;&#20102;CBN&#32467;&#26500;&#22312;&#19979;&#37319;&#26679;&#19979;&#20173;&#28982;&#25104;&#31435;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;CBN&#32467;&#26500;&#26469;&#35299;&#37322;...&#65288;&#25688;&#35201;&#23436;&#25972;&#20869;&#23481;&#35831;&#35265;&#27491;&#25991;&#65289;</title><link>https://arxiv.org/abs/2402.08010</link><description>&lt;p&gt;
CNN&#38656;&#35201;&#21738;&#20123;&#39057;&#29575;&#65311;&#29305;&#24449;&#23398;&#20064;&#20013;&#30340;&#32039;&#24613;&#29942;&#39048;&#32467;&#26500;&#30340;&#20986;&#29616;
&lt;/p&gt;
&lt;p&gt;
Which Frequencies do CNNs Need? Emergent Bottleneck Structure in Feature Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08010
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25551;&#36848;&#20102;CNN&#20013;&#21367;&#31215;&#29942;&#39048;&#65288;CBN&#65289;&#32467;&#26500;&#30340;&#20986;&#29616;&#65292;&#32593;&#32476;&#22312;&#21069;&#20960;&#23618;&#23558;&#36755;&#20837;&#34920;&#31034;&#36716;&#25442;&#20026;&#22312;&#23569;&#25968;&#39057;&#29575;&#21644;&#36890;&#36947;&#19978;&#21463;&#25903;&#25345;&#30340;&#34920;&#31034;&#65292;&#28982;&#21518;&#36890;&#36807;&#26368;&#21518;&#20960;&#23618;&#26144;&#23556;&#22238;&#36755;&#20986;&#12290;CBN&#31209;&#23450;&#20041;&#20102;&#20445;&#30041;&#22312;&#29942;&#39048;&#20013;&#30340;&#39057;&#29575;&#30340;&#25968;&#37327;&#21644;&#31867;&#22411;&#65292;&#24182;&#37096;&#20998;&#35777;&#26126;&#20102;&#21442;&#25968;&#33539;&#25968;&#19982;&#28145;&#24230;&#21644;CBN&#31209;&#30340;&#27604;&#20363;&#25104;&#27491;&#27604;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#32593;&#32476;&#30340;&#21442;&#25968;&#33539;&#25968;&#20381;&#36182;&#20110;&#20989;&#25968;&#30340;&#35268;&#21017;&#24615;&#12290;&#25105;&#20204;&#21457;&#29616;&#20219;&#20309;&#20855;&#26377;&#25509;&#36817;&#26368;&#20248;&#21442;&#25968;&#33539;&#25968;&#30340;&#32593;&#32476;&#37117;&#20250;&#23637;&#31034;&#20986;CBN&#32467;&#26500;&#65292;&#36825;&#35299;&#37322;&#20102;&#19979;&#37319;&#26679;&#30340;&#24120;&#35265;&#23454;&#36341;&#65307;&#25105;&#20204;&#36824;&#39564;&#35777;&#20102;CBN&#32467;&#26500;&#22312;&#19979;&#37319;&#26679;&#19979;&#20173;&#28982;&#25104;&#31435;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;CBN&#32467;&#26500;&#26469;&#35299;&#37322;...&#65288;&#25688;&#35201;&#23436;&#25972;&#20869;&#23481;&#35831;&#35265;&#27491;&#25991;&#65289;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25551;&#36848;&#20102;CNN&#20013;&#21367;&#31215;&#29942;&#39048;&#65288;CBN&#65289;&#32467;&#26500;&#30340;&#20986;&#29616;&#65292;&#32593;&#32476;&#20351;&#29992;&#20854;&#21069;&#20960;&#23618;&#23558;&#36755;&#20837;&#34920;&#31034;&#36716;&#25442;&#20026;&#20165;&#22312;&#20960;&#20010;&#39057;&#29575;&#21644;&#36890;&#36947;&#19978;&#21463;&#25903;&#25345;&#30340;&#34920;&#31034;&#65292;&#28982;&#21518;&#20351;&#29992;&#26368;&#21518;&#20960;&#23618;&#23558;&#20854;&#26144;&#23556;&#22238;&#36755;&#20986;&#12290;&#25105;&#20204;&#23450;&#20041;&#20102;CBN&#31209;&#65292;&#25551;&#36848;&#20102;&#20445;&#30041;&#22312;&#29942;&#39048;&#20869;&#30340;&#39057;&#29575;&#30340;&#25968;&#37327;&#21644;&#31867;&#22411;&#65292;&#24182;&#22312;&#19968;&#23450;&#31243;&#24230;&#19978;&#35777;&#26126;&#20102;&#34920;&#31034;&#20989;&#25968;$f$&#25152;&#38656;&#30340;&#21442;&#25968;&#33539;&#25968;&#25353;&#28145;&#24230;&#20056;&#20197;CBN&#31209;$f$&#30340;&#27604;&#20363;&#32553;&#25918;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#21442;&#25968;&#33539;&#25968;&#22312;&#19979;&#19968;&#38454;&#20013;&#20381;&#36182;&#20110;$f$&#30340;&#27491;&#21017;&#24615;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#20219;&#20309;&#20855;&#26377;&#36817;&#20046;&#26368;&#20248;&#21442;&#25968;&#33539;&#25968;&#30340;&#32593;&#32476;&#37117;&#20250;&#22312;&#26435;&#37325;&#21644;&#65288;&#22312;&#32593;&#32476;&#23545;&#22823;&#23398;&#20064;&#29575;&#31283;&#23450;&#30340;&#20551;&#35774;&#19979;&#65289;&#28608;&#27963;&#20013;&#34920;&#29616;&#20986;CBN&#32467;&#26500;&#65292;&#36825;&#20419;&#20351;&#20102;&#19979;&#37319;&#26679;&#30340;&#24120;&#35265;&#20570;&#27861;&#65307;&#24182;&#19988;&#25105;&#20204;&#39564;&#35777;&#20102;CBN&#32467;&#26500;&#22312;&#19979;&#37319;&#26679;&#19979;&#20173;&#28982;&#25104;&#31435;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;CBN&#32467;&#26500;&#26469;&#35299;&#37322;...
&lt;/p&gt;
&lt;p&gt;
We describe the emergence of a Convolution Bottleneck (CBN) structure in CNNs, where the network uses its first few layers to transform the input representation into a representation that is supported only along a few frequencies and channels, before using the last few layers to map back to the outputs. We define the CBN rank, which describes the number and type of frequencies that are kept inside the bottleneck, and partially prove that the parameter norm required to represent a function $f$ scales as depth times the CBN rank $f$. We also show that the parameter norm depends at next order on the regularity of $f$. We show that any network with almost optimal parameter norm will exhibit a CBN structure in both the weights and - under the assumption that the network is stable under large learning rate - the activations, which motivates the common practice of down-sampling; and we verify that the CBN results still hold with down-sampling. Finally we use the CBN structure to interpret the
&lt;/p&gt;</description></item><item><title>PQMass&#26159;&#19968;&#31181;&#20351;&#29992;&#27010;&#29575;&#36136;&#37327;&#20272;&#35745;&#26469;&#35780;&#20272;&#29983;&#25104;&#27169;&#22411;&#36136;&#37327;&#30340;&#20840;&#38754;&#26041;&#27861;&#65292;&#33021;&#22815;&#30452;&#25509;&#22788;&#29702;&#39640;&#32500;&#25968;&#25454;&#65292;&#19981;&#20381;&#36182;&#20110;&#20551;&#35774;&#25110;&#35757;&#32451;&#20854;&#20182;&#27169;&#22411;&#12290;</title><link>https://arxiv.org/abs/2402.04355</link><description>&lt;p&gt;
PQMass: &#20351;&#29992;&#27010;&#29575;&#36136;&#37327;&#20272;&#35745;&#30340;&#29983;&#25104;&#27169;&#22411;&#36136;&#37327;&#30340;&#27010;&#29575;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
PQMass: Probabilistic Assessment of the Quality of Generative Models using Probability Mass Estimation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04355
&lt;/p&gt;
&lt;p&gt;
PQMass&#26159;&#19968;&#31181;&#20351;&#29992;&#27010;&#29575;&#36136;&#37327;&#20272;&#35745;&#26469;&#35780;&#20272;&#29983;&#25104;&#27169;&#22411;&#36136;&#37327;&#30340;&#20840;&#38754;&#26041;&#27861;&#65292;&#33021;&#22815;&#30452;&#25509;&#22788;&#29702;&#39640;&#32500;&#25968;&#25454;&#65292;&#19981;&#20381;&#36182;&#20110;&#20551;&#35774;&#25110;&#35757;&#32451;&#20854;&#20182;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20840;&#38754;&#30340;&#22522;&#20110;&#26679;&#26412;&#30340;&#26041;&#27861;&#26469;&#35780;&#20272;&#29983;&#25104;&#27169;&#22411;&#30340;&#36136;&#37327;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#33021;&#22815;&#20272;&#35745;&#20004;&#20010;&#26679;&#26412;&#38598;&#21512;&#26469;&#33258;&#21516;&#19968;&#20998;&#24067;&#30340;&#27010;&#29575;&#65292;&#20026;&#35780;&#20272;&#21333;&#20010;&#29983;&#25104;&#27169;&#22411;&#30340;&#24615;&#33021;&#25110;&#27604;&#36739;&#22312;&#21516;&#19968;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#30340;&#22810;&#20010;&#31454;&#20105;&#27169;&#22411;&#25552;&#20379;&#20102;&#19968;&#20010;&#32479;&#35745;&#19978;&#20005;&#26684;&#30340;&#26041;&#27861;&#12290;&#35813;&#27604;&#36739;&#21487;&#20197;&#36890;&#36807;&#23558;&#31354;&#38388;&#21010;&#20998;&#20026;&#38750;&#37325;&#21472;&#30340;&#21306;&#22495;&#24182;&#27604;&#36739;&#27599;&#20010;&#21306;&#22495;&#20013;&#30340;&#25968;&#25454;&#26679;&#26412;&#25968;&#37327;&#26469;&#36827;&#34892;&#12290;&#35813;&#26041;&#27861;&#20165;&#38656;&#35201;&#29983;&#25104;&#27169;&#22411;&#21644;&#27979;&#35797;&#25968;&#25454;&#30340;&#26679;&#26412;&#12290;&#23427;&#33021;&#22815;&#30452;&#25509;&#22788;&#29702;&#39640;&#32500;&#25968;&#25454;&#65292;&#26080;&#38656;&#38477;&#32500;&#12290;&#26174;&#33879;&#30340;&#26159;&#65292;&#35813;&#26041;&#27861;&#19981;&#20381;&#36182;&#20110;&#20851;&#20110;&#30495;&#23454;&#20998;&#24067;&#23494;&#24230;&#30340;&#20551;&#35774;&#65292;&#24182;&#19988;&#19981;&#20381;&#36182;&#20110;&#35757;&#32451;&#25110;&#25311;&#21512;&#20219;&#20309;&#36741;&#21161;&#27169;&#22411;&#12290;&#30456;&#21453;&#65292;&#23427;&#30528;&#37325;&#20110;&#36817;&#20284;&#35745;&#31639;&#23494;&#24230;&#30340;&#31215;&#20998;&#65288;&#27010;&#29575;&#36136;&#37327;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a comprehensive sample-based method for assessing the quality of generative models. The proposed approach enables the estimation of the probability that two sets of samples are drawn from the same distribution, providing a statistically rigorous method for assessing the performance of a single generative model or the comparison of multiple competing models trained on the same dataset. This comparison can be conducted by dividing the space into non-overlapping regions and comparing the number of data samples in each region. The method only requires samples from the generative model and the test data. It is capable of functioning directly on high-dimensional data, obviating the need for dimensionality reduction. Significantly, the proposed method does not depend on assumptions regarding the density of the true distribution, and it does not rely on training or fitting any auxiliary models. Instead, it focuses on approximating the integral of the density (probability mass) acros
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#23558;&#35757;&#32451;&#25439;&#22833;&#26799;&#24230;&#21644;&#36741;&#21161;&#26799;&#24230;&#22312;&#35757;&#32451;&#26799;&#24230;&#26041;&#21521;&#19978;&#30340;&#27491;&#20132;&#25237;&#24433;&#32467;&#21512;&#36215;&#26469;&#65292;&#20351;&#29992;EMA&#65288;&#25351;&#25968;&#31227;&#21160;&#24179;&#22343;&#65289;&#21487;&#20197;&#25913;&#36827;&#26799;&#24230;&#25163;&#26415;&#65292;&#25552;&#39640;&#28145;&#24230;&#23398;&#20064;&#20272;&#35745;&#31649;&#36947;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.02998</link><description>&lt;p&gt;
&#23567;&#24515;&#20351;&#29992;&#25163;&#26415;&#20992;&#65306;&#20351;&#29992;EMA&#25913;&#36827;&#26799;&#24230;&#25163;&#26415;
&lt;/p&gt;
&lt;p&gt;
Careful with that Scalpel: Improving Gradient Surgery with an EMA
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02998
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23558;&#35757;&#32451;&#25439;&#22833;&#26799;&#24230;&#21644;&#36741;&#21161;&#26799;&#24230;&#22312;&#35757;&#32451;&#26799;&#24230;&#26041;&#21521;&#19978;&#30340;&#27491;&#20132;&#25237;&#24433;&#32467;&#21512;&#36215;&#26469;&#65292;&#20351;&#29992;EMA&#65288;&#25351;&#25968;&#31227;&#21160;&#24179;&#22343;&#65289;&#21487;&#20197;&#25913;&#36827;&#26799;&#24230;&#25163;&#26415;&#65292;&#25552;&#39640;&#28145;&#24230;&#23398;&#20064;&#20272;&#35745;&#31649;&#36947;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#28145;&#24230;&#23398;&#20064;&#20272;&#35745;&#31649;&#36947;&#20013;&#65292;&#38500;&#20102;&#26368;&#23567;&#21270;&#21333;&#19968;&#30340;&#35757;&#32451;&#25439;&#22833;&#22806;&#65292;&#36824;&#20381;&#36182;&#20110;&#36741;&#21161;&#30446;&#26631;&#26469;&#37327;&#21270;&#21644;&#40723;&#21169;&#27169;&#22411;&#30340;&#21487;&#21462;&#23646;&#24615;&#65288;&#20363;&#22914;&#22312;&#21478;&#19968;&#20010;&#25968;&#25454;&#38598;&#19978;&#30340;&#34920;&#29616;&#65292;&#40065;&#26834;&#24615;&#65292;&#19982;&#20808;&#21069;&#30340;&#19968;&#33268;&#24615;&#65289;&#12290;&#34429;&#28982;&#23558;&#36741;&#21161;&#25439;&#22833;&#19982;&#35757;&#32451;&#25439;&#22833;&#30456;&#21152;&#20316;&#20026;&#27491;&#21017;&#21270;&#30340;&#26368;&#31616;&#21333;&#26041;&#27861;&#65292;&#20294;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#36890;&#36807;&#28151;&#21512;&#26799;&#24230;&#32780;&#19981;&#20165;&#20165;&#26159;&#31616;&#21333;&#30456;&#21152;&#65292;&#21487;&#20197;&#25552;&#39640;&#24615;&#33021;&#65307;&#36825;&#34987;&#31216;&#20026;&#26799;&#24230;&#25163;&#26415;&#12290;&#25105;&#20204;&#23558;&#36825;&#20010;&#38382;&#39064;&#30475;&#20316;&#26159;&#19968;&#20010;&#32422;&#26463;&#26368;&#23567;&#21270;&#38382;&#39064;&#65292;&#20854;&#20013;&#36741;&#21161;&#30446;&#26631;&#22312;&#35757;&#32451;&#25439;&#22833;&#30340;&#26368;&#23567;&#21270;&#38598;&#21512;&#20013;&#34987;&#26368;&#23567;&#21270;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#21452;&#23618;&#38382;&#39064;&#65292;&#25105;&#20204;&#37319;&#29992;&#20102;&#19968;&#20010;&#21442;&#25968;&#26356;&#26032;&#26041;&#21521;&#65292;&#23427;&#23558;&#35757;&#32451;&#25439;&#22833;&#26799;&#24230;&#21644;&#36741;&#21161;&#26799;&#24230;&#22312;&#35757;&#32451;&#26799;&#24230;&#26041;&#21521;&#19978;&#30340;&#27491;&#20132;&#25237;&#24433;&#32467;&#21512;&#36215;&#26469;&#12290;&#22312;&#26799;&#24230;&#26469;&#33258;&#23567;&#25209;&#27425;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#35299;&#37322;&#20102;&#22914;&#20309;&#20351;&#29992;&#35757;&#32451;&#25439;&#22833;&#26799;&#24230;&#30340;&#31227;&#21160;&#24179;&#22343;&#26469;&#32500;&#25252;&#12290;
&lt;/p&gt;
&lt;p&gt;
Beyond minimizing a single training loss, many deep learning estimation pipelines rely on an auxiliary objective to quantify and encourage desirable properties of the model (e.g. performance on another dataset, robustness, agreement with a prior). Although the simplest approach to incorporating an auxiliary loss is to sum it with the training loss as a regularizer, recent works have shown that one can improve performance by blending the gradients beyond a simple sum; this is known as gradient surgery. We cast the problem as a constrained minimization problem where the auxiliary objective is minimized among the set of minimizers of the training loss. To solve this bilevel problem, we follow a parameter update direction that combines the training loss gradient and the orthogonal projection of the auxiliary gradient to the training gradient. In a setting where gradients come from mini-batches, we explain how, using a moving average of the training loss gradients, we can carefully maintain
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#35268;&#33539;&#21270;&#27491;&#24577;&#27969;&#26041;&#27861;&#65292;&#29992;&#20110;&#27969;&#24418;&#23398;&#20064;&#12290;&#36890;&#36807;&#21487;&#23398;&#20064;&#30340;&#21487;&#36870;&#21464;&#25442;&#23558;&#25968;&#25454;&#23884;&#20837;&#21040;&#39640;&#32500;&#31354;&#38388;&#20013;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#22312;&#27969;&#24418;&#19978;&#35745;&#31639;&#27010;&#29575;&#23494;&#24230;&#24182;&#20248;&#21270;&#32593;&#32476;&#21442;&#25968;&#30340;&#30446;&#26631;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#30340;&#26041;&#27861;&#22312;&#23398;&#20064;&#21040;&#30340;&#27969;&#24418;&#34920;&#31034;&#20013;&#23384;&#22312;&#30528;&#19982;&#27969;&#24418;&#20851;&#32852;&#19988;&#36864;&#21270;&#30340;&#20869;&#22312;&#22522;&#20989;&#25968;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.12743</link><description>&lt;p&gt;
&#27969;&#24418;&#23398;&#20064;&#30340;&#35268;&#33539;&#21270;&#27491;&#24577;&#27969;
&lt;/p&gt;
&lt;p&gt;
Canonical normalizing flows for manifold learning. (arXiv:2310.12743v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12743
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#35268;&#33539;&#21270;&#27491;&#24577;&#27969;&#26041;&#27861;&#65292;&#29992;&#20110;&#27969;&#24418;&#23398;&#20064;&#12290;&#36890;&#36807;&#21487;&#23398;&#20064;&#30340;&#21487;&#36870;&#21464;&#25442;&#23558;&#25968;&#25454;&#23884;&#20837;&#21040;&#39640;&#32500;&#31354;&#38388;&#20013;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#22312;&#27969;&#24418;&#19978;&#35745;&#31639;&#27010;&#29575;&#23494;&#24230;&#24182;&#20248;&#21270;&#32593;&#32476;&#21442;&#25968;&#30340;&#30446;&#26631;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#30340;&#26041;&#27861;&#22312;&#23398;&#20064;&#21040;&#30340;&#27969;&#24418;&#34920;&#31034;&#20013;&#23384;&#22312;&#30528;&#19982;&#27969;&#24418;&#20851;&#32852;&#19988;&#36864;&#21270;&#30340;&#20869;&#22312;&#22522;&#20989;&#25968;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27969;&#24418;&#23398;&#20064;&#27969;&#26159;&#19968;&#31867;&#29983;&#25104;&#24314;&#27169;&#25216;&#26415;&#65292;&#20551;&#35774;&#25968;&#25454;&#20855;&#26377;&#20302;&#32500;&#27969;&#24418;&#25551;&#36848;&#12290;&#36890;&#36807;&#21487;&#23398;&#20064;&#30340;&#21487;&#36870;&#21464;&#25442;&#23558;&#36825;&#31181;&#27969;&#24418;&#23884;&#20837;&#21040;&#25968;&#25454;&#30340;&#39640;&#32500;&#31354;&#38388;&#20013;&#12290;&#22240;&#27492;&#65292;&#19968;&#26086;&#36890;&#36807;&#37325;&#26500;&#25439;&#22833;&#27491;&#30830;&#23545;&#40784;&#27969;&#24418;&#65292;&#27969;&#24418;&#19978;&#30340;&#27010;&#29575;&#23494;&#24230;&#23601;&#26159;&#21487;&#35745;&#31639;&#30340;&#65292;&#24182;&#19988;&#21487;&#20197;&#20351;&#29992;&#26368;&#22823;&#20284;&#28982;&#26469;&#20248;&#21270;&#32593;&#32476;&#21442;&#25968;&#12290;&#33258;&#28982;&#22320;&#65292;&#25968;&#25454;&#30340;&#20302;&#32500;&#34920;&#31034;&#38656;&#35201;&#26159;&#21333;&#23556;&#26144;&#23556;&#12290;&#26368;&#36817;&#30340;&#26041;&#27861;&#33021;&#22815;&#22312;&#24314;&#27169;&#30340;&#27969;&#24418;&#19978;&#23545;&#23494;&#24230;&#36827;&#34892;&#23545;&#20934;&#65292;&#24182;&#22312;&#23884;&#20837;&#21040;&#39640;&#32500;&#31354;&#38388;&#26102;&#39640;&#25928;&#35745;&#31639;&#23494;&#24230;&#20307;&#31215;&#21464;&#21270;&#39033;&#12290;&#28982;&#32780;&#65292;&#38500;&#38750;&#21333;&#23556;&#26144;&#23556;&#22312;&#35299;&#26512;&#19978;&#39044;&#23450;&#20041;&#65292;&#21542;&#21017;&#23398;&#20064;&#21040;&#30340;&#27969;&#24418;&#19981;&#19968;&#23450;&#26159;&#25968;&#25454;&#30340;&#26377;&#25928;&#34920;&#31034;&#12290;&#20063;&#23601;&#26159;&#35828;&#65292;&#36825;&#31181;&#27169;&#22411;&#30340;&#28508;&#22312;&#32500;&#24230;&#32463;&#24120;&#20250;&#23398;&#20064;&#21040;&#19982;&#27969;&#24418;&#30456;&#20851;&#24182;&#19988;&#36864;&#21270;&#30340;&#20869;&#22312;&#22522;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Manifold learning flows are a class of generative modelling techniques that assume a low-dimensional manifold description of the data. The embedding of such manifold into the high-dimensional space of the data is achieved via learnable invertible transformations. Therefore, once the manifold is properly aligned via a reconstruction loss, the probability density is tractable on the manifold and maximum likelihood can be used optimize the network parameters. Naturally, the lower-dimensional representation of the data requires an injective-mapping. Recent approaches were able to enforce that density aligns with the modelled manifold, while efficiently calculating the density volume-change term when embedding to the higher-dimensional space. However, unless the injective-mapping is analytically predefined, the learned manifold is not necessarily an efficient representation of the data. Namely, the latent dimensions of such models frequently learn an entangled intrinsic basis with degenerat
&lt;/p&gt;</description></item><item><title>&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#20852;&#30340;&#22312;&#32447;&#38750;&#38543;&#26426;&#25511;&#21046;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#19968;&#32452;&#31574;&#30053;&#20013;&#23547;&#25214;&#20302;&#21518;&#24724;&#65292;&#33719;&#24471;&#23545;&#26368;&#20248;&#31574;&#30053;&#30340;&#36817;&#20284;&#12290;</title><link>http://arxiv.org/abs/2211.09619</link><description>&lt;p&gt;
&#22312;&#32447;&#38750;&#38543;&#26426;&#25511;&#21046;&#31616;&#20171;
&lt;/p&gt;
&lt;p&gt;
Introduction to Online Nonstochastic Control. (arXiv:2211.09619v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.09619
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#20852;&#30340;&#22312;&#32447;&#38750;&#38543;&#26426;&#25511;&#21046;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#19968;&#32452;&#31574;&#30053;&#20013;&#23547;&#25214;&#20302;&#21518;&#24724;&#65292;&#33719;&#24471;&#23545;&#26368;&#20248;&#31574;&#30053;&#30340;&#36817;&#20284;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#20852;&#30340;&#21160;&#24577;&#31995;&#32479;&#25511;&#21046;&#19982;&#21487;&#24494;&#24378;&#21270;&#23398;&#20064;&#33539;&#24335;&#8212;&#8212;&#22312;&#32447;&#38750;&#38543;&#26426;&#25511;&#21046;&#65292;&#24182;&#24212;&#29992;&#22312;&#32447;&#20984;&#20248;&#21270;&#21644;&#20984;&#26494;&#24347;&#25216;&#26415;&#24471;&#21040;&#20102;&#20855;&#26377;&#21487;&#35777;&#26126;&#20445;&#35777;&#30340;&#26032;&#26041;&#27861;&#65292;&#22312;&#26368;&#20339;&#21644;&#40065;&#26834;&#25511;&#21046;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#25104;&#26524;&#12290;&#19982;&#20854;&#20182;&#26694;&#26550;&#19981;&#21516;&#65292;&#35813;&#26041;&#27861;&#30340;&#30446;&#26631;&#26159;&#23545;&#25239;&#24615;&#25915;&#20987;&#65292;&#22312;&#26080;&#27861;&#39044;&#27979;&#25200;&#21160;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#22312;&#19968;&#32452;&#31574;&#30053;&#20013;&#23547;&#25214;&#20302;&#21518;&#24724;&#65292;&#33719;&#24471;&#23545;&#26368;&#20248;&#31574;&#30053;&#30340;&#36817;&#20284;&#12290;
&lt;/p&gt;
&lt;p&gt;
This text presents an introduction to an emerging paradigm in control of dynamical systems and differentiable reinforcement learning called online nonstochastic control. The new approach applies techniques from online convex optimization and convex relaxations to obtain new methods with provable guarantees for classical settings in optimal and robust control.  The primary distinction between online nonstochastic control and other frameworks is the objective. In optimal control, robust control, and other control methodologies that assume stochastic noise, the goal is to perform comparably to an offline optimal strategy. In online nonstochastic control, both the cost functions as well as the perturbations from the assumed dynamical model are chosen by an adversary. Thus the optimal policy is not defined a priori. Rather, the target is to attain low regret against the best policy in hindsight from a benchmark class of policies.  This objective suggests the use of the decision making frame
&lt;/p&gt;</description></item></channel></rss>