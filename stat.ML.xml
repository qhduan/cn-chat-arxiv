<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#35770;&#25991;&#36890;&#36807;&#24314;&#31435;&#26497;&#22823;&#20284;&#28982;&#20272;&#35745;&#37327;&#30340;&#28176;&#36817;&#27491;&#24577;&#24615;&#32467;&#26524;&#65292;&#22635;&#34917;&#20102;&#37197;&#23545;&#27604;&#36739;&#27169;&#22411;&#20013;&#32479;&#35745;&#25512;&#26029;&#30340;&#31354;&#30333;&#65292;&#20026;&#21508;&#31181;&#37197;&#23545;&#27604;&#36739;&#27169;&#22411;&#25552;&#20379;&#20102;&#32479;&#19968;&#30340;&#26041;&#27861;&#65292;&#36229;&#36234;&#20102;Bradley-Terry&#27169;&#22411;&#65292;&#20026;&#23454;&#36341;&#32773;&#25552;&#20379;&#20102;&#22362;&#23454;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2401.08463</link><description>&lt;p&gt;
&#23545;&#20110;&#37197;&#23545;&#27604;&#36739;&#27169;&#22411;&#30340;&#32479;&#35745;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Statistical inference for pairwise comparison models. (arXiv:2401.08463v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.08463
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#36890;&#36807;&#24314;&#31435;&#26497;&#22823;&#20284;&#28982;&#20272;&#35745;&#37327;&#30340;&#28176;&#36817;&#27491;&#24577;&#24615;&#32467;&#26524;&#65292;&#22635;&#34917;&#20102;&#37197;&#23545;&#27604;&#36739;&#27169;&#22411;&#20013;&#32479;&#35745;&#25512;&#26029;&#30340;&#31354;&#30333;&#65292;&#20026;&#21508;&#31181;&#37197;&#23545;&#27604;&#36739;&#27169;&#22411;&#25552;&#20379;&#20102;&#32479;&#19968;&#30340;&#26041;&#27861;&#65292;&#36229;&#36234;&#20102;Bradley-Terry&#27169;&#22411;&#65292;&#20026;&#23454;&#36341;&#32773;&#25552;&#20379;&#20102;&#22362;&#23454;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37197;&#23545;&#27604;&#36739;&#27169;&#22411;&#34987;&#29992;&#20110;&#21508;&#20010;&#39046;&#22495;&#30340;&#23454;&#29992;&#24615;&#21644;&#25490;&#21517;&#35780;&#20272;&#12290;&#29616;&#20195;&#38382;&#39064;&#35268;&#27169;&#30340;&#22686;&#21152;&#24378;&#35843;&#20102;&#23545;&#20110;&#24403;&#34987;&#27604;&#36739;&#23545;&#35937;&#25968;&#37327;&#26080;&#38480;&#22686;&#21152;&#26102;&#65292;&#23545;&#20110;&#36825;&#20123;&#27169;&#22411;&#20013;&#30340;&#32479;&#35745;&#25512;&#26029;&#30340;&#29702;&#35299;&#30340;&#38656;&#27714;&#12290;&#30446;&#21069;&#65292;&#25991;&#29486;&#20013;&#23545;&#20110;&#36825;&#20123;&#27169;&#22411;&#20013;&#30340;&#32479;&#35745;&#25512;&#26029;&#30340;&#29702;&#35299;&#36824;&#30456;&#24403;&#26377;&#38480;&#65292;&#38500;&#38750;&#21482;&#26159;&#22312;&#23569;&#25968;&#29305;&#27530;&#23454;&#20363;&#20013;&#12290;&#26412;&#25991;&#36890;&#36807;&#22312;&#24191;&#27867;&#30340;&#37197;&#23545;&#27604;&#36739;&#27169;&#22411;&#20013;&#24314;&#31435;&#26497;&#22823;&#20284;&#28982;&#20272;&#35745;&#37327;&#30340;&#28176;&#36817;&#27491;&#24577;&#24615;&#32467;&#26524;&#26469;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#12290;&#20851;&#38190;&#24605;&#24819;&#22312;&#20110;&#23558;&#36153;&#33293;&#23572;&#20449;&#24687;&#30697;&#38453;&#35782;&#21035;&#20026;&#21152;&#26435;&#22270;&#25289;&#26222;&#25289;&#26031;&#30697;&#38453;&#65292;&#36890;&#36807;&#19968;&#31181;&#32454;&#33268;&#20837;&#24494;&#30340;&#35889;&#20998;&#26512;&#26041;&#27861;&#26469;&#36827;&#34892;&#30740;&#31350;&#12290;&#25105;&#20204;&#30340;&#21457;&#29616;&#20026;&#22312;&#21508;&#31181;&#37197;&#23545;&#27604;&#36739;&#27169;&#22411;&#20013;&#36827;&#34892;&#32479;&#35745;&#25512;&#26029;&#25552;&#20379;&#20102;&#31532;&#19968;&#20010;&#32479;&#19968;&#30340;&#26041;&#27861;&#65292;&#36229;&#36234;&#20102;Bradley-Terry&#27169;&#22411;&#65292;&#20026;&#23454;&#36341;&#32773;&#25552;&#20379;&#20102;&#22362;&#23454;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;&#36890;&#36807;&#21033;&#29992;&#21512;&#25104;&#25968;&#25454;&#36827;&#34892;&#30340;&#27169;&#25311;&#39564;&#35777;&#36825;&#19968;&#28176;&#36817;&#27491;&#24577;&#24615;&#32467;&#26524;&#65292;&#28982;&#21518;&#36827;&#34892;&#20102;
&lt;/p&gt;
&lt;p&gt;
Pairwise comparison models are used for quantitatively evaluating utility and ranking in various fields. The increasing scale of modern problems underscores the need to understand statistical inference in these models when the number of subjects diverges, which is currently lacking in the literature except in a few special instances. This paper addresses this gap by establishing an asymptotic normality result for the maximum likelihood estimator in a broad class of pairwise comparison models. The key idea lies in identifying the Fisher information matrix as a weighted graph Laplacian matrix which can be studied via a meticulous spectral analysis. Our findings provide the first unified theory for performing statistical inference in a wide range of pairwise comparison models beyond the Bradley--Terry model, benefiting practitioners with a solid theoretical guarantee for their use. Simulations utilizing synthetic data are conducted to validate the asymptotic normality result, followed by 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#36866;&#29992;&#20110;&#38543;&#26426;&#36125;&#21494;&#26031;&#33218;&#26426;&#30340;&#38543;&#26102;&#21644;&#26080;&#21442;&#25968;&#37319;&#26679;&#35268;&#21017;APGAI&#65292;&#36890;&#36807;&#33258;&#36866;&#24212;&#31574;&#30053;&#25552;&#39640;&#20102;&#22909;&#33218;&#35782;&#21035;&#25928;&#29575;&#65292;&#22312;&#22266;&#23450;&#32622;&#20449;&#24230;&#21644;&#22266;&#23450;&#39044;&#31639;&#30340;&#24773;&#20917;&#19979;&#26377;&#33391;&#22909;&#23454;&#39564;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2310.10359</link><description>&lt;p&gt;
&#19968;&#20010;&#36866;&#29992;&#20110;&#22909;&#33218;&#35782;&#21035;&#30340;&#38543;&#26102;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
An Anytime Algorithm for Good Arm Identification. (arXiv:2310.10359v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10359
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#36866;&#29992;&#20110;&#38543;&#26426;&#36125;&#21494;&#26031;&#33218;&#26426;&#30340;&#38543;&#26102;&#21644;&#26080;&#21442;&#25968;&#37319;&#26679;&#35268;&#21017;APGAI&#65292;&#36890;&#36807;&#33258;&#36866;&#24212;&#31574;&#30053;&#25552;&#39640;&#20102;&#22909;&#33218;&#35782;&#21035;&#25928;&#29575;&#65292;&#22312;&#22266;&#23450;&#32622;&#20449;&#24230;&#21644;&#22266;&#23450;&#39044;&#31639;&#30340;&#24773;&#20917;&#19979;&#26377;&#33391;&#22909;&#23454;&#39564;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22909;&#33218;&#35782;&#21035;&#65288;GAI&#65289;&#20013;&#65292;&#30446;&#26631;&#26159;&#35782;&#21035;&#20854;&#20013;&#19968;&#20010;&#24179;&#22343;&#24615;&#33021;&#36229;&#36807;&#32473;&#23450;&#38408;&#20540;&#30340;&#33218;&#65292;&#31216;&#20026;&#22909;&#33218;&#65288;&#22914;&#26524;&#23384;&#22312;&#65289;&#12290;&#30446;&#21069;&#24456;&#23569;&#26377;&#30740;&#31350;&#22312;&#22266;&#23450;&#39044;&#31639;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;GAI&#65292;&#21363;&#22312;&#20808;&#30830;&#23450;&#22909;&#39044;&#31639;&#20043;&#21518;&#65292;&#25110;&#32773;&#22312;&#20219;&#20309;&#26102;&#21051;&#37117;&#21487;&#20197;&#35201;&#27714;&#25512;&#33616;&#30340;&#38543;&#26102;&#35774;&#32622;&#19979;&#36827;&#34892;GAI&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;APGAI&#30340;&#38543;&#26102;&#21644;&#26080;&#21442;&#25968;&#37319;&#26679;&#35268;&#21017;&#65292;&#29992;&#20110;&#38543;&#26426;&#36125;&#21494;&#26031;&#33218;&#26426;&#12290;APGAI&#21487;&#20197;&#30452;&#25509;&#29992;&#20110;&#22266;&#23450;&#32622;&#20449;&#24230;&#21644;&#22266;&#23450;&#39044;&#31639;&#30340;&#35774;&#23450;&#20013;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#24471;&#20986;&#20854;&#20219;&#20309;&#26102;&#21051;&#30340;&#35823;&#24046;&#27010;&#29575;&#30340;&#19978;&#30028;&#12290;&#36825;&#20123;&#19978;&#30028;&#34920;&#26126;&#65292;&#33258;&#36866;&#24212;&#31574;&#30053;&#22312;&#26816;&#27979;&#27809;&#26377;&#22909;&#33218;&#30340;&#26102;&#20505;&#27604;&#22343;&#21248;&#37319;&#26679;&#26356;&#39640;&#25928;&#12290;&#20854;&#27425;&#65292;&#24403;APGAI&#19982;&#19968;&#20010;&#20572;&#27490;&#35268;&#21017;&#32467;&#21512;&#26102;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#20219;&#20309;&#32622;&#20449;&#27700;&#24179;&#19979;&#30340;&#39044;&#26399;&#37319;&#26679;&#22797;&#26434;&#24615;&#30340;&#19978;&#30028;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;APGAI&#22312;&#21512;&#25104;&#25968;&#25454;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#19978;&#30340;&#33391;&#22909;&#23454;&#39564;&#24615;&#33021;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#20026;&#25152;&#26377;&#35774;&#32622;&#20013;&#30340;GAI&#38382;&#39064;&#25552;&#20379;&#20102;&#19968;&#20010;&#24191;&#27867;&#30340;&#27010;&#36848;&#12290;
&lt;/p&gt;
&lt;p&gt;
In good arm identification (GAI), the goal is to identify one arm whose average performance exceeds a given threshold, referred to as good arm, if it exists. Few works have studied GAI in the fixed-budget setting, when the sampling budget is fixed beforehand, or the anytime setting, when a recommendation can be asked at any time. We propose APGAI, an anytime and parameter-free sampling rule for GAI in stochastic bandits. APGAI can be straightforwardly used in fixed-confidence and fixed-budget settings. First, we derive upper bounds on its probability of error at any time. They show that adaptive strategies are more efficient in detecting the absence of good arms than uniform sampling. Second, when APGAI is combined with a stopping rule, we prove upper bounds on the expected sampling complexity, holding at any confidence level. Finally, we show good empirical performance of APGAI on synthetic and real-world data. Our work offers an extensive overview of the GAI problem in all settings.
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#24037;&#20855;&#65292;Transductive Local Rademacher Complexity (TLRC)&#65292;&#29992;&#20110;&#20998;&#26512;transductive learning&#26041;&#27861;&#30340;&#27867;&#21270;&#24615;&#33021;&#24182;&#25512;&#21160;&#26032;&#30340;transductive learning&#31639;&#27861;&#30340;&#21457;&#23637;&#12290;&#25105;&#20204;&#21033;&#29992;&#21464;&#37327;&#30340;&#26041;&#24046;&#20449;&#24687;&#26500;&#24314;&#20102;TLRC&#65292;&#24182;&#23558;transductive learning&#27169;&#22411;&#30340;&#39044;&#27979;&#20989;&#25968;&#31867;&#20998;&#20026;&#22810;&#20010;&#37096;&#20998;&#65292;&#27599;&#20010;&#37096;&#20998;&#30340;Rademacher complexity&#19978;&#30028;&#30001;&#19968;&#20010;&#23376;&#26681;&#20989;&#25968;&#32473;&#20986;&#65292;&#24182;&#38480;&#21046;&#20102;&#27599;&#20010;&#37096;&#20998;&#20013;&#25152;&#26377;&#20989;&#25968;&#30340;&#26041;&#24046;&#12290;</title><link>http://arxiv.org/abs/2309.16858</link><description>&lt;p&gt;
Transductive Learning&#30340;&#23574;&#38160;&#27867;&#21270;&#65306;&#19968;&#31181;Transductive Local Rademacher Complexity&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Sharp Generalization of Transductive Learning: A Transductive Local Rademacher Complexity Approach. (arXiv:2309.16858v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.16858
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#24037;&#20855;&#65292;Transductive Local Rademacher Complexity (TLRC)&#65292;&#29992;&#20110;&#20998;&#26512;transductive learning&#26041;&#27861;&#30340;&#27867;&#21270;&#24615;&#33021;&#24182;&#25512;&#21160;&#26032;&#30340;transductive learning&#31639;&#27861;&#30340;&#21457;&#23637;&#12290;&#25105;&#20204;&#21033;&#29992;&#21464;&#37327;&#30340;&#26041;&#24046;&#20449;&#24687;&#26500;&#24314;&#20102;TLRC&#65292;&#24182;&#23558;transductive learning&#27169;&#22411;&#30340;&#39044;&#27979;&#20989;&#25968;&#31867;&#20998;&#20026;&#22810;&#20010;&#37096;&#20998;&#65292;&#27599;&#20010;&#37096;&#20998;&#30340;Rademacher complexity&#19978;&#30028;&#30001;&#19968;&#20010;&#23376;&#26681;&#20989;&#25968;&#32473;&#20986;&#65292;&#24182;&#38480;&#21046;&#20102;&#27599;&#20010;&#37096;&#20998;&#20013;&#25152;&#26377;&#20989;&#25968;&#30340;&#26041;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#24037;&#20855;&#65292;Transductive Local Rademacher Complexity (TLRC)&#65292;&#29992;&#20110;&#20998;&#26512;transductive learning&#26041;&#27861;&#30340;&#27867;&#21270;&#24615;&#33021;&#24182;&#25512;&#21160;&#26032;&#30340;transductive learning&#31639;&#27861;&#30340;&#21457;&#23637;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#23558;&#20256;&#32479;&#30340;local rademacher complexity (LRC)&#30340;&#24605;&#24819;&#25193;&#23637;&#21040;&#20102;transductive&#35774;&#32622;&#20013;&#65292;&#30456;&#23545;&#20110;&#20856;&#22411;&#30340;LRC&#26041;&#27861;&#22312;&#24402;&#32435;&#35774;&#32622;&#20013;&#30340;&#20998;&#26512;&#26377;&#20102;&#30456;&#24403;&#22823;&#30340;&#21464;&#21270;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Rademacher complex&#30340;&#23616;&#37096;&#21270;&#24037;&#20855;&#65292;&#21487;&#20197;&#24212;&#29992;&#20110;&#21508;&#31181;transductive learning&#38382;&#39064;&#65292;&#24182;&#22312;&#36866;&#24403;&#26465;&#20214;&#19979;&#24471;&#21040;&#20102;&#23574;&#38160;&#30340;&#30028;&#38480;&#12290;&#19982;LRC&#30340;&#21457;&#23637;&#31867;&#20284;&#65292;&#25105;&#20204;&#36890;&#36807;&#20174;&#29420;&#31435;&#21464;&#37327;&#30340;&#26041;&#24046;&#20449;&#24687;&#24320;&#22987;&#26500;&#24314;TLRC&#65292;&#23558;transductive learning&#27169;&#22411;&#30340;&#39044;&#27979;&#20989;&#25968;&#31867;&#20998;&#20026;&#22810;&#20010;&#37096;&#20998;&#65292;&#27599;&#20010;&#37096;&#20998;&#30340;Rademacher complexity&#19978;&#30028;&#30001;&#19968;&#20010;&#23376;&#26681;&#20989;&#25968;&#32473;&#20986;&#65292;&#24182;&#38480;&#21046;&#20102;&#27599;&#20010;&#37096;&#20998;&#20013;&#25152;&#26377;&#20989;&#25968;&#30340;&#26041;&#24046;&#12290;&#32463;&#36807;&#31934;&#24515;&#35774;&#35745;&#30340;...
&lt;/p&gt;
&lt;p&gt;
We introduce a new tool, Transductive Local Rademacher Complexity (TLRC), to analyze the generalization performance of transductive learning methods and motivate new transductive learning algorithms. Our work extends the idea of the popular Local Rademacher Complexity (LRC) to the transductive setting with considerable changes compared to the analysis of typical LRC methods in the inductive setting. We present a localized version of Rademacher complexity based tool wihch can be applied to various transductive learning problems and gain sharp bounds under proper conditions. Similar to the development of LRC, we build TLRC by starting from a sharp concentration inequality for independent variables with variance information. The prediction function class of a transductive learning model is then divided into pieces with a sub-root function being the upper bound for the Rademacher complexity of each piece, and the variance of all the functions in each piece is limited. A carefully designed 
&lt;/p&gt;</description></item></channel></rss>