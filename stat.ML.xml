<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39044;&#39564;&#35777;&#30340;&#23725;&#22238;&#24402;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#22312;&#39640;&#32500;&#25968;&#25454;&#20013;&#19982;&#36923;&#36753;&#22238;&#24402;&#38750;&#24120;&#25509;&#36817;&#65292;&#20294;&#20855;&#26377;&#26356;&#39640;&#30340;&#35745;&#31639;&#25928;&#29575;&#21644;&#20960;&#20046;&#27809;&#26377;&#36229;&#21442;&#25968;&#12290;&#23427;&#36890;&#36807;&#21033;&#29992;&#22312;&#25311;&#21512;&#36807;&#31243;&#20013;&#35745;&#31639;&#24471;&#21040;&#30340;&#25968;&#37327;&#26469;&#32553;&#25918;&#27169;&#22411;&#31995;&#25968;&#65292;&#24182;&#26368;&#23567;&#21270;&#19968;&#32452;&#39044;&#39564;&#35777;&#39044;&#27979;&#30340;&#23545;&#25968;&#25439;&#22833;&#12290;</title><link>http://arxiv.org/abs/2401.15610</link><description>&lt;p&gt;
&#39044;&#39564;&#35777;&#30340;&#23725;&#22238;&#24402;&#26159;&#39640;&#32500;&#25968;&#25454;&#20013;&#36923;&#36753;&#22238;&#24402;&#30340;&#39640;&#25928;&#26367;&#20195;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Prevalidated ridge regression is a highly-efficient drop-in replacement for logistic regression for high-dimensional data. (arXiv:2401.15610v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15610
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39044;&#39564;&#35777;&#30340;&#23725;&#22238;&#24402;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#22312;&#39640;&#32500;&#25968;&#25454;&#20013;&#19982;&#36923;&#36753;&#22238;&#24402;&#38750;&#24120;&#25509;&#36817;&#65292;&#20294;&#20855;&#26377;&#26356;&#39640;&#30340;&#35745;&#31639;&#25928;&#29575;&#21644;&#20960;&#20046;&#27809;&#26377;&#36229;&#21442;&#25968;&#12290;&#23427;&#36890;&#36807;&#21033;&#29992;&#22312;&#25311;&#21512;&#36807;&#31243;&#20013;&#35745;&#31639;&#24471;&#21040;&#30340;&#25968;&#37327;&#26469;&#32553;&#25918;&#27169;&#22411;&#31995;&#25968;&#65292;&#24182;&#26368;&#23567;&#21270;&#19968;&#32452;&#39044;&#39564;&#35777;&#39044;&#27979;&#30340;&#23545;&#25968;&#25439;&#22833;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36923;&#36753;&#22238;&#24402;&#26159;&#19968;&#31181;&#24120;&#35265;&#30340;&#27010;&#29575;&#20998;&#31867;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#36923;&#36753;&#22238;&#24402;&#30340;&#26377;&#25928;&#24615;&#21462;&#20915;&#20110;&#20180;&#32454;&#19988;&#30456;&#23545;&#35745;&#31639;&#23494;&#38598;&#30340;&#35843;&#20248;&#65292;&#23588;&#20854;&#26159;&#23545;&#20110;&#27491;&#21017;&#21270;&#36229;&#21442;&#25968;&#65292;&#24182;&#19988;&#23588;&#20854;&#22312;&#39640;&#32500;&#25968;&#25454;&#30340;&#32972;&#26223;&#19979;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#39044;&#39564;&#35777;&#30340;&#23725;&#22238;&#24402;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#22312;&#20998;&#31867;&#38169;&#35823;&#21644;&#23545;&#25968;&#25439;&#22833;&#26041;&#38754;&#19982;&#36923;&#36753;&#22238;&#24402;&#38750;&#24120;&#25509;&#36817;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#39640;&#32500;&#25968;&#25454;&#65292;&#21516;&#26102;&#22312;&#35745;&#31639;&#25928;&#29575;&#19978;&#26126;&#26174;&#26356;&#39640;&#65292;&#24182;&#19988;&#38500;&#20102;&#27491;&#21017;&#21270;&#20043;&#22806;&#27809;&#26377;&#36229;&#21442;&#25968;&#12290;&#25105;&#20204;&#36890;&#36807;&#32553;&#25918;&#27169;&#22411;&#30340;&#31995;&#25968;&#26469;&#26368;&#23567;&#21270;&#30001;&#20272;&#35745;&#30340;&#30041;&#19968;&#20132;&#21449;&#39564;&#35777;&#35823;&#24046;&#25512;&#23548;&#20986;&#30340;&#19968;&#32452;&#39044;&#39564;&#35777;&#39044;&#27979;&#30340;&#23545;&#25968;&#25439;&#22833;&#12290;&#36825;&#21033;&#29992;&#20102;&#22312;&#25311;&#21512;&#23725;&#22238;&#24402;&#27169;&#22411;&#36807;&#31243;&#20013;&#24050;&#32463;&#35745;&#31639;&#30340;&#25968;&#37327;&#65292;&#20197;&#25214;&#21040;&#20855;&#26377;&#21517;&#20041;&#38468;&#21152;&#35745;&#31639;&#24320;&#38144;&#30340;&#32553;&#25918;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Logistic regression is a ubiquitous method for probabilistic classification. However, the effectiveness of logistic regression depends upon careful and relatively computationally expensive tuning, especially for the regularisation hyperparameter, and especially in the context of high-dimensional data. We present a prevalidated ridge regression model that closely matches logistic regression in terms of classification error and log-loss, particularly for high-dimensional data, while being significantly more computationally efficient and having effectively no hyperparameters beyond regularisation. We scale the coefficients of the model so as to minimise log-loss for a set of prevalidated predictions derived from the estimated leave-one-out cross-validation error. This exploits quantities already computed in the course of fitting the ridge regression model in order to find the scaling parameter with nominal additional computational expense.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20174;&#32479;&#35745;&#23398;&#35282;&#24230;&#24314;&#31435;&#25928;&#29992;&#29702;&#35770;&#65292;&#26088;&#22312;&#22522;&#20110;&#19968;&#33324;&#24615;&#25351;&#26631;&#23450;&#37327;&#35780;&#20272;&#21512;&#25104;&#31639;&#27861;&#30340;&#25928;&#29992;&#65292;&#25928;&#29992;&#25351;&#26631;&#30340;&#20998;&#26512;&#30028;&#38480;&#25581;&#31034;&#20102;&#25351;&#26631;&#25910;&#25947;&#30340;&#20851;&#38190;&#26465;&#20214;&#65292;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#21482;&#35201;&#19979;&#28216;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#27169;&#22411;&#35268;&#33539;&#26159;&#27491;&#30830;&#30340;&#65292;&#21512;&#25104;&#29305;&#24449;&#20998;&#24067;&#19981;&#19968;&#23450;&#19982;&#21407;&#22987;&#29305;&#24449;&#20998;&#24067;&#30456;&#21516;&#65292;&#25928;&#29992;&#25351;&#26631;&#20250;&#25910;&#25947;&#12290;</title><link>http://arxiv.org/abs/2305.10015</link><description>&lt;p&gt;
&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#30340;&#25928;&#29992;&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
Utility Theory of Synthetic Data Generation. (arXiv:2305.10015v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.10015
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20174;&#32479;&#35745;&#23398;&#35282;&#24230;&#24314;&#31435;&#25928;&#29992;&#29702;&#35770;&#65292;&#26088;&#22312;&#22522;&#20110;&#19968;&#33324;&#24615;&#25351;&#26631;&#23450;&#37327;&#35780;&#20272;&#21512;&#25104;&#31639;&#27861;&#30340;&#25928;&#29992;&#65292;&#25928;&#29992;&#25351;&#26631;&#30340;&#20998;&#26512;&#30028;&#38480;&#25581;&#31034;&#20102;&#25351;&#26631;&#25910;&#25947;&#30340;&#20851;&#38190;&#26465;&#20214;&#65292;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#21482;&#35201;&#19979;&#28216;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#27169;&#22411;&#35268;&#33539;&#26159;&#27491;&#30830;&#30340;&#65292;&#21512;&#25104;&#29305;&#24449;&#20998;&#24067;&#19981;&#19968;&#23450;&#19982;&#21407;&#22987;&#29305;&#24449;&#20998;&#24067;&#30456;&#21516;&#65292;&#25928;&#29992;&#25351;&#26631;&#20250;&#25910;&#25947;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35780;&#20272;&#21512;&#25104;&#25968;&#25454;&#30340;&#25928;&#29992;&#23545;&#20110;&#34913;&#37327;&#21512;&#25104;&#31639;&#27861;&#30340;&#26377;&#25928;&#24615;&#21644;&#25928;&#29575;&#33267;&#20851;&#37325;&#35201;&#12290;&#29616;&#26377;&#30340;&#32467;&#26524;&#20391;&#37325;&#20110;&#23545;&#21512;&#25104;&#25968;&#25454;&#25928;&#29992;&#30340;&#32463;&#39564;&#35780;&#20272;&#65292;&#32780;&#38024;&#23545;&#21512;&#25104;&#25968;&#25454;&#31639;&#27861;&#22914;&#20309;&#24433;&#21709;&#25928;&#29992;&#30340;&#29702;&#35770;&#29702;&#35299;&#20173;&#28982;&#26410;&#34987;&#20805;&#20998;&#25506;&#32034;&#12290;&#26412;&#25991;&#20174;&#32479;&#35745;&#23398;&#35282;&#24230;&#24314;&#31435;&#25928;&#29992;&#29702;&#35770;&#65292;&#26088;&#22312;&#22522;&#20110;&#19968;&#33324;&#24615;&#25351;&#26631;&#23450;&#37327;&#35780;&#20272;&#21512;&#25104;&#31639;&#27861;&#30340;&#25928;&#29992;&#12290;&#35813;&#25351;&#26631;&#23450;&#20041;&#20026;&#22312;&#21512;&#25104;&#21644;&#21407;&#22987;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#30340;&#27169;&#22411;&#20043;&#38388;&#27867;&#21270;&#30340;&#32477;&#23545;&#24046;&#24322;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#35813;&#25928;&#29992;&#25351;&#26631;&#30340;&#20998;&#26512;&#30028;&#38480;&#26469;&#30740;&#31350;&#25351;&#26631;&#25910;&#25947;&#30340;&#20851;&#38190;&#26465;&#20214;&#12290;&#19968;&#20010;&#26377;&#36259;&#30340;&#32467;&#26524;&#26159;&#65292;&#21482;&#35201;&#19979;&#28216;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#27169;&#22411;&#35268;&#33539;&#26159;&#27491;&#30830;&#30340;&#65292;&#21512;&#25104;&#29305;&#24449;&#20998;&#24067;&#19981;&#19968;&#23450;&#19982;&#21407;&#22987;&#29305;&#24449;&#20998;&#24067;&#30456;&#21516;&#65292;&#21017;&#35813;&#25928;&#29992;&#25351;&#26631;&#20250;&#25910;&#25947;&#12290;&#21478;&#19968;&#20010;&#37325;&#35201;&#30340;&#25928;&#29992;&#25351;&#26631;&#22522;&#20110;&#21512;&#25104;&#21644;&#21407;&#22987;&#25968;&#25454;&#20043;&#38388;&#28508;&#22312;&#30340;&#22240;&#26524;&#26426;&#21046;&#19968;&#33268;&#24615;&#12290;&#35813;&#29702;&#35770;&#20351;&#29992;&#20960;&#31181;&#21512;&#25104;&#31639;&#27861;&#36827;&#34892;&#35828;&#26126;&#65292;&#24182;&#20998;&#26512;&#20102;&#23427;&#20204;&#30340;&#25928;&#29992;&#23646;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Evaluating the utility of synthetic data is critical for measuring the effectiveness and efficiency of synthetic algorithms. Existing results focus on empirical evaluations of the utility of synthetic data, whereas the theoretical understanding of how utility is affected by synthetic data algorithms remains largely unexplored. This paper establishes utility theory from a statistical perspective, aiming to quantitatively assess the utility of synthetic algorithms based on a general metric. The metric is defined as the absolute difference in generalization between models trained on synthetic and original datasets. We establish analytical bounds for this utility metric to investigate critical conditions for the metric to converge. An intriguing result is that the synthetic feature distribution is not necessarily identical to the original one for the convergence of the utility metric as long as the model specification in downstream learning tasks is correct. Another important utility metri
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36845;&#20195;&#26041;&#26696;&#65292;&#29992;&#20110;&#27714;&#35299;&#27010;&#29575;&#21333;&#32431;&#24418;&#19978;&#30340;&#20984;&#20248;&#21270;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#20855;&#26377;&#25910;&#25947;&#36895;&#24230;&#24555;&#19988;&#31616;&#21333;&#26131;&#34892;&#30340;&#29305;&#28857;&#12290;</title><link>http://arxiv.org/abs/2305.09046</link><description>&lt;p&gt;
&#27010;&#29575;&#21333;&#32431;&#24418;&#19978;&#30340;&#20984;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Convex optimization over a probability simplex. (arXiv:2305.09046v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.09046
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36845;&#20195;&#26041;&#26696;&#65292;&#29992;&#20110;&#27714;&#35299;&#27010;&#29575;&#21333;&#32431;&#24418;&#19978;&#30340;&#20984;&#20248;&#21270;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#20855;&#26377;&#25910;&#25947;&#36895;&#24230;&#24555;&#19988;&#31616;&#21333;&#26131;&#34892;&#30340;&#29305;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36845;&#20195;&#26041;&#26696;&#8212;&#8212;&#26607;&#35199;&#21333;&#32431;&#24418;&#26469;&#20248;&#21270;&#20984;&#38382;&#39064;&#65292;&#20351;&#20854;&#28385;&#36275;&#27010;&#29575;&#21333;&#32431;&#24418;&#19978;&#30340;&#38480;&#21046;&#26465;&#20214;&#65292;&#21363;$w\in\mathbb{R}^n$&#20013;$\sum_i w_i=1$&#65292;$w_i\geq0$&#12290;&#25105;&#20204;&#23558;&#21333;&#32431;&#24418;&#26144;&#23556;&#21040;&#21333;&#20301;&#29699;&#30340;&#27491;&#22235;&#38754;&#20307;&#65292;&#36890;&#36807;&#26799;&#24230;&#19979;&#38477;&#33719;&#24471;&#38544;&#21464;&#37327;&#30340;&#35299;&#65292;&#24182;&#23558;&#32467;&#26524;&#26144;&#23556;&#22238;&#21407;&#22987;&#21464;&#37327;&#12290;&#35813;&#26041;&#27861;&#36866;&#29992;&#20110;&#39640;&#32500;&#38382;&#39064;&#65292;&#27599;&#27425;&#36845;&#20195;&#30001;&#31616;&#21333;&#30340;&#25805;&#20316;&#32452;&#25104;&#65292;&#19988;&#38024;&#23545;&#20984;&#20989;&#25968;&#35777;&#26126;&#20102;&#25910;&#25947;&#36895;&#24230;&#20026;${O}(1/T)$&#12290;&#21516;&#26102;&#26412;&#25991;&#20851;&#27880;&#20102;&#20449;&#24687;&#29702;&#35770;&#65288;&#22914;&#20132;&#21449;&#29109;&#21644;KL&#25955;&#24230;&#65289;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a new iteration scheme, the Cauchy-Simplex, to optimize convex problems over the probability simplex $\{w\in\mathbb{R}^n\ |\ \sum_i w_i=1\ \textrm{and}\ w_i\geq0\}$. Other works have taken steps to enforce positivity or unit normalization automatically but never simultaneously within a unified setting. This paper presents a natural framework for manifestly requiring the probability condition. Specifically, we map the simplex to the positive quadrant of a unit sphere, envisage gradient descent in latent variables, and map the result back in a way that only depends on the simplex variable. Moreover, proving rigorous convergence results in this formulation leads inherently to tools from information theory (e.g. cross entropy and KL divergence). Each iteration of the Cauchy-Simplex consists of simple operations, making it well-suited for high-dimensional problems. We prove that it has a convergence rate of ${O}(1/T)$ for convex functions, and numerical experiments of projection 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#38750;&#24179;&#31283;&#26102;&#38388;&#24207;&#21015;&#30340;&#33258;&#36866;&#24212;&#23398;&#29983;t&#20998;&#24067;&#26041;&#27861;&#65292;&#22522;&#20110;&#26041;&#27861;&#30340;&#19968;&#33324;&#33258;&#36866;&#24212;&#30697;&#21487;&#20197;&#20351;&#29992;&#24265;&#20215;&#30340;&#25351;&#25968;&#31227;&#21160;&#24179;&#22343;&#20540;&#65288;EMA&#65289;&#26469;&#20272;&#35745;&#21442;&#25968;&#12290;</title><link>http://arxiv.org/abs/2304.03069</link><description>&lt;p&gt;
&#33258;&#36866;&#24212;&#23398;&#29983;t&#20998;&#24067;&#19982;&#26041;&#27861;&#30697;&#31227;&#21160;&#20272;&#35745;&#22120;&#29992;&#20110;&#38750;&#24179;&#31283;&#26102;&#38388;&#24207;&#21015;
&lt;/p&gt;
&lt;p&gt;
Adaptive Student's t-distribution with method of moments moving estimator for nonstationary time series. (arXiv:2304.03069v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03069
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#38750;&#24179;&#31283;&#26102;&#38388;&#24207;&#21015;&#30340;&#33258;&#36866;&#24212;&#23398;&#29983;t&#20998;&#24067;&#26041;&#27861;&#65292;&#22522;&#20110;&#26041;&#27861;&#30340;&#19968;&#33324;&#33258;&#36866;&#24212;&#30697;&#21487;&#20197;&#20351;&#29992;&#24265;&#20215;&#30340;&#25351;&#25968;&#31227;&#21160;&#24179;&#22343;&#20540;&#65288;EMA&#65289;&#26469;&#20272;&#35745;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30495;&#23454;&#30340;&#26102;&#38388;&#24207;&#21015;&#36890;&#24120;&#26159;&#38750;&#24179;&#31283;&#30340;&#65292;&#36825;&#24102;&#26469;&#20102;&#27169;&#22411;&#36866;&#24212;&#30340;&#38590;&#39064;&#12290;&#20256;&#32479;&#26041;&#27861;&#22914;GARCH&#20551;&#23450;&#20219;&#24847;&#31867;&#22411;&#30340;&#20381;&#36182;&#24615;&#12290;&#20026;&#20102;&#36991;&#20813;&#36825;&#31181;&#20559;&#24046;&#65292;&#25105;&#20204;&#23558;&#30528;&#30524;&#20110;&#26368;&#36817;&#25552;&#20986;&#30340;&#19981;&#21487;&#30693;&#30340;&#31227;&#21160;&#20272;&#35745;&#22120;&#21746;&#23398;&#65306;&#22312;&#26102;&#38388;$t$&#25214;&#21040;&#20248;&#21270;$F_t=\sum_{\tau&lt;t} (1-\eta)^{t-\tau} \ln(\rho_\theta (x_\tau))$&#31227;&#21160;&#23545;&#25968;&#20284;&#28982;&#30340;&#21442;&#25968;&#65292;&#38543;&#26102;&#38388;&#28436;&#21270;&#12290;&#20363;&#22914;&#65292;&#23427;&#20801;&#35768;&#20351;&#29992;&#24265;&#20215;&#30340;&#25351;&#25968;&#31227;&#21160;&#24179;&#22343;&#20540;&#65288;EMA&#65289;&#26469;&#20272;&#35745;&#21442;&#25968;&#65292;&#20363;&#22914;&#32477;&#23545;&#20013;&#24515;&#30697;$E[|x-\mu|^p]$&#38543;$p\in\mathbb{R}^+$&#30340;&#21464;&#21270;&#32780;&#28436;&#21270;$m_{p,t+1} = m_{p,t} + \eta (|x_t-\mu_t|^p-m_{p,t})$&#12290;&#36825;&#31181;&#22522;&#20110;&#26041;&#27861;&#30340;&#19968;&#33324;&#33258;&#36866;&#24212;&#30697;&#30340;&#24212;&#29992;&#23558;&#21576;&#29616;&#22312;&#23398;&#29983;t&#20998;&#24067;&#19978;&#65292;&#23588;&#20854;&#26159;&#22312;&#32463;&#27982;&#24212;&#29992;&#20013;&#27969;&#34892;&#65292;&#36825;&#37324;&#24212;&#29992;&#20110;DJIA&#20844;&#21496;&#30340;&#23545;&#25968;&#25910;&#30410;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
The real life time series are usually nonstationary, bringing a difficult question of model adaptation. Classical approaches like GARCH assume arbitrary type of dependence. To prevent such bias, we will focus on recently proposed agnostic philosophy of moving estimator: in time $t$ finding parameters optimizing e.g. $F_t=\sum_{\tau&lt;t} (1-\eta)^{t-\tau} \ln(\rho_\theta (x_\tau))$ moving log-likelihood, evolving in time. It allows for example to estimate parameters using inexpensive exponential moving averages (EMA), like absolute central moments $E[|x-\mu|^p]$ evolving with $m_{p,t+1} = m_{p,t} + \eta (|x_t-\mu_t|^p-m_{p,t})$ for one or multiple powers $p\in\mathbb{R}^+$. Application of such general adaptive methods of moments will be presented on Student's t-distribution, popular especially in economical applications, here applied to log-returns of DJIA companies.
&lt;/p&gt;</description></item></channel></rss>