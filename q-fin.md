# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Stylized Facts of High-Frequency Bitcoin Time Series](https://arxiv.org/abs/2402.11930) | 本文研究了2019年至2022年间的高频比特币日内数据集，发现比特币价格回报表现出了两个不同时期的异常扩散过程，具有重尾特征和时间依赖性。 |
| [^2] | [Partially Law-Invariant Risk Measures.](http://arxiv.org/abs/2401.17265) | 这篇论文介绍了部分律法不变性的概念，通过刻画部分律法不变的一致风险度量的表示公式，将决策理论和金融风险管理的文献联系起来，提出了新的风险度量，并在模型不确定性下的风险评估中展示了其应用。 |
| [^3] | [Human-AI Interactions and Societal Pitfalls.](http://arxiv.org/abs/2309.10448) | 本研究研究了人工智能与人类互动中面临的同质化和偏见问题，提出了改善人工智能与人类互动的解决办法，实现个性化输出而不牺牲生产力。 |

# 详细

[^1]: 高频比特币时间序列的风格化事实

    Stylized Facts of High-Frequency Bitcoin Time Series

    [https://arxiv.org/abs/2402.11930](https://arxiv.org/abs/2402.11930)

    本文研究了2019年至2022年间的高频比特币日内数据集，发现比特币价格回报表现出了两个不同时期的异常扩散过程，具有重尾特征和时间依赖性。

    

    本文分析了2019年至2022年间的高频比特币日内数据集。在此期间，比特币市场指数表现出两个明显时期，其特征是波动性的突然变化。两个时期的比特币价格回报可用异常扩散过程来描述，从短时间间隔下的次扩散过渡到长时间间隔上的弱超扩散。本文研究的与这种异常行为相关的特征包括重尾，可以用$q$-高斯分布和相关性来描述。当对绝对回报的自相关进行取样时，我们观察到一种幂律关系，表明两个时期中最初存在时间依赖性。回报的整体自相关迅速衰减并表现出周期性。我们将自相关拟合为幂律和余弦函数，以捕捉衰减和波动，并发现了这两种函数的特征

    arXiv:2402.11930v1 Announce Type: new  Abstract: This paper analyses the high-frequency intraday Bitcoin dataset from 2019 to 2022. During this time frame, the Bitcoin market index exhibited two distinct periods characterized by abrupt changes in volatility. The Bitcoin price returns for both periods can be described by an anomalous diffusion process, transitioning from subdiffusion for short intervals to weak superdiffusion over longer time intervals. The characteristic features related to this anomalous behavior studied in the present paper include heavy tails, which can be described using a $q$-Gaussian distribution and correlations. When we sample the autocorrelation of absolute returns, we observe a power-law relationship, indicating time dependency in both periods initially. The ensemble autocorrelation of returns decays rapidly and exhibits periodicity. We fitted the autocorrelation with a power law and a cosine function to capture both the decay and the fluctuation and found th
    
[^2]: 部分律法不变风险度量

    Partially Law-Invariant Risk Measures. (arXiv:2401.17265v1 [q-fin.RM])

    [http://arxiv.org/abs/2401.17265](http://arxiv.org/abs/2401.17265)

    这篇论文介绍了部分律法不变性的概念，通过刻画部分律法不变的一致风险度量的表示公式，将决策理论和金融风险管理的文献联系起来，提出了新的风险度量，并在模型不确定性下的风险评估中展示了其应用。

    

    我们引入了部分律法不变性的概念，推广了统计和金融应用中广泛使用的律法不变风险度量的概念。这个新概念是由决策理论和金融风险管理的实际考虑所激发的，从而连接了决策理论和金融风险管理的文献。我们通过一种新颖的表示公式充分地刻画了部分律法不变的一致风险度量，这个表示公式与律法不变的一致风险度量的经典公式几乎没有相似之处。我们引入了强部分律法不变性的概念，从而可以得到与经典公式类似的表示公式。我们提出了几类新的风险度量，包括预期损失和熵风险度量的部分律法不变版本，并且展示了它们在模型不确定性下的风险评估应用。

    We introduce the concept of partial law invariance, generalizing the concept of law-invariant risk measures widely used in statistical and financial applications. This new concept is motivated by practical considerations of decision-making under uncertainty, thus connecting the literature on decision theory and that on financial risk management. We fully characterize partially law-invariant coherent risk measures via a novel representation formula, which, surprisingly, has little resemblance to the classical formula for law-invariant coherent risk measures. A notion of strong partial law invariance is introduced, allowing for a representation formula akin to the classical one. We propose a few classes of new risk measures, including partially law-invariant versions of the Expected Shortfall and the entropic risk measures, and illustrate their applications in risk assessment under model uncertainty.
    
[^3]: 人工智能与人类互动以及社会陷阱

    Human-AI Interactions and Societal Pitfalls. (arXiv:2309.10448v1 [cs.AI])

    [http://arxiv.org/abs/2309.10448](http://arxiv.org/abs/2309.10448)

    本研究研究了人工智能与人类互动中面临的同质化和偏见问题，提出了改善人工智能与人类互动的解决办法，实现个性化输出而不牺牲生产力。

    

    当与生成式人工智能（AI）合作时，用户可能会看到生产力的提升，但AI生成的内容可能不完全符合他们的偏好。为了研究这种影响，我们引入了一个贝叶斯框架，其中异质用户选择与AI共享多少信息，面临输出保真度和通信成本之间的权衡。我们展示了这些个体决策与AI训练之间的相互作用可能导致社会挑战。输出可能变得更加同质化，特别是当AI在AI生成的内容上进行训练时。而任何AI的偏见可能成为社会偏见。解决同质化和偏见问题的办法是改进人工智能与人类的互动，实现个性化输出而不牺牲生产力。

    When working with generative artificial intelligence (AI), users may see productivity gains, but the AI-generated content may not match their preferences exactly. To study this effect, we introduce a Bayesian framework in which heterogeneous users choose how much information to share with the AI, facing a trade-off between output fidelity and communication cost. We show that the interplay between these individual-level decisions and AI training may lead to societal challenges. Outputs may become more homogenized, especially when the AI is trained on AI-generated content. And any AI bias may become societal bias. A solution to the homogenization and bias issues is to improve human-AI interactions, enabling personalized outputs without sacrificing productivity.
    

