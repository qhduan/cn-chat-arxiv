# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [How Periodic Forecast Updates Influence MRP Planning Parameters: A Simulation Study](https://arxiv.org/abs/2403.11010) | 本研究调查了预测更新如何影响MRP计划参数，并提出了扩展MRP的方法以减轻信息更新对生产订单的干扰。 |
| [^2] | [Quantitative Trading using Deep Q Learning.](http://arxiv.org/abs/2304.06037) | 本文探讨了强化学习在量化交易中的运用，揭示了基于 RL 的交易算法的案例研究结果表明，它有潜力优于传统的交易算法。这一研究代表了一个有希望的研究领域，可以潜在地引导更为复杂和有效的交易系统的开发。 |

# 详细

[^1]: 定期预测更新如何影响MRP计划参数：一项模拟研究

    How Periodic Forecast Updates Influence MRP Planning Parameters: A Simulation Study

    [https://arxiv.org/abs/2403.11010](https://arxiv.org/abs/2403.11010)

    本研究调查了预测更新如何影响MRP计划参数，并提出了扩展MRP的方法以减轻信息更新对生产订单的干扰。

    

    在许多供应链中，当前的数字化努力已经导致制造商和客户之间的信息交流得到改善。具体而言，需求预测通常由客户提供，并随着相关客户信息的改善而定期更新。本文研究了预测更新对物料需求计划（MRP）生产规划方法的影响。进行了模拟研究，以评估信息更新如何影响滚动视野MRP计划生产系统中设置规划参数。直观的结果是信息更新导致MRP标准生产订单出现干扰，因此开发了一个扩展MRP以减轻这些影响的方法。通过大规模的数值模拟实验表明，开发的MRP安全库存利用启发式方法显著改善了结果。

    arXiv:2403.11010v1 Announce Type: new  Abstract: In many supply chains, the current efforts at digitalization have led to improved information exchanges between manufacturers and their customers. Specifically, demand forecasts are often provided by the customers and regularly updated as the related customer information improves. In this paper, we investigate the influence of forecast updates on the production planning method of Material Requirements Planning (MRP). A simulation study was carried out to assess how updates in information affect the setting of planning parameters in a rolling horizon MRP planned production system. An intuitive result is that information updates lead to disturbances in the production orders for the MRP standard, and, therefore, an extension for MRP to mitigate these effects is developed. A large numerical simulation experiment shows that the MRP safety stock exploitation heuristic, that has been developed, leads to significantly improved results as far as 
    
[^2]: 使用深度 Q 学习进行量化交易。

    Quantitative Trading using Deep Q Learning. (arXiv:2304.06037v1 [q-fin.TR])

    [http://arxiv.org/abs/2304.06037](http://arxiv.org/abs/2304.06037)

    本文探讨了强化学习在量化交易中的运用，揭示了基于 RL 的交易算法的案例研究结果表明，它有潜力优于传统的交易算法。这一研究代表了一个有希望的研究领域，可以潜在地引导更为复杂和有效的交易系统的开发。

    

    强化学习是机器学习的一个分支，已被用于机器人技术、游戏玩法和自主系统等多种应用。近年来，人们越来越关注强化学习在量化交易领域的应用，旨在在金融市场上进行盈利交易。本论文探讨了 RL 在量化交易中的使用，并提供了一个基于 RL 的交易算法的案例研究。结果显示，RL 可以成为量化交易的强有力工具，并且它有潜力优于传统的交易算法。在量化交易中使用强化学习代表着一个有希望的研究领域，可以潜在地引导更为复杂和有效的交易系统的开发。未来的工作可以探索使用替代的强化学习算法，整合其他数据来源，并在不同的资产类别上测试该系统。总体而言，我们的研究证明了它的潜力。

    Reinforcement learning (RL) is a branch of machine learning that has been used in a variety of applications such as robotics, game playing, and autonomous systems. In recent years, there has been growing interest in applying RL to quantitative trading, where the goal is to make profitable trades in financial markets. This paper explores the use of RL in quantitative trading and presents a case study of a RL-based trading algorithm. The results show that RL can be a powerful tool for quantitative trading, and that it has the potential to outperform traditional trading algorithms. The use of reinforcement learning in quantitative trading represents a promising area of research that can potentially lead to the development of more sophisticated and effective trading systems. Future work could explore the use of alternative reinforcement learning algorithms, incorporate additional data sources, and test the system on different asset classes. Overall, our research demonstrates the potential 
    

