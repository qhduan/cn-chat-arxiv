# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Federated Multi-Agent Mapping for Planetary Exploration](https://arxiv.org/abs/2404.02289) | 联邦学习在多智能体机器人探测中的应用，利用隐式神经映射和地球数据集上的元初始化，实现了对不同领域如火星地形和冰川的强泛化能力。 |
| [^2] | [Privacy-Aware Semantic Cache for Large Language Models](https://arxiv.org/abs/2403.02694) | MeanCache是一种面向LLMs的语义缓存，能够识别语义上相似的查询，从而减少查询成本，服务提供商负载和环境影响。 |
| [^3] | [Simple linear attention language models balance the recall-throughput tradeoff](https://arxiv.org/abs/2402.18668) | 提出了一种简单的线性注意力语言模型架构，可以平衡召回和内存消耗之间的权衡。 |
| [^4] | [Learning-Augmented Skip Lists](https://arxiv.org/abs/2402.10457) | 通过将机器学习建议与跳表设计整合，提出了一种学习增强型跳表，能够实现最优期望搜索时间，在处理搜索查询时具有显著改进。 |
| [^5] | [AI, Meet Human: Learning Paradigms for Hybrid Decision Making Systems](https://arxiv.org/abs/2402.06287) | 本调查提出了混合决策系统的分类方法，为理解如何对人与机器之间的交互进行建模提供了概念性和技术性的框架。 |
| [^6] | [On the Completeness of Invariant Geometric Deep Learning Models](https://arxiv.org/abs/2402.04836) | 这项研究集中于不变模型的理论表达能力，通过引入完备的设计GeoNGNN，并利用其作为理论工具，首次证明了E(3)-完备性。 |
| [^7] | [Stochastic Modified Flows for Riemannian Stochastic Gradient Descent](https://arxiv.org/abs/2402.03467) | 本文研究了黎曼随机梯度下降（RSGD）的收敛速度，并介绍了一种基于随机修改流（RSMF）的扩散逼近方法，该方法可以提高对RSGD的近似精度。 |
| [^8] | [Universal Post-Training Reverse-Engineering Defense Against Backdoors in Deep Neural Networks](https://arxiv.org/abs/2402.02034) | 本文提出了一种针对深度神经网络中后门攻击的通用后训练反向工程防御方法，通过依赖内部特征图来检测和反向工程后门，并识别其目标类别，具有广泛适用性和低计算开销。 |
| [^9] | [Beyond RMSE and MAE: Introducing EAUC to unmask hidden bias and unfairness in dyadic regression models.](http://arxiv.org/abs/2401.10690) | 本研究引入EAUC作为一种新的度量标准，用以揭示迪亚德回归模型中隐藏的偏见和不公平问题。传统的全局错误度量标准如RMSE和MAE无法捕捉到这种问题。 |
| [^10] | [A match made in consistency heaven: when large language models meet evolutionary algorithms.](http://arxiv.org/abs/2401.10510) | 大型语言模型和进化算法的结合具有强大的一致性，包括标记嵌入和基因型-表现型映射、位置编码和适应性塑造、位置嵌入和选择、注意力和交叉、前馈神经网络和突变、模型训练和参数更新以及多任务学习和多目标优化等多个核心特征。本文分析了现有的耦合研究，并为未来的研究提供了基本路线和关键挑战。 |
| [^11] | [Improving the Accuracy and Interpretability of Random Forests via Forest Pruning.](http://arxiv.org/abs/2401.05535) | 通过森林修剪方法，本研究提出了一种兼顾随机森林准确性和决策树可解释性的方法。实验证明，在大多数情景下，这种方法能够显著提高随机森林的性能。 |
| [^12] | [On Forecast Stability.](http://arxiv.org/abs/2310.17332) | 本文研究了预测稳定性的两种类型：垂直稳定性和水平稳定性，并提出了一种适用于任何基础模型的简单线性插值方法来实现这种稳定性。这种方法可以产生准确而稳定的预测。 |
| [^13] | [CAMELL: Confidence-based Acquisition Model for Efficient Self-supervised Active Learning with Label Validation.](http://arxiv.org/abs/2310.08944) | CAMELL是一个适用于序列多输出问题的主动学习框架，通过仅需专家标注序列的一小部分、自监督和标签验证机制来解决监督神经方法对大规模标注数据集的依赖限制。 |
| [^14] | [AI-Enabled Software and System Architecture Frameworks: Focusing on smart Cyber-Physical Systems (CPS).](http://arxiv.org/abs/2308.05239) | 这篇论文提出了适应现代应用和组织要求的AI-enabled软件和系统架构框架，重点关注机器学习驱动的智能物联网系统(CPS)。作者提出了用于评估和基准化ML-enabled CPS的优点标准。 |
| [^15] | [Sustainable Transparency in Recommender Systems: Bayesian Ranking of Images for Explainability.](http://arxiv.org/abs/2308.01196) | 这项研究旨在实现推荐系统的可持续透明性，并提出了一种使用贝叶斯排名图像进行个性化解释的方法，以最大化透明度和用户信任。 |
| [^16] | [MutateNN: Mutation Testing of Image Recognition Models Deployed on Hardware Accelerators.](http://arxiv.org/abs/2306.01697) | MutateNN是一种用于探索硬件加速器上深度学习图像识别模型鲁棒性的工具，提供突变测试和分析能力，且有效性已在多种预训练深度神经网络模型中得到验证。 |
| [^17] | [Demystifying Misconceptions in Social Bots Research.](http://arxiv.org/abs/2303.17251) | 这篇文章揭示了关于社交机器人研究的普遍误解，强调需要以严谨、公正和负责任的方式讨论虚假信息研究。 |
| [^18] | [A fuzzy adaptive evolutionary-based feature selection and machine learning framework for single and multi-objective body fat prediction.](http://arxiv.org/abs/2303.11949) | 本文提出了一种模糊自适应进化特征选择与机器学习框架用于单目标和多目标身体脂肪预测，该方法在管理参数化和计算成本的同时确定了适当的探索和开发水平，可以避免陷入局部最优问题。 |

# 详细

[^1]: 行星探测的联邦多智能体建图

    Federated Multi-Agent Mapping for Planetary Exploration

    [https://arxiv.org/abs/2404.02289](https://arxiv.org/abs/2404.02289)

    联邦学习在多智能体机器人探测中的应用，利用隐式神经映射和地球数据集上的元初始化，实现了对不同领域如火星地形和冰川的强泛化能力。

    

    在多智能体机器人探测中，管理和有效利用动态环境产生的大量异构数据构成了一个重要挑战。联邦学习（FL）是一种有前途的分布式映射方法，它解决了协作学习中去中心化数据的挑战。FL使多个智能体之间可以进行联合模型训练，而无需集中化或共享原始数据，克服了带宽和存储限制。我们的方法利用隐式神经映射，将地图表示为由神经网络学习的连续函数，以便实现紧凑和适应性的表示。我们进一步通过在地球数据集上进行元初始化来增强这一方法，预训练网络以快速学习新的地图结构。这种组合在诸如火星地形和冰川等不同领域展现了较强的泛化能力。我们对这一方法进行了严格评估，展示了其有效性。

    arXiv:2404.02289v1 Announce Type: cross  Abstract: In multi-agent robotic exploration, managing and effectively utilizing the vast, heterogeneous data generated from dynamic environments poses a significant challenge. Federated learning (FL) is a promising approach for distributed mapping, addressing the challenges of decentralized data in collaborative learning. FL enables joint model training across multiple agents without requiring the centralization or sharing of raw data, overcoming bandwidth and storage constraints. Our approach leverages implicit neural mapping, representing maps as continuous functions learned by neural networks, for compact and adaptable representations. We further enhance this approach with meta-initialization on Earth datasets, pre-training the network to quickly learn new map structures. This combination demonstrates strong generalization to diverse domains like Martian terrain and glaciers. We rigorously evaluate this approach, demonstrating its effectiven
    
[^2]: 面向大型语言模型的隐私感知语义缓存

    Privacy-Aware Semantic Cache for Large Language Models

    [https://arxiv.org/abs/2403.02694](https://arxiv.org/abs/2403.02694)

    MeanCache是一种面向LLMs的语义缓存，能够识别语义上相似的查询，从而减少查询成本，服务提供商负载和环境影响。

    

    大型语言模型（LLMs）如ChatGPT、Google Bard、Claude和Llama 2彻底改变了自然语言处理和搜索引擎动态。然而，这些模型造成了异常高的计算成本。本文介绍了MeanCache，一种用于LLMs的语义缓存，它能够识别语义上相似的查询以确定缓存命中或未命中。

    arXiv:2403.02694v1 Announce Type: cross  Abstract: Large Language Models (LLMs) like ChatGPT, Google Bard, Claude, and Llama 2 have revolutionized natural language processing and search engine dynamics. However, these models incur exceptionally high computational costs. For instance, GPT-3 consists of 175 billion parameters and inference on these models also demands billions of floating-point operations. Caching is a natural solution to reduce LLM inference costs on repeated queries. However, existing caching methods are incapable of finding semantic similarities among LLM queries, leading to unacceptable false hit-and-miss rates.   This paper introduces MeanCache, a semantic cache for LLMs that identifies semantically similar queries to determine cache hit or miss. Using MeanCache, the response to a user's semantically similar query can be retrieved from a local cache rather than re-querying the LLM, thus reducing costs, service provider load, and environmental impact. MeanCache lever
    
[^3]: 简单的线性注意力语言模型平衡了召回-吞吐量的折衷

    Simple linear attention language models balance the recall-throughput tradeoff

    [https://arxiv.org/abs/2402.18668](https://arxiv.org/abs/2402.18668)

    提出了一种简单的线性注意力语言模型架构，可以平衡召回和内存消耗之间的权衡。

    

    最近的研究表明，基于注意力的语言模型擅长召回，即在上下文中已经看到的标记。然而，在推断过程中，基于注意力的模型的效率受到KV-cache的内存消耗的瓶颈限制。在这项工作中，我们探讨了是否可以提高语言模型的效率（例如通过减少内存消耗）而不影响召回。通过将实验和理论应用于广泛的架构，我们确定了模型状态大小和召回能力之间的一个关键权衡。我们发现，与注意力的高效替代方法（例如H3、Mamba、RWKV）保持固定大小的循环状态，但在召回方面表现不佳。我们提出了BASED，这是一种结合了线性和滑动窗口注意力的简单架构。通过改变BASED窗口大小和线性注意力特征维度，我们可以调整状态大小，并遍历召回-内存折衷的帕累托前沿。

    arXiv:2402.18668v1 Announce Type: new  Abstract: Recent work has shown that attention-based language models excel at recall, the ability to ground generations in tokens previously seen in context. However, the efficiency of attention-based models is bottle-necked during inference by the KV-cache's aggressive memory consumption. In this work, we explore whether we can improve language model efficiency (e.g. by reducing memory consumption) without compromising on recall. By applying experiments and theory to a broad set of architectures, we identify a key tradeoff between a model's state size and recall ability. We show that efficient alternatives to attention (e.g. H3, Mamba, RWKV) maintain a fixed-size recurrent state, but struggle at recall. We propose BASED a simple architecture combining linear and sliding window attention. By varying BASED window size and linear attention feature dimension, we can dial the state size and traverse the pareto frontier of the recall-memory tradeoff cu
    
[^4]: 学习增强型跳表

    Learning-Augmented Skip Lists

    [https://arxiv.org/abs/2402.10457](https://arxiv.org/abs/2402.10457)

    通过将机器学习建议与跳表设计整合，提出了一种学习增强型跳表，能够实现最优期望搜索时间，在处理搜索查询时具有显著改进。

    

    我们研究了将机器学习建议整合到跳表设计中，以改进传统数据结构设计。通过访问可能有误的预测分数频率的预测值的预言神谕，我们构建了一个跳表，可以证明提供最佳的期望搜索时间，几乎有二倍的优势。事实上，我们的学习增强型跳表仍然是最佳的，即使神谕只在常数因子内准确。我们表明，如果搜索查询遵循普遍存在的Zipfian分布，那么我们的跳表对于一个项目的期望搜索时间仅为一个常数，与项目总数n无关，即O(1)，而传统的跳表的期望搜索时间为O(log n)。我们还展示了我们的数据结构的鲁棒性，通过展示我们的数据结构实现了一个期望搜索时间，

    arXiv:2402.10457v1 Announce Type: cross  Abstract: We study the integration of machine learning advice into the design of skip lists to improve upon traditional data structure design. Given access to a possibly erroneous oracle that outputs estimated fractional frequencies for search queries on a set of items, we construct a skip list that provably provides the optimal expected search time, within nearly a factor of two. In fact, our learning-augmented skip list is still optimal up to a constant factor, even if the oracle is only accurate within a constant factor. We show that if the search queries follow the ubiquitous Zipfian distribution, then the expected search time for an item by our skip list is only a constant, independent of the total number $n$ of items, i.e., $\mathcal{O}(1)$, whereas a traditional skip list will have an expected search time of $\mathcal{O}(\log n)$. We also demonstrate robustness by showing that our data structure achieves an expected search time that is wi
    
[^5]: AI，与人相遇：混合决策系统的学习范式

    AI, Meet Human: Learning Paradigms for Hybrid Decision Making Systems

    [https://arxiv.org/abs/2402.06287](https://arxiv.org/abs/2402.06287)

    本调查提出了混合决策系统的分类方法，为理解如何对人与机器之间的交互进行建模提供了概念性和技术性的框架。

    

    每天，我们越来越多地依赖机器学习模型来自动化和支持高风险任务和决策。这种日益增长的存在意味着人类现在不断与基于机器学习的系统进行互动，每天进行模型的培训和使用。计算机科学文献中有几种不同的技术来考虑人与机器学习系统的交互，但其分类稀疏且目标各异。本调查提出了混合决策系统的分类方法，为理解当前计算机科学文献如何对人与机器之间的交互进行建模提供了概念性和技术性的框架。

    Everyday we increasingly rely on machine learning models to automate and support high-stake tasks and decisions. This growing presence means that humans are now constantly interacting with machine learning-based systems, training and using models everyday. Several different techniques in computer science literature account for the human interaction with machine learning systems, but their classification is sparse and the goals varied. This survey proposes a taxonomy of Hybrid Decision Making Systems, providing both a conceptual and technical framework for understanding how current computer science literature models interaction between humans and machines.
    
[^6]: 关于不变几何深度学习模型的完备性

    On the Completeness of Invariant Geometric Deep Learning Models

    [https://arxiv.org/abs/2402.04836](https://arxiv.org/abs/2402.04836)

    这项研究集中于不变模型的理论表达能力，通过引入完备的设计GeoNGNN，并利用其作为理论工具，首次证明了E(3)-完备性。

    

    不变模型是一类重要的几何深度学习模型，通过利用信息丰富的几何特征生成有意义的几何表示。这些模型以其简单性、良好的实验结果和计算效率而闻名。然而，它们的理论表达能力仍然不清楚，限制了对这种模型潜力的深入理解。在这项工作中，我们集中讨论不变模型的理论表达能力。我们首先严格限制了最经典的不变模型Vanilla DisGNN（结合距离的消息传递神经网络）的表达能力，将其不可识别的情况仅限于高度对称的几何图形。为了打破这些特殊情况的对称性，我们引入了一个简单而完备的不变设计，即嵌套Vanilla DisGNN的GeoNGNN。利用GeoNGNN作为理论工具，我们首次证明了E(3)-完备性。

    Invariant models, one important class of geometric deep learning models, are capable of generating meaningful geometric representations by leveraging informative geometric features. These models are characterized by their simplicity, good experimental results and computational efficiency. However, their theoretical expressive power still remains unclear, restricting a deeper understanding of the potential of such models. In this work, we concentrate on characterizing the theoretical expressiveness of invariant models. We first rigorously bound the expressiveness of the most classical invariant model, Vanilla DisGNN (message passing neural networks incorporating distance), restricting its unidentifiable cases to be only those highly symmetric geometric graphs. To break these corner cases' symmetry, we introduce a simple yet E(3)-complete invariant design by nesting Vanilla DisGNN, named GeoNGNN. Leveraging GeoNGNN as a theoretical tool, we for the first time prove the E(3)-completeness 
    
[^7]: 基于随机修改流的黎曼随机梯度下降

    Stochastic Modified Flows for Riemannian Stochastic Gradient Descent

    [https://arxiv.org/abs/2402.03467](https://arxiv.org/abs/2402.03467)

    本文研究了黎曼随机梯度下降（RSGD）的收敛速度，并介绍了一种基于随机修改流（RSMF）的扩散逼近方法，该方法可以提高对RSGD的近似精度。

    

    我们对黎曼随机梯度下降（RSGD）收敛速度给出了定量估计，并将其与黎曼梯度流和扩散过程——黎曼随机修改流（RSMF）进行了比较。利用随机微分几何工具，我们证明在小学习率范围内，RSGD可以近似为由无穷维维纳过程驱动的RSMF的解。RSMF考虑到了RSGD的随机波动，从而提高了与确定性黎曼梯度流的逼近顺序。RSGD使用了重传递映射的概念，即对指数映射的一种成本效益近似，我们对扩散逼近的弱误差进行了定量界定，在重传递映射、流形几何和梯度的随机估计的假设下证明了这些界定。

    We give quantitative estimates for the rate of convergence of Riemannian stochastic gradient descent (RSGD) to Riemannian gradient flow and to a diffusion process, the so-called Riemannian stochastic modified flow (RSMF). Using tools from stochastic differential geometry we show that, in the small learning rate regime, RSGD can be approximated by the solution to the RSMF driven by an infinite-dimensional Wiener process. The RSMF accounts for the random fluctuations of RSGD and, thereby, increases the order of approximation compared to the deterministic Riemannian gradient flow. The RSGD is build using the concept of a retraction map, that is, a cost efficient approximation of the exponential map, and we prove quantitative bounds for the weak error of the diffusion approximation under assumptions on the retraction map, the geometry of the manifold, and the random estimators of the gradient.
    
[^8]: 深度神经网络中针对后门攻击的通用后训练反向工程防御方法

    Universal Post-Training Reverse-Engineering Defense Against Backdoors in Deep Neural Networks

    [https://arxiv.org/abs/2402.02034](https://arxiv.org/abs/2402.02034)

    本文提出了一种针对深度神经网络中后门攻击的通用后训练反向工程防御方法，通过依赖内部特征图来检测和反向工程后门，并识别其目标类别，具有广泛适用性和低计算开销。

    

    针对深度神经网络分类器的后门攻击，提出了各种防御方法。通用方法旨在可靠地检测和/或减轻后门攻击，而反向工程方法通常明确假设其中一种。本文提出了一种新的检测器，它依赖于被防守的DNN的内部特征图来检测和反向工程后门，并识别其目标类别；它可以在后训练时操作（无需访问训练数据集）；对于不同的嵌入机制（即通用的）非常有效；并且具有低计算开销，因此可扩展。我们对基准CIFAR-10图像分类器的不同攻击进行了检测方法的评估。

    A variety of defenses have been proposed against backdoors attacks on deep neural network (DNN) classifiers. Universal methods seek to reliably detect and/or mitigate backdoors irrespective of the incorporation mechanism used by the attacker, while reverse-engineering methods often explicitly assume one. In this paper, we describe a new detector that: relies on internal feature map of the defended DNN to detect and reverse-engineer the backdoor and identify its target class; can operate post-training (without access to the training dataset); is highly effective for various incorporation mechanisms (i.e., is universal); and which has low computational overhead and so is scalable. Our detection approach is evaluated for different attacks on a benchmark CIFAR-10 image classifier.
    
[^9]: 超越RMSE和MAE：引入EAUC来揭示偏见和不公平的迪亚德回归模型中的隐藏因素

    Beyond RMSE and MAE: Introducing EAUC to unmask hidden bias and unfairness in dyadic regression models. (arXiv:2401.10690v1 [cs.LG])

    [http://arxiv.org/abs/2401.10690](http://arxiv.org/abs/2401.10690)

    本研究引入EAUC作为一种新的度量标准，用以揭示迪亚德回归模型中隐藏的偏见和不公平问题。传统的全局错误度量标准如RMSE和MAE无法捕捉到这种问题。

    

    迪亚德回归模型用于预测一对实体的实值结果，在许多领域中都是基础的（例如，在推荐系统中预测用户对产品的评分），在许多其他领域中也有许多潜力但尚未深入探索（例如，在个性化药理学中近似确定患者的适当剂量）。本研究中，我们证明个体实体观察值分布的非均匀性导致了最先进模型中的严重偏见预测，偏向于实体的观察过去值的平均值，并在另类但同样重要的情况下提供比随机预测更差的预测能力。我们表明，全局错误度量标准如均方根误差（RMSE）和平均绝对误差（MAE）不足以捕捉到这种现象，我们将其命名为另类偏见，并引入另类-曲线下面积（EAUC）作为一个新的补充度量，可以在所有研究的模型中量化它。

    Dyadic regression models, which predict real-valued outcomes for pairs of entities, are fundamental in many domains (e.g. predicting the rating of a user to a product in Recommender Systems) and promising and under exploration in many others (e.g. approximating the adequate dosage of a drug for a patient in personalized pharmacology). In this work, we demonstrate that non-uniformity in the observed value distributions of individual entities leads to severely biased predictions in state-of-the-art models, skewing predictions towards the average of observed past values for the entity and providing worse-than-random predictive power in eccentric yet equally important cases. We show that the usage of global error metrics like Root Mean Squared Error (RMSE) and Mean Absolute Error (MAE) is insufficient to capture this phenomenon, which we name eccentricity bias, and we introduce Eccentricity-Area Under the Curve (EAUC) as a new complementary metric that can quantify it in all studied models
    
[^10]: 天作之合：大型语言模型与进化算法的结合

    A match made in consistency heaven: when large language models meet evolutionary algorithms. (arXiv:2401.10510v1 [cs.NE])

    [http://arxiv.org/abs/2401.10510](http://arxiv.org/abs/2401.10510)

    大型语言模型和进化算法的结合具有强大的一致性，包括标记嵌入和基因型-表现型映射、位置编码和适应性塑造、位置嵌入和选择、注意力和交叉、前馈神经网络和突变、模型训练和参数更新以及多任务学习和多目标优化等多个核心特征。本文分析了现有的耦合研究，并为未来的研究提供了基本路线和关键挑战。

    

    预训练的大型语言模型（LLMs）在生成创造性的自然文本方面具有强大的能力。进化算法（EAs）可以发现复杂实际问题的多样解决方案。本文通过比较文本序列生成和进化的共同特点和方向性，阐述了LLMs与EAs之间的强大一致性，包括多个一对一的核心特征：标记嵌入和基因型-表现型映射、位置编码和适应性塑造、位置嵌入和选择、注意力和交叉、前馈神经网络和突变、模型训练和参数更新以及多任务学习和多目标优化。在这种一致性视角下，分析了现有的耦合研究，包括进化微调和LLM增强型EAs。借助这些洞见，我们概述了未来在LLMs和EAs耦合方面的基本研究路线，并突出了其中的关键挑战。

    Pre-trained large language models (LLMs) have powerful capabilities for generating creative natural text. Evolutionary algorithms (EAs) can discover diverse solutions to complex real-world problems. Motivated by the common collective and directionality of text sequence generation and evolution, this paper illustrates the strong consistency of LLMs and EAs, which includes multiple one-to-one key characteristics: token embedding and genotype-phenotype mapping, position encoding and fitness shaping, position embedding and selection, attention and crossover, feed-forward neural network and mutation, model training and parameter update, and multi-task learning and multi-objective optimization. Based on this consistency perspective, existing coupling studies are analyzed, including evolutionary fine-tuning and LLM-enhanced EAs. Leveraging these insights, we outline a fundamental roadmap for future research in coupling LLMs and EAs, while highlighting key challenges along the way. The consist
    
[^11]: 通过森林修剪提高随机森林的准确性和可解释性

    Improving the Accuracy and Interpretability of Random Forests via Forest Pruning. (arXiv:2401.05535v1 [stat.ML])

    [http://arxiv.org/abs/2401.05535](http://arxiv.org/abs/2401.05535)

    通过森林修剪方法，本研究提出了一种兼顾随机森林准确性和决策树可解释性的方法。实验证明，在大多数情景下，这种方法能够显著提高随机森林的性能。

    

    接近几十年的发展之后，随机森林仍然在各种学习问题中提供最先进的准确性，在这方面超越了决策树甚至神经网络等替代机器学习算法。然而，作为一种集成方法，随机森林在解释性方面往往比决策树表现不佳。在本研究中，我们提出了一种事后方法，旨在兼顾随机森林的准确性和决策树的可解释性。为此，我们提出了两种森林修剪方法，以在给定的随机森林内找到最佳子森林，然后在适用的情况下将选定的树合并为一棵。我们的第一种方法依赖于约束穷举搜索，而第二种方法基于LASSO方法的改进。在合成和真实世界数据集上进行的大量实验证明，在大多数情景下，这两种方法中至少有一种能够显著提高随机森林的准确性和可解释性。

    Decades after their inception, random forests continue to provide state-of-the-art accuracy in a variety of learning problems, outperforming in this respect alternative machine learning algorithms such as decision trees or even neural networks. However, being an ensemble method, the one aspect where random forests tend to severely underperform decision trees is interpretability. In the present work, we propose a post-hoc approach that aims to have the best of both worlds: the accuracy of random forests and the interpretability of decision trees. To this end, we present two forest-pruning methods to find an optimal sub-forest within a given random forest, and then, when applicable, combine the selected trees into one. Our first method relies on constrained exhaustive search, while our second method is based on an adaptation of the LASSO methodology. Extensive experiments over synthetic and real world datasets show that, in the majority of scenarios, at least one of the two methods propo
    
[^12]: 关于预测稳定性

    On Forecast Stability. (arXiv:2310.17332v1 [cs.LG])

    [http://arxiv.org/abs/2310.17332](http://arxiv.org/abs/2310.17332)

    本文研究了预测稳定性的两种类型：垂直稳定性和水平稳定性，并提出了一种适用于任何基础模型的简单线性插值方法来实现这种稳定性。这种方法可以产生准确而稳定的预测。

    

    预测通常不是在真空中产生的，而是在商业环境中生成的，预测是定期生成的，并且彼此之间互相影响。对于决策来说，预测不会任意变化，并且在某种程度上是稳定的可能很重要。然而，在预测文献中，这个领域只受到了有限的关注。在本文中，我们探索了两种我们称之为垂直稳定性和水平稳定性的预测稳定性类型。现有的文献工作只适用于某些基础模型，将这些框架扩展成与任何基础模型兼容并不容易。此外，这些框架只能使预测垂直稳定。为了填补这个空白，我们提出了一种基于简单线性插值的方法，适用于垂直和水平稳定化任何基础模型的预测。该方法可以产生准确而稳定的预测。

    Forecasts are typically not produced in a vacuum but in a business context, where forecasts are generated on a regular basis and interact with each other. For decisions, it may be important that forecasts do not change arbitrarily, and are stable in some sense. However, this area has received only limited attention in the forecasting literature. In this paper, we explore two types of forecast stability that we call vertical stability and horizontal stability. The existing works in the literature are only applicable to certain base models and extending these frameworks to be compatible with any base model is not straightforward. Furthermore, these frameworks can only stabilise the forecasts vertically. To fill this gap, we propose a simple linear-interpolation-based approach that is applicable to stabilise the forecasts provided by any base model vertically and horizontally. The approach can produce both accurate and stable forecasts. Using N-BEATS, Pooled Regression and LightGBM as the
    
[^13]: CAMELL：基于置信度的高效自监督主动学习与标签验证获取模型

    CAMELL: Confidence-based Acquisition Model for Efficient Self-supervised Active Learning with Label Validation. (arXiv:2310.08944v1 [cs.CL])

    [http://arxiv.org/abs/2310.08944](http://arxiv.org/abs/2310.08944)

    CAMELL是一个适用于序列多输出问题的主动学习框架，通过仅需专家标注序列的一小部分、自监督和标签验证机制来解决监督神经方法对大规模标注数据集的依赖限制。

    

    在序列任务中，受大规模且精确标注数据集的依赖限制，监督神经方法受到阻碍。标注质量随着从专家标注向众包标注的转变而逐渐恶化。为了解决这些挑战，我们提出了CAMELL（Confidence-based Acquisition Model for Efficient self-supervised active Learning with Label validation），这是一个针对序列多输出问题量身定制的基于池化的主动学习框架。CAMELL具有三个核心特点：(1)仅要求专家标注所选序列的一小部分，(2)为其余序列提供自监督，(3)采用标签验证机制，防止错误标签污染数据集并影响模型性能。我们在序列任务中对CAMELL进行了评估，特别强调对话信念跟踪，这是一个受限制的任务。

    Supervised neural approaches are hindered by their dependence on large, meticulously annotated datasets, a requirement that is particularly cumbersome for sequential tasks. The quality of annotations tends to deteriorate with the transition from expert-based to crowd-sourced labelling. To address these challenges, we present \textbf{CAMELL} (Confidence-based Acquisition Model for Efficient self-supervised active Learning with Label validation), a pool-based active learning framework tailored for sequential multi-output problems. CAMELL possesses three core features: (1) it requires expert annotators to label only a fraction of a chosen sequence, (2) it facilitates self-supervision for the remainder of the sequence, and (3) it employs a label validation mechanism to prevent erroneous labels from contaminating the dataset and harming model performance. We evaluate CAMELL on sequential tasks, with a special emphasis on dialogue belief tracking, a task plagued by the constraints of limited
    
[^14]: AI-Enabled Software and System Architecture Frameworks: Focusing on smart Cyber-Physical Systems (CPS).

    AI-Enabled Software and System Architecture Frameworks: Focusing on smart Cyber-Physical Systems (CPS). (arXiv:2308.05239v1 [cs.SE])

    [http://arxiv.org/abs/2308.05239](http://arxiv.org/abs/2308.05239)

    这篇论文提出了适应现代应用和组织要求的AI-enabled软件和系统架构框架，重点关注机器学习驱动的智能物联网系统(CPS)。作者提出了用于评估和基准化ML-enabled CPS的优点标准。

    

    在文献中提出了几种软件、系统和企业的架构框架。它们识别了各种利益相关者，并定义了架构的观点和视图，以框架和解决利益相关者的关注点。然而，在现有的架构框架中，尚未包括与数据科学和机器学习相关的利益相关者，如数据科学家和数据工程师。因此，它们未能解决响应数据科学社区关注的架构视点和视图。本文通过建立适用于现代应用和组织的架构框架来填补这一空白，其中机器学习工件普遍存在且至关重要。具体而言，我们专注于机器学习驱动的智能物联网系统（CPS），并提出了两组适应CPS高效开发和性能评估的优点标准，即用于评估和基准化机器学习驱动CPS的标准，

    Several architecture frameworks for software, systems, and enterprises have been proposed in the literature. They identified various stakeholders and defined architecture viewpoints and views to frame and address stakeholder concerns. However, the stakeholders with data science and Machine Learning (ML) related concerns, such as data scientists and data engineers, are yet to be included in existing architecture frameworks. Therefore, they failed to address the architecture viewpoints and views responsive to the concerns of the data science community. In this paper, we address this gap by establishing the architecture frameworks adapted to meet the requirements of modern applications and organizations where ML artifacts are both prevalent and crucial. In particular, we focus on ML-enabled Cyber-Physical Systems (CPSs) and propose two sets of merit criteria for their efficient development and performance assessment, namely the criteria for evaluating and benchmarking ML-enabled CPSs, and
    
[^15]: 可持续透明的推荐系统: 用于解释性的贝叶斯图像排名

    Sustainable Transparency in Recommender Systems: Bayesian Ranking of Images for Explainability. (arXiv:2308.01196v1 [cs.IR])

    [http://arxiv.org/abs/2308.01196](http://arxiv.org/abs/2308.01196)

    这项研究旨在实现推荐系统的可持续透明性，并提出了一种使用贝叶斯排名图像进行个性化解释的方法，以最大化透明度和用户信任。

    

    推荐系统在现代世界中变得至关重要，通常指导用户找到相关的内容或产品，并对用户和公民的决策产生重大影响。然而，确保这些系统的透明度和用户信任仍然是一个挑战；个性化解释已经成为一个解决方案，为推荐提供理由。在生成个性化解释的现有方法中，使用用户创建的视觉内容是一个特别有潜力的选项，有潜力最大化透明度和用户信任。然而，现有模型在这个背景下解释推荐时存在一些限制：可持续性是一个关键问题，因为它们经常需要大量的计算资源，导致的碳排放量与它们被整合到推荐系统中相当。此外，大多数模型使用的替代学习目标与排名最有效的目标不一致。

    Recommender Systems have become crucial in the modern world, commonly guiding users towards relevant content or products, and having a large influence over the decisions of users and citizens. However, ensuring transparency and user trust in these systems remains a challenge; personalized explanations have emerged as a solution, offering justifications for recommendations. Among the existing approaches for generating personalized explanations, using visual content created by the users is one particularly promising option, showing a potential to maximize transparency and user trust. Existing models for explaining recommendations in this context face limitations: sustainability has been a critical concern, as they often require substantial computational resources, leading to significant carbon emissions comparable to the Recommender Systems where they would be integrated. Moreover, most models employ surrogate learning goals that do not align with the objective of ranking the most effect
    
[^16]: MutateNN：用于硬件加速器上图像识别模型的突变测试

    MutateNN: Mutation Testing of Image Recognition Models Deployed on Hardware Accelerators. (arXiv:2306.01697v1 [cs.LG])

    [http://arxiv.org/abs/2306.01697](http://arxiv.org/abs/2306.01697)

    MutateNN是一种用于探索硬件加速器上深度学习图像识别模型鲁棒性的工具，提供突变测试和分析能力，且有效性已在多种预训练深度神经网络模型中得到验证。

    

    随着人工智能的研究进展，解决现实世界问题并推动技术发展的新机遇应运而生。图像识别模型特别是被分配了感知任务，以解决复杂的现实世界挑战并导致新的解决方案。此外，这类模型的计算复杂度和资源需求也有所增加。为了解决这个问题，模型优化和硬件加速已成为关键技术，但有效整合这些概念是一个具有挑战性和容易出错的过程。为了让开发人员和研究人员能够探索在不同硬件加速设备上部署的深度学习图像识别模型的鲁棒性，我们提出了MutateNN，这是一个为此目的提供突变测试和分析能力的工具。为了展示其功能，我们对7个广为人知的预训练深度神经网络模型进行了21种变异。我们在4种不同类型的硬件加速器上部署了我们的变异体，分析了它们的行为，并评估了MutateNN在检测出不正确或不精确的模型行为方面的有效性。

    With the research advancement of Artificial Intelligence in the last years, there are new opportunities to mitigate real-world problems and advance technologically. Image recognition models in particular, are assigned with perception tasks to mitigate complex real-world challenges and lead to new solutions. Furthermore, the computational complexity and demand for resources of such models has also increased. To mitigate this, model optimization and hardware acceleration has come into play, but effectively integrating such concepts is a challenging and error-prone process.  In order to allow developers and researchers to explore the robustness of deep learning image recognition models deployed on different hardware acceleration devices, we propose MutateNN, a tool that provides mutation testing and analysis capabilities for that purpose. To showcase its capabilities, we utilized 21 mutations for 7 widely-known pre-trained deep neural network models. We deployed our mutants on 4 different
    
[^17]: 揭开对社交机器人研究的误解

    Demystifying Misconceptions in Social Bots Research. (arXiv:2303.17251v1 [cs.SI])

    [http://arxiv.org/abs/2303.17251](http://arxiv.org/abs/2303.17251)

    这篇文章揭示了关于社交机器人研究的普遍误解，强调需要以严谨、公正和负责任的方式讨论虚假信息研究。

    

    社交机器人科学寻求解决网络虚假信息最受争议的形式之一的知识和解决方案。然而，社交机器人研究受到普遍的偏见、夸大的结果和误解的困扰，这些都为歧义、不切实际的期望和看似无法调和的发现打下了基础。克服这些问题对于确保可靠的解决方案和重申科学方法的有效性至关重要。在这篇文章中，我们修订了社交机器人研究中的一些最新结果，强调和纠正了事实错误以及方法论和概念问题。更重要的是，我们揭开了普遍的误解，解决了有关如何讨论社交机器人研究的基本问题。我们的分析揭示了以严谨、公正和负责任的方式讨论虚假信息研究的必要性。本文通过确定并驳斥社交机器人研究的支持者和反对者常用的谬误论证，支持这种努力。

    The science of social bots seeks knowledge and solutions to one of the most debated forms of online misinformation. Yet, social bots research is plagued by widespread biases, hyped results, and misconceptions that set the stage for ambiguities, unrealistic expectations, and seemingly irreconcilable findings. Overcoming such issues is instrumental towards ensuring reliable solutions and reaffirming the validity of the scientific method. In this contribution we revise some recent results in social bots research, highlighting and correcting factual errors as well as methodological and conceptual issues. More importantly, we demystify common misconceptions, addressing fundamental points on how social bots research is discussed. Our analysis surfaces the need to discuss misinformation research in a rigorous, unbiased, and responsible way. This article bolsters such effort by identifying and refuting common fallacious arguments used by both proponents and opponents of social bots research as
    
[^18]: 一种模糊自适应进化特征选择与机器学习框架用于单目标和多目标身体脂肪预测

    A fuzzy adaptive evolutionary-based feature selection and machine learning framework for single and multi-objective body fat prediction. (arXiv:2303.11949v1 [cs.NE])

    [http://arxiv.org/abs/2303.11949](http://arxiv.org/abs/2303.11949)

    本文提出了一种模糊自适应进化特征选择与机器学习框架用于单目标和多目标身体脂肪预测，该方法在管理参数化和计算成本的同时确定了适当的探索和开发水平，可以避免陷入局部最优问题。

    

    预测身体脂肪可以为医学从业者和用户提供预防和诊断心脏疾病的重要信息。混合机器学习模型通过选择相关的身体测量值和捕捉模型中所选特征之间的复杂非线性关系，提供了比简单的回归分析方法更好的性能。然而，它们仍然存在一些缺点。当前的机器学习建模方法将身体脂肪预测问题建模为组合的单目标和多目标优化问题，往往会陷入局部最优。当多个特征子集产生类似或接近的预测时，避免局部最优变得更加复杂。进化特征选择已被用于解决几个基于机器学习的优化问题。一个模糊集理论确定适当的探索和开发水平，同时管理参数化和计算成本。采用加权和身体脂肪预测方法进行实验评估

    Predicting body fat can provide medical practitioners and users with essential information for preventing and diagnosing heart diseases. Hybrid machine learning models offer better performance than simple regression analysis methods by selecting relevant body measurements and capturing complex nonlinear relationships among selected features in modelling body fat prediction problems. There are, however, some disadvantages to them. Current machine learning. Modelling body fat prediction as a combinatorial single- and multi-objective optimisation problem often gets stuck in local optima. When multiple feature subsets produce similar or close predictions, avoiding local optima becomes more complex. Evolutionary feature selection has been used to solve several machine-learning-based optimisation problems. A fuzzy set theory determines appropriate levels of exploration and exploitation while managing parameterisation and computational costs. A weighted-sum body fat prediction approach was ex
    

