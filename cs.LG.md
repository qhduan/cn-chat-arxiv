# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Tensor-based Graph Learning with Consistency and Specificity for Multi-view Clustering](https://arxiv.org/abs/2403.18393) | 本文提出了一种新颖的基于张量的图学习框架，同时考虑了多视图聚类的一致性和特异性，解决了现有方法在相似性测量和图信息利用方面的局限性。 |
| [^2] | [Self-Rectifying Diffusion Sampling with Perturbed-Attention Guidance](https://arxiv.org/abs/2403.17377) | 提出了一种名为扰动注意力引导（PAG）的新型抽样引导技术，通过在扩散 U-Net 中替换自注意力映射来生成结构降级的中间样本，从而在无条件和有条件设置下改善扩散样本质量。 |
| [^3] | [Privacy-Preserving Collaborative Split Learning Framework for Smart Grid Load Forecasting](https://arxiv.org/abs/2403.01438) | 提出了面向智能电网负荷预测的隐私保护协同分裂学习框架，通过将深度神经网络模型分裂为Grid Station（GS）和服务提供商（SP）部分，实现智能电表数据的隐私保护和负载预测的个性化模型训练。 |
| [^4] | [Geometric Deep Learning for Computer-Aided Design: A Survey](https://arxiv.org/abs/2402.17695) | 几何深度学习技术在计算机辅助设计领域具有变革性力量，可以通过机器学习优化CAD设计师的工作流程，节省时间和精力，提高决策效率，并创造出具有创新性和实用性的设计。 |
| [^5] | [VGMShield: Mitigating Misuse of Video Generative Models](https://arxiv.org/abs/2402.13126) | VGMShield提出了三项简单但开创性的措施，通过检测虚假视频、溯源问题和利用预训练的空间-时间动态模型，防范视频生成模型的误用。 |
| [^6] | [Score-based Diffusion Models via Stochastic Differential Equations -- a Technical Tutorial](https://arxiv.org/abs/2402.07487) | 本文是基于分数的扩散模型的技术教程，重点讲解了通过随机微分方程进行公式化的方法，包括采样和分数匹配。适合初学者了解该领域，并且从业人员在设计新模型或算法时也可能会有所帮助。 |
| [^7] | [Provably Stable Feature Rankings with SHAP and LIME.](http://arxiv.org/abs/2401.15800) | 这项研究提出了一种通过利用多重假设检验的思想，来设计可靠地排名机器学习模型中最重要特征的特征归因方法，旨在解决SHAP和LIME等常用方法由于随机采样导致的高度不稳定性问题。实验证明了该方法的有效性和计算效率。 |
| [^8] | [Four Facets of Forecast Felicity: Calibration, Predictiveness, Randomness and Regret.](http://arxiv.org/abs/2401.14483) | 本文展示了校准和遗憾在评估预测中的概念等价性，将评估问题构建为一个预测者、一个赌徒和自然之间的博弈，并将预测的评估与结果的随机性联系起来。 |
| [^9] | [Efficient generative adversarial networks using linear additive-attention Transformers.](http://arxiv.org/abs/2401.09596) | 这项工作提出了一种名为LadaGAN的高效生成对抗网络，它使用了一种名为Ladaformer的新型Transformer块，通过线性加法注意机制来降低计算复杂度并解决训练不稳定性问题。 |
| [^10] | [Deep Kalman Filters Can Filter.](http://arxiv.org/abs/2310.19603) | 本研究展示了一类连续时间的深度卡尔曼滤波器（DKFs），可以近似实现一类非马尔可夫和条件高斯信号过程的条件分布律，从而具有在数学金融领域中传统模型基础上的滤波问题的应用潜力。 |
| [^11] | [Model-free Posterior Sampling via Learning Rate Randomization.](http://arxiv.org/abs/2310.18186) | 本文介绍了一种随机化无模型算法RandQL，用于减小马尔科夫决策过程中的遗憾。RandQL通过学习率随机化实现乐观探索，并在实证研究中表现出色。 |
| [^12] | [AVTENet: Audio-Visual Transformer-based Ensemble Network Exploiting Multiple Experts for Video Deepfake Detection.](http://arxiv.org/abs/2310.13103) | 本文提出了AVTENet框架，该框架是一个基于音频-视觉Transformer的多专家集成网络，用于在视频深度伪造检测中考虑声学和视觉操作。 |
| [^13] | [Statistical guarantees for stochastic Metropolis-Hastings.](http://arxiv.org/abs/2310.09335) | 该论文研究了针对随机Metropolis-Hastings算法的统计保证。通过引入简单的修正项，该方法可以避免计算成本上的损失，并通过分析非参数回归情景和深度神经网络回归的数值实例来证明了其在采样和可信区间方面的优势。 |
| [^14] | [Efficient Finite Initialization for Tensorized Neural Networks.](http://arxiv.org/abs/2309.06577) | 这种方法提出了一种高效有限初始化张量化神经网络层的方法，避免了参数爆炸问题，并通过使用弗罗贝尼乌斯范数的迭代部分形式来计算范数，使其具有有限范围。应用于不同层的实验表明其性能良好。 |
| [^15] | [On the quality of randomized approximations of Tukey's depth.](http://arxiv.org/abs/2309.05657) | 本文研究了Tukey深度的随机近似质量问题，证明了在维度较高且数据从对数凹集的均匀分布中抽样的情况下，随机算法可以正确近似最大深度和接近零的深度，而对于中间深度的点，任何好的近似都需要指数复杂度。 |
| [^16] | [Relation-Aware Network with Attention-Based Loss for Few-Shot Knowledge Graph Completion.](http://arxiv.org/abs/2306.09519) | 本文提出了一种新颖的RANA框架，利用有策略地选择相关负样本和设计基于注意力机制的损失函数来更好地利用负样本并缓解零损失问题，同时设计了一种动态的关系感知实体编码来捕获不同关系下实体的不同表示。 |
| [^17] | [The geometry of financial institutions -- Wasserstein clustering of financial data.](http://arxiv.org/abs/2305.03565) | 本文提出了一种新的算法，Wasserstein聚类，用于处理金融机构的复杂数据，有效地解决了缺失值和基于特定特征识别聚类所面临的挑战。该算法可用于监管者的监管工作，并在其领域取得了良好的效果。 |
| [^18] | [Specification-Driven Neural Network Reduction for Scalable Formal Verification.](http://arxiv.org/abs/2305.01932) | 本文提出了一种基于规范的神经网络简化方法用于大规模形式化验证。该方法采用保守的简化方法，确保简化后的网络验证与原网络验证派生等价。简化后可将网络减少到小于5％的神经元数量，从而减少了相应的验证时间。 |
| [^19] | [Learning from Similar Linear Representations: Adaptivity, Minimaxity, and Robustness.](http://arxiv.org/abs/2303.17765) | 本文提出了两种算法，适应相似性结构并对异常值任务具有稳健性，适用于表示多任务学习和迁移学习设置。 |
| [^20] | [Uncertainty in Real-Time Semantic Segmentation on Embedded Systems.](http://arxiv.org/abs/2301.01201) | 本文提出了一种结合贝叶斯回归和动量传播的预测方法，能够实时在嵌入式硬件上产生有意义的不确定性，从而使语义分割模型在自动驾驶和人机交互等领域的实时应用成为可能。 |
| [^21] | [Normality-Guided Distributional Reinforcement Learning for Continuous Control.](http://arxiv.org/abs/2208.13125) | 本论文研究了连续控制任务中的值分布，并发现学习的值分布与正态分布非常接近。基于这一观察，提出了一种正态引导的分布式强化学习方法，利用方差网络预测的方差和回报，以及与标准值函数不同的值分布结构特征来更新策略。这种方法在两种在线算法上产生了显著效果。 |

# 详细

[^1]: 基于张量的一致性和特异性多视角聚类图学习

    Tensor-based Graph Learning with Consistency and Specificity for Multi-view Clustering

    [https://arxiv.org/abs/2403.18393](https://arxiv.org/abs/2403.18393)

    本文提出了一种新颖的基于张量的图学习框架，同时考虑了多视图聚类的一致性和特异性，解决了现有方法在相似性测量和图信息利用方面的局限性。

    

    图学习被广泛认为是多视角聚类中的关键技术。现有的图学习方法通常涉及基于概率邻居构建自适应邻居图，然后学习一致性图进行聚类，然而，它们面临两个局限性。首先，它们通常依赖欧氏距离来衡量相似性，这在许多真实场景中捕捉数据点间的内在结构时证明是不足够的。其次，大多数这些方法仅关注一致性图，忽略了特定视图的图信息。针对上述缺点，本文提出了一种新颖的基于张量的图学习框架，同时考虑了多视图聚类的一致性和特异性。具体地，我们在斯蒂弗尔流形上计算相似距离以保留内在str

    arXiv:2403.18393v1 Announce Type: new  Abstract: Graph learning is widely recognized as a crucial technique in multi-view clustering. Existing graph learning methods typically involve constructing an adaptive neighbor graph based on probabilistic neighbors and then learning a consensus graph to for clustering, however, they are confronted with two limitations. Firstly, they often rely on Euclidean distance to measure similarity when constructing the adaptive neighbor graph, which proves inadequate in capturing the intrinsic structure among data points in many real-world scenarios. Secondly, most of these methods focus solely on consensus graph, ignoring view-specific graph information. In response to the aforementioned drawbacks, we in this paper propose a novel tensor-based graph learning framework that simultaneously considers consistency and specificity for multi-view clustering. Specifically, we calculate the similarity distance on the Stiefel manifold to preserve the intrinsic str
    
[^2]: 具有扰动注意力引导的自矫正扩散抽样

    Self-Rectifying Diffusion Sampling with Perturbed-Attention Guidance

    [https://arxiv.org/abs/2403.17377](https://arxiv.org/abs/2403.17377)

    提出了一种名为扰动注意力引导（PAG）的新型抽样引导技术，通过在扩散 U-Net 中替换自注意力映射来生成结构降级的中间样本，从而在无条件和有条件设置下改善扩散样本质量。

    

    近期研究表明，扩散模型能够生成高质量样本，但其质量很大程度上依赖于抽样引导技术，比如分类器引导（CG）和无分类器引导（CFG）。这些技术通常在无条件生成或各种下游任务如图像恢复中无法应用。本文提出了一种新颖的抽样引导技术，称为扰动注意力引导（PAG），它改进了扩散样本的质量，不管是在无条件还是有条件的设置中，都能实现这一目标，而不需要额外训练或整合外部模块。PAG 旨在通过整个去噪过程逐步增强样本的结构。它涉及通过用恒等矩阵替换扩散 U-Net 中选择的自注意力映射生成结构降级的中间样本，考虑自注意力机制。

    arXiv:2403.17377v1 Announce Type: cross  Abstract: Recent studies have demonstrated that diffusion models are capable of generating high-quality samples, but their quality heavily depends on sampling guidance techniques, such as classifier guidance (CG) and classifier-free guidance (CFG). These techniques are often not applicable in unconditional generation or in various downstream tasks such as image restoration. In this paper, we propose a novel sampling guidance, called Perturbed-Attention Guidance (PAG), which improves diffusion sample quality across both unconditional and conditional settings, achieving this without requiring additional training or the integration of external modules. PAG is designed to progressively enhance the structure of samples throughout the denoising process. It involves generating intermediate samples with degraded structure by substituting selected self-attention maps in diffusion U-Net with an identity matrix, by considering the self-attention mechanisms
    
[^3]: 面向智能电网负荷预测的隐私保护协同分裂学习框架

    Privacy-Preserving Collaborative Split Learning Framework for Smart Grid Load Forecasting

    [https://arxiv.org/abs/2403.01438](https://arxiv.org/abs/2403.01438)

    提出了面向智能电网负荷预测的隐私保护协同分裂学习框架，通过将深度神经网络模型分裂为Grid Station（GS）和服务提供商（SP）部分，实现智能电表数据的隐私保护和负载预测的个性化模型训练。

    

    准确的负荷预测对能源管理、基础设施规划和供需平衡至关重要。智能电表数据的可用性导致了传感器数据驱动的负荷预测需求。传统机器学习允许使用来自多个智能电表的数据训练单个全局模型，这需要将数据传输到中央服务器，引发了对网络要求、隐私和安全性的担忧。我们提出了一种基于分裂学习的负荷预测框架，以缓解这一问题。我们将深度神经网络模型分为两个部分，一个用于每个Grid Station（GS），负责一个整个社区的智能电表；另一个用于服务提供商（SP）。客户智能电表不共享其数据，而是使用各自的GS模型拆分进行前向传递，只将其激活与GS共享。在这一框架下，每个GS负责为其各自的社区训练个性化模型分裂。

    arXiv:2403.01438v1 Announce Type: new  Abstract: Accurate load forecasting is crucial for energy management, infrastructure planning, and demand-supply balancing. Smart meter data availability has led to the demand for sensor-based load forecasting. Conventional ML allows training a single global model using data from multiple smart meters requiring data transfer to a central server, raising concerns for network requirements, privacy, and security. We propose a split learning-based framework for load forecasting to alleviate this issue. We split a deep neural network model into two parts, one for each Grid Station (GS) responsible for an entire neighbourhood's smart meters and the other for the Service Provider (SP). Instead of sharing their data, client smart meters use their respective GSs' model split for forward pass and only share their activations with the GS. Under this framework, each GS is responsible for training a personalized model split for their respective neighbourhoods,
    
[^4]: 计算机辅助设计的几何深度学习：一项调查

    Geometric Deep Learning for Computer-Aided Design: A Survey

    [https://arxiv.org/abs/2402.17695](https://arxiv.org/abs/2402.17695)

    几何深度学习技术在计算机辅助设计领域具有变革性力量，可以通过机器学习优化CAD设计师的工作流程，节省时间和精力，提高决策效率，并创造出具有创新性和实用性的设计。

    

    几何深度学习技术已成为计算机辅助设计（CAD）领域的一股变革力量，并有可能彻底改变设计师和工程师处理和增强设计过程的方式。通过利用基于机器学习的方法，CAD设计师可以优化他们的工作流程，节省时间和精力，做出更为明智的决策，创造既创新又实用的设计。处理以几何数据表示的CAD设计并分析其编码特征的能力使得能够识别不同CAD模型之间的相似之处，提出替代设计和增强方案，甚至生成新的设计替代方案。这份调查全面介绍了计算机辅助设计中基于学习的方法，涵盖了各种类别，包括相似性分析和检索、2D和3D CAD模型合成，以及CAD生成。

    arXiv:2402.17695v1 Announce Type: cross  Abstract: Geometric Deep Learning techniques have become a transformative force in the field of Computer-Aided Design (CAD), and have the potential to revolutionize how designers and engineers approach and enhance the design process. By harnessing the power of machine learning-based methods, CAD designers can optimize their workflows, save time and effort while making better informed decisions, and create designs that are both innovative and practical. The ability to process the CAD designs represented by geometric data and to analyze their encoded features enables the identification of similarities among diverse CAD models, the proposition of alternative designs and enhancements, and even the generation of novel design alternatives. This survey offers a comprehensive overview of learning-based methods in computer-aided design across various categories, including similarity analysis and retrieval, 2D and 3D CAD model synthesis, and CAD generatio
    
[^5]: VGMShield：缓解视频生成模型的误用

    VGMShield: Mitigating Misuse of Video Generative Models

    [https://arxiv.org/abs/2402.13126](https://arxiv.org/abs/2402.13126)

    VGMShield提出了三项简单但开创性的措施，通过检测虚假视频、溯源问题和利用预训练的空间-时间动态模型，防范视频生成模型的误用。

    

    随着视频生成技术的快速发展，人们可以方便地利用视频生成模型创建符合其特定需求的视频。然而，人们也越来越担心这些技术被用于创作和传播虚假信息。在这项工作中，我们介绍了VGMShield：一套包含三项直接但开创性的措施，用于防范虚假视频生成过程中可能出现的问题。我们首先从“虚假视频检测”开始，尝试理解生成的视频中是否存在独特性，以及我们是否能够区分它们与真实视频的不同；然后，我们探讨“溯源”问题，即将一段虚假视频追溯回生成它的模型。为此，我们提出利用预训练的关注“时空动态”的模型作为骨干，以识别视频中的不一致性。通过对七个最先进的开源模型进行实验，我们证明了...

    arXiv:2402.13126v1 Announce Type: cross  Abstract: With the rapid advancement in video generation, people can conveniently utilize video generation models to create videos tailored to their specific desires. Nevertheless, there are also growing concerns about their potential misuse in creating and disseminating false information.   In this work, we introduce VGMShield: a set of three straightforward but pioneering mitigations through the lifecycle of fake video generation. We start from \textit{fake video detection} trying to understand whether there is uniqueness in generated videos and whether we can differentiate them from real videos; then, we investigate the \textit{tracing} problem, which maps a fake video back to a model that generates it. Towards these, we propose to leverage pre-trained models that focus on {\it spatial-temporal dynamics} as the backbone to identify inconsistencies in videos. Through experiments on seven state-of-the-art open-source models, we demonstrate that
    
[^6]: 基于分数的扩散模型：随机微分方程的技术教程

    Score-based Diffusion Models via Stochastic Differential Equations -- a Technical Tutorial

    [https://arxiv.org/abs/2402.07487](https://arxiv.org/abs/2402.07487)

    本文是基于分数的扩散模型的技术教程，重点讲解了通过随机微分方程进行公式化的方法，包括采样和分数匹配。适合初学者了解该领域，并且从业人员在设计新模型或算法时也可能会有所帮助。

    

    本文是关于基于分数的扩散模型的阐释性文章，重点介绍了通过随机微分方程(SDE)进行公式化的方法。在温和的介绍之后，我们讨论了扩散建模的两个关键点--采样和分数匹配，其中包括SDE/ODE采样，分数匹配效率，一致性模型和强化学习。我们提供了简短的证明来说明所述结果的主要思想。本文主要是为了向初学者介绍这个领域，同时从业人员在设计新模型或算法时也可能会发现一些分析有用。

    This is an expository article on the score-based diffusion models, with a particular focus on the formulation via stochastic differential equations (SDE). After a gentle introduction, we discuss the two pillars in the diffusion modeling -- sampling and score matching, which encompass the SDE/ODE sampling, score matching efficiency, the consistency model, and reinforcement learning. Short proofs are given to illustrate the main idea of the stated results. The article is primarily for introducing the beginners to the field, and practitioners may also find some analysis useful in designing new models or algorithms.
    
[^7]: 使用SHAP和LIME进行可证明稳定的特征排名

    Provably Stable Feature Rankings with SHAP and LIME. (arXiv:2401.15800v1 [stat.ML])

    [http://arxiv.org/abs/2401.15800](http://arxiv.org/abs/2401.15800)

    这项研究提出了一种通过利用多重假设检验的思想，来设计可靠地排名机器学习模型中最重要特征的特征归因方法，旨在解决SHAP和LIME等常用方法由于随机采样导致的高度不稳定性问题。实验证明了该方法的有效性和计算效率。

    

    特征归因是了解机器学习模型预测的普遍工具。然而，用于评分输入变量的常用方法，如SHAP和LIME，由于随机采样而具有高度不稳定性。借鉴多重假设检验的思想，我们设计了能够以高概率正确排名最重要特征的归因方法。我们的算法RankSHAP保证$K$个最高Shapley值具有超过$1-\alpha$的正确排序概率。实证结果证明了其有效性和令人印象深刻的计算效率。我们还在之前的工作基础上为LIME提供了类似的结果，确保以正确顺序选择最重要的特征。

    Feature attributions are ubiquitous tools for understanding the predictions of machine learning models. However, popular methods for scoring input variables such as SHAP and LIME suffer from high instability due to random sampling. Leveraging ideas from multiple hypothesis testing, we devise attribution methods that correctly rank the most important features with high probability. Our algorithm RankSHAP guarantees that the $K$ highest Shapley values have the proper ordering with probability exceeding $1-\alpha$. Empirical results demonstrate its validity and impressive computational efficiency. We also build on previous work to yield similar results for LIME, ensuring the most important features are selected in the right order.
    
[^8]: 预测的四个方面：校准、预测性、随机性和遗憾

    Four Facets of Forecast Felicity: Calibration, Predictiveness, Randomness and Regret. (arXiv:2401.14483v1 [cs.LG])

    [http://arxiv.org/abs/2401.14483](http://arxiv.org/abs/2401.14483)

    本文展示了校准和遗憾在评估预测中的概念等价性，将评估问题构建为一个预测者、一个赌徒和自然之间的博弈，并将预测的评估与结果的随机性联系起来。

    

    机器学习是关于预测的。然而，预测只有经过评估后才具有其有用性。机器学习传统上关注损失类型及其相应的遗憾。目前，机器学习社区重新对校准产生了兴趣。在这项工作中，我们展示了校准和遗憾在评估预测中的概念等价性。我们将评估问题构建为一个预测者、一个赌徒和自然之间的博弈。通过对赌徒和预测者施加直观的限制，校准和遗憾自然地成为了这个框架的一部分。此外，这个博弈将预测的评估与结果的随机性联系起来。相对于预测而言，结果的随机性等同于关于结果的好的预测。我们称这两个方面为校准和遗憾、预测性和随机性，即预测的四个方面。

    Machine learning is about forecasting. Forecasts, however, obtain their usefulness only through their evaluation. Machine learning has traditionally focused on types of losses and their corresponding regret. Currently, the machine learning community regained interest in calibration. In this work, we show the conceptual equivalence of calibration and regret in evaluating forecasts. We frame the evaluation problem as a game between a forecaster, a gambler and nature. Putting intuitive restrictions on gambler and forecaster, calibration and regret naturally fall out of the framework. In addition, this game links evaluation of forecasts to randomness of outcomes. Random outcomes with respect to forecasts are equivalent to good forecasts with respect to outcomes. We call those dual aspects, calibration and regret, predictiveness and randomness, the four facets of forecast felicity.
    
[^9]: 使用线性加法注意力Transformer的高效生成对抗网络

    Efficient generative adversarial networks using linear additive-attention Transformers. (arXiv:2401.09596v1 [cs.CV])

    [http://arxiv.org/abs/2401.09596](http://arxiv.org/abs/2401.09596)

    这项工作提出了一种名为LadaGAN的高效生成对抗网络，它使用了一种名为Ladaformer的新型Transformer块，通过线性加法注意机制来降低计算复杂度并解决训练不稳定性问题。

    

    尽管像扩散模型（DMs）和生成对抗网络（GANs）等深度生成模型在图像生成方面的能力近年来得到了显著提高，但是它们的成功很大程度上归功于计算复杂的架构。这限制了它们在研究实验室和资源充足的公司中的采用和使用，同时也极大地增加了训练、微调和推理的碳足迹。在这项工作中，我们提出了LadaGAN，这是一个高效的生成对抗网络，它建立在一种名为Ladaformer的新型Transformer块上。该块的主要组成部分是一个线性加法注意机制，它每个头部计算一个注意向量，而不是二次的点积注意力。我们在生成器和判别器中都采用了Ladaformer，这降低了计算复杂度，并克服了Transformer GAN经常出现的训练不稳定性。LadaGAN一直表现优于现有的GANs。

    Although the capacity of deep generative models for image generation, such as Diffusion Models (DMs) and Generative Adversarial Networks (GANs), has dramatically improved in recent years, much of their success can be attributed to computationally expensive architectures. This has limited their adoption and use to research laboratories and companies with large resources, while significantly raising the carbon footprint for training, fine-tuning, and inference. In this work, we present LadaGAN, an efficient generative adversarial network that is built upon a novel Transformer block named Ladaformer. The main component of this block is a linear additive-attention mechanism that computes a single attention vector per head instead of the quadratic dot-product attention. We employ Ladaformer in both the generator and discriminator, which reduces the computational complexity and overcomes the training instabilities often associated with Transformer GANs. LadaGAN consistently outperforms exist
    
[^10]: 深度卡尔曼滤波器可以进行滤波

    Deep Kalman Filters Can Filter. (arXiv:2310.19603v1 [cs.LG])

    [http://arxiv.org/abs/2310.19603](http://arxiv.org/abs/2310.19603)

    本研究展示了一类连续时间的深度卡尔曼滤波器（DKFs），可以近似实现一类非马尔可夫和条件高斯信号过程的条件分布律，从而具有在数学金融领域中传统模型基础上的滤波问题的应用潜力。

    

    深度卡尔曼滤波器（DKFs）是一类神经网络模型，可以从序列数据中生成高斯概率测度。虽然DKFs受卡尔曼滤波器的启发，但它们缺乏与随机滤波问题的具体理论关联，从而限制了它们在传统模型基础上的滤波问题的应用，例如数学金融中的债券和期权定价模型校准。我们通过展示一类连续时间DKFs，可以近似实现一类非马尔可夫和条件高斯信号过程的条件分布律，从而解决了深度学习数学基础中的这个问题。我们的近似结果在路径的足够规则的紧致子集上一致成立，其中近似误差由在给定紧致路径集上均一地计算的最坏情况2-Wasserstein距离量化。

    Deep Kalman filters (DKFs) are a class of neural network models that generate Gaussian probability measures from sequential data. Though DKFs are inspired by the Kalman filter, they lack concrete theoretical ties to the stochastic filtering problem, thus limiting their applicability to areas where traditional model-based filters have been used, e.g.\ model calibration for bond and option prices in mathematical finance. We address this issue in the mathematical foundations of deep learning by exhibiting a class of continuous-time DKFs which can approximately implement the conditional law of a broad class of non-Markovian and conditionally Gaussian signal processes given noisy continuous-times measurements. Our approximation results hold uniformly over sufficiently regular compact subsets of paths, where the approximation error is quantified by the worst-case 2-Wasserstein distance computed uniformly over the given compact set of paths.
    
[^11]: 无模型后验采样的模型自由随机学习方法

    Model-free Posterior Sampling via Learning Rate Randomization. (arXiv:2310.18186v1 [stat.ML])

    [http://arxiv.org/abs/2310.18186](http://arxiv.org/abs/2310.18186)

    本文介绍了一种随机化无模型算法RandQL，用于减小马尔科夫决策过程中的遗憾。RandQL通过学习率随机化实现乐观探索，并在实证研究中表现出色。

    

    本文介绍了一种新颖的随机化无模型算法，Randomized Q-learning（简称RandQL），用于减小马尔科夫决策过程（MDPs）中的遗憾。据我们所知，RandQL是第一个可行的模型自由后验采样算法。我们分析了RandQL在表格和非表格度量空间设置下的性能。在表格MDPs中，RandQL实现了一个遗憾界的顺序为$\widetilde{\mathcal{O}}(\sqrt{H^{5}SAT})$，其中$H$是计划的时间长度，$S$是状态数，$A$是动作数，$T$是回合数。对于度量状态-动作空间，RandQL实现了一个遗憾界的顺序为$\widetilde{\mathcal{O}}(H^{5/2} T^{(d_z+1)/(d_z+2)})$，其中$d_z$表示缩放维度。需要注意的是，RandQL实现了乐观探索，而不使用奖励，而是依赖于学习率随机化的新思想。我们的实证研究表明，RandQL在基线探索上胜过现有方法。

    In this paper, we introduce Randomized Q-learning (RandQL), a novel randomized model-free algorithm for regret minimization in episodic Markov Decision Processes (MDPs). To the best of our knowledge, RandQL is the first tractable model-free posterior sampling-based algorithm. We analyze the performance of RandQL in both tabular and non-tabular metric space settings. In tabular MDPs, RandQL achieves a regret bound of order $\widetilde{\mathcal{O}}(\sqrt{H^{5}SAT})$, where $H$ is the planning horizon, $S$ is the number of states, $A$ is the number of actions, and $T$ is the number of episodes. For a metric state-action space, RandQL enjoys a regret bound of order $\widetilde{\mathcal{O}}(H^{5/2} T^{(d_z+1)/(d_z+2)})$, where $d_z$ denotes the zooming dimension. Notably, RandQL achieves optimistic exploration without using bonuses, relying instead on a novel idea of learning rate randomization. Our empirical study shows that RandQL outperforms existing approaches on baseline exploration en
    
[^12]: AVTENet: 基于音频-视觉Transformer的多专家集成网络在视频深度伪造检测中的应用

    AVTENet: Audio-Visual Transformer-based Ensemble Network Exploiting Multiple Experts for Video Deepfake Detection. (arXiv:2310.13103v1 [cs.CV])

    [http://arxiv.org/abs/2310.13103](http://arxiv.org/abs/2310.13103)

    本文提出了AVTENet框架，该框架是一个基于音频-视觉Transformer的多专家集成网络，用于在视频深度伪造检测中考虑声学和视觉操作。

    

    在社交媒体平台上广泛分享的伪造内容是一个重大社会问题，要求加强监管并给研究社区带来新的挑战。近年来，超真实的深度伪造视频的普及引起了对音频和视觉伪造威胁的关注。大多数关于检测AI生成的伪造视频的先前工作只利用了视觉模态或音频模态。虽然文献中有一些方法利用音频和视觉模态来检测伪造视频，但它们尚未在涉及声学和视觉操作的多模态深度伪造视频数据集上进行全面评估。此外，这些现有方法大多基于CNN，并且检测准确率较低。受到Transformer在各个领域的最新成功启发，为了解决深度伪造技术带来的挑战，本文提出了一种考虑声学操作的音频-视觉Transformer集成网络（AVTENet）框架。

    Forged content shared widely on social media platforms is a major social problem that requires increased regulation and poses new challenges to the research community. The recent proliferation of hyper-realistic deepfake videos has drawn attention to the threat of audio and visual forgeries. Most previous work on detecting AI-generated fake videos only utilizes visual modality or audio modality. While there are some methods in the literature that exploit audio and visual modalities to detect forged videos, they have not been comprehensively evaluated on multi-modal datasets of deepfake videos involving acoustic and visual manipulations. Moreover, these existing methods are mostly based on CNN and suffer from low detection accuracy. Inspired by the recent success of Transformer in various fields, to address the challenges posed by deepfake technology, in this paper, we propose an Audio-Visual Transformer-based Ensemble Network (AVTENet) framework that considers both acoustic manipulatio
    
[^13]: 针对随机Metropolis-Hastings算法的统计保证

    Statistical guarantees for stochastic Metropolis-Hastings. (arXiv:2310.09335v1 [stat.ML])

    [http://arxiv.org/abs/2310.09335](http://arxiv.org/abs/2310.09335)

    该论文研究了针对随机Metropolis-Hastings算法的统计保证。通过引入简单的修正项，该方法可以避免计算成本上的损失，并通过分析非参数回归情景和深度神经网络回归的数值实例来证明了其在采样和可信区间方面的优势。

    

    Metropolis-Hastings步骤被广泛应用于基于梯度的马尔可夫链蒙特卡洛方法中的不确定性量化中。通过对批次计算接受概率，随机Metropolis-Hastings步骤节省了计算成本，但降低了有效样本量。我们展示了通过简单的修正项可以避免这个障碍。我们研究了如果在非参数回归设置中应用改进的随机Metropolis-Hastings方法从Gibbs后验分布中采样，则链的结果稳态分布的统计属性。针对深度神经网络回归，我们证明了PAC-Bayes预言不等式，它提供了最优的收缩速率，并分析了结果可信区间的直径和高置信概率。通过在高维参数空间中的数值实例，我们说明了随机Metropolis-Hastings算法的可信区间和收缩速率确实表现出类似的行为。

    A Metropolis-Hastings step is widely used for gradient-based Markov chain Monte Carlo methods in uncertainty quantification. By calculating acceptance probabilities on batches, a stochastic Metropolis-Hastings step saves computational costs, but reduces the effective sample size. We show that this obstacle can be avoided by a simple correction term. We study statistical properties of the resulting stationary distribution of the chain if the corrected stochastic Metropolis-Hastings approach is applied to sample from a Gibbs posterior distribution in a nonparametric regression setting. Focusing on deep neural network regression, we prove a PAC-Bayes oracle inequality which yields optimal contraction rates and we analyze the diameter and show high coverage probability of the resulting credible sets. With a numerical example in a high-dimensional parameter space, we illustrate that credible sets and contraction rates of the stochastic Metropolis-Hastings algorithm indeed behave similar to 
    
[^14]: 高效有限初始化张量化神经网络的方法

    Efficient Finite Initialization for Tensorized Neural Networks. (arXiv:2309.06577v1 [cs.LG])

    [http://arxiv.org/abs/2309.06577](http://arxiv.org/abs/2309.06577)

    这种方法提出了一种高效有限初始化张量化神经网络层的方法，避免了参数爆炸问题，并通过使用弗罗贝尼乌斯范数的迭代部分形式来计算范数，使其具有有限范围。应用于不同层的实验表明其性能良好。

    

    我们提出了一种新的方法，用于初始化张量化神经网络的层，以避免参数爆炸。该方法适用于具有大量节点的层，其中所有或大多数节点与输入或输出有连接。该方法的核心是使用该层的弗罗贝尼乌斯范数的迭代部分形式，使其具有有限的范围。这个范数的计算是高效的，对于大多数情况都可以完全或部分计算。我们将这个方法应用于不同的层，并检查其性能。我们创建了一个Python函数，在i3BQuantum存储库的Jupyter Notebook中可以运行它：https://github.com/i3BQuantumTeam/Q4Real/blob/e07c827651ef16bcf74590ab965ea3985143f891/Quantum-Inspired%20Variational%20Methods/Normalization_process.ipynb

    We present a novel method for initializing layers of tensorized neural networks in a way that avoids the explosion of the parameters of the matrix it emulates. The method is intended for layers with a high number of nodes in which there is a connection to the input or output of all or most of the nodes. The core of this method is the use of the Frobenius norm of this layer in an iterative partial form, so that it has to be finite and within a certain range. This norm is efficient to compute, fully or partially for most cases of interest. We apply the method to different layers and check its performance. We create a Python function to run it on an arbitrary layer, available in a Jupyter Notebook in the i3BQuantum repository: https://github.com/i3BQuantumTeam/Q4Real/blob/e07c827651ef16bcf74590ab965ea3985143f891/Quantum-Inspired%20Variational%20Methods/Normalization_process.ipynb
    
[^15]: 关于Tukey深度的随机近似质量

    On the quality of randomized approximations of Tukey's depth. (arXiv:2309.05657v1 [stat.ML])

    [http://arxiv.org/abs/2309.05657](http://arxiv.org/abs/2309.05657)

    本文研究了Tukey深度的随机近似质量问题，证明了在维度较高且数据从对数凹集的均匀分布中抽样的情况下，随机算法可以正确近似最大深度和接近零的深度，而对于中间深度的点，任何好的近似都需要指数复杂度。

    

    Tukey深度（或半空间深度）是用于多元数据中心度量的广泛应用的指标。然而，在高维度下，Tukey深度的精确计算被认为是一个困难的问题。为了解决这个问题，人们提出了Tukey深度的随机近似方法。在本文中，我们探讨了这样的随机算法何时能够返回一个良好的Tukey深度近似。我们研究了数据从对数凹陷均匀分布中抽样的情况。我们证明了，如果要求算法在维度上以多项式时间运行，随机算法可以正确地近似最大深度1/2和接近零的深度。另一方面，对于任何中间深度的点，任何好的近似都需要指数复杂度。

    Tukey's depth (or halfspace depth) is a widely used measure of centrality for multivariate data. However, exact computation of Tukey's depth is known to be a hard problem in high dimensions. As a remedy, randomized approximations of Tukey's depth have been proposed. In this paper we explore when such randomized algorithms return a good approximation of Tukey's depth. We study the case when the data are sampled from a log-concave isotropic distribution. We prove that, if one requires that the algorithm runs in polynomial time in the dimension, the randomized algorithm correctly approximates the maximal depth $1/2$ and depths close to zero. On the other hand, for any point of intermediate depth, any good approximation requires exponential complexity.
    
[^16]: 关系感知网络基于注意力损失的小样本知识图谱补全

    Relation-Aware Network with Attention-Based Loss for Few-Shot Knowledge Graph Completion. (arXiv:2306.09519v1 [cs.CL])

    [http://arxiv.org/abs/2306.09519](http://arxiv.org/abs/2306.09519)

    本文提出了一种新颖的RANA框架，利用有策略地选择相关负样本和设计基于注意力机制的损失函数来更好地利用负样本并缓解零损失问题，同时设计了一种动态的关系感知实体编码来捕获不同关系下实体的不同表示。

    

    小样本知识图谱补全旨在利用少量参考实体对预测关系的未见事实。现有方法随机选择一个负采样来最小化基于边界的排名损失，但这容易导致零损失问题。此外，实体在不同的上下文中应该具有不同的表征。为了解决这些问题，我们提出了一种新颖的关系感知网络基于注意力损失的框架。具体而言，我们通过有策略地选择相关负样本和设计基于注意力机制的损失函数来更好地利用丰富的负样本并缓解零损失问题。直觉上，与正样本更相似的负样本将对模型贡献更大。此外，我们设计了一种动态的关系感知实体编码来捕捉不同关系下实体的不同表示。三个基准数据集上的实验结果表明，相比最先进的方法，所提出的RANA框架的有效性。

    Few-shot knowledge graph completion (FKGC) task aims to predict unseen facts of a relation with few-shot reference entity pairs. Current approaches randomly select one negative sample for each reference entity pair to minimize a margin-based ranking loss, which easily leads to a zero-loss problem if the negative sample is far away from the positive sample and then out of the margin. Moreover, the entity should have a different representation under a different context. To tackle these issues, we propose a novel Relation-Aware Network with Attention-Based Loss (RANA) framework. Specifically, to better utilize the plentiful negative samples and alleviate the zero-loss issue, we strategically select relevant negative samples and design an attention-based loss function to further differentiate the importance of each negative sample. The intuition is that negative samples more similar to positive samples will contribute more to the model. Further, we design a dynamic relation-aware entity en
    
[^17]: 金融机构的几何形态--金融数据的Wasserstein聚类

    The geometry of financial institutions -- Wasserstein clustering of financial data. (arXiv:2305.03565v1 [stat.ML])

    [http://arxiv.org/abs/2305.03565](http://arxiv.org/abs/2305.03565)

    本文提出了一种新的算法，Wasserstein聚类，用于处理金融机构的复杂数据，有效地解决了缺失值和基于特定特征识别聚类所面临的挑战。该算法可用于监管者的监管工作，并在其领域取得了良好的效果。

    

    不断增加的各种有趣对象的细节和大数据的可用性使得有必要开发将这些信息压缩成代表性和可理解的地图的方法。金融监管是一个展示这种需求的领域，因为监管机构需要从金融机构获取多样化的数据，有时是高度细粒度的，以监督和评估他们的活动。然而，处理和分析这样的数据可能是一项艰巨的任务，尤其是考虑到处理缺失值和基于特定特征识别聚类所面临的挑战。为了解决这些挑战，我们提出了一种适用于概率分布的Lloyd算法变体，并使用广义Wasserstein重心构建表示不同对象上的给定数据的度量空间，从而应对金融监管背景下监管者面临的具体挑战。我们相信这种方法在金融监管领域具有实用价值。

    The increasing availability of granular and big data on various objects of interest has made it necessary to develop methods for condensing this information into a representative and intelligible map. Financial regulation is a field that exemplifies this need, as regulators require diverse and often highly granular data from financial institutions to monitor and assess their activities. However, processing and analyzing such data can be a daunting task, especially given the challenges of dealing with missing values and identifying clusters based on specific features.  To address these challenges, we propose a variant of Lloyd's algorithm that applies to probability distributions and uses generalized Wasserstein barycenters to construct a metric space which represents given data on various objects in condensed form. By applying our method to the financial regulation context, we demonstrate its usefulness in dealing with the specific challenges faced by regulators in this domain. We beli
    
[^18]: 基于规范的神经网络简化方法，用于大规模形式化验证

    Specification-Driven Neural Network Reduction for Scalable Formal Verification. (arXiv:2305.01932v1 [cs.LG])

    [http://arxiv.org/abs/2305.01932](http://arxiv.org/abs/2305.01932)

    本文提出了一种基于规范的神经网络简化方法用于大规模形式化验证。该方法采用保守的简化方法，确保简化后的网络验证与原网络验证派生等价。简化后可将网络减少到小于5％的神经元数量，从而减少了相应的验证时间。

    

    在神经网络在安全关键环境中部署之前，形式验证是必不可少的。然而，现有的神经网络形式验证方法还无法处理涉及大量神经元的实际问题。本文提出了一种新方法来解决这个挑战：保守的神经网络简化方法，确保简化后的网络验证派生出原网络的验证。我们的方法同时构造简化网络，验证原始网络及其规范。简化将所有输出相似的非线性层神经元合并，适用于具有任何类型的激活函数，如ReLU，sigmoid和tanh的神经网络。我们的评估表明，我们的方法可以将网络减少到小于神经元数的5％，因此可以将验证时间相似减少。

    Formal verification of neural networks is essential before their deployment in safety-critical settings. However, existing methods for formally verifying neural networks are not yet scalable enough to handle practical problems that involve a large number of neurons. In this work, we propose a novel approach to address this challenge: A conservative neural network reduction approach that ensures that the verification of the reduced network implies the verification of the original network. Our approach constructs the reduction on-the-fly, while simultaneously verifying the original network and its specifications. The reduction merges all neurons of a nonlinear layer with similar outputs and is applicable to neural networks with any type of activation function such as ReLU, sigmoid, and tanh. Our evaluation shows that our approach can reduce a network to less than 5% of the number of neurons and thus to a similar degree the verification time is reduced.
    
[^19]: 学习相似的线性表示：适应性、极小化、以及稳健性

    Learning from Similar Linear Representations: Adaptivity, Minimaxity, and Robustness. (arXiv:2303.17765v1 [stat.ML])

    [http://arxiv.org/abs/2303.17765](http://arxiv.org/abs/2303.17765)

    本文提出了两种算法，适应相似性结构并对异常值任务具有稳健性，适用于表示多任务学习和迁移学习设置。

    

    表示多任务学习和迁移学习在实践中取得了巨大的成功，然而对这些方法的理论理解仍然欠缺。本文旨在理解从具有相似但并非完全相同的线性表示的任务中学习，同时处理异常值任务。我们提出了两种算法，适应相似性结构并对异常值任务具有稳健性，适用于表示多任务学习和迁移学习设置，我们的算法在单任务或仅目标学习时表现优异。

    Representation multi-task learning (MTL) and transfer learning (TL) have achieved tremendous success in practice. However, the theoretical understanding of these methods is still lacking. Most existing theoretical works focus on cases where all tasks share the same representation, and claim that MTL and TL almost always improve performance. However, as the number of tasks grow, assuming all tasks share the same representation is unrealistic. Also, this does not always match empirical findings, which suggest that a shared representation may not necessarily improve single-task or target-only learning performance. In this paper, we aim to understand how to learn from tasks with \textit{similar but not exactly the same} linear representations, while dealing with outlier tasks. We propose two algorithms that are \textit{adaptive} to the similarity structure and \textit{robust} to outlier tasks under both MTL and TL settings. Our algorithms outperform single-task or target-only learning when
    
[^20]: 嵌入式系统实时语义分割中的不确定性

    Uncertainty in Real-Time Semantic Segmentation on Embedded Systems. (arXiv:2301.01201v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2301.01201](http://arxiv.org/abs/2301.01201)

    本文提出了一种结合贝叶斯回归和动量传播的预测方法，能够实时在嵌入式硬件上产生有意义的不确定性，从而使语义分割模型在自动驾驶和人机交互等领域的实时应用成为可能。

    

    语义分割模型在自动驾驶和人机交互等领域的应用需要实时预测能力。实时应用的挑战被资源受限的硬件所加剧。虽然这些平台上实时方法的开发得到了增加，但这些模型无法足够地考虑到存在的不确定性。本文通过将预先训练模型的深层特征提取与贝叶斯回归和动量传播相结合，提出了一种关注不确定性的预测方法。我们演示了该方法如何在嵌入式硬件上实时产生有意义的不确定性，同时保持预测性能。

    Application for semantic segmentation models in areas such as autonomous vehicles and human computer interaction require real-time predictive capabilities. The challenges of addressing real-time application is amplified by the need to operate on resource constrained hardware. Whilst development of real-time methods for these platforms has increased, these models are unable to sufficiently reason about uncertainty present. This paper addresses this by combining deep feature extraction from pre-trained models with Bayesian regression and moment propagation for uncertainty aware predictions. We demonstrate how the proposed method can yield meaningful uncertainty on embedded hardware in real-time whilst maintaining predictive performance.
    
[^21]: 连续控制的正常引导分布强化学习

    Normality-Guided Distributional Reinforcement Learning for Continuous Control. (arXiv:2208.13125v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2208.13125](http://arxiv.org/abs/2208.13125)

    本论文研究了连续控制任务中的值分布，并发现学习的值分布与正态分布非常接近。基于这一观察，提出了一种正态引导的分布式强化学习方法，利用方差网络预测的方差和回报，以及与标准值函数不同的值分布结构特征来更新策略。这种方法在两种在线算法上产生了显著效果。

    

    在许多强化学习算法中，学习一个预测回报的均值模型，或价值函数，起着关键作用。分布式强化学习(DRL)通过建模值分布而不仅仅是均值来提高性能。我们研究了几个连续控制任务中的值分布，并发现学习的值分布与正态分布非常接近。我们设计了一种利用这个性质的方法，利用从方差网络预测的方差，以及回报，来分析计算代表我们分布式值函数的正态分布的目标分位栏。此外，我们提出了一种基于值分布的结构特征的正确性来衡量的策略更新方法，这些特征在标准的值函数中不存在。我们概述的方法与许多DRL结构兼容。我们使用两种代表性的在线算法，PPO和TRPO，作为测试平台。我们的方法在统计上产生了显著的效果。

    Learning a predictive model of the mean return, or value function, plays a critical role in many reinforcement learning algorithms. Distributional reinforcement learning (DRL) has been shown to improve performance by modeling the value distribution, not just the mean. We study the value distribution in several continuous control tasks and find that the learned value distribution is empirical quite close to normal. We design a method that exploits this property, employ variances predicted from a variance network, along with returns, to analytically compute target quantile bars representing a normal for our distributional value function. In addition, we propose a policy update strategy based on the correctness as measured by structural characteristics of the value distribution not present in the standard value function. The approach we outline is compatible with many DRL structures. We use two representative on-policy algorithms, PPO and TRPO, as testbeds. Our method yields statistically
    

