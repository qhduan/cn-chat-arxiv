# æ‘˜è¦

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [CBQ: Cross-Block Quantization for Large Language Models](https://rss.arxiv.org/abs/2312.07950) | CBQæ˜¯ä¸€ç§ç”¨äºå¤§å‹è¯­è¨€æ¨¡å‹çš„è·¨å—é‡æ„å‹åè®­ç»ƒé‡åŒ–æ–¹æ³•ã€‚CBQé€šè¿‡ä½¿ç”¨åŒæºé‡æ„æ–¹æ¡ˆæ¥å»ºç«‹å—é—´çš„é•¿ç¨‹ä¾èµ–å…³ç³»ï¼Œæœ€å°åŒ–è¯¯å·®ç§¯ç´¯ã€‚CBQè¿˜é‡‡ç”¨äº†ç²—åˆ°ç²¾çš„é¢„å¤„ç†ç­–ç•¥å’Œè‡ªé€‚åº”çš„å–æ•´æŠ€æœ¯ï¼Œä½¿å…¶èƒ½å¤Ÿæœ‰æ•ˆå¤„ç†æç«¯å¼‚å¸¸å€¼å¹¶æé«˜æ•´ä½“é‡åŒ–ç²¾åº¦ã€‚ |
| [^2] | [Few-Shot Cross-System Anomaly Trace Classification for Microservice-based systems](https://arxiv.org/abs/2403.18998) | æå‡ºäº†é’ˆå¯¹å¾®æœåŠ¡ç³»ç»Ÿçš„å°‘æ ·æœ¬å¼‚å¸¸è·Ÿè¸ªåˆ†ç±»çš„æ–°æ¡†æ¶ï¼Œåˆ©ç”¨å¤šå¤´æ³¨æ„åŠ›è‡ªç¼–ç å™¨æ„å»ºç³»ç»Ÿç‰¹å®šçš„è·Ÿè¸ªè¡¨ç¤ºï¼Œå¹¶åº”ç”¨åŸºäºTransformerç¼–ç å™¨çš„æ¨¡å‹æ— å…³å…ƒå­¦ä¹ è¿›è¡Œé«˜æ•ˆåˆ†ç±»ã€‚ |
| [^3] | [ELLEN: Extremely Lightly Supervised Learning For Efficient Named Entity Recognition](https://arxiv.org/abs/2403.17385) | ELLENæ˜¯ä¸€ç§ç®€å•è€Œå¼ºå¤§çš„ç¥ç»ç¬¦å·æ–¹æ³•ï¼Œå°†å¾®è°ƒè¯­è¨€æ¨¡å‹ä¸è¯­è¨€è§„åˆ™ç›¸ç»“åˆï¼Œåœ¨æå…¶è½»ç›‘ç£çš„æƒ…å†µä¸‹å–å¾—äº†éå¸¸å¼ºåŠ²çš„å‘½åå®ä½“è¯†åˆ«æ€§èƒ½ã€‚ |
| [^4] | [ChatDBG: An AI-Powered Debugging Assistant](https://arxiv.org/abs/2403.16354) | ChatDBGæ˜¯ç¬¬ä¸€ä¸ªAI-Poweredè°ƒè¯•åŠ©æ‰‹ï¼Œé€šè¿‡å°†å¤§å‹è¯­è¨€æ¨¡å‹é›†æˆåˆ°ä¼ ç»Ÿè°ƒè¯•å™¨ä¸­ï¼Œå®ç°äº†ç¨‹åºå‘˜ä¸è°ƒè¯•å™¨ä¹‹é—´çš„åä½œå¯¹è¯ï¼Œèƒ½å¤Ÿå¤„ç†å¤æ‚é—®é¢˜ã€æ‰§è¡Œæ ¹æœ¬åŸå› åˆ†æï¼Œå¹¶æ¢ç´¢å¼€æ”¾æ€§æŸ¥è¯¢ã€‚ |
| [^5] | [Re-Simulation-based Self-Supervised Learning for Pre-Training Foundation Models](https://arxiv.org/abs/2403.07066) | æå‡ºäº†ä¸€ç§æ–°é¢–çš„åŸºäºé‡æ–°æ¨¡æ‹Ÿçš„è‡ªç›‘ç£å­¦ä¹ ç­–ç•¥RS3Lï¼Œé€šè¿‡ä»‹å…¥æ¨¡æ‹Ÿè¿‡ç¨‹å¹¶é‡æ–°æ¨¡æ‹Ÿäº‹ä»¶å®ç°ï¼Œç”Ÿæˆä¸€ç»„æ¶µç›–æ‰€æœ‰ç‰©ç†é©±åŠ¨å˜åŒ–çš„æ•°æ®å¢å¼ºï¼Œä»è€Œä¿ƒè¿›åŸºç¡€æ¨¡å‹çš„å‘å±•ï¼Œå¹¶å±•ç¤ºäº†é¢„è®­ç»ƒR3SLåœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸­è¡¨ç°å‡ºå¼ºå¤§æ€§èƒ½ã€‚ |
| [^6] | [Signature Isolation Forest](https://arxiv.org/abs/2403.04405) | ä»‹ç»äº†ä¸€ç§æ–°é¢–çš„å¼‚å¸¸æ£€æµ‹ç®—æ³•"Signature Isolation Forest"ï¼Œåˆ©ç”¨ç²—è·¯å¾„ç†è®ºçš„ç­¾åå˜æ¢å»é™¤äº†Functional Isolation Forestçš„çº¿æ€§å†…ç§¯å’Œè¯å…¸é€‰æ‹©æ–¹é¢çš„é™åˆ¶ã€‚ |
| [^7] | [Parameterized quantum comb and simpler circuits for reversing unknown qubit-unitary operations](https://arxiv.org/abs/2403.03761) | é€šè¿‡ä¼˜åŒ–å‚æ•°åŒ–é‡å­ç”µè·¯ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ªç®€åŒ–çš„åè®®ï¼Œç”¨äºé€†è½¬æœªçŸ¥é‡å­æ¯”ç‰¹é…‰æ“ä½œï¼Œå°†è¾…åŠ©æ¯”ç‰¹å¼€é”€å‡å°‘åˆ°3ï¼Œæ˜¾ç¤ºäº†é‡å­æ¢³ç»“æ„çš„å®ç”¨æ€§å’ŒPQCombåœ¨è§£å†³å¤æ‚é‡å­ä»»åŠ¡ä¸­çš„æ½œåŠ›ã€‚ |
| [^8] | [Stability-Aware Training of Neural Network Interatomic Potentials with Differentiable Boltzmann Estimators](https://arxiv.org/abs/2402.13984) | æå‡ºäº†ç¨³å®šæ€§æ„ŸçŸ¥Boltzmannä¼°è®¡å™¨ï¼ˆStABlEï¼‰è®­ç»ƒæ–¹æ³•ï¼Œç»“åˆä¼ ç»Ÿç›‘ç£è®­ç»ƒå’Œå‚è€ƒç³»ç»Ÿå¯è§‚å¯Ÿé‡ï¼Œç”¨äºç”Ÿæˆç¨³å®šä¸”å‡†ç¡®çš„ç¥ç»ç½‘ç»œåŸå­é—´åŠ¿ã€‚ |
| [^9] | [Rethinking Semi-Supervised Imbalanced Node Classification from Bias-Variance Decomposition](https://arxiv.org/abs/2310.18765) | æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•æ¥è§£å†³å›¾ç¥ç»ç½‘ç»œä¸­çš„ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜ã€‚è¯¥æ–¹æ³•å°†ä¸å¹³è¡¡èŠ‚ç‚¹åˆ†ç±»å’Œåå·®-æ–¹å·®åˆ†è§£ç›¸ç»“åˆï¼Œåˆ©ç”¨å›¾æ‰©å……æŠ€æœ¯ä¼°è®¡æ–¹å·®ï¼Œå¹¶é€šè¿‡æ­£åˆ™é¡¹å‡è½»ä¸å¹³è¡¡çš„å½±å“ã€‚åœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šè¿›è¡Œçš„æµ‹è¯•ç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å„ç§ä¸å¹³è¡¡åœºæ™¯ä¸­ä¼˜äºç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œå¹¶ä¸ºè§£å†³GNNä¸­çš„ä¸å¹³è¡¡èŠ‚ç‚¹åˆ†ç±»é—®é¢˜æä¾›äº†ä¸€ç§æ–°é¢–çš„ç†è®ºè§†è§’ã€‚ |
| [^10] | [Manifold GCN: Diffusion-based Convolutional Neural Network for Manifold-valued Graphs.](http://arxiv.org/abs/2401.14381) | æœ¬ç ”ç©¶æå‡ºäº†ä¸¤ä¸ªç”¨äºå…·æœ‰æµå½¢å€¼ç‰¹å¾çš„å›¾çš„ç¥ç»ç½‘ç»œå±‚ã€‚è¿™äº›å±‚å…·æœ‰å¯¹èŠ‚ç‚¹æ’åˆ—å’Œç‰¹å¾æµå½¢çš„ç­‰å˜æ€§ï¼Œå¹¶åœ¨æ·±åº¦å­¦ä¹ ä»»åŠ¡ä¸­æ˜¾ç¤ºå‡ºæœ‰ç›Šçš„å½’çº³åå·®ã€‚ |
| [^11] | [Enhancing selectivity using Wasserstein distance based reweighing.](http://arxiv.org/abs/2401.11562) | æˆ‘ä»¬è®¾è®¡äº†ä¸€ç§ä½¿ç”¨Wassersteinè·ç¦»è¿›è¡ŒåŠ æƒçš„ç®—æ³•ï¼Œåœ¨æ ‡è®°çš„æ•°æ®é›†ä¸Šè®­ç»ƒç¥ç»ç½‘ç»œå¯ä»¥é€¼è¿‘åœ¨å…¶ä»–æ•°æ®é›†ä¸Šè®­ç»ƒå¾—åˆ°çš„ç»“æœã€‚æˆ‘ä»¬è¯æ˜äº†ç®—æ³•å¯ä»¥è¾“å‡ºæ¥è¿‘æœ€ä¼˜çš„åŠ æƒï¼Œä¸”ç®—æ³•ç®€å•å¯æ‰©å±•ã€‚æˆ‘ä»¬çš„ç®—æ³•å¯ä»¥æœ‰æ„åœ°å¼•å…¥åˆ†å¸ƒåç§»è¿›è¡Œå¤šç›®æ ‡ä¼˜åŒ–ã€‚ä½œä¸ºåº”ç”¨å®ä¾‹ï¼Œæˆ‘ä»¬è®­ç»ƒäº†ä¸€ä¸ªç¥ç»ç½‘ç»œæ¥è¯†åˆ«å¯¹ç»†èƒä¿¡å·ä¼ å¯¼çš„MAPæ¿€é…¶å…·æœ‰éç»“åˆæ€§çš„å°åˆ†å­ç»“åˆç‰©ã€‚ |
| [^12] | [D-STGCNT: A Dense Spatio-Temporal Graph Conv-GRU Network based on transformer for assessment of patient physical rehabilitation.](http://arxiv.org/abs/2401.06150) | D-STGCNTæ˜¯ä¸€ç§æ–°çš„æ¨¡å‹ï¼Œç»“åˆäº†STGCNå’Œtransformerçš„æ¶æ„ï¼Œç”¨äºè‡ªåŠ¨è¯„ä¼°æ‚£è€…èº«ä½“åº·å¤é”»ç‚¼ã€‚å®ƒé€šè¿‡å°†éª¨æ¶æ•°æ®è§†ä¸ºå›¾å½¢ï¼Œå¹¶æ£€æµ‹å…³é”®å…³èŠ‚ï¼Œåœ¨å¤„ç†æ—¶ç©ºæ•°æ®æ–¹é¢å…·æœ‰é«˜æ•ˆæ€§ã€‚è¯¥æ¨¡å‹é€šè¿‡å¯†é›†è¿æ¥å’ŒGRUæœºåˆ¶æ¥å¤„ç†å¤§å‹3Déª¨æ¶è¾“å…¥ï¼Œæœ‰æ•ˆå»ºç«‹æ—¶ç©ºåŠ¨æ€æ¨¡å‹ã€‚transformerçš„æ³¨æ„åŠ›æœºåˆ¶å¯¹äºè¯„ä¼°åº·å¤é”»ç‚¼éå¸¸æœ‰ç”¨ã€‚ |
| [^13] | [Machine Learning and Feature Ranking for Impact Fall Detection Event Using Multisensor Data.](http://arxiv.org/abs/2401.05407) | æœ¬è®ºæ–‡é€šè¿‡å¯¹å¤šä¼ æ„Ÿå™¨æ•°æ®è¿›è¡Œå½»åº•çš„é¢„å¤„ç†å’Œç‰¹å¾é€‰æ‹©ï¼ŒæˆåŠŸåº”ç”¨æœºå™¨å­¦ä¹ æ¨¡å‹å®ç°äº†å†²å‡»å è½æ£€æµ‹ï¼Œå–å¾—äº†è¾ƒé«˜çš„å‡†ç¡®ç‡ã€‚ |
| [^14] | [Reinforcing POD based model reduction techniques in reaction-diffusion complex networks using stochastic filtering and pattern recognition.](http://arxiv.org/abs/2307.09762) | è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§ç®—æ³•æ¡†æ¶ï¼Œé€šè¿‡å°†æ¨¡å¼è¯†åˆ«å’Œéšæœºæ»¤æ³¢ç†è®ºçš„æŠ€æœ¯ç»“åˆèµ·æ¥ï¼Œå¼ºåŒ–äº†åŸºäºPODçš„ååº”æ‰©æ•£å¤æ‚ç½‘ç»œæ¨¡å‹ç®€åŒ–æŠ€æœ¯ï¼Œåœ¨å—æ‰°åŠ¨è¾“å…¥çš„æƒ…å†µä¸‹æé«˜äº†ä»£ç†æ¨¡å‹çš„å‡†ç¡®æ€§ã€‚ |
| [^15] | [The Adaptive $\tau$-Lasso: Its Robustness and Oracle Properties.](http://arxiv.org/abs/2304.09310) | æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°å‹é²æ£’çš„è‡ªé€‚åº” $\tau$-Lasso ä¼°è®¡å™¨ï¼ŒåŒæ—¶é‡‡ç”¨è‡ªé€‚åº” $\ell_1$-èŒƒæ•°æƒ©ç½šé¡¹ä»¥é™ä½çœŸå®å›å½’ç³»æ•°çš„åå·®ã€‚å®ƒå…·æœ‰å˜é‡é€‰æ‹©ä¸€è‡´æ€§å’ŒçœŸå®æ”¯æŒä¸‹å›å½’å‘é‡çš„æ¸è¿‘æ­£æ€æ€§çš„æœ€ä¼˜æ€§è´¨ï¼Œå‡å®šå·²çŸ¥çœŸå®å›å½’å‘é‡çš„æ”¯æŒã€‚ |

# è¯¦ç»†

[^1]: è·¨å—é‡åŒ–ï¼šç”¨äºå¤§å‹è¯­è¨€æ¨¡å‹çš„è·¨å—é‡åŒ–æ–¹æ³•

    CBQ: Cross-Block Quantization for Large Language Models

    [https://rss.arxiv.org/abs/2312.07950](https://rss.arxiv.org/abs/2312.07950)

    CBQæ˜¯ä¸€ç§ç”¨äºå¤§å‹è¯­è¨€æ¨¡å‹çš„è·¨å—é‡æ„å‹åè®­ç»ƒé‡åŒ–æ–¹æ³•ã€‚CBQé€šè¿‡ä½¿ç”¨åŒæºé‡æ„æ–¹æ¡ˆæ¥å»ºç«‹å—é—´çš„é•¿ç¨‹ä¾èµ–å…³ç³»ï¼Œæœ€å°åŒ–è¯¯å·®ç§¯ç´¯ã€‚CBQè¿˜é‡‡ç”¨äº†ç²—åˆ°ç²¾çš„é¢„å¤„ç†ç­–ç•¥å’Œè‡ªé€‚åº”çš„å–æ•´æŠ€æœ¯ï¼Œä½¿å…¶èƒ½å¤Ÿæœ‰æ•ˆå¤„ç†æç«¯å¼‚å¸¸å€¼å¹¶æé«˜æ•´ä½“é‡åŒ–ç²¾åº¦ã€‚

    

    åè®­ç»ƒé‡åŒ–ï¼ˆPTQï¼‰åœ¨ä»¥æä½æˆæœ¬å‹ç¼©å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ–¹é¢èµ·ç€é‡è¦ä½œç”¨ã€‚ç„¶è€Œï¼Œç°æœ‰çš„PTQæ–¹æ³•åªå…³æ³¨å¤„ç†å•ä¸ªå±‚æˆ–å•ä¸ªå—å†…çš„å¼‚å¸¸å€¼ï¼Œå¿½ç•¥äº†å—ä¹‹é—´çš„ä¾èµ–å…³ç³»ï¼Œåœ¨ä½ä½è®¾ç½®ä¸­å¯¼è‡´ä¸¥é‡çš„æ€§èƒ½ä¸‹é™ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå—é—´é‡æ„çš„è·¨å—PTQæ–¹æ³•CBQã€‚CBQé‡‡ç”¨äº†ä¸€ç§åŒæºé‡æ„æ–¹æ¡ˆæ¥å®ç°å—é—´çš„é•¿ç¨‹ä¾èµ–å…³ç³»ï¼Œä»¥æœ€å°åŒ–è¯¯å·®ç§¯ç´¯ã€‚æ­¤å¤–ï¼ŒCBQè¿˜ç»“åˆäº†ä¸€ç§ç²—åˆ°ç²¾çš„é¢„å¤„ç†ç­–ç•¥ï¼ˆCFPï¼‰æ¥æŠ‘åˆ¶æƒé‡å’Œæ¿€æ´»å€¼çš„å¼‚å¸¸å€¼ï¼Œå¹¶é…åˆä¸€ç§è‡ªé€‚åº”çš„LoRAå–æ•´æŠ€æœ¯å®ç°ç²¾ç¡®çš„æƒé‡é‡åŒ–ã€‚è¿™äº›åˆ›æ–°ä½¿CBQä¸ä»…èƒ½å¤Ÿæœ‰æ•ˆå¤„ç†æç«¯å¼‚å¸¸å€¼ï¼Œè¿˜èƒ½æé«˜æ•´ä½“é‡åŒ–ç²¾åº¦ã€‚å¹¿æ³›çš„å®éªŒè¯æ˜ï¼ŒCBQåœ¨ä½ä½é‡åŒ–ï¼ˆW4A4ï¼ŒW4A8ç­‰ï¼‰æ–¹é¢å…·æœ‰ä¼˜è¶Šæ€§èƒ½ã€‚

    Post-training quantization (PTQ) has played a key role in compressing large language models (LLMs) with ultra-low costs. However, existing PTQ methods only focus on handling the outliers within one layer or one block, which ignores the dependency of blocks and leads to severe performance degradation in low-bit settings. In this paper, we propose CBQ, a cross-block reconstruction-based PTQ method for LLMs. CBQ employs a cross-block dependency using a homologous reconstruction scheme, establishing long-range dependencies across multiple blocks to minimize error accumulation. Furthermore, CBQ incorporates a coarse-to-fine preprocessing (CFP) strategy for suppressing weight and activation outliers, coupled with an adaptive LoRA-Rounding technique for precise weight quantization. These innovations enable CBQ to not only handle extreme outliers effectively but also improve overall quantization accuracy. Extensive experiments show that CBQ achieves superior low-bit quantization (W4A4, W4A8, W
    
[^2]: å¾®æœåŠ¡ç³»ç»Ÿçš„å°‘æ ·æœ¬è·¨ç³»ç»Ÿå¼‚å¸¸è·Ÿè¸ªåˆ†ç±»

    Few-Shot Cross-System Anomaly Trace Classification for Microservice-based systems

    [https://arxiv.org/abs/2403.18998](https://arxiv.org/abs/2403.18998)

    æå‡ºäº†é’ˆå¯¹å¾®æœåŠ¡ç³»ç»Ÿçš„å°‘æ ·æœ¬å¼‚å¸¸è·Ÿè¸ªåˆ†ç±»çš„æ–°æ¡†æ¶ï¼Œåˆ©ç”¨å¤šå¤´æ³¨æ„åŠ›è‡ªç¼–ç å™¨æ„å»ºç³»ç»Ÿç‰¹å®šçš„è·Ÿè¸ªè¡¨ç¤ºï¼Œå¹¶åº”ç”¨åŸºäºTransformerç¼–ç å™¨çš„æ¨¡å‹æ— å…³å…ƒå­¦ä¹ è¿›è¡Œé«˜æ•ˆåˆ†ç±»ã€‚

    

    å¾®æœåŠ¡ç³»ç»Ÿï¼ˆMSSï¼‰ç”±äºå…¶å¤æ‚å’ŒåŠ¨æ€çš„ç‰¹æ€§å¯èƒ½åœ¨å„ç§æ•…éšœç±»åˆ«ä¸­å‡ºç°æ•…éšœã€‚ä¸ºäº†æœ‰æ•ˆå¤„ç†æ•…éšœï¼ŒAIOpså·¥å…·åˆ©ç”¨åŸºäºè·Ÿè¸ªçš„å¼‚å¸¸æ£€æµ‹å’Œæ ¹æœ¬åŸå› åˆ†æã€‚æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªæ–°é¢–çš„æ¡†æ¶ï¼Œç”¨äºå¾®æœåŠ¡ç³»ç»Ÿçš„å°‘æ ·æœ¬å¼‚å¸¸è·Ÿè¸ªåˆ†ç±»ã€‚æˆ‘ä»¬çš„æ¡†æ¶åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦ç»„æˆéƒ¨åˆ†ï¼šï¼ˆ1ï¼‰å¤šå¤´æ³¨æ„åŠ›è‡ªç¼–ç å™¨ç”¨äºæ„å»ºç³»ç»Ÿç‰¹å®šçš„è·Ÿè¸ªè¡¨ç¤ºï¼Œä»è€Œå®ç°ï¼ˆ2ï¼‰åŸºäºTransformerç¼–ç å™¨çš„æ¨¡å‹æ— å…³å…ƒå­¦ä¹ ï¼Œä»¥è¿›è¡Œæœ‰æ•ˆå’Œé«˜æ•ˆçš„å°‘æ ·æœ¬å¼‚å¸¸è·Ÿè¸ªåˆ†ç±»ã€‚è¯¥æ¡†æ¶åœ¨ä¸¤ä¸ªä»£è¡¨æ€§çš„MSSï¼ŒTrainticketå’ŒOnlineBoutiqueä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œä½¿ç”¨å¼€æ”¾æ•°æ®é›†ã€‚ç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¡†æ¶èƒ½å¤Ÿè°ƒæ•´å­¦åˆ°çš„çŸ¥è¯†ï¼Œä»¥å¯¹æ–°çš„ã€æœªè§çš„æ–°é¢–æ•…éšœç±»åˆ«çš„å¼‚å¸¸è·Ÿè¸ªè¿›è¡Œåˆ†ç±»ï¼Œæ— è®ºæ˜¯åœ¨æœ€åˆè®­ç»ƒçš„åŒä¸€ç³»ç»Ÿå†…ï¼Œè¿˜æ˜¯åœ¨å…¶ä»–ç³»ç»Ÿä¸­ã€‚

    arXiv:2403.18998v1 Announce Type: cross  Abstract: Microservice-based systems (MSS) may experience failures in various fault categories due to their complex and dynamic nature. To effectively handle failures, AIOps tools utilize trace-based anomaly detection and root cause analysis. In this paper, we propose a novel framework for few-shot abnormal trace classification for MSS. Our framework comprises two main components: (1) Multi-Head Attention Autoencoder for constructing system-specific trace representations, which enables (2) Transformer Encoder-based Model-Agnostic Meta-Learning to perform effective and efficient few-shot learning for abnormal trace classification. The proposed framework is evaluated on two representative MSS, Trainticket and OnlineBoutique, with open datasets. The results show that our framework can adapt the learned knowledge to classify new, unseen abnormal traces of novel fault categories both within the same system it was initially trained on and even in the 
    
[^3]: ELLEN: éå¸¸è½»ç›‘ç£å­¦ä¹ ç”¨äºé«˜æ•ˆå‘½åå®ä½“è¯†åˆ«

    ELLEN: Extremely Lightly Supervised Learning For Efficient Named Entity Recognition

    [https://arxiv.org/abs/2403.17385](https://arxiv.org/abs/2403.17385)

    ELLENæ˜¯ä¸€ç§ç®€å•è€Œå¼ºå¤§çš„ç¥ç»ç¬¦å·æ–¹æ³•ï¼Œå°†å¾®è°ƒè¯­è¨€æ¨¡å‹ä¸è¯­è¨€è§„åˆ™ç›¸ç»“åˆï¼Œåœ¨æå…¶è½»ç›‘ç£çš„æƒ…å†µä¸‹å–å¾—äº†éå¸¸å¼ºåŠ²çš„å‘½åå®ä½“è¯†åˆ«æ€§èƒ½ã€‚

    

    åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬é‡æ–°å®¡è§†äº†åŠç›‘ç£å‘½åå®ä½“è¯†åˆ«ï¼ˆNERï¼‰é—®é¢˜ï¼Œä¾§é‡äºæå…¶è½»é‡çº§çš„ç›‘ç£ï¼ŒåŒ…æ‹¬ä»…åŒ…å«æ¯ç±»åˆ«10ä¸ªç¤ºä¾‹çš„è¯æ±‡è¡¨ã€‚æˆ‘ä»¬å¼•å…¥äº†ELLENï¼Œè¿™æ˜¯ä¸€ç§ç®€å•ã€å®Œå…¨æ¨¡å—åŒ–çš„ç¥ç»ç¬¦å·æ–¹æ³•ï¼Œå®ƒå°†ç»è¿‡å¾®è°ƒçš„è¯­è¨€æ¨¡å‹ä¸è¯­è¨€è§„åˆ™ç›¸ç»“åˆã€‚è¿™äº›è§„åˆ™åŒ…æ‹¬â€œä¸€ä¸ªè¯è¯­ä¸€ä¸ªæ„ä¹‰â€è¿™æ ·çš„è§è§£ï¼Œä½¿ç”¨æ©ç è¯­è¨€æ¨¡å‹ä½œä¸ºæ— ç›‘ç£NERï¼Œåˆ©ç”¨è¯æ€§æ ‡ç­¾è¯†åˆ«å’Œæ¶ˆé™¤æœªæ ‡è®°å®ä½“ä½œä¸ºå‡è´Ÿä¾‹ï¼Œä»¥åŠå…³äºåˆ†ç±»å™¨ç½®ä¿¡åº¦å¾—åˆ†åœ¨å±€éƒ¨å’Œå…¨å±€èƒŒæ™¯ä¸‹çš„å…¶ä»–ç›´è§‰ã€‚åœ¨ä½¿ç”¨ä¸Šè¿°è¯æ±‡è¡¨æå°ç›‘ç£çš„æƒ…å†µä¸‹ï¼ŒELLENåœ¨CoNLL-2003æ•°æ®é›†ä¸Šå–å¾—äº†éå¸¸å¼ºå¤§çš„æ€§èƒ½ã€‚å®ƒè¿˜åœ¨æ–‡çŒ®ä¸­å¸¸ç”¨çš„ç›¸åŒç›‘ç£è®¾ç½®ï¼ˆå³ï¼Œè®­ç»ƒæ•°æ®çš„5%ï¼‰ä¸‹ï¼Œä¼˜äºå¤§å¤šæ•°ç°æœ‰ï¼ˆä¸”æ›´ä¸ºå¤æ‚ï¼‰çš„åŠç›‘ç£NERæ–¹æ³•ã€‚

    arXiv:2403.17385v1 Announce Type: cross  Abstract: In this work, we revisit the problem of semi-supervised named entity recognition (NER) focusing on extremely light supervision, consisting of a lexicon containing only 10 examples per class. We introduce ELLEN, a simple, fully modular, neuro-symbolic method that blends fine-tuned language models with linguistic rules. These rules include insights such as ''One Sense Per Discourse'', using a Masked Language Model as an unsupervised NER, leveraging part-of-speech tags to identify and eliminate unlabeled entities as false negatives, and other intuitions about classifier confidence scores in local and global context. ELLEN achieves very strong performance on the CoNLL-2003 dataset when using the minimal supervision from the lexicon above. It also outperforms most existing (and considerably more complex) semi-supervised NER methods under the same supervision settings commonly used in the literature (i.e., 5% of the training data). Further, 
    
[^4]: ChatDBG: ä¸€ç§åŸºäºäººå·¥æ™ºèƒ½çš„è°ƒè¯•åŠ©æ‰‹

    ChatDBG: An AI-Powered Debugging Assistant

    [https://arxiv.org/abs/2403.16354](https://arxiv.org/abs/2403.16354)

    ChatDBGæ˜¯ç¬¬ä¸€ä¸ªAI-Poweredè°ƒè¯•åŠ©æ‰‹ï¼Œé€šè¿‡å°†å¤§å‹è¯­è¨€æ¨¡å‹é›†æˆåˆ°ä¼ ç»Ÿè°ƒè¯•å™¨ä¸­ï¼Œå®ç°äº†ç¨‹åºå‘˜ä¸è°ƒè¯•å™¨ä¹‹é—´çš„åä½œå¯¹è¯ï¼Œèƒ½å¤Ÿå¤„ç†å¤æ‚é—®é¢˜ã€æ‰§è¡Œæ ¹æœ¬åŸå› åˆ†æï¼Œå¹¶æ¢ç´¢å¼€æ”¾æ€§æŸ¥è¯¢ã€‚

    

    æœ¬æ–‡ä»‹ç»äº†ChatDBGï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªåŸºäºäººå·¥æ™ºèƒ½çš„è°ƒè¯•åŠ©æ‰‹ã€‚ChatDBGé›†æˆäº†å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)ï¼Œæ˜¾è‘—å¢å¼ºäº†ä¼ ç»Ÿè°ƒè¯•å™¨çš„åŠŸèƒ½å’Œç”¨æˆ·å‹å¥½æ€§ã€‚ChatDBGå…è®¸ç¨‹åºå‘˜ä¸è°ƒè¯•å™¨è¿›è¡Œåä½œå¯¹è¯ï¼Œä½¿ä»–ä»¬èƒ½å¤Ÿæå‡ºå…³äºç¨‹åºçŠ¶æ€çš„å¤æ‚é—®é¢˜ï¼Œå¯¹å´©æºƒæˆ–æ–­è¨€å¤±è´¥è¿›è¡Œæ ¹æœ¬åŸå› åˆ†æï¼Œå¹¶æ¢ç´¢è¯¸å¦‚â€œä¸ºä»€ä¹ˆxä¸ºç©ºï¼Ÿâ€ä¹‹ç±»çš„å¼€æ”¾æ€§æŸ¥è¯¢ã€‚ä¸ºäº†å¤„ç†è¿™äº›æŸ¥è¯¢ï¼ŒChatDBGæˆäºˆLLMè‡ªä¸»æƒï¼Œé€šè¿‡å‘å‡ºå‘½ä»¤æ¥æµè§ˆå †æ ˆå’Œæ£€æŸ¥ç¨‹åºçŠ¶æ€è¿›è¡Œè°ƒè¯•ï¼›ç„¶åæŠ¥å‘Šå…¶å‘ç°å¹¶å°†æ§åˆ¶æƒäº¤è¿˜ç»™ç¨‹åºå‘˜ã€‚æˆ‘ä»¬çš„ChatDBGåŸå‹ä¸æ ‡å‡†è°ƒè¯•å™¨é›†æˆï¼ŒåŒ…æ‹¬LLDBã€GDBå’ŒWinDBGç”¨äºæœ¬åœ°ä»£ç ä»¥åŠç”¨äºPythonçš„Pdbã€‚æˆ‘ä»¬åœ¨å„ç§ä»£ç é›†åˆä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼ŒåŒ…æ‹¬å…·æœ‰å·²çŸ¥é”™è¯¯çš„C/C++ä»£ç å’Œä¸€å¥—Pythonä»£ç ã€‚

    arXiv:2403.16354v1 Announce Type: cross  Abstract: This paper presents ChatDBG, the first AI-powered debugging assistant. ChatDBG integrates large language models (LLMs) to significantly enhance the capabilities and user-friendliness of conventional debuggers. ChatDBG lets programmers engage in a collaborative dialogue with the debugger, allowing them to pose complex questions about program state, perform root cause analysis for crashes or assertion failures, and explore open-ended queries like "why is x null?". To handle these queries, ChatDBG grants the LLM autonomy to take the wheel and drive debugging by issuing commands to navigate through stacks and inspect program state; it then reports its findings and yields back control to the programmer. Our ChatDBG prototype integrates with standard debuggers including LLDB, GDB, and WinDBG for native code and Pdb for Python. Our evaluation across a diverse set of code, including C/C++ code with known bugs and a suite of Python code includi
    
[^5]: åŸºäºé‡æ–°æ¨¡æ‹Ÿçš„è‡ªç›‘ç£å­¦ä¹ ç”¨äºé¢„è®­ç»ƒåŸºç¡€æ¨¡å‹

    Re-Simulation-based Self-Supervised Learning for Pre-Training Foundation Models

    [https://arxiv.org/abs/2403.07066](https://arxiv.org/abs/2403.07066)

    æå‡ºäº†ä¸€ç§æ–°é¢–çš„åŸºäºé‡æ–°æ¨¡æ‹Ÿçš„è‡ªç›‘ç£å­¦ä¹ ç­–ç•¥RS3Lï¼Œé€šè¿‡ä»‹å…¥æ¨¡æ‹Ÿè¿‡ç¨‹å¹¶é‡æ–°æ¨¡æ‹Ÿäº‹ä»¶å®ç°ï¼Œç”Ÿæˆä¸€ç»„æ¶µç›–æ‰€æœ‰ç‰©ç†é©±åŠ¨å˜åŒ–çš„æ•°æ®å¢å¼ºï¼Œä»è€Œä¿ƒè¿›åŸºç¡€æ¨¡å‹çš„å‘å±•ï¼Œå¹¶å±•ç¤ºäº†é¢„è®­ç»ƒR3SLåœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸­è¡¨ç°å‡ºå¼ºå¤§æ€§èƒ½ã€‚

    

    è‡ªç›‘ç£å­¦ä¹ ï¼ˆSSLï¼‰æ˜¯è®­ç»ƒç°ä»£å¤§å‹æœºå™¨å­¦ä¹ æ¨¡å‹çš„æ ¸å¿ƒï¼Œæä¾›äº†ä¸€ç§å­¦ä¹ å¼ºå¤§è¡¨ç¤ºçš„æ–¹æ¡ˆï¼Œå¯ç”¨äºå„ç§ä¸‹æ¸¸ä»»åŠ¡ã€‚ç„¶è€Œï¼ŒSSLç­–ç•¥å¿…é¡»é€‚åº”æ‰€éœ€çš„è®­ç»ƒæ•°æ®ç±»å‹å’Œä¸‹æ¸¸ä»»åŠ¡ã€‚æˆ‘ä»¬æå‡ºäº†RS3Lï¼Œä¸€ç§æ–°é¢–çš„åŸºäºæ¨¡æ‹Ÿçš„SSLç­–ç•¥ï¼Œé‡‡ç”¨é‡æ–°æ¨¡æ‹Ÿçš„æ–¹æ³•æ¥é©±åŠ¨å¯¹æ¯”å­¦ä¹ çš„æ•°æ®å¢å¼ºã€‚é€šè¿‡ä»‹å…¥æ¨¡æ‹Ÿè¿‡ç¨‹çš„ä¸­é—´å¹¶é‡æ–°è¿è¡Œä»‹å…¥ä¹‹åçš„æ¨¡æ‹Ÿç»„ä»¶ï¼Œæˆ‘ä»¬ç”Ÿæˆä¸€ä¸ªäº‹ä»¶çš„å¤šä¸ªå®ç°ï¼Œä»è€Œäº§ç”Ÿä¸€ç»„æ¶µç›–æ¨¡æ‹Ÿå™¨ä¸­æ‰€æœ‰ç‰©ç†é©±åŠ¨å˜åŒ–çš„å¢å¼ºã€‚é€šè¿‡ä½¿ç”¨é«˜èƒ½ç‰©ç†å®éªŒï¼Œæˆ‘ä»¬æ¢è®¨äº†è¿™ç§ç­–ç•¥å¦‚ä½•ä¿ƒè¿›åŸºç¡€æ¨¡å‹çš„å‘å±•ï¼›æˆ‘ä»¬å±•ç¤ºäº†R3SLé¢„è®­ç»ƒå¦‚ä½•åœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸­å®ç°å¼ºå¤§çš„æ€§èƒ½ï¼Œä¾‹å¦‚åŒºåˆ†ä»»åŠ¡ã€‚

    arXiv:2403.07066v1 Announce Type: cross  Abstract: Self-Supervised Learning (SSL) is at the core of training modern large machine learning models, providing a scheme for learning powerful representations that can be used in a variety of downstream tasks. However, SSL strategies must be adapted to the type of training data and downstream tasks required. We propose RS3L, a novel simulation-based SSL strategy that employs a method of re-simulation to drive data augmentation for contrastive learning. By intervening in the middle of the simulation process and re-running simulation components downstream of the intervention, we generate multiple realizations of an event, thus producing a set of augmentations covering all physics-driven variations available in the simulator. Using experiments from high-energy physics, we explore how this strategy may enable the development of a foundation model; we show how R3SL pre-training enables powerful performance in downstream tasks such as discriminati
    
[^6]: Signature Isolation Forest

    Signature Isolation Forest

    [https://arxiv.org/abs/2403.04405](https://arxiv.org/abs/2403.04405)

    ä»‹ç»äº†ä¸€ç§æ–°é¢–çš„å¼‚å¸¸æ£€æµ‹ç®—æ³•"Signature Isolation Forest"ï¼Œåˆ©ç”¨ç²—è·¯å¾„ç†è®ºçš„ç­¾åå˜æ¢å»é™¤äº†Functional Isolation Forestçš„çº¿æ€§å†…ç§¯å’Œè¯å…¸é€‰æ‹©æ–¹é¢çš„é™åˆ¶ã€‚

    

    Functional Isolation Forest (FIF)æ˜¯ä¸€ç§é’ˆå¯¹åŠŸèƒ½æ•°æ®è®¾è®¡çš„æœ€æ–°ä¸€æµå¼‚å¸¸æ£€æµ‹(AD)ç®—æ³•ã€‚å®ƒä¾èµ–äºä¸€ç§æ ‘åˆ†åŒºè¿‡ç¨‹ï¼Œé€šè¿‡å°†æ¯ä¸ªæ›²çº¿è§‚æµ‹æŠ•å½±åˆ°é€šè¿‡çº¿æ€§å†…ç§¯ç»˜åˆ¶çš„è¯å…¸ä¸Šæ¥è®¡ç®—å¼‚å¸¸å¾—åˆ†ã€‚æœ¬æ–‡é€šè¿‡å¼•å…¥â€œSignature Isolation Forestâ€ï¼Œä¸€ç§åˆ©ç”¨ç²—è·¯å¾„ç†è®ºç­¾åå˜æ¢çš„æ–°é¢–ADç®—æ³•ç±»ï¼Œæ¥è§£å†³è¿™äº›æŒ‘æˆ˜ã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯é€šè¿‡æå‡ºä¸¤ç§ç®—æ³•æ¥æ¶ˆé™¤FIFæ–½åŠ çš„é™åˆ¶ï¼Œè¿™ä¸¤ç§ç®—æ³•ç‰¹åˆ«é’ˆå¯¹FIFå†…ç§¯çš„çº¿æ€§æ€§å’Œè¯å…¸çš„é€‰æ‹©ã€‚

    arXiv:2403.04405v1 Announce Type: cross  Abstract: Functional Isolation Forest (FIF) is a recent state-of-the-art Anomaly Detection (AD) algorithm designed for functional data. It relies on a tree partition procedure where an abnormality score is computed by projecting each curve observation on a drawn dictionary through a linear inner product. Such linear inner product and the dictionary are a priori choices that highly influence the algorithm's performances and might lead to unreliable results, particularly with complex datasets. This work addresses these challenges by introducing \textit{Signature Isolation Forest}, a novel AD algorithm class leveraging the rough path theory's signature transform. Our objective is to remove the constraints imposed by FIF through the proposition of two algorithms which specifically target the linearity of the FIF inner product and the choice of the dictionary. We provide several numerical experiments, including a real-world applications benchmark sho
    
[^7]: å‚æ•°åŒ–é‡å­æ¢³å’Œç®€åŒ–ç”µè·¯ç”¨äºé€†è½¬æœªçŸ¥é‡å­æ¯”ç‰¹-é…‰æ“ä½œ

    Parameterized quantum comb and simpler circuits for reversing unknown qubit-unitary operations

    [https://arxiv.org/abs/2403.03761](https://arxiv.org/abs/2403.03761)

    é€šè¿‡ä¼˜åŒ–å‚æ•°åŒ–é‡å­ç”µè·¯ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ªç®€åŒ–çš„åè®®ï¼Œç”¨äºé€†è½¬æœªçŸ¥é‡å­æ¯”ç‰¹é…‰æ“ä½œï¼Œå°†è¾…åŠ©æ¯”ç‰¹å¼€é”€å‡å°‘åˆ°3ï¼Œæ˜¾ç¤ºäº†é‡å­æ¢³ç»“æ„çš„å®ç”¨æ€§å’ŒPQCombåœ¨è§£å†³å¤æ‚é‡å­ä»»åŠ¡ä¸­çš„æ½œåŠ›ã€‚

    

    Quantum combæ˜¯é‡å­ä¿¡æ¯å¤„ç†ä¸­è¡¨å¾å¤æ‚é‡å­åè®®çš„é‡è¦å·¥å…·ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†PQCombï¼Œä¸€ä¸ªåˆ©ç”¨å‚æ•°åŒ–é‡å­ç”µè·¯æ¢ç´¢é‡å­æ¢³åœ¨ä¸€èˆ¬é‡å­è¿‡ç¨‹è½¬æ¢ä»»åŠ¡åŠå…¶ä»–æ–¹é¢èƒ½åŠ›çš„æ¡†æ¶ã€‚é€šè¿‡ä¼˜åŒ–PQCombè¿›è¡ŒæœªçŸ¥é…‰æ¼”åŒ–çš„æ—¶é—´åæ¼æ¨¡æ‹Ÿï¼Œæˆ‘ä»¬å¼€å‘å‡ºäº†ä¸€ç§æ›´ç®€å•çš„æœªçŸ¥é‡å­æ¯”ç‰¹é…‰åæ¼”åè®®ï¼Œå°†æ¯”ç°æœ‰æ–¹æ³•[Yoshida, Soeda, Murao, PRL 131, 120602, 2023]çš„è¾…åŠ©æ¯”ç‰¹å¼€é”€ä»6å‡å°‘åˆ°3ã€‚è¿™å±•ç¤ºäº†é‡å­æ¢³ç»“æ„çš„å®ç”¨æ€§ï¼Œå±•ç¤ºäº†PQCombåœ¨è§£å†³å¤æ‚é‡å­ä»»åŠ¡æ–¹é¢çš„æ½œåŠ›ã€‚æˆ‘ä»¬çš„ç»“æœä¸ºPQCombåœ¨é‡å­è®¡ç®—å’Œé‡å­ä¿¡æ¯ä¸­æ›´å¹¿æ³›çš„åº”ç”¨é“ºå¹³äº†é“è·¯ï¼Œå¼ºè°ƒäº†å®ƒåœ¨è§£å†³é‡å­æœºå™¨å­¦ä¹ ä¸­çš„å¤šæ ·é—®é¢˜æ—¶çš„å¤šåŠŸèƒ½æ€§ã€‚

    arXiv:2403.03761v1 Announce Type: cross  Abstract: Quantum comb is an essential tool for characterizing complex quantum protocols in quantum information processing. In this work, we introduce PQComb, a framework leveraging parameterized quantum circuits to explore the capabilities of quantum combs for general quantum process transformation tasks and beyond. By optimizing PQComb for time-reversal simulations of unknown unitary evolutions, we develop a simpler protocol for unknown qubit unitary inversion that reduces the ancilla qubit overhead from 6 to 3 compared to the existing method in [Yoshida, Soeda, Murao, PRL 131, 120602, 2023]. This demonstrates the utility of quantum comb structures and showcases PQComb's potential for solving complex quantum tasks. Our results pave the way for broader PQComb applications in quantum computing and quantum information, emphasizing its versatility for tackling diverse problems in quantum machine learning.
    
[^8]: å…·æœ‰å¯å¾®Boltzmannä¼°è®¡å™¨çš„ç¥ç»ç½‘ç»œåŸå­é—´åŠ¿çš„ç¨³å®šæ€§è®­ç»ƒ

    Stability-Aware Training of Neural Network Interatomic Potentials with Differentiable Boltzmann Estimators

    [https://arxiv.org/abs/2402.13984](https://arxiv.org/abs/2402.13984)

    æå‡ºäº†ç¨³å®šæ€§æ„ŸçŸ¥Boltzmannä¼°è®¡å™¨ï¼ˆStABlEï¼‰è®­ç»ƒæ–¹æ³•ï¼Œç»“åˆä¼ ç»Ÿç›‘ç£è®­ç»ƒå’Œå‚è€ƒç³»ç»Ÿå¯è§‚å¯Ÿé‡ï¼Œç”¨äºç”Ÿæˆç¨³å®šä¸”å‡†ç¡®çš„ç¥ç»ç½‘ç»œåŸå­é—´åŠ¿ã€‚

    

    ç¥ç»ç½‘ç»œåŸå­é—´åŠ¿ï¼ˆNNIPsï¼‰æ˜¯åˆ†å­åŠ¨åŠ›å­¦ï¼ˆMDï¼‰æ¨¡æ‹Ÿä¸­çš„ä¸€ç§å¸å¼•äººçš„æ›¿ä»£æ–¹æ³•ã€‚ç„¶è€Œï¼Œå®ƒä»¬å¯èƒ½äº§ç”Ÿä¸ç¨³å®šçš„æ¨¡æ‹Ÿï¼Œé‡‡æ ·éç‰©ç†çŠ¶æ€ï¼Œä»è€Œé™åˆ¶äº†å…¶åœ¨å¯¹æ¨¡æ‹Ÿé•¿æ—¶é—´å°ºåº¦ç°è±¡å»ºæ¨¡ä¸­çš„å®ç”¨æ€§ã€‚ä¸ºè§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ç¨³å®šæ€§æ„ŸçŸ¥Boltzmannä¼°è®¡å™¨ï¼ˆStABlEï¼‰è®­ç»ƒï¼Œè¿™æ˜¯ä¸€ç§å¤šæ¨¡å¼è®­ç»ƒè¿‡ç¨‹ï¼Œç»“åˆäº†ä¼ ç»Ÿç›‘ç£è®­ç»ƒå’Œå‚è€ƒç³»ç»Ÿå¯è§‚å¯Ÿé‡ï¼Œä»¥äº§ç”Ÿç¨³å®šä¸”å‡†ç¡®çš„NNIPsã€‚StABlEè®­ç»ƒé€šè¿‡è¿­ä»£è¿è¡ŒMDæ¨¡æ‹Ÿä»¥å¯»æ‰¾ä¸ç¨³å®šåŒºåŸŸï¼Œå¹¶é€šè¿‡ä¸å‚è€ƒå¯è§‚å¯Ÿé‡çš„ç›‘ç£æ¥çº æ­£è¿™äº›ä¸ç¨³å®šæ€§ã€‚è¯¥è®­ç»ƒè¿‡ç¨‹ç”±Boltzmannä¼°è®¡å™¨æ”¯æŒï¼Œè¯¥ä¼°è®¡å™¨å…è®¸å¯¹ç³»ç»Ÿå¯è§‚å¯Ÿé‡è®­ç»ƒç¥ç»ç½‘ç»œæ‰€éœ€çš„æ¢¯åº¦è¿›è¡Œé«˜æ•ˆè®¡ç®—ï¼Œå¹¶èƒ½æ£€æµ‹å…¨å±€å’Œå±€éƒ¨

    arXiv:2402.13984v1 Announce Type: new  Abstract: Neural network interatomic potentials (NNIPs) are an attractive alternative to ab-initio methods for molecular dynamics (MD) simulations. However, they can produce unstable simulations which sample unphysical states, limiting their usefulness for modeling phenomena occurring over longer timescales. To address these challenges, we present Stability-Aware Boltzmann Estimator (StABlE) Training, a multi-modal training procedure which combines conventional supervised training from quantum-mechanical energies and forces with reference system observables, to produce stable and accurate NNIPs. StABlE Training iteratively runs MD simulations to seek out unstable regions, and corrects the instabilities via supervision with a reference observable. The training procedure is enabled by the Boltzmann Estimator, which allows efficient computation of gradients required to train neural networks to system observables, and can detect both global and local 
    
[^9]: é‡æ–°æ€è€ƒåŸºäºåå·®-æ–¹å·®åˆ†è§£çš„åŠç›‘ç£ä¸å¹³è¡¡èŠ‚ç‚¹åˆ†ç±»é—®é¢˜

    Rethinking Semi-Supervised Imbalanced Node Classification from Bias-Variance Decomposition

    [https://arxiv.org/abs/2310.18765](https://arxiv.org/abs/2310.18765)

    æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•æ¥è§£å†³å›¾ç¥ç»ç½‘ç»œä¸­çš„ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜ã€‚è¯¥æ–¹æ³•å°†ä¸å¹³è¡¡èŠ‚ç‚¹åˆ†ç±»å’Œåå·®-æ–¹å·®åˆ†è§£ç›¸ç»“åˆï¼Œåˆ©ç”¨å›¾æ‰©å……æŠ€æœ¯ä¼°è®¡æ–¹å·®ï¼Œå¹¶é€šè¿‡æ­£åˆ™é¡¹å‡è½»ä¸å¹³è¡¡çš„å½±å“ã€‚åœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šè¿›è¡Œçš„æµ‹è¯•ç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å„ç§ä¸å¹³è¡¡åœºæ™¯ä¸­ä¼˜äºç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œå¹¶ä¸ºè§£å†³GNNä¸­çš„ä¸å¹³è¡¡èŠ‚ç‚¹åˆ†ç±»é—®é¢˜æä¾›äº†ä¸€ç§æ–°é¢–çš„ç†è®ºè§†è§’ã€‚

    

    æœ¬æ–‡ä»‹ç»äº†ä¸€ç§æ–°çš„æ–¹æ³•æ¥è§£å†³å›¾ç¥ç»ç½‘ç»œï¼ˆGNNï¼‰ä¸­çš„ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜ã€‚æˆ‘ä»¬çš„æ–¹æ³•å°†ä¸å¹³è¡¡èŠ‚ç‚¹åˆ†ç±»å’Œåå·®-æ–¹å·®åˆ†è§£ç›¸ç»“åˆï¼Œå»ºç«‹äº†ä¸€ä¸ªå°†æ•°æ®ä¸å¹³è¡¡ä¸æ¨¡å‹æ–¹å·®å¯†åˆ‡ç›¸å…³çš„ç†è®ºæ¡†æ¶ã€‚æˆ‘ä»¬è¿˜åˆ©ç”¨å›¾æ‰©å……æŠ€æœ¯æ¥ä¼°è®¡æ–¹å·®ï¼Œå¹¶è®¾è®¡äº†ä¸€ä¸ªæ­£åˆ™é¡¹æ¥å‡è½»ä¸å¹³è¡¡çš„å½±å“ã€‚æˆ‘ä»¬åœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯¦å°½çš„æµ‹è¯•ï¼ŒåŒ…æ‹¬è‡ªç„¶ä¸å¹³è¡¡çš„æ•°æ®é›†å’Œå…¬å¼€åˆ’åˆ†çš„ç±»åˆ«ä¸å¹³è¡¡æ•°æ®é›†ï¼Œç»“æœè¡¨æ˜æˆ‘ä»¬çš„æ–¹æ³•åœ¨å„ç§ä¸å¹³è¡¡åœºæ™¯ä¸­ä¼˜äºç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚è¯¥å·¥ä½œä¸ºè§£å†³GNNä¸­çš„ä¸å¹³è¡¡èŠ‚ç‚¹åˆ†ç±»é—®é¢˜æä¾›äº†ä¸€ç§æ–°é¢–çš„ç†è®ºè§†è§’ã€‚

    This paper introduces a new approach to address the issue of class imbalance in graph neural networks (GNNs) for learning on graph-structured data. Our approach integrates imbalanced node classification and Bias-Variance Decomposition, establishing a theoretical framework that closely relates data imbalance to model variance. We also leverage graph augmentation technique to estimate the variance, and design a regularization term to alleviate the impact of imbalance. Exhaustive tests are conducted on multiple benchmarks, including naturally imbalanced datasets and public-split class-imbalanced datasets, demonstrating that our approach outperforms state-of-the-art methods in various imbalanced scenarios. This work provides a novel theoretical perspective for addressing the problem of imbalanced node classification in GNNs.
    
[^10]: é¢å‘æµå½¢å€¼å›¾çš„æ‰©æ•£å·ç§¯ç¥ç»ç½‘ç»œï¼šå¤šé‡éš¾é¢˜å›¾ç¥ç»ç½‘ç»œå±‚

    Manifold GCN: Diffusion-based Convolutional Neural Network for Manifold-valued Graphs. (arXiv:2401.14381v1 [cs.LG])

    [http://arxiv.org/abs/2401.14381](http://arxiv.org/abs/2401.14381)

    æœ¬ç ”ç©¶æå‡ºäº†ä¸¤ä¸ªç”¨äºå…·æœ‰æµå½¢å€¼ç‰¹å¾çš„å›¾çš„ç¥ç»ç½‘ç»œå±‚ã€‚è¿™äº›å±‚å…·æœ‰å¯¹èŠ‚ç‚¹æ’åˆ—å’Œç‰¹å¾æµå½¢çš„ç­‰å˜æ€§ï¼Œå¹¶åœ¨æ·±åº¦å­¦ä¹ ä»»åŠ¡ä¸­æ˜¾ç¤ºå‡ºæœ‰ç›Šçš„å½’çº³åå·®ã€‚

    

    æˆ‘ä»¬æå‡ºäº†ä¸¤ç§ç”¨äºå…·æœ‰Riemannianæµå½¢ç‰¹å¾çš„å›¾ä¸Šçš„å›¾ç¥ç»ç½‘ç»œå±‚ã€‚ç¬¬ä¸€ï¼ŒåŸºäºæµå½¢å€¼å›¾çš„æ‰©æ•£æ–¹ç¨‹ï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªæ‰©æ•£å±‚ï¼Œå¯ä»¥åº”ç”¨äºä»»æ„æ•°é‡çš„èŠ‚ç‚¹å’Œå›¾è¿æ¥æ¨¡å¼ã€‚ç¬¬äºŒï¼Œæˆ‘ä»¬é€šè¿‡å°†å‘é‡ç¥ç»å…ƒæ¡†æ¶çš„æ€æƒ³è½¬åŒ–åˆ°æˆ‘ä»¬çš„ä¸€èˆ¬è®¾ç½®ä¸­ï¼Œå»ºç«‹äº†ä¸€ä¸ªåˆ‡çº¿å¤šå±‚æ„ŸçŸ¥å™¨ã€‚è¿™ä¸¤ä¸ªå±‚å¯¹èŠ‚ç‚¹æ’åˆ—å’Œç‰¹å¾æµå½¢çš„ç­‰å˜å…·æœ‰å“åº”ï¼Œè¿™äº›ç‰¹æ€§åœ¨è®¸å¤šæ·±åº¦å­¦ä¹ ä»»åŠ¡ä¸­å·²è¢«è¯æ˜å…·æœ‰æœ‰ç›Šçš„å½’çº³åå·®ã€‚æˆ‘ä»¬åœ¨åˆæˆæ•°æ®ä¸Šä»¥åŠåœ¨å³ä¾§æµ·é©¬ä¸‰è§’ç½‘æ ¼ä¸Šåˆ†ç±»é˜¿å°”èŒ¨æµ·é»˜ç—…çš„æ•°å€¼å®ä¾‹è¡¨æ˜æˆ‘ä»¬å»ºç«‹çš„å±‚å…·æœ‰éå¸¸å¥½çš„æ€§èƒ½ã€‚

    We propose two graph neural network layers for graphs with features in a Riemannian manifold. First, based on a manifold-valued graph diffusion equation, we construct a diffusion layer that can be applied to an arbitrary number of nodes and graph connectivity patterns. Second, we model a tangent multilayer perceptron by transferring ideas from the vector neuron framework to our general setting. Both layers are equivariant with respect to node permutations and isometries of the feature manifold. These properties have been shown to lead to a beneficial inductive bias in many deep learning tasks. Numerical examples on synthetic data as well as on triangle meshes of the right hippocampus to classify Alzheimer's disease demonstrate the very good performance of our layers.
    
[^11]: ä½¿ç”¨Wassersteinè·ç¦»è¿›è¡ŒåŠ æƒä»¥å¢å¼ºé€‰æ‹©æ€§

    Enhancing selectivity using Wasserstein distance based reweighing. (arXiv:2401.11562v1 [stat.ML])

    [http://arxiv.org/abs/2401.11562](http://arxiv.org/abs/2401.11562)

    æˆ‘ä»¬è®¾è®¡äº†ä¸€ç§ä½¿ç”¨Wassersteinè·ç¦»è¿›è¡ŒåŠ æƒçš„ç®—æ³•ï¼Œåœ¨æ ‡è®°çš„æ•°æ®é›†ä¸Šè®­ç»ƒç¥ç»ç½‘ç»œå¯ä»¥é€¼è¿‘åœ¨å…¶ä»–æ•°æ®é›†ä¸Šè®­ç»ƒå¾—åˆ°çš„ç»“æœã€‚æˆ‘ä»¬è¯æ˜äº†ç®—æ³•å¯ä»¥è¾“å‡ºæ¥è¿‘æœ€ä¼˜çš„åŠ æƒï¼Œä¸”ç®—æ³•ç®€å•å¯æ‰©å±•ã€‚æˆ‘ä»¬çš„ç®—æ³•å¯ä»¥æœ‰æ„åœ°å¼•å…¥åˆ†å¸ƒåç§»è¿›è¡Œå¤šç›®æ ‡ä¼˜åŒ–ã€‚ä½œä¸ºåº”ç”¨å®ä¾‹ï¼Œæˆ‘ä»¬è®­ç»ƒäº†ä¸€ä¸ªç¥ç»ç½‘ç»œæ¥è¯†åˆ«å¯¹ç»†èƒä¿¡å·ä¼ å¯¼çš„MAPæ¿€é…¶å…·æœ‰éç»“åˆæ€§çš„å°åˆ†å­ç»“åˆç‰©ã€‚

    

    ç»™å®šä¸¤ä¸ªæ ‡è®°æ•°æ®é›†ğ’®å’Œğ’¯ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç§ç®€å•é«˜æ•ˆçš„è´ªå©ªç®—æ³•æ¥å¯¹æŸå¤±å‡½æ•°è¿›è¡ŒåŠ æƒï¼Œä½¿å¾—åœ¨ğ’®ä¸Šè®­ç»ƒå¾—åˆ°çš„ç¥ç»ç½‘ç»œæƒé‡çš„æé™åˆ†å¸ƒé€¼è¿‘åœ¨ğ’¯ä¸Šè®­ç»ƒå¾—åˆ°çš„æé™åˆ†å¸ƒã€‚åœ¨ç†è®ºæ–¹é¢ï¼Œæˆ‘ä»¬è¯æ˜äº†å½“è¾“å…¥æ•°æ®é›†çš„åº¦é‡ç†µæœ‰ç•Œæ—¶ï¼Œæˆ‘ä»¬çš„è´ªå©ªç®—æ³•è¾“å‡ºæ¥è¿‘æœ€ä¼˜çš„åŠ æƒï¼Œå³ç½‘ç»œæƒé‡çš„ä¸¤ä¸ªä¸å˜åˆ†å¸ƒåœ¨æ€»å˜å·®è·ç¦»ä¸Šå¯ä»¥è¯æ˜æ¥è¿‘ã€‚æ­¤å¤–ï¼Œè¯¥ç®—æ³•ç®€å•å¯æ‰©å±•ï¼Œå¹¶ä¸”æˆ‘ä»¬è¿˜è¯æ˜äº†ç®—æ³•çš„æ•ˆç‡ä¸Šç•Œã€‚æˆ‘ä»¬çš„ç®—æ³•å¯ä»¥æœ‰æ„åœ°å¼•å…¥åˆ†å¸ƒåç§»ä»¥è¿›è¡Œï¼ˆè½¯ï¼‰å¤šç›®æ ‡ä¼˜åŒ–ã€‚ä½œä¸ºä¸€ä¸ªåŠ¨æœºåº”ç”¨ï¼Œæˆ‘ä»¬è®­ç»ƒäº†ä¸€ä¸ªç¥ç»ç½‘ç»œæ¥è¯†åˆ«å¯¹MNK2ï¼ˆä¸€ç§ç»†èƒä¿¡å·ä¼ å¯¼çš„MAPæ¿€é…¶ï¼‰å…·æœ‰éç»“åˆæ€§çš„å°åˆ†å­ç»“åˆç‰©ã€‚

    Given two labeled data-sets $\mathcal{S}$ and $\mathcal{T}$, we design a simple and efficient greedy algorithm to reweigh the loss function such that the limiting distribution of the neural network weights that result from training on $\mathcal{S}$ approaches the limiting distribution that would have resulted by training on $\mathcal{T}$.  On the theoretical side, we prove that when the metric entropy of the input data-sets is bounded, our greedy algorithm outputs a close to optimal reweighing, i.e., the two invariant distributions of network weights will be provably close in total variation distance. Moreover, the algorithm is simple and scalable, and we prove bounds on the efficiency of the algorithm as well.  Our algorithm can deliberately introduce distribution shift to perform (soft) multi-criteria optimization. As a motivating application, we train a neural net to recognize small molecule binders to MNK2 (a MAP Kinase, responsible for cell signaling) which are non-binders to MNK1
    
[^12]: D-STGCNT:ä¸€ç§åŸºäºtransformerçš„å¯†é›†æ—¶ç©ºå›¾å·ç§¯GRUç½‘ç»œç”¨äºè¯„ä¼°æ‚£è€…èº«ä½“åº·å¤

    D-STGCNT: A Dense Spatio-Temporal Graph Conv-GRU Network based on transformer for assessment of patient physical rehabilitation. (arXiv:2401.06150v1 [eess.IV])

    [http://arxiv.org/abs/2401.06150](http://arxiv.org/abs/2401.06150)

    D-STGCNTæ˜¯ä¸€ç§æ–°çš„æ¨¡å‹ï¼Œç»“åˆäº†STGCNå’Œtransformerçš„æ¶æ„ï¼Œç”¨äºè‡ªåŠ¨è¯„ä¼°æ‚£è€…èº«ä½“åº·å¤é”»ç‚¼ã€‚å®ƒé€šè¿‡å°†éª¨æ¶æ•°æ®è§†ä¸ºå›¾å½¢ï¼Œå¹¶æ£€æµ‹å…³é”®å…³èŠ‚ï¼Œåœ¨å¤„ç†æ—¶ç©ºæ•°æ®æ–¹é¢å…·æœ‰é«˜æ•ˆæ€§ã€‚è¯¥æ¨¡å‹é€šè¿‡å¯†é›†è¿æ¥å’ŒGRUæœºåˆ¶æ¥å¤„ç†å¤§å‹3Déª¨æ¶è¾“å…¥ï¼Œæœ‰æ•ˆå»ºç«‹æ—¶ç©ºåŠ¨æ€æ¨¡å‹ã€‚transformerçš„æ³¨æ„åŠ›æœºåˆ¶å¯¹äºè¯„ä¼°åº·å¤é”»ç‚¼éå¸¸æœ‰ç”¨ã€‚

    

    æœ¬æ–‡è§£å†³äº†è‡ªåŠ¨è¯„ä¼°æ— ä¸´åºŠç›‘ç£æƒ…å†µä¸‹æ‚£è€…è¿›è¡Œèº«ä½“åº·å¤é”»ç‚¼çš„æŒ‘æˆ˜ã€‚å…¶ç›®æ ‡æ˜¯æä¾›è´¨é‡è¯„åˆ†ä»¥ç¡®ä¿æ­£ç¡®æ‰§è¡Œå’Œè·å¾—æœŸæœ›ç»“æœã€‚ä¸ºå®ç°è¿™ä¸€ç›®æ ‡ï¼Œå¼•å…¥äº†ä¸€ç§æ–°çš„åŸºäºå›¾ç»“æ„çš„æ¨¡å‹ï¼ŒDense Spatio-Temporal Graph Conv-GRU Network with Transformerã€‚è¯¥æ¨¡å‹ç»“åˆäº†æ”¹è¿›çš„STGCNå’Œtransformeræ¶æ„ï¼Œç”¨äºé«˜æ•ˆå¤„ç†æ—¶ç©ºæ•°æ®ã€‚å…¶å…³é”®æ€æƒ³æ˜¯å°†éª¨æ¶æ•°æ®è§†ä¸ºå›¾å½¢ï¼Œå¹¶æ£€æµ‹æ¯ä¸ªåº·å¤é”»ç‚¼ä¸­èµ·ä¸»è¦ä½œç”¨çš„å…³èŠ‚ã€‚å¯†é›†è¿æ¥å’ŒGRUæœºåˆ¶ç”¨äºå¿«é€Ÿå¤„ç†å¤§å‹3Déª¨æ¶è¾“å…¥å¹¶æœ‰æ•ˆå»ºæ¨¡æ—¶ç©ºåŠ¨æ€ã€‚transformerç¼–ç å™¨çš„æ³¨æ„æœºåˆ¶ä¾§é‡äºè¾“å…¥åºåˆ—çš„ç›¸å…³éƒ¨åˆ†ï¼Œä½¿å…¶åœ¨è¯„ä¼°åº·å¤é”»ç‚¼æ–¹é¢éå¸¸æœ‰ç”¨ã€‚

    This paper tackles the challenge of automatically assessing physical rehabilitation exercises for patients who perform the exercises without clinician supervision. The objective is to provide a quality score to ensure correct performance and achieve desired results. To achieve this goal, a new graph-based model, the Dense Spatio-Temporal Graph Conv-GRU Network with Transformer, is introduced. This model combines a modified version of STGCN and transformer architectures for efficient handling of spatio-temporal data. The key idea is to consider skeleton data respecting its non-linear structure as a graph and detecting joints playing the main role in each rehabilitation exercise. Dense connections and GRU mechanisms are used to rapidly process large 3D skeleton inputs and effectively model temporal dynamics. The transformer encoder's attention mechanism focuses on relevant parts of the input sequence, making it useful for evaluating rehabilitation exercises. The evaluation of our propose
    
[^13]: æœºå™¨å­¦ä¹ å’Œç‰¹å¾æ’åºåœ¨å¤šä¼ æ„Ÿå™¨æ•°æ®çš„å†²å‡»å è½æ£€æµ‹äº‹ä»¶ä¸­çš„åº”ç”¨

    Machine Learning and Feature Ranking for Impact Fall Detection Event Using Multisensor Data. (arXiv:2401.05407v1 [eess.SP])

    [http://arxiv.org/abs/2401.05407](http://arxiv.org/abs/2401.05407)

    æœ¬è®ºæ–‡é€šè¿‡å¯¹å¤šä¼ æ„Ÿå™¨æ•°æ®è¿›è¡Œå½»åº•çš„é¢„å¤„ç†å’Œç‰¹å¾é€‰æ‹©ï¼ŒæˆåŠŸåº”ç”¨æœºå™¨å­¦ä¹ æ¨¡å‹å®ç°äº†å†²å‡»å è½æ£€æµ‹ï¼Œå–å¾—äº†è¾ƒé«˜çš„å‡†ç¡®ç‡ã€‚

    

    ä¸ªäººçš„è·Œå€’ï¼Œç‰¹åˆ«æ˜¯è€å¹´äººï¼Œå¯èƒ½å¯¼è‡´ä¸¥é‡çš„ä¼¤å®³å’Œå¹¶å‘ç—‡ã€‚åœ¨è·Œå€’äº‹ä»¶ä¸­æ£€æµ‹å†²å‡»ç¬é—´å¯¹äºåŠæ—¶æä¾›å¸®åŠ©å’Œå‡å°‘è´Ÿé¢å½±å“è‡³å…³é‡è¦ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬é€šè¿‡å¯¹å¤šä¼ æ„Ÿå™¨æ•°æ®é›†åº”ç”¨å½»åº•çš„é¢„å¤„ç†æŠ€æœ¯æ¥è§£å†³è¿™ä¸ªæŒ‘æˆ˜ï¼Œç›®çš„æ˜¯æ¶ˆé™¤å™ªéŸ³å¹¶æé«˜æ•°æ®è´¨é‡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜ä½¿ç”¨ç‰¹å¾é€‰æ‹©è¿‡ç¨‹æ¥è¯†åˆ«å¤šä¼ æ„Ÿå™¨UP-FALLæ•°æ®é›†ä¸­æœ€ç›¸å…³çš„ç‰¹å¾ï¼Œä»è€Œæé«˜æœºå™¨å­¦ä¹ æ¨¡å‹çš„æ€§èƒ½å’Œæ•ˆç‡ã€‚ç„¶åï¼Œæˆ‘ä»¬ä½¿ç”¨å¤šä¸ªä¼ æ„Ÿå™¨çš„ç»“æœæ•°æ®ä¿¡æ¯è¯„ä¼°å„ç§æœºå™¨å­¦ä¹ æ¨¡å‹åœ¨æ£€æµ‹å†²å‡»ç¬é—´æ–¹é¢çš„æ•ˆç‡ã€‚é€šè¿‡å¤§é‡å®éªŒï¼Œæˆ‘ä»¬ä½¿ç”¨å„ç§è¯„ä¼°æŒ‡æ ‡è¯„ä¼°äº†æˆ‘ä»¬æ–¹æ³•çš„å‡†ç¡®æ€§ã€‚æˆ‘ä»¬çš„ç»“æœåœ¨å†²å‡»æ£€æµ‹æ–¹é¢å–å¾—äº†è¾ƒé«˜çš„å‡†ç¡®ç‡ï¼Œå±•ç¤ºäº†åˆ©ç”¨å¤šä¼ æ„Ÿå™¨æ•°æ®ä¿¡æ¯çš„èƒ½åŠ›ã€‚

    Falls among individuals, especially the elderly population, can lead to serious injuries and complications. Detecting impact moments within a fall event is crucial for providing timely assistance and minimizing the negative consequences. In this work, we aim to address this challenge by applying thorough preprocessing techniques to the multisensor dataset, the goal is to eliminate noise and improve data quality. Furthermore, we employ a feature selection process to identify the most relevant features derived from the multisensor UP-FALL dataset, which in turn will enhance the performance and efficiency of machine learning models. We then evaluate the efficiency of various machine learning models in detecting the impact moment using the resulting data information from multiple sensors. Through extensive experimentation, we assess the accuracy of our approach using various evaluation metrics. Our results achieve high accuracy rates in impact detection, showcasing the power of leveraging 
    
[^14]: é€šè¿‡éšæœºæ»¤æ³¢å’Œæ¨¡å¼è¯†åˆ«å¼ºåŒ–åŸºäºPODçš„ååº”æ‰©æ•£å¤æ‚ç½‘ç»œæ¨¡å‹ç®€åŒ–æŠ€æœ¯

    Reinforcing POD based model reduction techniques in reaction-diffusion complex networks using stochastic filtering and pattern recognition. (arXiv:2307.09762v1 [cs.CE])

    [http://arxiv.org/abs/2307.09762](http://arxiv.org/abs/2307.09762)

    è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§ç®—æ³•æ¡†æ¶ï¼Œé€šè¿‡å°†æ¨¡å¼è¯†åˆ«å’Œéšæœºæ»¤æ³¢ç†è®ºçš„æŠ€æœ¯ç»“åˆèµ·æ¥ï¼Œå¼ºåŒ–äº†åŸºäºPODçš„ååº”æ‰©æ•£å¤æ‚ç½‘ç»œæ¨¡å‹ç®€åŒ–æŠ€æœ¯ï¼Œåœ¨å—æ‰°åŠ¨è¾“å…¥çš„æƒ…å†µä¸‹æé«˜äº†ä»£ç†æ¨¡å‹çš„å‡†ç¡®æ€§ã€‚

    

    å¤æ‚ç½‘ç»œè¢«ç”¨äºå»ºæ¨¡è®¸å¤šç°å®ä¸–ç•Œç³»ç»Ÿï¼Œç„¶è€Œè¿™äº›ç³»ç»Ÿçš„ç»´åº¦ä½¿å¾—å…¶åˆ†æå˜å¾—å›°éš¾ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå¯ä»¥ä½¿ç”¨PODç­‰é™ç»´æŠ€æœ¯ã€‚ç„¶è€Œï¼Œè¿™äº›æ¨¡å‹å®¹æ˜“å—è¾“å…¥æ•°æ®æ‰°åŠ¨çš„å½±å“ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§ç®—æ³•æ¡†æ¶ï¼Œå°†æ¨¡å¼è¯†åˆ«å’Œéšæœºæ»¤æ³¢ç†è®ºçš„æŠ€æœ¯ç»“åˆèµ·æ¥ï¼Œä»¥å¢å¼ºè¿™äº›æ¨¡å‹çš„è¾“å‡ºã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥åœ¨å—æ‰°åŠ¨è¾“å…¥çš„æƒ…å†µä¸‹æé«˜ä»£ç†æ¨¡å‹çš„å‡†ç¡®æ€§ã€‚æ·±åº¦ç¥ç»ç½‘ç»œ(DNNs)å®¹æ˜“å—åˆ°å¯¹æŠ—æ€§æ”»å‡»ï¼Œç„¶è€Œæœ€è¿‘çš„ç ”ç©¶å‘ç°ï¼Œç¥ç»å¸¸å¾®åˆ†æ–¹ç¨‹(ODEs)åœ¨ç‰¹å®šåº”ç”¨ä¸­è¡¨ç°å‡ºé²æ£’æ€§ã€‚æˆ‘ä»¬å°†æˆ‘ä»¬çš„ç®—æ³•æ¡†æ¶ä¸åŸºäºç¥ç»ODEçš„æ–¹æ³•è¿›è¡Œäº†åŸºå‡†æ¯”è¾ƒã€‚

    Complex networks are used to model many real-world systems. However, the dimensionality of these systems can make them challenging to analyze. Dimensionality reduction techniques like POD can be used in such cases. However, these models are susceptible to perturbations in the input data. We propose an algorithmic framework that combines techniques from pattern recognition (PR) and stochastic filtering theory to enhance the output of such models. The results of our study show that our method can improve the accuracy of the surrogate model under perturbed inputs. Deep Neural Networks (DNNs) are susceptible to adversarial attacks. However, recent research has revealed that neural Ordinary Differential Equations (ODEs) exhibit robustness in specific applications. We benchmark our algorithmic framework with a Neural ODE-based approach as a reference.
    
[^15]: è‡ªé€‚åº” $\tau$-Lassoï¼šå…¶å¥å£®æ€§å’Œæœ€ä¼˜æ€§è´¨ã€‚

    The Adaptive $\tau$-Lasso: Its Robustness and Oracle Properties. (arXiv:2304.09310v1 [stat.ML])

    [http://arxiv.org/abs/2304.09310](http://arxiv.org/abs/2304.09310)

    æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°å‹é²æ£’çš„è‡ªé€‚åº” $\tau$-Lasso ä¼°è®¡å™¨ï¼ŒåŒæ—¶é‡‡ç”¨è‡ªé€‚åº” $\ell_1$-èŒƒæ•°æƒ©ç½šé¡¹ä»¥é™ä½çœŸå®å›å½’ç³»æ•°çš„åå·®ã€‚å®ƒå…·æœ‰å˜é‡é€‰æ‹©ä¸€è‡´æ€§å’ŒçœŸå®æ”¯æŒä¸‹å›å½’å‘é‡çš„æ¸è¿‘æ­£æ€æ€§çš„æœ€ä¼˜æ€§è´¨ï¼Œå‡å®šå·²çŸ¥çœŸå®å›å½’å‘é‡çš„æ”¯æŒã€‚

    

    æœ¬æ–‡ä»‹ç»äº†ä¸€ç§ç”¨äºåˆ†æé«˜ç»´æ•°æ®é›†çš„æ–°å‹æ­£åˆ™åŒ–é²æ£’ $\tau$-å›å½’ä¼°è®¡å™¨ï¼Œä»¥åº”å¯¹å“åº”å˜é‡å’Œåå˜é‡çš„ä¸¥é‡æ±¡æŸ“ã€‚æˆ‘ä»¬ç§°è¿™ç§ä¼°è®¡å™¨ä¸ºè‡ªé€‚åº” $\tau$-Lassoï¼Œå®ƒå¯¹å¼‚å¸¸å€¼å’Œé«˜æ æ†ç‚¹å…·æœ‰é²æ£’æ€§ï¼ŒåŒæ—¶é‡‡ç”¨è‡ªé€‚åº” $\ell_1$-èŒƒæ•°æƒ©ç½šé¡¹æ¥å‡å°‘çœŸå®å›å½’ç³»æ•°çš„åå·®ã€‚å…·ä½“è€Œè¨€ï¼Œè¯¥è‡ªé€‚åº” $\ell_1$-èŒƒæ•°æƒ©ç½šé¡¹ä¸ºæ¯ä¸ªå›å½’ç³»æ•°åˆ†é…ä¸€ä¸ªæƒé‡ã€‚å¯¹äºå›ºå®šæ•°é‡çš„é¢„æµ‹å˜é‡ $p$ï¼Œæˆ‘ä»¬æ˜¾ç¤ºå‡ºè‡ªé€‚åº” $\tau$-Lasso å…·æœ‰å˜é‡é€‰æ‹©ä¸€è‡´æ€§å’ŒçœŸå®æ”¯æŒä¸‹å›å½’å‘é‡çš„æ¸è¿‘æ­£æ€æ€§çš„æœ€ä¼˜æ€§è´¨ï¼Œå‡å®šå·²çŸ¥çœŸå®å›å½’å‘é‡çš„æ”¯æŒã€‚ç„¶åæˆ‘ä»¬é€šè¿‡æœ‰é™æ ·æœ¬æ–­ç‚¹å’Œå½±å“å‡½æ•°æ¥è¡¨å¾å…¶å¥å£®æ€§ã€‚æˆ‘ä»¬è¿›è¡Œäº†å¹¿æ³›çš„æ¨¡æ‹Ÿæ¥æ¯”è¾ƒä¸åŒçš„ä¼°è®¡å™¨çš„æ€§èƒ½ã€‚

    This paper introduces a new regularized version of the robust $\tau$-regression estimator for analyzing high-dimensional data sets subject to gross contamination in the response variables and covariates. We call the resulting estimator adaptive $\tau$-Lasso that is robust to outliers and high-leverage points and simultaneously employs adaptive $\ell_1$-norm penalty term to reduce the bias associated with large true regression coefficients. More specifically, this adaptive $\ell_1$-norm penalty term assigns a weight to each regression coefficient. For a fixed number of predictors $p$, we show that the adaptive $\tau$-Lasso has the oracle property with respect to variable-selection consistency and asymptotic normality for the regression vector corresponding to the true support, assuming knowledge of the true regression vector support. We then characterize its robustness via the finite-sample breakdown point and the influence function. We carry-out extensive simulations to compare the per
    

