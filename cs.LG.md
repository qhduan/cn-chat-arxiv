# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Predicting risk of cardiovascular disease using retinal OCT imaging](https://arxiv.org/abs/2403.18873) | 这项研究探讨了使用光学相干断层扫描（OCT）作为额外成像技术来预测心血管疾病的潜力，并通过自监督深度学习和随机森林分类器结合的方法成功区分了心血管疾病风险和非风险患者。 |
| [^2] | [Uncertainty estimation in spatial interpolation of satellite precipitation with ensemble learning](https://arxiv.org/abs/2403.10567) | 引入九种集成学习器并利用新颖特征工程策略，结合多种分位数回归算法，填补了空间插值中集成学习的不确定性估计领域的研究空白 |
| [^3] | [Approximation and bounding techniques for the Fisher-Rao distances](https://arxiv.org/abs/2403.10089) | 本文考虑了几种数值上稳健的Fisher-Rao距离的近似和界定技术，包括基于闭合形式1D子模型Fisher-Rao距离的通用上界以及取决于测地线或预测测地线是否闭合形式获得的几种通用近似方案，并提出了一种通用方法保证近似误差任意小。 |
| [^4] | [Unity by Diversity: Improved Representation Learning in Multimodal VAEs](https://arxiv.org/abs/2403.05300) | 通过软约束取代硬约束，提出了一种新的专家混合先验，改善了多模态VAEs中的表示学习。 |
| [^5] | [Scaling Efficient LLMs](https://arxiv.org/abs/2402.14746) | 训练得到的LLM模型通常是稀疏的，为了提高效率，研究了在训练语料上达到所需准确度的参数最少的高效LLM模型，得出了参数数量与自然训练语料规模之间的关系，并指出扩展可以揭示新技能。 |
| [^6] | [FIDLAR: Forecast-Informed Deep Learning Architecture for Flood Mitigation](https://arxiv.org/abs/2402.13371) | FIDLAR提出了一种预测导向深度学习架构，实现了快速和最优洪水管理，准确进行水前释放。 |
| [^7] | [Boosting of Thoughts: Trial-and-Error Problem Solving with Large Language Models](https://arxiv.org/abs/2402.11140) | 本文提出了一种名为Boosting of Thoughts（BoT）的自动提示框架，通过迭代地探索和自我评估多个思维树，获得一系列试错推理经验，作为解决复杂问题的新形式的提示。 |
| [^8] | [Generative Modeling for Tabular Data via Penalized Optimal Transport Network](https://arxiv.org/abs/2402.10456) | 提出了一种名为POTNet的生成建模网络，基于边缘惩罚的Wasserstein损失，能够有效地建模同时包含分类和连续特征的表格数据。 |
| [^9] | [Decoupling Learning and Decision-Making: Breaking the $\mathcal{O}(\sqrt{T})$ Barrier in Online Resource Allocation with First-Order Methods](https://arxiv.org/abs/2402.07108) | 本文研究了在线线性规划的问题，并提出了一种新的算法框架，解决了一阶方法在线算法实现超过$\mathcal{O}(\sqrt{T})$遗憾的挑战，实现了$\mathcal{O}(T^{1/3})$的遗憾。 |
| [^10] | [Uncertainty-Aware Partial-Label Learning](https://arxiv.org/abs/2402.00592) | 本文提出了一种基于最近邻的部分标签学习算法，利用Dempster-Shafer理论实现对模糊标记的数据的训练。实验结果表明，该算法能够提供良好的不确定性估计，并具有竞争力的预测性能。 |
| [^11] | [AllSpark: A Multimodal Spatio-Temporal General Intelligence Model with Thirteen Modalities](https://arxiv.org/abs/2401.00546) | 提出了一个名为AllSpark的多模态时空智能通用人工智能模型，集成了十三种不同的模态，旨在解决多模态时空数据联合解释的挑战。 |
| [^12] | [DPOD: Domain-Specific Prompt Tuning for Multimodal Fake News Detection](https://arxiv.org/abs/2311.16496) | 本研究提出了一种名为DPOD的框架，通过利用跨领域数据来改善所需领域的脱离上下文误信息检测，解决数据不平衡的问题。 |
| [^13] | [A Survey of Federated Unlearning: A Taxonomy, Challenges and Future Directions](https://arxiv.org/abs/2310.19218) | 联邦遗忘（FU）是解决联邦学习（FL）中数据隐私问题的战略解决方案。在发展FU方法时需要平衡隐私、安全、效用和效率的竞争性要求，以维持FL系统的效果和可用性。 |
| [^14] | [Continuously Learning New Words in Automatic Speech Recognition.](http://arxiv.org/abs/2401.04482) | 该论文提出了一种自我监督的持续学习方法，用于解决自动语音识别中识别新词的问题。通过对讲座录音进行推理和收集包含新词的话语，然后在自适应数据集上进行持续学习，可以在新词出现频率较高时提高性能，同时保持整体性能。 |
| [^15] | [Unexpected Improvements to Expected Improvement for Bayesian Optimization.](http://arxiv.org/abs/2310.20708) | 提出了LogEI作为一类新的贝叶斯优化的获得函数，具有与传统的EI函数相同或近似相等的最优解，但数值上更容易进行优化。 |
| [^16] | [GUPNet++: Geometry Uncertainty Propagation Network for Monocular 3D Object Detection.](http://arxiv.org/abs/2310.15624) | GUPNet++是一种通过以概率方式建模几何投影的几何不确定性传播网络，可以提高单目三维物体检测的深度预测稳定性和效率。 |
| [^17] | [Towards Mitigating Architecture Overfitting in Dataset Distillation.](http://arxiv.org/abs/2309.04195) | 本文解决了数据集蒸馏中的架构过度拟合问题，提出了一系列方法来提高不同网络架构在蒸馏训练数据上的泛化性能。 |
| [^18] | [On Penalty-based Bilevel Gradient Descent Method.](http://arxiv.org/abs/2302.05185) | 本文提出了基于惩罚的双层梯度下降算法，解决了下层非强凸约束双层问题，实验表明该算法有效。 |

# 详细

[^1]: 使用视网膜OCT成像预测心血管疾病风险

    Predicting risk of cardiovascular disease using retinal OCT imaging

    [https://arxiv.org/abs/2403.18873](https://arxiv.org/abs/2403.18873)

    这项研究探讨了使用光学相干断层扫描（OCT）作为额外成像技术来预测心血管疾病的潜力，并通过自监督深度学习和随机森林分类器结合的方法成功区分了心血管疾病风险和非风险患者。

    

    我们调查了光学相干断层扫描（OCT）作为一种额外成像技术来预测未来心血管疾病（CVD）的潜力。我们利用基于变分自动编码器（VAE）的自监督深度学习方法学习了高维3D OCT图像的低维表示，并捕捉了OCT图像中不同视网膜层的独特特征。随后使用学习到的潜在特征和参与者的人口统计数据以及临床数据训练了一个随机森林（RF）分类器，以区分处于CVD事件风险（心梗或中风）和非CVD病例的患者。我们的预测模型基于对多模态数据的训练，评估其能力来正确识别在图像获取后的5年内可能患有CVD事件（心梗或中风）的个体。我们的自监督VAE特征选择和多模态随机森林分类器区分

    arXiv:2403.18873v1 Announce Type: cross  Abstract: We investigated the potential of optical coherence tomography (OCT) as an additional imaging technique to predict future cardiovascular disease (CVD). We utilised a self-supervised deep learning approach based on Variational Autoencoders (VAE) to learn low-dimensional representations of high-dimensional 3D OCT images and to capture distinct characteristics of different retinal layers within the OCT image. A Random Forest (RF) classifier was subsequently trained using the learned latent features and participant demographic and clinical data, to differentiate between patients at risk of CVD events (MI or stroke) and non-CVD cases. Our predictive model, trained on multimodal data, was assessed based on its ability to correctly identify individuals likely to suffer from a CVD event(MI or stroke), within a 5-year interval after image acquisition. Our self-supervised VAE feature selection and multimodal Random Forest classifier differentiate
    
[^2]: 集成学习中的卫星降水空间插值不确定性估计

    Uncertainty estimation in spatial interpolation of satellite precipitation with ensemble learning

    [https://arxiv.org/abs/2403.10567](https://arxiv.org/abs/2403.10567)

    引入九种集成学习器并利用新颖特征工程策略，结合多种分位数回归算法，填补了空间插值中集成学习的不确定性估计领域的研究空白

    

    arXiv:2403.10567v1 公告类型：新的 摘要：概率分布形式的预测对决策至关重要。分位数回归在空间插值设置中能够合并遥感和雨量数据，实现此目标。然而，在这种情境下，分位数回归算法的集成学习尚未被研究。本文通过引入九种基于分位数的集成学习器并将其应用于大型降水数据集来填补这一空白。我们采用了一种新颖的特征工程策略，将预测因子减少为相关位置的加权距离卫星降水，结合位置高程。我们的集成学习器包括六种堆叠方法和三种简单方法（均值、中位数、最佳组合器），结合了六种个体算法：分位数回归(QR)、分位数回归森林(QRF)、广义随机森林(GRF)、梯度提升机(GBM)、轻量级梯度提升机(LightGBM)和分位数回归神经网络

    arXiv:2403.10567v1 Announce Type: new  Abstract: Predictions in the form of probability distributions are crucial for decision-making. Quantile regression enables this within spatial interpolation settings for merging remote sensing and gauge precipitation data. However, ensemble learning of quantile regression algorithms remains unexplored in this context. Here, we address this gap by introducing nine quantile-based ensemble learners and applying them to large precipitation datasets. We employed a novel feature engineering strategy, reducing predictors to distance-weighted satellite precipitation at relevant locations, combined with location elevation. Our ensemble learners include six stacking and three simple methods (mean, median, best combiner), combining six individual algorithms: quantile regression (QR), quantile regression forests (QRF), generalized random forests (GRF), gradient boosting machines (GBM), light gradient boosting machines (LightGBM), and quantile regression neur
    
[^3]: 用于Fisher-Rao距离的近似和界定技术

    Approximation and bounding techniques for the Fisher-Rao distances

    [https://arxiv.org/abs/2403.10089](https://arxiv.org/abs/2403.10089)

    本文考虑了几种数值上稳健的Fisher-Rao距离的近似和界定技术，包括基于闭合形式1D子模型Fisher-Rao距离的通用上界以及取决于测地线或预测测地线是否闭合形式获得的几种通用近似方案，并提出了一种通用方法保证近似误差任意小。

    

    统计模型的两个概率分布之间的Fisher-Rao距离被定义为Fisher信息度量诱导的Riemannian测地距离。为了以闭合形式计算Fisher-Rao距离，我们需要（1）推导出Fisher-Rao测地线的公式，以及（2）沿着这些测地线积分Fisher长度元素。我们考虑了几种数值上稳健的Fisher-Rao距离的近似和界定技术：首先，我们基于子模型的闭合形式1D Fisher-Rao距离报告了Fisher-Rao距离的通用上界。其次，我们描述了几种通用的近似方案，取决于Fisher-Rao测地线或预测测地线是否能以闭合形式获得。特别地，我们获得了一种通用的方法，可以保证在提供Fisher-Rao预测测地线和严格的下界和上界时近似产生任意小的附加误差。

    arXiv:2403.10089v1 Announce Type: cross  Abstract: The Fisher-Rao distance between two probability distributions of a statistical model is defined as the Riemannian geodesic distance induced by the Fisher information metric. In order to calculate the Fisher-Rao distance in closed-form, we need (1) to elicit a formula for the Fisher-Rao geodesics, and (2) to integrate the Fisher length element along those geodesics. We consider several numerically robust approximation and bounding techniques for the Fisher-Rao distances: First, we report generic upper bounds on Fisher-Rao distances based on closed-form 1D Fisher-Rao distances of submodels. Second, we describe several generic approximation schemes depending on whether the Fisher-Rao geodesics or pregeodesics are available in closed-form or not. In particular, we obtain a generic method to guarantee an arbitrarily small additive error on the approximation provided that Fisher-Rao pregeodesics and tight lower and upper bounds are available
    
[^4]: 多模态VAEs中的统一多样性：改进的表示学习

    Unity by Diversity: Improved Representation Learning in Multimodal VAEs

    [https://arxiv.org/abs/2403.05300](https://arxiv.org/abs/2403.05300)

    通过软约束取代硬约束，提出了一种新的专家混合先验，改善了多模态VAEs中的表示学习。

    

    多模态数据的变分自编码器在数据分析的许多任务中表现出潜力，如表示学习、有条件生成和填补。目前的架构要么跨模态共享编码器输出、解码器输入，要么两者都要学习共享表示。这样的架构对模型施加了严格约束。在这项工作中，我们展示了通过用软约束取代这些硬约束可以获得更好的潜在表示。我们提出了一种新的专家混合先验，软性地引导每个模态的潜在表示朝着共享的后验。这种方法导致了优秀的潜在表示，并允许每个编码保留来自其未压缩原始特征更好的信息。通过对多个基准数据集和一个具有挑战性的现实世界神经科学数据集进行的广泛实验，我们展示了改进的学习潜在表示和填补。

    arXiv:2403.05300v1 Announce Type: cross  Abstract: Variational Autoencoders for multimodal data hold promise for many tasks in data analysis, such as representation learning, conditional generation, and imputation. Current architectures either share the encoder output, decoder input, or both across modalities to learn a shared representation. Such architectures impose hard constraints on the model. In this work, we show that a better latent representation can be obtained by replacing these hard constraints with a soft constraint. We propose a new mixture-of-experts prior, softly guiding each modality's latent representation towards a shared aggregate posterior. This approach results in a superior latent representation and allows each encoding to preserve information from its uncompressed original features better. In extensive experiments on multiple benchmark datasets and a challenging real-world neuroscience data set, we show improved learned latent representations and imputation of m
    
[^5]: 扩展高效的LLM模型

    Scaling Efficient LLMs

    [https://arxiv.org/abs/2402.14746](https://arxiv.org/abs/2402.14746)

    训练得到的LLM模型通常是稀疏的，为了提高效率，研究了在训练语料上达到所需准确度的参数最少的高效LLM模型，得出了参数数量与自然训练语料规模之间的关系，并指出扩展可以揭示新技能。

    

    训练得到的LLM模型通常是稀疏的，即大部分参数为零，这引发了关于效率的问题。为此，我们研究了高效的LLM模型，即那些在训练语料上达到所需准确度的参数最少。具体地，我们比较了当前规模下训练损失的理论和实证估计，以获得自然训练语料中独特序列数量上下界的数量。我们的结果暗示：(1)要在训练语料中表示的技能数量翻倍，需要将语料规模大约扩展三到五倍，(2)对于高效的LLM模型，参数数量$N$和自然训练语料规模$D$满足$N \sim D^{0.58}$的关系，(3)如果一个LLM模型的参数数量小于训练语料中的独特序列数量，扩展可以揭示出新的技能。

    arXiv:2402.14746v1 Announce Type: new  Abstract: Trained LLMs are typically sparse in that most of the parameters are zero, raising questions on efficiency. In response, we inquire into efficient LLMs, i.e. those with the fewest parameters that achieve the desired accuracy on a training corpus. Specifically, we compare theoretical and empirical estimates for training loss at current scale to obtain upper and lower bounds on the number of unique sequences in a natural training corpus as a function of its size. Our result implies (1) to double the number of skills represented in a training corpus, the corpus must scale roughly between three and five fold (2) for efficient LLMs, the number of parameters $N$ and the size $D$ of a natural training corpus scale as $N \sim D^{0.58}$ (3) if the number of parameters of an LLM is smaller than the number of unique sequences in the training corpus, scaling up can uncover emergent skills.
    
[^6]: FIDLAR: 水灾减灾的预测导向深度学习架构

    FIDLAR: Forecast-Informed Deep Learning Architecture for Flood Mitigation

    [https://arxiv.org/abs/2402.13371](https://arxiv.org/abs/2402.13371)

    FIDLAR提出了一种预测导向深度学习架构，实现了快速和最优洪水管理，准确进行水前释放。

    

    在沿海河流系统中，频繁发生的洪水往往在大风暴或满潮时发生，对生命和财产构成严重威胁。然而，通过在枢纽结构(如水坝、闸门、泵站和水库)在极端天气事件前进行战略性地释放水，这些洪水可以得到减轻甚至预防。当地水利管理机构通常使用的标准方法是“基于规则”的方法，该方法基于历史和经过时间验证的人类经验指定预先释放水，但往往导致过量或不足的水量释放。模型预测控制(MPC)是一个替代方法，是基于物理的预测模型，尽管需要进行计算密集型计算。本文提出了一种名为FIDLAR的预测导向深度学习架构，以实现精确的水前释放，实现快速和最优的洪水管理。

    arXiv:2402.13371v1 Announce Type: new  Abstract: In coastal river systems, frequent floods, often occurring during major storms or king tides, pose a severe threat to lives and property. However, these floods can be mitigated or even prevented by strategically releasing water before extreme weather events with hydraulic structures such as dams, gates, pumps, and reservoirs. A standard approach used by local water management agencies is the "rule-based" method, which specifies predetermined pre-releases of water based on historical and time-tested human experience, but which tends to result in excess or inadequate water release. The model predictive control (MPC), a physics-based model for prediction, is an alternative approach, albeit involving computationally intensive calculations. In this paper, we propose a Forecast Informed Deep Learning Architecture, FIDLAR, to achieve rapid and optimal flood management with precise water pre-releases. FIDLAR seamlessly integrates two neural netw
    
[^7]: 思维的提升：使用大型语言模型进行试错问题解决

    Boosting of Thoughts: Trial-and-Error Problem Solving with Large Language Models

    [https://arxiv.org/abs/2402.11140](https://arxiv.org/abs/2402.11140)

    本文提出了一种名为Boosting of Thoughts（BoT）的自动提示框架，通过迭代地探索和自我评估多个思维树，获得一系列试错推理经验，作为解决复杂问题的新形式的提示。

    

    大型语言模型（LLMs）在各种问题上的推理性能关键取决于思维链提示，其中包括在提示中提供一些思维链示范作为示例。最近的工作（例如Thought Tree）指出了在复杂问题解决的推理步骤选择中，探索和自我评估的重要性。在本文中，我们提出了一种名为Boosting of Thoughts（BoT）的自动提示框架，用于通过迭代地探索和自我评估许多思维树来获得一系列试错推理经验，这将作为解决复杂问题的新形式的提示。BoT从一个简单提示开始，无需示例，迭代地探索和评估大量的推理步骤，更重要的是，利用LLM获得的错误分析来明确修改提示。

    arXiv:2402.11140v1 Announce Type: new  Abstract: The reasoning performance of Large Language Models (LLMs) on a wide range of problems critically relies on chain-of-thought prompting, which involves providing a few chain of thought demonstrations as exemplars in prompts. Recent work, e.g., Tree of Thoughts, has pointed out the importance of exploration and self-evaluation in reasoning step selection for complex problem solving. In this paper, we present Boosting of Thoughts (BoT), an automated prompting framework for problem solving with LLMs by iteratively exploring and self-evaluating many trees of thoughts in order to acquire an ensemble of trial-and-error reasoning experiences, which will serve as a new form of prompting to solve the complex problem. Starting from a simple prompt without requiring examples, BoT iteratively explores and evaluates a large collection of reasoning steps, and more importantly, uses error analysis obtained from the LLM on them to explicitly revise prompt
    
[^8]: 通过惩罚最优输运网络对表格数据进行生成建模

    Generative Modeling for Tabular Data via Penalized Optimal Transport Network

    [https://arxiv.org/abs/2402.10456](https://arxiv.org/abs/2402.10456)

    提出了一种名为POTNet的生成建模网络，基于边缘惩罚的Wasserstein损失，能够有效地建模同时包含分类和连续特征的表格数据。

    

    准确学习表格数据中行的概率分布并生成真实的合成样本的任务既关键又非平凡。Wasserstein生成对抗网络(WGAN)在生成建模中取得了显著进展，解决了其前身生成对抗网络所面临的挑战。然而，由于表格数据中存在混合数据类型和多模态性，生成器和鉴别器之间的微妙平衡以及Wasserstein距离在高维度中的固有不稳定性，WGAN通常无法生成高保真样本。因此，我们提出了POTNet（惩罚最优输运网络），这是一种基于新颖、强大且可解释的边际惩罚Wasserstein（MPW）损失的生成深度神经网络。POTNet能够有效地建模包含分类和连续特征的表格数据。

    arXiv:2402.10456v1 Announce Type: cross  Abstract: The task of precisely learning the probability distribution of rows within tabular data and producing authentic synthetic samples is both crucial and non-trivial. Wasserstein generative adversarial network (WGAN) marks a notable improvement in generative modeling, addressing the challenges faced by its predecessor, generative adversarial network. However, due to the mixed data types and multimodalities prevalent in tabular data, the delicate equilibrium between the generator and discriminator, as well as the inherent instability of Wasserstein distance in high dimensions, WGAN often fails to produce high-fidelity samples. To this end, we propose POTNet (Penalized Optimal Transport Network), a generative deep neural network based on a novel, robust, and interpretable marginally-penalized Wasserstein (MPW) loss. POTNet can effectively model tabular data containing both categorical and continuous features. Moreover, it offers the flexibil
    
[^9]: 解耦学习和决策：用一阶方法突破在线资源分配中的$\mathcal{O}(\sqrt{T})$障碍

    Decoupling Learning and Decision-Making: Breaking the $\mathcal{O}(\sqrt{T})$ Barrier in Online Resource Allocation with First-Order Methods

    [https://arxiv.org/abs/2402.07108](https://arxiv.org/abs/2402.07108)

    本文研究了在线线性规划的问题，并提出了一种新的算法框架，解决了一阶方法在线算法实现超过$\mathcal{O}(\sqrt{T})$遗憾的挑战，实现了$\mathcal{O}(T^{1/3})$的遗憾。

    

    在线线性规划在收益管理和资源分配之间起着重要作用，最近的研究集中在开发有效的一阶在线学习算法。尽管一阶方法在实证上取得了成功，但它们通常只能实现$\mathcal{O}(\sqrt{T})$的遗憾，与最先进的基于线性规划(LP)的在线算法所保证的$\mathcal{O}(\log T)$界限相比是次优的。本文确定了关于在线线性规划的几个重要事实，揭示了一阶方法在线算法实现超过$\mathcal{O}(\sqrt{T})$遗憾的挑战。为了解决这个挑战，我们引入了一个新的算法框架，将学习与决策分离。更重要的是，我们首次展示了一阶方法在这个新框架下可以达到$\mathcal{O}(T^{1/3})$的遗憾。最后，我们进行了数值实验，验证了我们的理论发现。

    Online linear programming plays an important role in both revenue management and resource allocation, and recent research has focused on developing efficient first-order online learning algorithms. Despite the empirical success of first-order methods, they typically achieve a regret no better than $\mathcal{O}(\sqrt{T})$, which is suboptimal compared to the $\mathcal{O}(\log T)$ bound guaranteed by the state-of-the-art linear programming (LP)-based online algorithms. This paper establishes several important facts about online linear programming, which unveils the challenge for first-order-method-based online algorithms to achieve beyond $\mathcal{O}(\sqrt{T})$ regret. To address the challenge, we introduce a new algorithmic framework that decouples learning from decision-making. More importantly, for the first time, we show that first-order methods can attain regret $\mathcal{O}(T^{1/3})$ with this new framework. Lastly, we conduct numerical experiments to validate our theoretical find
    
[^10]: 不确定性感知的部分标签学习

    Uncertainty-Aware Partial-Label Learning

    [https://arxiv.org/abs/2402.00592](https://arxiv.org/abs/2402.00592)

    本文提出了一种基于最近邻的部分标签学习算法，利用Dempster-Shafer理论实现对模糊标记的数据的训练。实验结果表明，该算法能够提供良好的不确定性估计，并具有竞争力的预测性能。

    

    在现实世界的应用中，人们经常遇到标记模糊的数据，即不同的标注者为相同样本分配了冲突的类别标签。部分标签学习允许在这种弱监督的情况下训练分类器。虽然最先进的方法已经具有良好的预测性能，但它们往往受到错误的不确定性估计的影响。然而，在医学和自动驾驶等安全关键领域，具有良好校准的不确定性估计尤为重要。在本文中，我们提出了一种基于最近邻的部分标签学习算法，该算法利用了Dempster-Shafer理论。对人工数据集和实际数据集进行的广泛实验表明，所提出的方法能够提供良好的不确定性估计，并具有竞争力的预测性能。此外，我们还证明了我们的算法具有风险一致性。

    In real-world applications, one often encounters ambiguously labeled data, where different annotators assign conflicting class labels. Partial-label learning allows training classifiers in this weakly supervised setting. While state-of-the-art methods already feature good predictive performance, they often suffer from miscalibrated uncertainty estimates. However, having well-calibrated uncertainty estimates is important, especially in safety-critical domains like medicine and autonomous driving. In this article, we propose a novel nearest-neighbor-based partial-label-learning algorithm that leverages Dempster-Shafer theory. Extensive experiments on artificial and real-world datasets show that the proposed method provides a well-calibrated uncertainty estimate and achieves competitive prediction performance. Additionally, we prove that our algorithm is risk-consistent.
    
[^11]: AllSpark: 一个具有十三种模态的多模态时空智能模型

    AllSpark: A Multimodal Spatio-Temporal General Intelligence Model with Thirteen Modalities

    [https://arxiv.org/abs/2401.00546](https://arxiv.org/abs/2401.00546)

    提出了一个名为AllSpark的多模态时空智能通用人工智能模型，集成了十三种不同的模态，旨在解决多模态时空数据联合解释的挑战。

    

    长期以来，由于各种时空模态数据之间结构和语义的高度异质性，多模态时空数据的联合解释一直是一个极具挑战性的问题。主要挑战在于在不同模态之间的凝聚力和自治性之间取得平衡，而随着模态数量的增加，这种平衡表现出逐渐非线性的特性。我们引入了语言作为参考框架（LaRF），这是构建多模态统一模型的基本原则，旨在在不同模态之间取得凝聚力和自治性之间的平衡。我们提出了一个名为AllSpark的多模态时空智能通用人工智能模型。我们的模型将十三种不同的模态集成到一个统一框架中，包括1D（文本，代码），2D（RGB，红外线，SAR，多光谱，高光谱，表格，图表，轨迹，斜角摄影）。

    arXiv:2401.00546v2 Announce Type: replace  Abstract: For a long time, due to the high heterogeneity in structure and semantics among various spatiotemporal modal data, the joint interpretation of multimodal spatiotemporal data has been an extremely challenging problem. The primary challenge resides in striking a trade-off between the cohesion and autonomy of diverse modalities, and this trade-off exhibits a progressively nonlinear nature as the number of modalities expands. We introduce the Language as Reference Framework (LaRF), a fundamental principle for constructing a multimodal unified model, aiming to strike a trade-off between the cohesion and autonomy among different modalities. We propose a multimodal spatiotemporal general artificial intelligence model, called AllSpark. Our model integrates thirteen different modalities into a unified framework, including 1D (text, code), 2D (RGB, infrared, SAR, multispectral, hyperspectral, tables, graphs, trajectory, oblique photography), a
    
[^12]: DPOD：面向多模态假新闻检测的领域特定提示调节

    DPOD: Domain-Specific Prompt Tuning for Multimodal Fake News Detection

    [https://arxiv.org/abs/2311.16496](https://arxiv.org/abs/2311.16496)

    本研究提出了一种名为DPOD的框架，通过利用跨领域数据来改善所需领域的脱离上下文误信息检测，解决数据不平衡的问题。

    

    虚假新闻利用脱离上下文的图像传播已经变得普遍，是信息过载时代一个相关的问题。这种脱离上下文的虚假新闻可能涉及不同领域，如政治、体育、娱乐等。在实际场景中，不同领域新闻文章存在着数据不平衡的问题，部分领域数据丰富，而其他领域数据非常有限。在这种情况下，必须开发出能够适应不同数据量设置的方法。本文探讨了跨领域数据是否有助于改善所需领域的脱离上下文误信息检测（在此称为多模态虚假新闻检测）的方法以解决这一具有挑战性的问题。为此，我们提出了一种名为DPOD（使用跨领域数据进行领域特定提示调节）的新框架。

    arXiv:2311.16496v2 Announce Type: replace  Abstract: The spread of fake news using out-of-context images has become widespread and is a relevant problem in this era of information overload. Such out-of-context fake news may arise across different domains like politics, sports, entertainment, etc. In practical scenarios, an inherent problem of imbalance exists among news articles from such widely varying domains, resulting in a few domains with abundant data, while the rest containing very limited data. Under such circumstances, it is imperative to develop methods which can work in such varying amounts of data setting. In this work, we explore whether out-of-domain data can help to improve out-of-context misinformation detection (termed here as multi-modal fake news detection) of a desired domain, to address this challenging problem. Towards this goal, we propose a novel framework termed DPOD (Domain-specific Prompt-tuning using Out-of-Domain data). First, to compute generalizable featu
    
[^13]: 联邦遗忘的综述：分类、挑战和未来方向

    A Survey of Federated Unlearning: A Taxonomy, Challenges and Future Directions

    [https://arxiv.org/abs/2310.19218](https://arxiv.org/abs/2310.19218)

    联邦遗忘（FU）是解决联邦学习（FL）中数据隐私问题的战略解决方案。在发展FU方法时需要平衡隐私、安全、效用和效率的竞争性要求，以维持FL系统的效果和可用性。

    

    随着隐私保护的联邦学习（FL）的发展，对实现被遗忘权的需求越来越大。由于FL的分散性质，实施选择性遗忘尤其具有挑战性。这种复杂性催生了一个新的领域，即联邦遗忘（FU）。FU作为解决数据隐私需求的战略解决方案，包括实施“被遗忘权”。开发FU方法的主要挑战在于在隐私、安全、效用和效率之间取得平衡，因为这些因素往往具有竞争性要求。在保持FL系统的有效性和可用性的同时，实现这些方面的最佳平衡对于遵守隐私和安全标准至关重要。本综述对现有的FU方法进行了全面分析，包括对各种评估指标的详细评论。

    The evolution of privacy-preserving Federated Learning (FL) has led to an increasing demand for implementing the right to be forgotten. The implementation of selective forgetting is particularly challenging in FL due to its decentralized nature. This complexity has given rise to a new field, Federated Unlearning (FU). FU emerges as a strategic solution to address the increasing need for data privacy, including the implementation of the `right to be forgotten'. The primary challenge in developing FU approaches lies in balancing the trade-offs in privacy, security, utility, and efficiency, as these elements often have competing requirements. Achieving an optimal equilibrium among these facets is crucial for maintaining the effectiveness and usability of FL systems while adhering to privacy and security standards. This survey provides a comprehensive analysis of existing FU methods, incorporating a detailed review of the various evaluation metrics. Furthermore, we unify these diverse meth
    
[^14]: 在自动语音识别中持续学习新词

    Continuously Learning New Words in Automatic Speech Recognition. (arXiv:2401.04482v1 [cs.CL])

    [http://arxiv.org/abs/2401.04482](http://arxiv.org/abs/2401.04482)

    该论文提出了一种自我监督的持续学习方法，用于解决自动语音识别中识别新词的问题。通过对讲座录音进行推理和收集包含新词的话语，然后在自适应数据集上进行持续学习，可以在新词出现频率较高时提高性能，同时保持整体性能。

    

    尽管最近取得了进展，但自动语音识别（ASR）系统仍然远未完美。典型的错误包括缩写词、命名实体和领域特定的专用词，这些词几乎没有或没有数据可用来训练。为了解决识别这些词的问题，我们提出了一种自我监督的持续学习方法。给定带有对应幻灯片的讲座录音，我们通过使用先前工作中的记忆增强型ASR模型来将模型偏向于从幻灯片中解码新词。然后，我们对讲座进行推理，将包含检测到的新词的话语收集到自适应数据集中。接着，对这个集合进行持续学习，通过调整添加到模型的每个权重矩阵的低秩矩阵权重。整个过程对多个讲座进行迭代。我们展示了通过这种方法，我们在新词出现频率较高时获得了性能的提升（超过80%的召回率），同时保持了模型的整体性能。

    Despite recent advances, Automatic Speech Recognition (ASR) systems are still far from perfect. Typical errors include acronyms, named entities and domain-specific special words for which little or no data is available. To address the problem of recognizing these words, we propose an self-supervised continual learning approach. Given the audio of a lecture talk with corresponding slides, we bias the model towards decoding new words from the slides by using a memory-enhanced ASR model from previous work. Then, we perform inference on the talk, collecting utterances that contain detected new words into an adaptation dataset. Continual learning is then performed on this set by adapting low-rank matrix weights added to each weight matrix of the model. The whole procedure is iterated for many talks. We show that with this approach, we obtain increasing performance on the new words when they occur more frequently (more than 80% recall) while preserving the general performance of the model.
    
[^15]: 对贝叶斯优化的期望改进的意外提升

    Unexpected Improvements to Expected Improvement for Bayesian Optimization. (arXiv:2310.20708v1 [cs.LG])

    [http://arxiv.org/abs/2310.20708](http://arxiv.org/abs/2310.20708)

    提出了LogEI作为一类新的贝叶斯优化的获得函数，具有与传统的EI函数相同或近似相等的最优解，但数值上更容易进行优化。

    

    期望改进（EI）可以说是贝叶斯优化中最流行的获得函数，并且已经在很多成功的应用中得到了应用。但是，EI的性能往往被一些新方法超越。尤其是，EI及其变种在并行和多目标设置中很难进行优化，因为它们的获得值在许多区域中数值上变为零。当观测次数增加、搜索空间的维度增加或约束条件的数量增加时，这种困难通常会增加，导致性能在文献中不一致且大多数情况下亚优化。在本论文中，我们提出了LogEI，这是一类新的采样函数。与标准EI相比，这些LogEI函数的成员要么具有相同的最优解，要么具有近似相等的最优解，但数值上更容易进行优化。我们证明了数值病态在“经典”分析EI、期望超体积改进（EHVI）以及它们的...

    Expected Improvement (EI) is arguably the most popular acquisition function in Bayesian optimization and has found countless successful applications, but its performance is often exceeded by that of more recent methods. Notably, EI and its variants, including for the parallel and multi-objective settings, are challenging to optimize because their acquisition values vanish numerically in many regions. This difficulty generally increases as the number of observations, dimensionality of the search space, or the number of constraints grow, resulting in performance that is inconsistent across the literature and most often sub-optimal. Herein, we propose LogEI, a new family of acquisition functions whose members either have identical or approximately equal optima as their canonical counterparts, but are substantially easier to optimize numerically. We demonstrate that numerical pathologies manifest themselves in "classic" analytic EI, Expected Hypervolume Improvement (EHVI), as well as their
    
[^16]: GUPNet++：用于单目三维物体检测的几何不确定性传播网络

    GUPNet++: Geometry Uncertainty Propagation Network for Monocular 3D Object Detection. (arXiv:2310.15624v1 [cs.CV])

    [http://arxiv.org/abs/2310.15624](http://arxiv.org/abs/2310.15624)

    GUPNet++是一种通过以概率方式建模几何投影的几何不确定性传播网络，可以提高单目三维物体检测的深度预测稳定性和效率。

    

    几何在单目三维物体检测中起着重要作用。它可以通过物体的物理尺寸与图像平面中的二维投影之间的透视投影来估计物体的深度，这可以将数学先验引入深度模型。然而，这个投影过程也会引入误差放大，估计高度的误差会被放大并反映到投影的深度中。这导致深度推断不可靠，并且影响训练的稳定性。为了解决这个问题，我们提出了一种新颖的几何不确定性传播网络(GUPNet++)，通过以概率方式建模几何投影。这确保了深度预测是有界的，并与合理的不确定性相关联。引入这种几何不确定性的意义有两个方面：(1)。它模拟了几何投影在训练过程中的不确定性传播关系，提高了端到端模型学习的稳定性和效率。

    Geometry plays a significant role in monocular 3D object detection. It can be used to estimate object depth by using the perspective projection between object's physical size and 2D projection in the image plane, which can introduce mathematical priors into deep models. However, this projection process also introduces error amplification, where the error of the estimated height is amplified and reflected into the projected depth. It leads to unreliable depth inferences and also impairs training stability. To tackle this problem, we propose a novel Geometry Uncertainty Propagation Network (GUPNet++) by modeling geometry projection in a probabilistic manner. This ensures depth predictions are well-bounded and associated with a reasonable uncertainty. The significance of introducing such geometric uncertainty is two-fold: (1). It models the uncertainty propagation relationship of the geometry projection during training, improving the stability and efficiency of the end-to-end model learni
    
[^17]: 在数据集蒸馏中缓解架构过度拟合的方法

    Towards Mitigating Architecture Overfitting in Dataset Distillation. (arXiv:2309.04195v1 [cs.LG])

    [http://arxiv.org/abs/2309.04195](http://arxiv.org/abs/2309.04195)

    本文解决了数据集蒸馏中的架构过度拟合问题，提出了一系列方法来提高不同网络架构在蒸馏训练数据上的泛化性能。

    

    数据集蒸馏方法在使用极少训练数据进行神经网络训练时表现出了显著的性能。然而，一个重要的挑战是架构过度拟合：由特定网络架构（即训练网络）合成的蒸馏训练数据在其他网络架构（即测试网络）训练时表现出较差的性能。本文解决了这个问题，提出了一系列架构设计和训练方案的方法，可以共同提高不同网络架构在蒸馏训练数据上的泛化性能。我们进行了大量实验证明了我们方法的有效性和普适性。特别地，在不同大小的蒸馏数据涉及的各种场景中，我们的方法在使用容量更大的网络对蒸馏数据进行训练时实现了与现有方法相当或更好的性能。

    Dataset distillation methods have demonstrated remarkable performance for neural networks trained with very limited training data. However, a significant challenge arises in the form of architecture overfitting: the distilled training data synthesized by a specific network architecture (i.e., training network) generates poor performance when trained by other network architectures (i.e., test networks). This paper addresses this issue and proposes a series of approaches in both architecture designs and training schemes which can be adopted together to boost the generalization performance across different network architectures on the distilled training data. We conduct extensive experiments to demonstrate the effectiveness and generality of our methods. Particularly, across various scenarios involving different sizes of distilled data, our approaches achieve comparable or superior performance to existing methods when training on the distilled data using networks with larger capacities.
    
[^18]: 基于惩罚的双层梯度下降方法研究

    On Penalty-based Bilevel Gradient Descent Method. (arXiv:2302.05185v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.05185](http://arxiv.org/abs/2302.05185)

    本文提出了基于惩罚的双层梯度下降算法，解决了下层非强凸约束双层问题，实验表明该算法有效。

    This paper proposes a penalty-based bilevel gradient descent algorithm to solve the constrained bilevel problem without lower-level strong convexity, and experiments show its efficiency.

    双层优化在超参数优化、元学习和强化学习等领域有广泛应用，但是双层优化问题难以解决。最近的可扩展双层算法主要集中在下层目标函数是强凸或无约束的双层优化问题上。在本文中，我们通过惩罚方法来解决双层问题。我们证明，在一定条件下，惩罚重构可以恢复原始双层问题的解。此外，我们提出了基于惩罚的双层梯度下降（PBGD）算法，并证明了其在下层非强凸约束双层问题上的有限时间收敛性。实验展示了所提出的PBGD算法的效率。

    Bilevel optimization enjoys a wide range of applications in hyper-parameter optimization, meta-learning and reinforcement learning. However, bilevel optimization problems are difficult to solve. Recent progress on scalable bilevel algorithms mainly focuses on bilevel optimization problems where the lower-level objective is either strongly convex or unconstrained. In this work, we tackle the bilevel problem through the lens of the penalty method. We show that under certain conditions, the penalty reformulation recovers the solutions of the original bilevel problem. Further, we propose the penalty-based bilevel gradient descent (PBGD) algorithm and establish its finite-time convergence for the constrained bilevel problem without lower-level strong convexity. Experiments showcase the efficiency of the proposed PBGD algorithm.
    

