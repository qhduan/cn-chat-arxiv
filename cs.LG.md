# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Minimax Optimal and Computationally Efficient Algorithms for Distributionally Robust Offline Reinforcement Learning](https://arxiv.org/abs/2403.09621) | 研究提出了最小化最优和计算高效的算法，为鲁棒离线强化学习中的函数逼近带来新颖视角，并展示了其与标准离线强化学习中函数逼近的区别。 |
| [^2] | [Graph Generation via Spectral Diffusion](https://arxiv.org/abs/2402.18974) | 提出了一种基于图拉普拉斯矩阵谱分解和扩散过程的新颖图生成模型GRASP，能够通过截断拉普拉斯频谱快速准确地捕捉图的结构特征，同时处理节点特征，避免了二次复杂性瓶颈。 |
| [^3] | [AURA: Natural Language Reasoning for Aleatoric Uncertainty in Rationales](https://arxiv.org/abs/2402.14337) | 提出了在自然语言推理中处理引发模式合理性不确定性的不完美理由的方法，实施了使用熵分数和模型先验信念来指导模型的策略，并在实证中展示了方法相对于敌对理由的稳健性能优势 |
| [^4] | [The Loss Landscape of Shallow ReLU-like Neural Networks: Stationary Points, Saddle Escaping, and Network Embedding](https://arxiv.org/abs/2402.05626) | 本文研究了使用ReLU-like激活函数以经验平方损失训练的单隐藏层神经网络的损失景观，提出了稳定点条件和逃逸神经元的定义，并将鞍点逃逸与逃逸神经元的参数变化联系起来。 |
| [^5] | [DiffTOP: Differentiable Trajectory Optimization for Deep Reinforcement and Imitation Learning](https://arxiv.org/abs/2402.05421) | DiffTOP使用可微分轨迹优化作为策略表示来生成动作，解决了模型基于强化学习算法中的“目标不匹配”问题，并在模仿学习任务上进行了性能基准测试。 |
| [^6] | [EAGLE: Speculative Sampling Requires Rethinking Feature Uncertainty.](http://arxiv.org/abs/2401.15077) | EAGLE是一个无损加速语言模型推理的框架，通过在次顶层特征层面上自回归推理，并解决采样不确定性问题，实现了比传统方法更快3倍的速度。 |
| [^7] | [Last-Iterate Convergence Properties of Regret-Matching Algorithms in Games.](http://arxiv.org/abs/2311.00676) | 这篇论文研究了基于遗憾匹配的算法在游戏中的最终迭代收敛性质。通过数值实验发现多个实际变体在简单的游戏中缺乏最终迭代收敛保证，而基于平滑技术的最近变体则具有最终迭代收敛性。 |
| [^8] | [Optimal Batched Best Arm Identification.](http://arxiv.org/abs/2310.14129) | 本论文研究了最佳批处理武器识别问题，在渐近和非渐近设置中提出了Tri-BBAI和Opt-BBAI算法，分别实现了最优和几乎最优的样本和批处理复杂度。 |
| [^9] | [A Unifying Framework for Learning Argumentation Semantics.](http://arxiv.org/abs/2310.12309) | 本文提出了一种统一的框架来学习论证语义，通过使用可解释的方法，优于现有的论证求解器，并在形式论证和人机对话领域开辟了新的研究方向。 |
| [^10] | [Assessing Robustness via Score-Based Adversarial Image Generation.](http://arxiv.org/abs/2310.04285) | 本论文介绍了一种基于分数的对抗生成框架（ScoreAG），可以生成超过$\ell_p$-范数约束的对抗性示例，并通过图像转换或新图像合成的方法保持图像的核心语义，大大增强了分类器的鲁棒性。 |
| [^11] | [Thermodynamic Computing via Autonomous Quantum Thermal Machines.](http://arxiv.org/abs/2308.15905) | 通过自主量子热机实现了热力学计算模型。通过热流进行计算，可实现任何线性可分离函数，并可扩展到神经元网络执行任何 needed功能。 |
| [^12] | [HoSNN: Adversarially-Robust Homeostatic Spiking Neural Networks with Adaptive Firing Thresholds.](http://arxiv.org/abs/2308.10373) | HoSNN是一种对抗性稳态脉冲神经网络，通过采用自适应发放阈值的渗漏整合与发放（TA-LIF）神经元模型来抵御对抗攻击，并在无监督的方式下保护其鲁棒性。 |
| [^13] | [Persistent Homology of the Multiscale Clustering Filtration.](http://arxiv.org/abs/2305.04281) | 该论文引入了一种多尺度聚类过滤方法（MCF），用于描述不同尺度下的数据聚类，其中的持久同调可测量分区序列的层次关系和聚类分配冲突的出现和解决。 |
| [^14] | [Decentralized Adversarial Training over Graphs.](http://arxiv.org/abs/2303.13326) | 本文研究了在图上的去中心化对抗性训练，利用扩散学习的方法，开发了一种对抗性训练框架，增强了多个代理的鲁棒性以对抗攻击。 |
| [^15] | [Modeling Relational Patterns for Logical Query Answering over Knowledge Graphs.](http://arxiv.org/abs/2303.11858) | 本文介绍了一种新的查询嵌入方法RoConE，它允许学习关系模式并提高了逻辑查询推理的性能。 |
| [^16] | [MIXRTs: Toward Interpretable Multi-Agent Reinforcement Learning via Mixing Recurrent Soft Decision Trees.](http://arxiv.org/abs/2209.07225) | MIXRTs是一种可解释的多智能体强化学习架构，通过混合循环软决策树的方式，能够表达明确的决策过程并展示每个智能体的贡献。 |
| [^17] | [A Comparative Evaluation of Quantification Methods.](http://arxiv.org/abs/2103.03223) | 本研究通过对24种不同量化方法在超过40个数据集上进行全面实证比较，填补了量化方法比较研究的空白。我们发现在二分类设置中，基于阈值选择的Median Sweep和TSMax方法、DyS框架和弗里德曼的方法表现最佳；而在多分类设置中，Generaliz方法表现良好。 |

# 详细

[^1]: 最小化最优和计算高效的分布鲁棒离线强化学习算法

    Minimax Optimal and Computationally Efficient Algorithms for Distributionally Robust Offline Reinforcement Learning

    [https://arxiv.org/abs/2403.09621](https://arxiv.org/abs/2403.09621)

    研究提出了最小化最优和计算高效的算法，为鲁棒离线强化学习中的函数逼近带来新颖视角，并展示了其与标准离线强化学习中函数逼近的区别。

    

    分布鲁棒离线强化学习（RL）寻求针对环境扰动的鲁棒策略训练，通过建模动态不确定性来调用函数逼近，当面对庞大的状态-动作空间时，这种RL需要考虑到动态不确定性，引入了基本的非线性和计算负担，这给分析和实际应用函数逼近提出了独特挑战。在基本设置下，提议最小化最优和计算高效的算法，实现函数逼近，并在鲁棒离线RL的背景下启动对实例相关次优性分析的研究。我们的结果揭示了鲁棒离线RL中的函数逼近本质上与标准离线RL中的函数逼近有明显区别，可能更加困难。我们的算法和理论结果至关重要地依赖于

    arXiv:2403.09621v1 Announce Type: cross  Abstract: Distributionally robust offline reinforcement learning (RL), which seeks robust policy training against environment perturbation by modeling dynamics uncertainty, calls for function approximations when facing large state-action spaces. However, the consideration of dynamics uncertainty introduces essential nonlinearity and computational burden, posing unique challenges for analyzing and practically employing function approximation. Focusing on a basic setting where the nominal model and perturbed models are linearly parameterized, we propose minimax optimal and computationally efficient algorithms realizing function approximation and initiate the study on instance-dependent suboptimality analysis in the context of robust offline RL. Our results uncover that function approximation in robust offline RL is essentially distinct from and probably harder than that in standard offline RL. Our algorithms and theoretical results crucially depen
    
[^2]: 通过谱扩散生成图形

    Graph Generation via Spectral Diffusion

    [https://arxiv.org/abs/2402.18974](https://arxiv.org/abs/2402.18974)

    提出了一种基于图拉普拉斯矩阵谱分解和扩散过程的新颖图生成模型GRASP，能够通过截断拉普拉斯频谱快速准确地捕捉图的结构特征，同时处理节点特征，避免了二次复杂性瓶颈。

    

    在本文中，我们提出了GRASP，一种基于图拉普拉斯矩阵的谱分解和扩散过程的新颖图生成模型。具体而言，我们提出使用去噪模型从中采样特征向量和特征值，从而可以重建图拉普拉斯矩阵和邻接矩阵。我们的置换不变模型还可以通过将节点特征连接到每个节点的特征向量来处理节点特征。使用拉普拉斯频谱使我们能够自然捕获图的结构特征，并直接在节点空间中工作，同时避免了限制其他方法适用性的二次复杂性瓶颈。通过截断谱，我们实现了更快但准确的生成过程，这在我们的实验中得到了证实。对合成和现实世界图形的大量实验显示了我们模型相对于最先进的模型的优势。

    arXiv:2402.18974v1 Announce Type: new  Abstract: In this paper, we present GRASP, a novel graph generative model based on 1) the spectral decomposition of the graph Laplacian matrix and 2) a diffusion process. Specifically, we propose to use a denoising model to sample eigenvectors and eigenvalues from which we can reconstruct the graph Laplacian and adjacency matrix. Our permutation invariant model can also handle node features by concatenating them to the eigenvectors of each node. Using the Laplacian spectrum allows us to naturally capture the structural characteristics of the graph and work directly in the node space while avoiding the quadratic complexity bottleneck that limits the applicability of other methods. This is achieved by truncating the spectrum, which as we show in our experiments results in a faster yet accurate generative process. An extensive set of experiments on both synthetic and real world graphs demonstrates the strengths of our model against state-of-the-art a
    
[^3]: AURA：自然语言推理中的模式合理性不确定性

    AURA: Natural Language Reasoning for Aleatoric Uncertainty in Rationales

    [https://arxiv.org/abs/2402.14337](https://arxiv.org/abs/2402.14337)

    提出了在自然语言推理中处理引发模式合理性不确定性的不完美理由的方法，实施了使用熵分数和模型先验信念来指导模型的策略，并在实证中展示了方法相对于敌对理由的稳健性能优势

    

    回策背后的理由不仅解释了模型决策，而且提升了语言模型在复杂推理任务上的推理能力。然而，获得无懈可击的理由通常是不可能的。此外，估计理由足够忠实以鼓励模型表现的程度并不是微不足道的。因此，这些推理任务通常迫使模型在不理想的理由下输出正确答案，并且与模型完全有能力的情况相比是次优的。在这项工作中，我们提出了如何应对引发模式合理性不确定性的不完美理由。我们首先用给定理由的熵分数来定义模糊的理由，使用模型先验信念作为信息量。然后根据理由的模糊性来引导模型选择两种不同的推理模型中的一种。我们在实证上论证了我们提出的方法相对于理由的敌对质量产生了稳健的性能优势。

    arXiv:2402.14337v1 Announce Type: new  Abstract: Rationales behind answers not only explain model decisions but boost language models to reason well on complex reasoning tasks. However, obtaining impeccable rationales is often impossible. Besides, it is non-trivial to estimate the degree to which the rationales are faithful enough to encourage model performance. Thus, such reasoning tasks often compel models to output correct answers under undesirable rationales and are sub-optimal compared to what the models are fully capable of. In this work, we propose how to deal with imperfect rationales causing aleatoric uncertainty. We first define the ambiguous rationales with entropy scores of given rationales, using model prior beliefs as informativeness. We then guide models to select one of two different reasoning models according to the ambiguity of rationales. We empirically argue that our proposed method produces robust performance superiority against the adversarial quality of rationale
    
[^4]: 浅层ReLU-like神经网络的损失景观：稳定点、鞍点逃逸和网络嵌入

    The Loss Landscape of Shallow ReLU-like Neural Networks: Stationary Points, Saddle Escaping, and Network Embedding

    [https://arxiv.org/abs/2402.05626](https://arxiv.org/abs/2402.05626)

    本文研究了使用ReLU-like激活函数以经验平方损失训练的单隐藏层神经网络的损失景观，提出了稳定点条件和逃逸神经元的定义，并将鞍点逃逸与逃逸神经元的参数变化联系起来。

    

    本文研究了使用ReLU-like激活函数以经验平方损失训练的单隐藏层神经网络的损失景观。由于激活函数是不可微的，目前还不清楚如何完全描述稳定点。我们提出了适用于非可微和可微情况的稳定点条件。此外，我们还展示了如果一个稳定点不包含“逃逸神经元”（通过一阶条件定义），那么它必定是一个局部最小值。此外，在标量输出情况下，逃逸神经元的存在保证了稳定点不是局部最小值。我们的结果进一步描述了从无穷小（消失）初始化开始的浅层ReLU-like网络的鞍点到鞍点的训练过程，直接将鞍点逃逸与逃逸神经元的参数变化联系起来。此外，我们还完全讨论了网络嵌入的方式。

    In this paper, we investigate the loss landscape of one-hidden-layer neural networks with ReLU-like activation functions trained with the empirical squared loss. As the activation function is non-differentiable, it is so far unclear how to completely characterize the stationary points. We propose the conditions for stationarity that apply to both non-differentiable and differentiable cases. Additionally, we show that, if a stationary point does not contain "escape neurons", which are defined with first-order conditions, then it must be a local minimum. Moreover, for the scalar-output case, the presence of an escape neuron guarantees that the stationary point is not a local minimum. Our results refine the description of the saddle-to-saddle training process starting from infinitesimally small (vanishing) initialization for shallow ReLU-like networks, linking saddle escaping directly with the parameter changes of escape neurons. Moreover, we are also able to fully discuss how network emb
    
[^5]: DiffTOP: 可微分轨迹优化在强化学习和模仿学习中的应用

    DiffTOP: Differentiable Trajectory Optimization for Deep Reinforcement and Imitation Learning

    [https://arxiv.org/abs/2402.05421](https://arxiv.org/abs/2402.05421)

    DiffTOP使用可微分轨迹优化作为策略表示来生成动作，解决了模型基于强化学习算法中的“目标不匹配”问题，并在模仿学习任务上进行了性能基准测试。

    

    本文介绍了DiffTOP，它利用可微分轨迹优化作为策略表示，为深度强化学习和模仿学习生成动作。轨迹优化是一种在控制领域中广泛使用的算法，由成本和动力学函数参数化。我们的方法的关键是利用了最近在可微分轨迹优化方面的进展，使得可以计算损失对于轨迹优化的参数的梯度。因此，轨迹优化的成本和动力学函数可以端到端地学习。DiffTOP解决了之前模型基于强化学习算法中的“目标不匹配”问题，因为DiffTOP中的动力学模型通过轨迹优化过程中的策略梯度损失直接最大化任务性能。我们还对DiffTOP在标准机器人操纵任务套件中进行了模仿学习性能基准测试。

    This paper introduces DiffTOP, which utilizes Differentiable Trajectory OPtimization as the policy representation to generate actions for deep reinforcement and imitation learning. Trajectory optimization is a powerful and widely used algorithm in control, parameterized by a cost and a dynamics function. The key to our approach is to leverage the recent progress in differentiable trajectory optimization, which enables computing the gradients of the loss with respect to the parameters of trajectory optimization. As a result, the cost and dynamics functions of trajectory optimization can be learned end-to-end. DiffTOP addresses the ``objective mismatch'' issue of prior model-based RL algorithms, as the dynamics model in DiffTOP is learned to directly maximize task performance by differentiating the policy gradient loss through the trajectory optimization process. We further benchmark DiffTOP for imitation learning on standard robotic manipulation task suites with high-dimensional sensory
    
[^6]: EAGLE: 推测采样需要重新思考特征不确定性

    EAGLE: Speculative Sampling Requires Rethinking Feature Uncertainty. (arXiv:2401.15077v1 [cs.LG])

    [http://arxiv.org/abs/2401.15077](http://arxiv.org/abs/2401.15077)

    EAGLE是一个无损加速语言模型推理的框架，通过在次顶层特征层面上自回归推理，并解决采样不确定性问题，实现了比传统方法更快3倍的速度。

    

    自回归解码使得大型语言模型（LLMs）的推理变得耗时。我们提出了一个简单的框架，EAGLE（用于提高语言模型效率的外推算法），实现了无损加速。与传统的推测采样方法不同，EAGLE在更规律的（次顶层）特征层面上自回归进行编写，并通过整合提前一个时间步的标记来解决下一个特征预测问题中的采样不确定性。EAGLE所提供的加速是无损的：它不需要微调目标LLM，并且生成的文本与原始的自回归解码的分布相同。截至本文提交时，EAGLE是已知推测采样家族中速度最快的框架。在MT-bench上，EAGLE比原始解码快3倍，比Lookahead快2倍，比Medusa快1.6倍。使用gpt-fast，EAGLE平均每秒达到160个标记与LLaMA2-Chat搭配。

    Auto-regressive decoding makes the inference of Large Language Models (LLMs) time-consuming. We propose a simple framework, EAGLE (Extrapolation Algorithm for Greater Language-model Efficiency), for lossless acceleration. Unlike traditional speculative sampling methods, EAGLE operates the drafting process auto-regressively at the more regular (second-top-layer) feature level and addresses the sampling uncertainty issues in the next-feature prediction problems by integrating tokens from one time step ahead. The acceleration provided by EAGLE is lossless: it involves no fine-tuning of the target LLM, and the generated text maintains the same distribution as that of vanilla auto-regressive decoding. As of the submission of this paper, EAGLE is the fastest known framework within the speculative sampling family. On MT-bench, EAGLE is 3x faster than vanilla decoding, 2x faster than Lookahead, and 1.6x faster than Medusa. Using gpt-fast, EAGLE attains on average 160 tokens/s with LLaMA2-Chat 
    
[^7]: Regret-Matching算法在游戏中的最终迭代收敛性质

    Last-Iterate Convergence Properties of Regret-Matching Algorithms in Games. (arXiv:2311.00676v1 [cs.GT])

    [http://arxiv.org/abs/2311.00676](http://arxiv.org/abs/2311.00676)

    这篇论文研究了基于遗憾匹配的算法在游戏中的最终迭代收敛性质。通过数值实验发现多个实际变体在简单的游戏中缺乏最终迭代收敛保证，而基于平滑技术的最近变体则具有最终迭代收敛性。

    

    基于遗憾匹配的算法，特别是遗憾匹配+ (RM+)及其变种，是解决大规模双人零和游戏的最流行方法。与具有零和游戏的强最终迭代和遍历收敛性质的算法（如乐观梯度上升）不同，我们对于遗憾匹配算法的最终迭代性质几乎一无所知。鉴于最终迭代收敛性对于数值优化和模拟现实世界中的游戏学习的重要性，本文研究了各种流行的RM+变体的最终迭代收敛性质。首先，我们通过数值实验证明，包括同时RM+、交替RM+和同时预测RM+在内的几个实际变体，甚至在简单的3x3游戏中也缺乏最终迭代收敛保证。然后，我们证明了这些算法的最近变体，基于平滑技术得到了最终迭代收敛性。

    Algorithms based on regret matching, specifically regret matching$^+$ (RM$^+$), and its variants are the most popular approaches for solving large-scale two-player zero-sum games in practice. Unlike algorithms such as optimistic gradient descent ascent, which have strong last-iterate and ergodic convergence properties for zero-sum games, virtually nothing is known about the last-iterate properties of regret-matching algorithms. Given the importance of last-iterate convergence for numerical optimization reasons and relevance as modeling real-word learning in games, in this paper, we study the last-iterate convergence properties of various popular variants of RM$^+$. First, we show numerically that several practical variants such as simultaneous RM$^+$, alternating RM$^+$, and simultaneous predictive RM$^+$, all lack last-iterate convergence guarantees even on a simple $3\times 3$ game. We then prove that recent variants of these algorithms based on a smoothing technique do enjoy last-it
    
[^8]: 最佳武器识别的最佳批处理算法

    Optimal Batched Best Arm Identification. (arXiv:2310.14129v1 [cs.LG])

    [http://arxiv.org/abs/2310.14129](http://arxiv.org/abs/2310.14129)

    本论文研究了最佳批处理武器识别问题，在渐近和非渐近设置中提出了Tri-BBAI和Opt-BBAI算法，分别实现了最优和几乎最优的样本和批处理复杂度。

    

    我们研究了最佳批处理武器识别（BBAI）问题，其中学习者的目标是在尽量少地更换策略的同时识别出最佳武器。具体而言，我们的目标是以概率$1-\delta$找到最佳武器，其中$\delta>0$是一个小常数，同时最小化样本复杂度（武器拉取的总数）和批处理复杂度（批处理的总数）。我们提出了三批次最佳武器识别（Tri-BBAI）算法，这是第一个在渐近设置（即$\delta\rightarrow0$）中实现最优样本复杂度且仅在最多三个批次中运行的批处理算法。基于Tri-BBAI，我们进一步提出了几乎最优的批处理最佳武器识别（Opt-BBAI）算法，在非渐近设置（即$\delta>0$是任意固定的）中实现近似最优的样本和批处理复杂度，同时在$\delta$趋于零时享受与Tri-BBAI相同的批处理和样本复杂度。

    We study the batched best arm identification (BBAI) problem, where the learner's goal is to identify the best arm while switching the policy as less as possible. In particular, we aim to find the best arm with probability $1-\delta$ for some small constant $\delta>0$ while minimizing both the sample complexity (total number of arm pulls) and the batch complexity (total number of batches). We propose the three-batch best arm identification (Tri-BBAI) algorithm, which is the first batched algorithm that achieves the optimal sample complexity in the asymptotic setting (i.e., $\delta\rightarrow 0$) and runs only in at most $3$ batches. Based on Tri-BBAI, we further propose the almost optimal batched best arm identification (Opt-BBAI) algorithm, which is the first algorithm that achieves the near-optimal sample and batch complexity in the non-asymptotic setting (i.e., $\delta>0$ is arbitrarily fixed), while enjoying the same batch and sample complexity as Tri-BBAI when $\delta$ tends to zer
    
[^9]: 一种统一的学习论证语义的框架

    A Unifying Framework for Learning Argumentation Semantics. (arXiv:2310.12309v1 [cs.AI])

    [http://arxiv.org/abs/2310.12309](http://arxiv.org/abs/2310.12309)

    本文提出了一种统一的框架来学习论证语义，通过使用可解释的方法，优于现有的论证求解器，并在形式论证和人机对话领域开辟了新的研究方向。

    

    论证是人工智能领域的一个非常活跃的研究领域，涉及到在人与人或人与人工智能代理之间的对话中所使用的论证的表示和评估。正式论证系统的可接受性语义定义了论证的接受或拒绝的标准。已经开发了一些称为论证求解器的软件系统，用于使用这些标准计算被接受/被拒绝的论证。其中一些系统通过使用不可解释的方法来学习识别接受的论证。在本文中，我们提出了一种新颖的框架，该框架采用归纳逻辑编程方法以可解释的方式来学习多个抽象和结构化论证框架的可接受性语义。通过实证评估，我们展示了我们的框架优于现有的论证求解器，从而开辟了形式论证和人机对话领域的新的未来研究方向。

    Argumentation is a very active research field of Artificial Intelligence concerned with the representation and evaluation of arguments used in dialogues between humans and/or artificial agents. Acceptability semantics of formal argumentation systems define the criteria for the acceptance or rejection of arguments. Several software systems, known as argumentation solvers, have been developed to compute the accepted/rejected arguments using such criteria. These include systems that learn to identify the accepted arguments using non-interpretable methods. In this paper we present a novel framework, which uses an Inductive Logic Programming approach to learn the acceptability semantics for several abstract and structured argumentation frameworks in an interpretable way. Through an empirical evaluation we show that our framework outperforms existing argumentation solvers, thus opening up new future research directions in the area of formal argumentation and human-machine dialogues.
    
[^10]: 通过基于分数的对抗图像生成评估鲁棒性

    Assessing Robustness via Score-Based Adversarial Image Generation. (arXiv:2310.04285v1 [cs.CV])

    [http://arxiv.org/abs/2310.04285](http://arxiv.org/abs/2310.04285)

    本论文介绍了一种基于分数的对抗生成框架（ScoreAG），可以生成超过$\ell_p$-范数约束的对抗性示例，并通过图像转换或新图像合成的方法保持图像的核心语义，大大增强了分类器的鲁棒性。

    

    大多数对抗攻击和防御都集中在小的$\ell_p$-范数约束内的扰动上。然而，$\ell_p$威胁模型无法捕捉到所有相关的保留语义的扰动，因此，鲁棒性评估的范围是有限的。在这项工作中，我们引入了基于分数的对抗生成（ScoreAG），一种利用基于分数的生成模型的进展来生成超过$\ell_p$-范数约束的对抗性示例的新的框架，称为无限制的对抗性示例，克服了它们的局限性。与传统方法不同，ScoreAG在生成逼真的对抗性示例时保持图像的核心语义，可以通过转换现有图像或完全从零开始合成新图像的方式实现。我们进一步利用ScoreAG的生成能力来净化图像，从经验上增强分类器的鲁棒性。我们的大量实证评估表明，ScoreAG与现有最先进的对抗攻击方法的性能相当。

    Most adversarial attacks and defenses focus on perturbations within small $\ell_p$-norm constraints. However, $\ell_p$ threat models cannot capture all relevant semantic-preserving perturbations, and hence, the scope of robustness evaluations is limited. In this work, we introduce Score-Based Adversarial Generation (ScoreAG), a novel framework that leverages the advancements in score-based generative models to generate adversarial examples beyond $\ell_p$-norm constraints, so-called unrestricted adversarial examples, overcoming their limitations. Unlike traditional methods, ScoreAG maintains the core semantics of images while generating realistic adversarial examples, either by transforming existing images or synthesizing new ones entirely from scratch. We further exploit the generative capability of ScoreAG to purify images, empirically enhancing the robustness of classifiers. Our extensive empirical evaluation demonstrates that ScoreAG matches the performance of state-of-the-art atta
    
[^11]: 通过自主量子热机实现热力学计算

    Thermodynamic Computing via Autonomous Quantum Thermal Machines. (arXiv:2308.15905v1 [quant-ph])

    [http://arxiv.org/abs/2308.15905](http://arxiv.org/abs/2308.15905)

    通过自主量子热机实现了热力学计算模型。通过热流进行计算，可实现任何线性可分离函数，并可扩展到神经元网络执行任何 needed功能。

    

    我们基于自主量子热机开发了一个基于物理的模型，用于经典计算。这些机器由少数相互作用的量子位（qubits）与不同温度的几个环境相连。通过机器的热流进行计算。过程从根据逻辑输入设定环境温度开始。机器演化，最终达到非平衡稳态，通过辅助有限尺寸储存池的温度可以确定计算结果。这样的机器，我们称之为“热力学神经元”，可以实现任何线性可分离函数，我们明确讨论了NOT，3-majority和NOR门的情况。反过来，我们展示了热力学神经元网络可以执行任何需要的函数。我们讨论了我们的模型与人工神经元（感知器）之间的密切关系，并认为我们的模型提供了一种基于物理的替代方法。

    We develop a physics-based model for classical computation based on autonomous quantum thermal machines. These machines consist of few interacting quantum bits (qubits) connected to several environments at different temperatures. Heat flows through the machine are here exploited for computing. The process starts by setting the temperatures of the environments according to the logical input. The machine evolves, eventually reaching a non-equilibrium steady state, from which the output of the computation can be determined via the temperature of an auxilliary finite-size reservoir. Such a machine, which we term a "thermodynamic neuron", can implement any linearly-separable function, and we discuss explicitly the cases of NOT, 3-majority and NOR gates. In turn, we show that a network of thermodynamic neurons can perform any desired function. We discuss the close connection between our model and artificial neurons (perceptrons), and argue that our model provides an alternative physics-based
    
[^12]: HoSNN: 具有自适应发放阈值的对抗性稳态脉冲神经网络

    HoSNN: Adversarially-Robust Homeostatic Spiking Neural Networks with Adaptive Firing Thresholds. (arXiv:2308.10373v2 [cs.NE] UPDATED)

    [http://arxiv.org/abs/2308.10373](http://arxiv.org/abs/2308.10373)

    HoSNN是一种对抗性稳态脉冲神经网络，通过采用自适应发放阈值的渗漏整合与发放（TA-LIF）神经元模型来抵御对抗攻击，并在无监督的方式下保护其鲁棒性。

    

    脉冲神经网络（SNNs）在高效和强大的神经启发式计算方面具有潜力。然而，与其他类型的神经网络一样，SNNs面临着对抗攻击的严重问题。我们提出了第一个从神经恒稳性中汲取灵感的研究，以开发一种仿生解决方案，来应对SNNs对对抗性攻击的敏感性。我们的方法的核心是一种新颖的自适应发放阈值的渗漏整合与发放（TA-LIF）神经元模型，我们采用它来构建所提出的对抗性稳态SNN（HoSNN）。与传统的LIF模型不同，我们的TA-LIF模型融入了自稳定动态阈值机制，限制对抗性噪声的传播，并以无监督的方式保护HoSNN的鲁棒性。我们还提出了理论分析，以阐明TA-LIF神经元的稳定性和收敛性，强调它们在输入多样性方面的卓越动态鲁棒性。

    Spiking neural networks (SNNs) offer promise for efficient and powerful neurally inspired computation. Common to other types of neural networks, however, SNNs face the severe issue of vulnerability to adversarial attacks. We present the first study that draws inspiration from neural homeostasis to develop a bio-inspired solution that counters the susceptibilities of SNNs to adversarial onslaughts. At the heart of our approach is a novel threshold-adapting leaky integrate-and-fire (TA-LIF) neuron model, which we adopt to construct the proposed adversarially robust homeostatic SNN (HoSNN). Distinct from traditional LIF models, our TA-LIF model incorporates a self-stabilizing dynamic thresholding mechanism, curtailing adversarial noise propagation and safeguarding the robustness of HoSNNs in an unsupervised manner. Theoretical analysis is presented to shed light on the stability and convergence properties of the TA-LIF neurons, underscoring their superior dynamic robustness under input di
    
[^13]: 多尺度聚类过滤中的持久同调

    Persistent Homology of the Multiscale Clustering Filtration. (arXiv:2305.04281v2 [math.AT] UPDATED)

    [http://arxiv.org/abs/2305.04281](http://arxiv.org/abs/2305.04281)

    该论文引入了一种多尺度聚类过滤方法（MCF），用于描述不同尺度下的数据聚类，其中的持久同调可测量分区序列的层次关系和聚类分配冲突的出现和解决。

    

    在许多数据聚类应用中，不仅希望找到一种单一的分区方式，还希望找到描述不同尺度或粗糙层次下的数据的一系列分区方式。因此，一个自然的问题是分析和比较支撑这种多尺度数据描述的（不一定是层次性的）分区序列。在这里，我们引入了一种抽象单纯复形的过滤，称为多尺度聚类过滤（MCF），它编码了跨尺度的任意模式的聚类分配，并证明了MCF产生稳定的持久图。然后，我们展示了MCF的零维持久同调测量了分区序列中的层次关系程度，而高维持久同调则跟踪了分区序列中聚类分配冲突的出现和解决。为了拓宽MCF的理论基础，我们还提供了一个等价的构造方法。

    In many applications in data clustering, it is desirable to find not just a single partition into clusters but a sequence of partitions describing the data at different scales, or levels of coarseness. A natural problem then is to analyse and compare the (not necessarily hierarchical) sequences of partitions that underpin such multiscale descriptions of data. Here, we introduce a filtration of abstract simplicial complexes, denoted the Multiscale Clustering Filtration (MCF), which encodes arbitrary patterns of cluster assignments across scales, and we prove that the MCF produces stable persistence diagrams. We then show that the zero-dimensional persistent homology of the MCF measures the degree of hierarchy in the sequence of partitions, and that the higher-dimensional persistent homology tracks the emergence and resolution of conflicts between cluster assignments across the sequence of partitions. To broaden the theoretical foundations of the MCF, we also provide an equivalent constr
    
[^14]: 基于图的去中心化对抗性训练

    Decentralized Adversarial Training over Graphs. (arXiv:2303.13326v1 [cs.LG])

    [http://arxiv.org/abs/2303.13326](http://arxiv.org/abs/2303.13326)

    本文研究了在图上的去中心化对抗性训练，利用扩散学习的方法，开发了一种对抗性训练框架，增强了多个代理的鲁棒性以对抗攻击。

    

    近年来，机器学习模型对抗攻击的漏洞引起了广泛关注。大多数现有研究都集中在独立单一代理学习者的行为上。相比之下，本文研究了在图上的对抗性训练，其中各个单独的代理会受到空间中不同强度的扰动。预期通过链接代理和可能在图上实现的攻击模型的异质性，协调整个团队的强大协同作用可以帮助增强鲁棒性。本文使用扩散学习的极小-极大公式，为多代理系统开发了一种去中心化的对抗性训练框架。我们分析了该方案在凸和非凸环境下的收敛特性，并说明了增强的鲁棒性对抗攻击。

    The vulnerability of machine learning models to adversarial attacks has been attracting considerable attention in recent years. Most existing studies focus on the behavior of stand-alone single-agent learners. In comparison, this work studies adversarial training over graphs, where individual agents are subjected to perturbations of varied strength levels across space. It is expected that interactions by linked agents, and the heterogeneity of the attack models that are possible over the graph, can help enhance robustness in view of the coordination power of the group. Using a min-max formulation of diffusion learning, we develop a decentralized adversarial training framework for multi-agent systems. We analyze the convergence properties of the proposed scheme for both convex and non-convex environments, and illustrate the enhanced robustness to adversarial attacks.
    
[^15]: 对知识图谱进行逻辑查询应答的关系模式建模

    Modeling Relational Patterns for Logical Query Answering over Knowledge Graphs. (arXiv:2303.11858v1 [cs.DB])

    [http://arxiv.org/abs/2303.11858](http://arxiv.org/abs/2303.11858)

    本文介绍了一种新的查询嵌入方法RoConE，它允许学习关系模式并提高了逻辑查询推理的性能。

    

    对知识图谱（KG）进行一阶逻辑（FOL）查询的回答仍然是一项具有挑战性的任务，主要是由于KG不完整性而导致的。查询嵌入方法通过计算实体、关系和逻辑查询的低维度向量表示来解决这个问题。KG表现出对称性和组合性等关系模式，建模这些模式可以进一步提高查询嵌入模型的性能。然而，这些模式在查询嵌入模型中的作用尚未在文献中进行研究。在本文中，我们填补了这一研究空白，并通过引入允许学习关系模式的归纳偏差，加强FOL查询推理的模式推理能力。为此，我们开发了一种新的查询嵌入方法RoConE，它将查询区域定义为几何锥体，并通过在复杂空间中旋转代数查询算子。RoConE结合了几何锥体作为可以明确定义查询表示的几何表示和旋转代数查询算子的优势。

    Answering first-order logical (FOL) queries over knowledge graphs (KG) remains a challenging task mainly due to KG incompleteness. Query embedding approaches this problem by computing the low-dimensional vector representations of entities, relations, and logical queries. KGs exhibit relational patterns such as symmetry and composition and modeling the patterns can further enhance the performance of query embedding models. However, the role of such patterns in answering FOL queries by query embedding models has not been yet studied in the literature. In this paper, we fill in this research gap and empower FOL queries reasoning with pattern inference by introducing an inductive bias that allows for learning relation patterns. To this end, we develop a novel query embedding method, RoConE, that defines query regions as geometric cones and algebraic query operators by rotations in complex space. RoConE combines the advantages of Cone as a well-specified geometric representation for query e
    
[^16]: MIXRTs:通过混合循环软决策树实现可解释的多智能体强化学习

    MIXRTs: Toward Interpretable Multi-Agent Reinforcement Learning via Mixing Recurrent Soft Decision Trees. (arXiv:2209.07225v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2209.07225](http://arxiv.org/abs/2209.07225)

    MIXRTs是一种可解释的多智能体强化学习架构，通过混合循环软决策树的方式，能够表达明确的决策过程并展示每个智能体的贡献。

    

    在各个领域取得巨大成功的同时，现有的具有黑盒神经网络结构的多智能体强化学习（MARL）以不透明的方式做出决策，阻碍了人们理解学习到的知识以及输入观测如何影响决策。与此相反，现有的可解释方法，如传统的线性模型和决策树，往往在表达能力和准确性方面存在问题。为了解决性能和解释性之间的明显二元对立，我们提出了一种新颖的可解释结构——混合循环软决策树（MIXRTs），它能够通过从根节点到叶节点的路径表示明确的决策过程，并反映每个智能体对团队的贡献。具体而言，我们构建了一种新颖的软决策树来解决局部可观察性问题，利用循环神经网络的进展，并通过基于树的模型展示哪些特征影响决策过程。

    While achieving tremendous success in various fields, existing multi-agent reinforcement learning (MARL) with a black-box neural network architecture makes decisions in an opaque manner that hinders humans from understanding the learned knowledge and how input observations influence decisions. Instead, existing interpretable approaches, such as traditional linear models and decision trees, usually suffer from weak expressivity and low accuracy. To address this apparent dichotomy between performance and interpretability, our solution, MIXing Recurrent soft decision Trees (MIXRTs), is a novel interpretable architecture that can represent explicit decision processes via the root-to-leaf path and reflect each agent's contribution to the team. Specifically, we construct a novel soft decision tree to address partial observability by leveraging the advances in recurrent neural networks, and demonstrate which features influence the decision-making process through the tree-based model. Then, ba
    
[^17]: 量化方法的比较评估

    A Comparative Evaluation of Quantification Methods. (arXiv:2103.03223v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2103.03223](http://arxiv.org/abs/2103.03223)

    本研究通过对24种不同量化方法在超过40个数据集上进行全面实证比较，填补了量化方法比较研究的空白。我们发现在二分类设置中，基于阈值选择的Median Sweep和TSMax方法、DyS框架和弗里德曼的方法表现最佳；而在多分类设置中，Generaliz方法表现良好。

    

    量化是指在数据集中预测类别分布的问题。它也代表着一个在监督式机器学习中不断发展的研究领域，近年来提出了大量不同的算法。然而，目前还没有一份全面的实证比较量化方法的研究，以支持算法选择。在本研究中，我们通过对超过40个数据集进行了24种不同量化方法的彻底实证性性能比较，包括二分类和多分类量化设置，填补了这一研究空白。我们观察到没有单一算法能够在所有竞争对手中始终表现最佳，但我们确定了一组在二分类设置中表现最佳的方法，包括基于阈值选择的Median Sweep和TSMax方法、DyS框架和弗里德曼的方法。对于多分类设置，我们观察到另一组算法表现良好，包括Generaliz方法。

    Quantification represents the problem of predicting class distributions in a dataset. It also represents a growing research field in supervised machine learning, for which a large variety of different algorithms has been proposed in recent years. However, a comprehensive empirical comparison of quantification methods that supports algorithm selection is not available yet. In this work, we close this research gap by conducting a thorough empirical performance comparison of 24 different quantification methods on overall more than 40 data sets, considering binary as well as multiclass quantification settings. We observe that no single algorithm generally outperforms all competitors, but identify a group of methods including the threshold selection-based Median Sweep and TSMax methods, the DyS framework, and Friedman's method that performs best in the binary setting. For the multiclass setting, we observe that a different group of algorithms yields good performance, including the Generaliz
    

