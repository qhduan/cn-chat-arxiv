# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Zero-Shot Machine Unlearning at Scale via Lipschitz Regularization](https://rss.arxiv.org/abs/2402.01401) | 通过Lipschitz正则化实现零样本机器遗忘，可以及时忘记私人或受版权保护的信息，同时保持模型性能。 |
| [^2] | [QFNN-FFD: Quantum Federated Neural Network for Financial Fraud Detection](https://arxiv.org/abs/2404.02595) | 介绍了将量子机器学习和量子计算技术与联邦学习相结合的Quantum Federated Neural Network for Financial Fraud Detection (QFNN-FFD)框架，提出了一种安全、高效的欺诈交易识别方法，显著改进了欺诈检测并确保了数据机密性。 |
| [^3] | [A Statistical Framework of Watermarks for Large Language Models: Pivot, Detection Efficiency and Optimal Rules](https://arxiv.org/abs/2404.01245) | 该论文提出了一个通用框架，用于设计大型语言模型水印的统计效率和检测规则，通过关键统计量和秘密密钥控制误报率，同时评估水印检测规则的能力。 |
| [^4] | [Inferring Latent Temporal Sparse Coordination Graph for Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2403.19253) | 提出了一种用于多智能体强化学习的潜在时间稀疏协调图，能够有效处理智能体之间的协作关系并利用历史观测来进行知识交换 |
| [^5] | [Dual-Personalizing Adapter for Federated Foundation Models](https://arxiv.org/abs/2403.19211) | 提出了一种新的设置，称为测试时间个性化，不仅关注目标本地任务，还延伸到其他展示测试时间个性化的任务 |
| [^6] | [Decoupled Vertical Federated Learning for Practical Training on Vertically Partitioned Data](https://arxiv.org/abs/2403.03871) | 提出了Decoupled VFL（DVFL），一种面向VFL的分段学习方法，实现了分散聚合和隔离，从而提高了容错性。 |
| [^7] | [Quantum Mixed-State Self-Attention Network](https://arxiv.org/abs/2403.02871) | 本论文介绍了一种新颖的量子混合态自注意力网络（QMSAN），结合了量子计算原理和经典机器学习算法，特别是自注意力网络，以增强处理NLP任务的效率和效果。 |
| [^8] | [2D Matryoshka Sentence Embeddings](https://arxiv.org/abs/2402.14776) | Matryoshka表示学习(MRL)以更细粒度地编码信息，以适应临时任务，同时实现了更小的嵌入大小，从而加快了下游任务的速度。 |
| [^9] | [The Edge-of-Reach Problem in Offline Model-Based Reinforcement Learning](https://arxiv.org/abs/2402.12527) | 学习的动力学模型被真实且无误差的动力学替代时，现有模型驱动方法将会完全失败，揭示出一个重大误解。 |
| [^10] | [Stochastic Hessian Fitting on Lie Group](https://arxiv.org/abs/2402.11858) | 本文研究了在随机Hessian-向量乘积上拟合Hessian或其逆，揭示了不同Hessian拟合方法的收敛速率，并证明了在特定李群上的Hessian拟合问题在轻微条件下是强凸的。 |
| [^11] | [Preserving Data Privacy for ML-driven Applications in Open Radio Access Networks](https://arxiv.org/abs/2402.09710) | 本文研究了在5G开放无线接入网络（O-RAN）中共享数据库场景下的数据隐私问题，并提出了一种基于洗牌的可学习加密技术来保护机器学习模型的数据隐私。 |
| [^12] | [DoorINet: A Deep-Learning Inertial Framework for Door-Mounted IoT Applications](https://arxiv.org/abs/2402.09427) | DoorINet是一种用于门贴式物联网应用的深度学习惯性框架，无需使用磁力计即可计算航向角度。 |
| [^13] | [Correction to "Wasserstein distance estimates for the distributions of numerical approximations to ergodic stochastic differential equations"](https://arxiv.org/abs/2402.08711) | 修正了《对于数值逼近遍历SDE的分布的Wasserstein距离估计》中的错误局部误差估计，提出了一种方法来分析数值离散遍历SDE的Wasserstein-2距离的非渐近保证，并解决了实践中维度依赖性的问题。 |
| [^14] | [Two Tales of Single-Phase Contrastive Hebbian Learning](https://arxiv.org/abs/2402.08573) | 两种单相对比海比安学习的故事探索了学习算法的生物合理性，并提出了一种全局学习算法，能够消除与反向传播之间的性能差距，并解决了同步和无限小扰动带来的问题。 |
| [^15] | [Differentially Private Zeroth-Order Methods for Scalable Large Language Model Finetuning](https://arxiv.org/abs/2402.07818) | 本文研究了差分隐私零阶方法在大型语言模型微调中的应用，该方法通过使用零阶梯度来避免传统优化方法的可扩展性瓶颈，实现了在隐私、效用和可扩展性之间的良好平衡。 |
| [^16] | [PoCo: Policy Composition from and for Heterogeneous Robot Learning](https://arxiv.org/abs/2402.02511) | PoCo是一种策略组合方法，通过组合不同模态和领域的数据分布，实现了从异构数据中训练通用机器人策略的目标。该方法可以实现场景级和任务级的广义操作技能学习，并在推理时通过任务级组合和分析成本函数进行策略行为的自适应调整。 |
| [^17] | [GLaPE: Gold Label-agnostic Prompt Evaluation and Optimization for Large Language Model](https://arxiv.org/abs/2402.02408) | GLaPE提出了一种无依赖于金标签的提示评估方法，通过自一致性作为初始评估分数，进一步改进了产生相同答案的提示的得分的互相一致性，提供了与准确性相一致的可靠评估，即使在没有金标签的情况下。 |
| [^18] | [Neural Scaling Laws on Graphs](https://arxiv.org/abs/2402.02054) | 本论文在图上深入研究了神经缩放定律，从模型和数据两个角度进行了探索。对于模型缩放，发现了缩放定律崩溃和过拟合之间的关系，以及深度图模型的模型深度对缩放行为的影响。对于数据缩放，提出了图数量不适合作为衡量缩放定律中图数据量的指标。 |
| [^19] | [Topology-Based Reconstruction Prevention for Decentralised Learning](https://arxiv.org/abs/2312.05248) | 通过研究发现，在去中心化学习中，被动的好奇敌手可以在几次保护隐私的求和操作后推断出其他用户的私人数据。 |
| [^20] | [A Proactive and Dual Prevention Mechanism against Illegal Song Covers empowered by Singing Voice Conversion.](http://arxiv.org/abs/2401.17133) | 这项工作提出了一种主动性的双重防护机制，通过引入人类无法察觉的扰动，干扰歌唱声音转换的生成过程，防止未经授权的基于歌唱声音转换的非法歌曲翻唱。该机制既扰乱了歌手身份，又扰乱了歌词，使得歌唱声音既不模仿目标歌手，也不保留原始歌词。 |
| [^21] | [Discovering group dynamics in synchronous time series via hierarchical recurrent switching-state models.](http://arxiv.org/abs/2401.14973) | 通过分层的循环切换状态模型，我们可以无监督地同时解释系统级和个体级的动态，从而更好地建模同步时间序列中的群体动态。 |
| [^22] | [Binary Feature Mask Optimization for Feature Selection.](http://arxiv.org/abs/2401.12644) | 这个论文提出了一种新颖的特征选择框架，通过使用特征屏蔽方法来消除特征，而不是从数据集中移除它们。这种方法不需要重新训练机器学习模型，可以综合考虑特征子集的重要性，为通用机器学习模型的特征选择问题提供了一种新的解决方案。 |
| [^23] | [Provably Scalable Black-Box Variational Inference with Structured Variational Families.](http://arxiv.org/abs/2401.10989) | 本文研究了均值场变分族和满秩变分族之间的理论中间地带：结构化变分族，并通过理论证明结构化变分族可以在迭代复杂性上表现更好，缩放效果更好。 |
| [^24] | [Physics-constrained convolutional neural networks for inverse problems in spatiotemporal partial differential equations.](http://arxiv.org/abs/2401.10306) | 本研究提出了一种物理约束卷积神经网络（PC-CNN），用于解决非线性且时空变化的偏微分方程中的两种反问题。该网络可以揭示受偏差影响的真实状态，并在给定稀疏信息的情况下以高分辨率重建解。 |
| [^25] | [Uncertainty Quantification on Clinical Trial Outcome Prediction.](http://arxiv.org/abs/2401.03482) | 本研究将不确定性量化方法应用于临床试验结果预测，提高模型对微妙差异的识别能力，从而改善其整体性能。 |
| [^26] | [Calibration Attack: A Framework For Adversarial Attacks Targeting Calibration.](http://arxiv.org/abs/2401.02718) | 校准攻击是一种新的对抗攻击框架，通过生成和组织攻击来使受害模型失去准确校准，而不影响其原始准确性。这对模型的可信度和基于置信分数的决策构成严重威胁。我们提出了四种校准攻击形式，并对常用的对抗防御和校准方法的有效性进行了研究。 |
| [^27] | [A Foundation Graph Model.](http://arxiv.org/abs/2311.03976) | 本文提出了一个基于对抗性对比学习的基础图模型FoToM，该模型通过节点和边特征排除进行图预训练，在多个领域上实现了正向迁移，并取得了显著的性能提升。 |
| [^28] | [Batch Calibration: Rethinking Calibration for In-Context Learning and Prompt Engineering.](http://arxiv.org/abs/2309.17249) | 本研究提出了一种名为批量校准（BC）的方法，用于解决大型语言模型中提示脆弱性和偏见因素导致的性能下降问题。BC通过控制批量输入的上下文偏见，统一了现有的校准方法，并具有零-shot和仅推理的特点。 |
| [^29] | [Methods for generating and evaluating synthetic longitudinal patient data: a systematic review.](http://arxiv.org/abs/2309.12380) | 本文对生成和评估合成纵向患者数据的方法进行了系统综述，以解决医学领域中数据使用和隐私保护的问题。 |
| [^30] | [Cross-Image Context Matters for Bongard Problems.](http://arxiv.org/abs/2309.03468) | Bongard问题是一种需要从一组正负图像中推导出抽象概念并进行分类的智力测试，现有方法在Bongard问题中准确率较低。本研究发现，这是因为现有方法未能整合支持集合中的信息，而是仅依赖于单个支持图像的信息。我们提出了一种通过跨图像上下文来提高准确性的解决方案。 |
| [^31] | [MM-Vet: Evaluating Large Multimodal Models for Integrated Capabilities.](http://arxiv.org/abs/2308.02490) | MM-Vet是一个评估标准，用于评估大型多模态模型在复杂任务上的综合能力。该标准解决了如何结构化和评估复杂多模态任务、设计适用于不同问题和回答类型的评估指标以及如何提供模型洞察的问题。通过整合不同的核心视觉-语言能力，MM-Vet展示了有趣的能力和解决复杂任务的方法。 |
| [^32] | [Learning from Invalid Data: On Constraint Satisfaction in Generative Models.](http://arxiv.org/abs/2306.15166) | 本论文提出了一种新的训练机制，利用包含无效数据点的数据集进行生成模型的训练，以提高生成结果的精度和满足约束条件的能力。实验证明，与只使用有效数据点进行训练的标准模型相比，基于无效数据训练的模型明显优于标准模型。 |
| [^33] | [On Architectural Compression of Text-to-Image Diffusion Models.](http://arxiv.org/abs/2305.15798) | 本文研究了如何通过架构压缩方法实现文本到图像生成模型的高效化，提出了一种块删除知识提取SDMs（BK-SDMs）方法，在减少采样步骤数量和利用网络量化的同时，可以显著减少模型的参数数量、MAC和延迟，最终实现了与使用更多资源训练的模型相竞争的效果。 |
| [^34] | [Localisation of Regularised and Multiview Support Vector Machine Learning.](http://arxiv.org/abs/2304.05655) | 本文针对正则化和多视角支持向量机学习问题的本地化版本，证明了一些表示定理，研究了与损失函数和输入空间维度相关的特殊情况，特别是损失函数为 Gâteaux 可微函数时的情况。 |
| [^35] | [A Block Coordinate Descent Method for Nonsmooth Composite Optimization under Orthogonality Constraints.](http://arxiv.org/abs/2304.03641) | 本文提出了一种新的块坐标下降方法OBCD，用于解决具有正交约束的一般非光滑组合问题。 OBCD是一种可行的方法，具有低的计算复杂性，并且获得严格的收敛保证。 |
| [^36] | [A Byzantine-Resilient Aggregation Scheme for Federated Learning via Matrix Autoregression on Client Updates.](http://arxiv.org/abs/2303.16668) | 本文提出了FLANDERS，一种基于矩阵自回归的联邦学习聚合方案，可以识别恶意客户端，并提供了强大的拜占庭攻击防御。 |
| [^37] | [Disentangling the Link Between Image Statistics and Human Perception.](http://arxiv.org/abs/2303.09874) | 本研究直接评估自然图像的概率，并分析它如何影响人类感知。通过展示具有更丰富统计特征的自然图像被感知为具有更大的显着性，论文提供了直接支持Barlow和Attneave理论的证据，并建立了一个新的框架，用于理解图像统计与知觉之间的关系。 |
| [^38] | [Rotation Invariant Quantization for Model Compression.](http://arxiv.org/abs/2303.03106) | 本研究提出了一种旋转不变量量化（RIQ）技术，可以在不同层次上实现混合精度量化，用于后训练神经网络模型压缩，并证明了其在压缩方面的优势。在多种模型和任务上进行了严格评估，取得了令人满意的结果。 |
| [^39] | [A Lower Bound and a Near-Optimal Algorithm for Bilevel Empirical Risk Minimization.](http://arxiv.org/abs/2302.08766) | 该论文提出了一种双层经验风险最小化算法，使用的梯度计算次数 $O((n+m)^{\frac{1}{2}}\varepsilon^{-1})$，在样本复杂度方面是最优的。 |
| [^40] | [Recurrences reveal shared causal drivers of complex time series.](http://arxiv.org/abs/2301.13516) | 该研究开发了一种新的无监督学习算法，能够使用时间序列测量中的复现逐渐重构未被观察到的驱动信号，从而可靠地推断共享因果驱动者，其已在多个示例中进行验证。 |

# 详细

[^1]: 通过Lipschitz正则化在规模上实现零样本机器遗忘

    Zero-Shot Machine Unlearning at Scale via Lipschitz Regularization

    [https://rss.arxiv.org/abs/2402.01401](https://rss.arxiv.org/abs/2402.01401)

    通过Lipschitz正则化实现零样本机器遗忘，可以及时忘记私人或受版权保护的信息，同时保持模型性能。

    

    为了遵守人工智能和数据规定，从训练得到的机器学习模型中遗忘私人或受版权保护的信息的需求变得越来越重要。遗忘的关键挑战是及时忘记必要的数据，同时保持模型性能。在这项工作中，我们解决了零样本遗忘的场景，即只有一个经过训练的模型和要遗忘的数据，遗忘算法必须能够移除数据。根据这样定义，现有的最先进的方法是不够的。基于Lipschitz连续性的概念，我们提出了一种方法，通过对样本扰动的输出进行平滑处理来诱导遗忘。我们展示了这种平滑性成功地实现了遗忘，同时保持了总体模型性能。我们对我们的方法进行了广泛的经验评估，包括一系列当代基准测试，验证了我们的方法在严格的零样本约束下达到了最先进的性能。

    To comply with AI and data regulations, the need to forget private or copyrighted information from trained machine learning models is increasingly important. The key challenge in unlearning is forgetting the necessary data in a timely manner, while preserving model performance. In this work, we address the zero-shot unlearning scenario, whereby an unlearning algorithm must be able to remove data given only a trained model and the data to be forgotten. Under such a definition, existing state-of-the-art methods are insufficient. Building on the concepts of Lipschitz continuity, we present a method that induces smoothing of the forget sample's output, with respect to perturbations of that sample. We show this smoothing successfully results in forgetting while preserving general model performance. We perform extensive empirical evaluation of our method over a range of contemporary benchmarks, verifying that our method achieves state-of-the-art performance under the strict constraints of ze
    
[^2]: QFNN-FFD：用于金融欺诈检测的量子联邦神经网络

    QFNN-FFD: Quantum Federated Neural Network for Financial Fraud Detection

    [https://arxiv.org/abs/2404.02595](https://arxiv.org/abs/2404.02595)

    介绍了将量子机器学习和量子计算技术与联邦学习相结合的Quantum Federated Neural Network for Financial Fraud Detection (QFNN-FFD)框架，提出了一种安全、高效的欺诈交易识别方法，显著改进了欺诈检测并确保了数据机密性。

    

    这项研究介绍了Quantum Federated Neural Network for Financial Fraud Detection (QFNN-FFD)，这是一个融合了量子机器学习（QML）和量子计算技术与联邦学习（FL）的前沿框架，用于创新金融欺诈检测。利用量子技术的计算能力和FL的数据隐私，QFNN-FFD提出了一种安全、高效的识别欺诈交易的方法。在分布式客户端实施双阶段训练模型超越了现有的性能方法。QFNN-FFD显著改进了欺诈检测并确保了数据机密性，标志着金融科技解决方案的重大进步，并为以隐私为重点的欺诈检测建立了新标准。

    arXiv:2404.02595v1 Announce Type: cross  Abstract: This study introduces the Quantum Federated Neural Network for Financial Fraud Detection (QFNN-FFD), a cutting-edge framework merging Quantum Machine Learning (QML) and quantum computing with Federated Learning (FL) to innovate financial fraud detection. Using quantum technologies' computational power and FL's data privacy, QFNN-FFD presents a secure, efficient method for identifying fraudulent transactions. Implementing a dual-phase training model across distributed clients surpasses existing methods in performance. QFNN-FFD significantly improves fraud detection and ensures data confidentiality, marking a significant advancement in fintech solutions and establishing a new standard for privacy-focused fraud detection.
    
[^3]: 大型语言模型水印的统计框架: 枢轴、检测效率和最优规则

    A Statistical Framework of Watermarks for Large Language Models: Pivot, Detection Efficiency and Optimal Rules

    [https://arxiv.org/abs/2404.01245](https://arxiv.org/abs/2404.01245)

    该论文提出了一个通用框架，用于设计大型语言模型水印的统计效率和检测规则，通过关键统计量和秘密密钥控制误报率，同时评估水印检测规则的能力。

    

    自ChatGPT于2022年11月推出以来，将几乎不可察觉的统计信号嵌入到大型语言模型（LLMs）生成的文本中，也被称为水印，已被用作从其人类撰写对应物上可证检测LLM生成文本的原则性方法。 本文介绍了一个通用灵活的框架，用于推理水印的统计效率并设计强大的检测规则。受水印检测的假设检验公式启发，我们的框架首先选择文本的枢轴统计量和由LLM提供给验证器的秘密密钥，以实现控制误报率（将人类撰写的文本错误地检测为LLM生成的错误）。 接下来，该框架允许通过获取渐近错误负率（将LLM生成文本错误地检测为人类撰写的错误）的封闭形式表达式来评估水印检测规则的能力。

    arXiv:2404.01245v1 Announce Type: cross  Abstract: Since ChatGPT was introduced in November 2022, embedding (nearly) unnoticeable statistical signals into text generated by large language models (LLMs), also known as watermarking, has been used as a principled approach to provable detection of LLM-generated text from its human-written counterpart. In this paper, we introduce a general and flexible framework for reasoning about the statistical efficiency of watermarks and designing powerful detection rules. Inspired by the hypothesis testing formulation of watermark detection, our framework starts by selecting a pivotal statistic of the text and a secret key -- provided by the LLM to the verifier -- to enable controlling the false positive rate (the error of mistakenly detecting human-written text as LLM-generated). Next, this framework allows one to evaluate the power of watermark detection rules by obtaining a closed-form expression of the asymptotic false negative rate (the error of 
    
[^4]: 推断多智能体强化学习的潜在时间稀疏协调图

    Inferring Latent Temporal Sparse Coordination Graph for Multi-Agent Reinforcement Learning

    [https://arxiv.org/abs/2403.19253](https://arxiv.org/abs/2403.19253)

    提出了一种用于多智能体强化学习的潜在时间稀疏协调图，能够有效处理智能体之间的协作关系并利用历史观测来进行知识交换

    

    有效的智能体协调对于合作式多智能体强化学习(MARL)至关重要。当前MARL中的图学习方法局限性较大，仅仅依赖一步观察，忽略了重要的历史经验，导致生成的图存在缺陷，促进了冗余或有害信息交换。为了解决这些挑战，我们提出了推断用于MARL的潜在时间稀疏协调图（LTS-CG）。LTS-CG利用智能体的历史观测来计算智能体对概率矩阵，从中抽取稀疏图并用于智能体之间的知识交换，从而同时捕捉智能体的依赖关系和关系不确定性。该过程的计算复杂性仅与智能

    arXiv:2403.19253v1 Announce Type: new  Abstract: Effective agent coordination is crucial in cooperative Multi-Agent Reinforcement Learning (MARL). While agent cooperation can be represented by graph structures, prevailing graph learning methods in MARL are limited. They rely solely on one-step observations, neglecting crucial historical experiences, leading to deficient graphs that foster redundant or detrimental information exchanges. Additionally, high computational demands for action-pair calculations in dense graphs impede scalability. To address these challenges, we propose inferring a Latent Temporal Sparse Coordination Graph (LTS-CG) for MARL. The LTS-CG leverages agents' historical observations to calculate an agent-pair probability matrix, where a sparse graph is sampled from and used for knowledge exchange between agents, thereby simultaneously capturing agent dependencies and relation uncertainty. The computational complexity of this procedure is only related to the number o
    
[^5]: 为联邦基金会模型提供双重个性化适配器

    Dual-Personalizing Adapter for Federated Foundation Models

    [https://arxiv.org/abs/2403.19211](https://arxiv.org/abs/2403.19211)

    提出了一种新的设置，称为测试时间个性化，不仅关注目标本地任务，还延伸到其他展示测试时间个性化的任务

    

    最近，基础模型，尤其是大型语言模型（LLMs），通过微调大量的指令数据，展现出了适应各种任务的令人印象深刻的能力。值得注意的是，联邦基金会模型作为一种隐私保护方法，在分布式学习（FL）环境下通过利用许多分布式数据集进行协作微调模型，这些数据集具有非IID数据。为了减轻通信和计算开销，引入了参数高效方法以提高效率，并且一些研究将个性化方法调整为联邦基金会模型，以获得更好的用户偏好对齐。然而，现有研究中存在的一个关键缺口是在真实应用中忽略了测试时间分布转移。因此，为了弥合这一差距，我们提出了一个新的设置，称为测试时间个性化，它不仅专注于目标本地任务，还延伸到其他展示测试时间个性化的任务。

    arXiv:2403.19211v1 Announce Type: cross  Abstract: Recently, foundation models, particularly large language models (LLMs), have demonstrated an impressive ability to adapt to various tasks by fine-tuning large amounts of instruction data. Notably, federated foundation models emerge as a privacy preservation method to fine-tune models collaboratively under federated learning (FL) settings by leveraging many distributed datasets with non-IID data. To alleviate communication and computation overhead, parameter-efficient methods are introduced for efficiency, and some research adapted personalization methods to federated foundation models for better user preferences alignment. However, a critical gap in existing research is the neglect of test-time distribution shifts in real-world applications. Therefore, to bridge this gap, we propose a new setting, termed test-time personalization, which not only concentrates on the targeted local task but also extends to other tasks that exhibit test-t
    
[^6]: 面向垂直分区数据的解耦式垂直联邦学习，用于实际训练

    Decoupled Vertical Federated Learning for Practical Training on Vertically Partitioned Data

    [https://arxiv.org/abs/2403.03871](https://arxiv.org/abs/2403.03871)

    提出了Decoupled VFL（DVFL），一种面向VFL的分段学习方法，实现了分散聚合和隔离，从而提高了容错性。

    

    垂直联邦学习（VFL）是一种新兴的分布式机器学习范式，其中共同实体的不同特征所有者合作学习全局模型而无需共享数据。在VFL中，主机客户端拥有每个实体的数据标签，并基于所有客户端的中间本地表示学习最终表示。因此，主机是一个单点故障，标签反馈可以被恶意客户端用来推断私有特征。要求所有参与者在整个训练过程中保持活跃和值得信赖通常是不切实际的，在受控环境之外完全不可行。我们提出了一种面向VFL的分段学习方法Decoupled VFL（DVFL）。通过在各自的目标上训练每个模型，DVFL允许特征学习和标签监督之间的分散聚合和隔离。具有这些属性，DVFL具有容错性。

    arXiv:2403.03871v1 Announce Type: new  Abstract: Vertical Federated Learning (VFL) is an emergent distributed machine learning paradigm wherein owners of disjoint features of a common set of entities collaborate to learn a global model without sharing data. In VFL, a host client owns data labels for each entity and learns a final representation based on intermediate local representations from all guest clients. Therefore, the host is a single point of failure and label feedback can be used by malicious guest clients to infer private features. Requiring all participants to remain active and trustworthy throughout the entire training process is generally impractical and altogether infeasible outside of controlled environments. We propose Decoupled VFL (DVFL), a blockwise learning approach to VFL. By training each model on its own objective, DVFL allows for decentralized aggregation and isolation between feature learning and label supervision. With these properties, DVFL is fault tolerant
    
[^7]: 量子混合态自注意力网络

    Quantum Mixed-State Self-Attention Network

    [https://arxiv.org/abs/2403.02871](https://arxiv.org/abs/2403.02871)

    本论文介绍了一种新颖的量子混合态自注意力网络（QMSAN），结合了量子计算原理和经典机器学习算法，特别是自注意力网络，以增强处理NLP任务的效率和效果。

    

    量子计算的快速发展越来越突出了其在机器学习领域的潜力，特别是在自然语言处理（NLP）任务中。量子机器学习（QML）利用量子计算的独特能力为复杂数据处理和模式识别挑战提供新颖的视角和方法论。本文介绍了一种新颖的量子混合态注意力网络（QMSAN），它将量子计算原理与经典机器学习算法，特别是自注意力网络，相结合，以增强处理NLP任务的效率和效果。QMSAN模型采用基于混合态的量子注意力机制，实现了在量子领域内查询和键之间相似性的高效直接估计，从而实现更有效的注意力权重获取。此外，我们提出了一种创新的量子 posit

    arXiv:2403.02871v1 Announce Type: cross  Abstract: The rapid advancement of quantum computing has increasingly highlighted its potential in the realm of machine learning, particularly in the context of natural language processing (NLP) tasks. Quantum machine learning (QML) leverages the unique capabilities of quantum computing to offer novel perspectives and methodologies for complex data processing and pattern recognition challenges. This paper introduces a novel Quantum Mixed-State Attention Network (QMSAN), which integrates the principles of quantum computing with classical machine learning algorithms, especially self-attention networks, to enhance the efficiency and effectiveness in handling NLP tasks. QMSAN model employs a quantum attention mechanism based on mixed states, enabling efficient direct estimation of similarity between queries and keys within the quantum domain, leading to more effective attention weight acquisition. Additionally, we propose an innovative quantum posit
    
[^8]: 2D Matryoshka句子嵌入

    2D Matryoshka Sentence Embeddings

    [https://arxiv.org/abs/2402.14776](https://arxiv.org/abs/2402.14776)

    Matryoshka表示学习(MRL)以更细粒度地编码信息，以适应临时任务，同时实现了更小的嵌入大小，从而加快了下游任务的速度。

    

    arXiv:2402.14776v1 公告类型：新  摘要：常见方法依赖于从语言模型中获得的固定长度的嵌入向量作为句子嵌入，用于语义文本相似性（STS）等下游任务。由于在各种应用程序中存在未知的计算约束和预算，这些方法在灵活性上受到限制。Matryoshka表示学习(MRL)(Kusupati等人，2022)以更细粒度地编码信息，即使用较低的嵌入维度，以自适应地适应临时任务。可以通过较小的嵌入大小达到类似的准确性，从而加快下游任务。尽管其改进了效率，MRL仍要在获得嵌入之前遍历所有Transformer层，这仍然是时间和内存消耗的主要因素。这引发了是否固定数量的Transformer层会影响表示质量以及使用中间层进行句子表示是否可行的考虑。

    arXiv:2402.14776v1 Announce Type: new  Abstract: Common approaches rely on fixed-length embedding vectors from language models as sentence embeddings for downstream tasks such as semantic textual similarity (STS). Such methods are limited in their flexibility due to unknown computational constraints and budgets across various applications. Matryoshka Representation Learning (MRL) (Kusupati et al., 2022) encodes information at finer granularities, i.e., with lower embedding dimensions, to adaptively accommodate ad hoc tasks. Similar accuracy can be achieved with a smaller embedding size, leading to speedups in downstream tasks. Despite its improved efficiency, MRL still requires traversing all Transformer layers before obtaining the embedding, which remains the dominant factor in time and memory consumption. This prompts consideration of whether the fixed number of Transformer layers affects representation quality and whether using intermediate layers for sentence representation is feas
    
[^9]: 离线模型驱动强化学习中的边缘问题

    The Edge-of-Reach Problem in Offline Model-Based Reinforcement Learning

    [https://arxiv.org/abs/2402.12527](https://arxiv.org/abs/2402.12527)

    学习的动力学模型被真实且无误差的动力学替代时，现有模型驱动方法将会完全失败，揭示出一个重大误解。

    

    离线强化学习旨在使智能体能够从预先收集的数据集中进行训练，然而，由此带来了一个额外的挑战，即估计数据集中未涵盖的行为的价值。模型驱动方法通过允许智能体通过在学习动力学模型中进行展开进行收集额外的合成数据来提供解决方案。然而，令人惊讶的是，我们发现，如果学习的动力学模型被真实且无误差的动力学替代，现有的模型驱动方法将完全失败。这揭示了一个重大误解。我们的后续调查发现，模型驱动算法中使用的一般过程导致存在一组触发病态值过高的边缘状态。

    arXiv:2402.12527v1 Announce Type: cross  Abstract: Offline reinforcement learning aims to enable agents to be trained from pre-collected datasets, however, this comes with the added challenge of estimating the value of behavior not covered in the dataset. Model-based methods offer a solution by allowing agents to collect additional synthetic data via rollouts in a learned dynamics model. The prevailing theoretical understanding is that this can then be viewed as online reinforcement learning in an approximate dynamics model, and any remaining gap is therefore assumed to be due to the imperfect dynamics model. Surprisingly, however, we find that if the learned dynamics model is replaced by the true error-free dynamics, existing model-based methods completely fail. This reveals a major misconception. Our subsequent investigation finds that the general procedure used in model-based algorithms results in the existence of a set of edge-of-reach states which trigger pathological value overes
    
[^10]: 在李群上的随机Hessian拟合

    Stochastic Hessian Fitting on Lie Group

    [https://arxiv.org/abs/2402.11858](https://arxiv.org/abs/2402.11858)

    本文研究了在随机Hessian-向量乘积上拟合Hessian或其逆，揭示了不同Hessian拟合方法的收敛速率，并证明了在特定李群上的Hessian拟合问题在轻微条件下是强凸的。

    

    本文研究了在随机Hessian-向量乘积上拟合Hessian或其逆。使用了一个Hessian拟合准则，可用于推导大部分常用方法，如BFGS、高斯牛顿、AdaGrad等。我们的研究揭示了不同Hessian拟合方法的不同收敛速率，例如，在欧几里德空间中的梯度下降的次线性速率和对称正定（SPL）矩阵和某些李群上的梯度下降的线性速率。在特定且足够一般的李群上的Hessian拟合问题在轻微条件下被证明是强凸的。为了确认我们的分析，这些方法在不同设置下进行了测试，如有噪声的Hessian-向量乘积、时变的Hessians和低精度算术。这些发现对依赖于随机二阶优化的方法是有用的。

    arXiv:2402.11858v1 Announce Type: cross  Abstract: This paper studies the fitting of Hessian or its inverse with stochastic Hessian-vector products. A Hessian fitting criterion, which can be used to derive most of the commonly used methods, e.g., BFGS, Gaussian-Newton, AdaGrad, etc., is used for the analysis. Our studies reveal different convergence rates for different Hessian fitting methods, e.g., sublinear rates for gradient descent in the Euclidean space and a commonly used closed-form solution, linear rates for gradient descent on the manifold of symmetric positive definite (SPL) matrices and certain Lie groups. The Hessian fitting problem is further shown to be strongly convex under mild conditions on a specific yet general enough Lie group. To confirm our analysis, these methods are tested under different settings like noisy Hessian-vector products, time varying Hessians, and low precision arithmetic. These findings are useful for stochastic second order optimizations that rely 
    
[^11]: 在开放无线接入网络中保护机器学习驱动的应用的数据隐私

    Preserving Data Privacy for ML-driven Applications in Open Radio Access Networks

    [https://arxiv.org/abs/2402.09710](https://arxiv.org/abs/2402.09710)

    本文研究了在5G开放无线接入网络（O-RAN）中共享数据库场景下的数据隐私问题，并提出了一种基于洗牌的可学习加密技术来保护机器学习模型的数据隐私。

    

    深度学习提供了一种改进频谱访问技术的有希望的解决方案，通过利用数据驱动的方法来管理和共享有限的频谱资源，用于新兴应用。对于其中几种应用，敏感的无线数据（如频谱图）存储在共享数据库或多方利益相关者云环境中，因此容易造成隐私泄漏。本文旨在通过研究5G开放无线接入网络（O-RAN）中共享数据库场景的典型案例来解决此类隐私问题，在这些场景中，我们在近实时（near-RT）无线接入网络智能控制器中有一个共享数据库。我们着重讨论了如何保护用于频谱共享和干扰缓解应用的机器学习（ML）模型所使用的数据，同时不影响模型和网络的性能。其中的基本想法是利用基于洗牌的可学习加密技术来加密数据。

    arXiv:2402.09710v1 Announce Type: cross  Abstract: Deep learning offers a promising solution to improve spectrum access techniques by utilizing data-driven approaches to manage and share limited spectrum resources for emerging applications. For several of these applications, the sensitive wireless data (such as spectrograms) are stored in a shared database or multistakeholder cloud environment and are therefore prone to privacy leaks. This paper aims to address such privacy concerns by examining the representative case study of shared database scenarios in 5G Open Radio Access Network (O-RAN) networks where we have a shared database within the near-real-time (near-RT) RAN intelligent controller. We focus on securing the data that can be used by machine learning (ML) models for spectrum sharing and interference mitigation applications without compromising the model and network performances. The underlying idea is to leverage a (i) Shuffling-based learnable encryption technique to encryp
    
[^12]: DoorINet: 一种用于门贴式物联网应用的深度学习惯性框架

    DoorINet: A Deep-Learning Inertial Framework for Door-Mounted IoT Applications

    [https://arxiv.org/abs/2402.09427](https://arxiv.org/abs/2402.09427)

    DoorINet是一种用于门贴式物联网应用的深度学习惯性框架，无需使用磁力计即可计算航向角度。

    

    许多物联网应用使用低成本的微型电动机械惯性传感器，其中一个常见的任务是方向估计。为了应对这种任务，应用姿态和航向参考系统算法。利用陀螺仪读数，通过加速度计读数更新姿态角度，利用磁力计测量更新航向角度。在室内环境中，磁力计受到干扰，会降低其性能。这主要影响到估计航向角度的应用，比如找到衣柜或冰箱门的航向角度。为了解决这种情况，我们提出了DoorINet，一种用于门贴式低成本惯性传感器的端到端深度学习框架，无需使用磁力计即可计算航向角度。为了评估我们的方法，我们记录了一个包含391分钟加速度计和陀螺仪测量的独特数据集。

    arXiv:2402.09427v1 Announce Type: cross  Abstract: Many Internet of Things applications utilize low-cost, micro, electro-mechanical inertial sensors. A common task is orientation estimation. To tackle such a task, attitude and heading reference system algorithms are applied. Relying on the gyroscope readings, the accelerometer readings are used to update the attitude angles, and magnetometer measurements are utilized to update the heading angle. In indoor environments, magnetometers suffer from interference that degrades their performance. This mainly influences applications focused on estimating the heading angle like finding the heading angle of a closet or fridge door. To circumvent such situations, we propose DoorINet, an end-to-end deep-learning framework to calculate the heading angle from door-mounted, low-cost inertial sensors without using magnetometers. To evaluate our approach, we record a unique dataset containing 391 minutes of accelerometer and gyroscope measurements and 
    
[^13]: 《对于数值逼近遍历SDE的分布的Wasserstein距离估计》修正

    Correction to "Wasserstein distance estimates for the distributions of numerical approximations to ergodic stochastic differential equations"

    [https://arxiv.org/abs/2402.08711](https://arxiv.org/abs/2402.08711)

    修正了《对于数值逼近遍历SDE的分布的Wasserstein距离估计》中的错误局部误差估计，提出了一种方法来分析数值离散遍历SDE的Wasserstein-2距离的非渐近保证，并解决了实践中维度依赖性的问题。

    

    本文对San-Serna和Zygalakis的《对于数值逼近遍历SDE的分布的Wasserstein距离估计》中的非渐近保证数值离散分析方法进行了修正。他们分析了UBU积分器，该积分器是二阶强型的，并且每个步骤只需要一次梯度评估，从而得到了理想的非渐近保证，特别是在Wasserstein-2距离中到达离目标分布 $\epsilon > 0$ 的距离仅需 $\mathcal{O}(d^{1/4}\epsilon^{-1/2})$ 步。然而，Sanz-Serna和Zygalakis (2021)中的局部误差估计存在错误，在实践中需要更强的假设才能实现这些复杂度估计。本文解决了理论与实践中观察到的许多应用场景中的维度依赖性。

    arXiv:2402.08711v1 Announce Type: cross Abstract: A method for analyzing non-asymptotic guarantees of numerical discretizations of ergodic SDEs in Wasserstein-2 distance is presented by Sanz-Serna and Zygalakis in ``Wasserstein distance estimates for the distributions of numerical approximations to ergodic stochastic differential equations". They analyze the UBU integrator which is strong order two and only requires one gradient evaluation per step, resulting in desirable non-asymptotic guarantees, in particular $\mathcal{O}(d^{1/4}\epsilon^{-1/2})$ steps to reach a distance of $\epsilon > 0$ in Wasserstein-2 distance away from the target distribution. However, there is a mistake in the local error estimates in Sanz-Serna and Zygalakis (2021), in particular, a stronger assumption is needed to achieve these complexity estimates. This note reconciles the theory with the dimension dependence observed in practice in many applications of interest.
    
[^14]: 两种单相对比海比安学习的故事

    Two Tales of Single-Phase Contrastive Hebbian Learning

    [https://arxiv.org/abs/2402.08573](https://arxiv.org/abs/2402.08573)

    两种单相对比海比安学习的故事探索了学习算法的生物合理性，并提出了一种全局学习算法，能够消除与反向传播之间的性能差距，并解决了同步和无限小扰动带来的问题。

    

    对于“生物学上合理”的学习算法的探索已经收敛于将梯度表示为活动差异的想法。然而，大多数方法需要较高程度的同步（学习期间的不同阶段）并引入大量的计算开销，这对于它们的生物学合理性以及其在神经形态计算中的潜在效用产生了疑问。此外，它们通常依赖于对输出单元施加无限小扰动（nudges），这在嘈杂环境中是不切实际的。最近研究发现，通过将人工神经元建模为两个相反扰动的组件，名为“双向传播”的全局学习算法能够弥合到反向传播的性能差距，而不需要分别的学习阶段或无限小扰动。然而，该算法的数值稳定性依赖于对称扰动，这可能在生物学上受到限制。

    The search for "biologically plausible" learning algorithms has converged on the idea of representing gradients as activity differences. However, most approaches require a high degree of synchronization (distinct phases during learning) and introduce substantial computational overhead, which raises doubts regarding their biological plausibility as well as their potential utility for neuromorphic computing. Furthermore, they commonly rely on applying infinitesimal perturbations (nudges) to output units, which is impractical in noisy environments. Recently it has been shown that by modelling artificial neurons as dyads with two oppositely nudged compartments, it is possible for a fully local learning algorithm named ``dual propagation'' to bridge the performance gap to backpropagation, without requiring separate learning phases or infinitesimal nudging. However, the algorithm has the drawback that its numerical stability relies on symmetric nudging, which may be restrictive in biological
    
[^15]: 可扩展大型语言模型微调的差分隐私零阶方法

    Differentially Private Zeroth-Order Methods for Scalable Large Language Model Finetuning

    [https://arxiv.org/abs/2402.07818](https://arxiv.org/abs/2402.07818)

    本文研究了差分隐私零阶方法在大型语言模型微调中的应用，该方法通过使用零阶梯度来避免传统优化方法的可扩展性瓶颈，实现了在隐私、效用和可扩展性之间的良好平衡。

    

    在特定任务的数据集上进行微调是利用预训练语言模型的强大能力进行各种下游任务的广泛接受的范例。由于预训练语言模型微调的普及以及与之相关的隐私问题，差分隐私预训练语言模型微调引起了越来越多的关注，以保护特定任务数据集的隐私。差分隐私预训练语言模型微调方法的设计核心是在隐私、效用和可扩展性之间达到满意的权衡。大多数现有方法都是基于DP-SGD的创新性工作。尽管将DP-SGD的可扩展性推到了极限，但基于DP-SGD的微调方法不幸地受到了SGD固有低效率的限制。在本文中，我们研究了DP零阶方法在LLM预训练中的潜力，该方法通过用更高效的零阶梯度来近似梯度，避免了SGD的可扩展性瓶颈。与将零阶方法作为一种替代方法进行处理不同，我们引入了一种新的割接框架，该框架能够以非常接近的方式模拟DP-SGD的基本操作，然后利用零阶优化方法来近似梯度。

    Finetuning on task-specific datasets is a widely-embraced paradigm of harnessing the powerful capability of pretrained LLMs for various downstream tasks. Due to the popularity of LLMs finetuning and its accompanying privacy concerns, differentially private (DP) finetuning of pretrained LLMs has garnered increasing attention to safeguarding the privacy of task-specific datasets. Lying at the design core of DP LLM finetuning methods is the satisfactory tradeoff between privacy, utility, and scalability. Most existing methods build upon the seminal work of DP-SGD. Despite pushing the scalability of DP-SGD to its limit, DP-SGD-based finetuning methods are unfortunately limited by the inherent inefficiency of SGD. In this paper, we investigate the potential of DP zeroth-order methods for LLM pretraining, which avoids the scalability bottleneck of SGD by approximating the gradient with the more efficient zeroth-order gradient. Rather than treating the zeroth-order method as a drop-in replace
    
[^16]: PoCo: 来自和为异构机器人学习的策略组合

    PoCo: Policy Composition from and for Heterogeneous Robot Learning

    [https://arxiv.org/abs/2402.02511](https://arxiv.org/abs/2402.02511)

    PoCo是一种策略组合方法，通过组合不同模态和领域的数据分布，实现了从异构数据中训练通用机器人策略的目标。该方法可以实现场景级和任务级的广义操作技能学习，并在推理时通过任务级组合和分析成本函数进行策略行为的自适应调整。

    

    从异构数据中训练通用的机器人策略以处理不同任务是一个重大挑战。现有的机器人数据集在颜色、深度、触觉和姿态感等不同模态上存在差异，并在模拟、真实机器人和人类视频等不同领域收集。目前的方法通常会收集并汇集一个领域的所有数据，以训练一个单一策略来处理任务和领域的异构性，这是非常昂贵和困难的。在这项工作中，我们提出了一种灵活的方法，称为策略组合，通过组合用扩散模型表示的不同数据分布，将跨不同模态和领域的信息结合起来，以学习场景级和任务级的广义操作技能。我们的方法可以在多任务操作中使用任务级组合，并与分析成本函数组合，以在推理时调整策略行为。我们在模拟、人类和实际机器人数据上训练我们的方法。

    Training general robotic policies from heterogeneous data for different tasks is a significant challenge. Existing robotic datasets vary in different modalities such as color, depth, tactile, and proprioceptive information, and collected in different domains such as simulation, real robots, and human videos. Current methods usually collect and pool all data from one domain to train a single policy to handle such heterogeneity in tasks and domains, which is prohibitively expensive and difficult. In this work, we present a flexible approach, dubbed Policy Composition, to combine information across such diverse modalities and domains for learning scene-level and task-level generalized manipulation skills, by composing different data distributions represented with diffusion models. Our method can use task-level composition for multi-task manipulation and be composed with analytic cost functions to adapt policy behaviors at inference time. We train our method on simulation, human, and real 
    
[^17]: GLaPE：大型语言模型的无依赖于金标签的提示评估与优化

    GLaPE: Gold Label-agnostic Prompt Evaluation and Optimization for Large Language Model

    [https://arxiv.org/abs/2402.02408](https://arxiv.org/abs/2402.02408)

    GLaPE提出了一种无依赖于金标签的提示评估方法，通过自一致性作为初始评估分数，进一步改进了产生相同答案的提示的得分的互相一致性，提供了与准确性相一致的可靠评估，即使在没有金标签的情况下。

    

    尽管大型语言模型（LLMs）取得了快速进展，但它们的任务性能仍然对提示设计敏感。最近的研究探索了利用LLM自身作为优化器来识别最大化任务准确性的最优提示。然而，在评估提示时，这些方法严重依赖于难以获取的手动标注的金标签，以计算每个候选提示的任务准确性，这阻碍了广泛的实施和通用性。为了克服这一限制，本研究提出了一种无依赖于金标签的提示评估方法（GLaPE），以减少对金标签的依赖。受到自一致性和答案准确性之间的相关性的启发，我们将自一致性作为初始评估分数。随后，我们对产生相同答案的提示进行得分的互相一致性的改进。实验结果表明，GLaPE在没有金标签的情况下提供了与准确性相一致的可靠评估。此外，对于六个任务，GLaPE在绝大部分情况下得到的评估结果与使用真实金标签评估的结果相似。

    Despite the rapid progress of large language models (LLMs), their task performance remains sensitive to prompt design. Recent studies have explored leveraging the LLM itself as an optimizer to identify optimal prompts that maximize task accuracy. However, when evaluating prompts, such approaches heavily rely on elusive manually annotated gold labels to calculate task accuracy for each candidate prompt, which hinders the widespread implementation and generality. To overcome the limitation, this work proposes a gold label-agnostic prompt evaluation (GLaPE) to alleviate dependence on gold labels. Motivated by the observed correlation between self-consistency and the accuracy of the answer, we adopt self-consistency as the initial evaluation score. Subsequently, we refine the scores of prompts producing identical answers to be mutually consistent. Experimental results show that GLaPE provides reliable evaluations uniform with accuracy, even in the absence of gold labels. Moreover, on six p
    
[^18]: 图上的神经缩放定律

    Neural Scaling Laws on Graphs

    [https://arxiv.org/abs/2402.02054](https://arxiv.org/abs/2402.02054)

    本论文在图上深入研究了神经缩放定律，从模型和数据两个角度进行了探索。对于模型缩放，发现了缩放定律崩溃和过拟合之间的关系，以及深度图模型的模型深度对缩放行为的影响。对于数据缩放，提出了图数量不适合作为衡量缩放定律中图数据量的指标。

    

    深度图模型（例如图神经网络和图变换器）已成为利用各种类型图的知识的重要技术。然而，深度图模型的缩放特性尚未得到系统研究，对通过扩大模型和数据集大小来实现大型图模型的可行性产生了疑问。在这项工作中，我们从模型和数据的角度深入探索了图上的神经缩放定律。我们首先验证了这些定律在图上的有效性，并建立了描述缩放行为的公式。对于模型缩放，我们研究了缩放定律崩溃现象，并确定了过拟合可能是原因。此外，我们揭示了深度图模型的模型深度可以影响模型缩放行为，这与其他领域（如计算机视觉和自然语言处理）的观察结果不同。对于数据缩放，我们建议图数量无法有效衡量图数据量的缩放定律，因为...

    Deep graph models (e.g., graph neural networks and graph transformers) have become important techniques for leveraging knowledge across various types of graphs. Yet, the scaling properties of deep graph models have not been systematically investigated, casting doubt on the feasibility of achieving large graph models through enlarging the model and dataset sizes. In this work, we delve into neural scaling laws on graphs from both model and data perspectives. We first verify the validity of such laws on graphs, establishing formulations to describe the scaling behaviors. For model scaling, we investigate the phenomenon of scaling law collapse and identify overfitting as the potential reason. Moreover, we reveal that the model depth of deep graph models can impact the model scaling behaviors, which differ from observations in other domains such as CV and NLP. For data scaling, we suggest that the number of graphs can not effectively metric the graph data volume in scaling law since the si
    
[^19]: 基于拓扑的去重建防护在去中心化学习中的应用

    Topology-Based Reconstruction Prevention for Decentralised Learning

    [https://arxiv.org/abs/2312.05248](https://arxiv.org/abs/2312.05248)

    通过研究发现，在去中心化学习中，被动的好奇敌手可以在几次保护隐私的求和操作后推断出其他用户的私人数据。

    

    最近，去中心化学习作为一种替代联邦学习的方式，获得了人们的关注，其中数据和协调都分布在用户之间。为了保护数据的机密性，去中心化学习依赖于差分隐私、多方计算，或者二者的结合。然而，连续运行多个保护隐私的求和操作可能会使对手进行重建攻击。不幸的是，当前的重建对策要么无法简单地适应分布式环境，要么会添加过多的噪音。在这项工作中，我们首先表明，被动的好奇敌手可以在几次保护隐私的求和之后推断出其他用户的私人数据。例如，在拓扑中有18个用户的子图中，我们发现只有三个被动的好奇敌手成功重建私人数据的概率为11.0%，平均每个对手需要8.8次求和。

    arXiv:2312.05248v2 Announce Type: replace-cross  Abstract: Decentralised learning has recently gained traction as an alternative to federated learning in which both data and coordination are distributed over its users. To preserve data confidentiality, decentralised learning relies on differential privacy, multi-party computation, or a combination thereof. However, running multiple privacy-preserving summations in sequence may allow adversaries to perform reconstruction attacks. Unfortunately, current reconstruction countermeasures either cannot trivially be adapted to the distributed setting, or add excessive amounts of noise.   In this work, we first show that passive honest-but-curious adversaries can infer other users' private data after several privacy-preserving summations. For example, in subgraphs with 18 users, we show that only three passive honest-but-curious adversaries succeed at reconstructing private data 11.0% of the time, requiring an average of 8.8 summations per adve
    
[^20]: 一种针对非法歌曲翻唱的主动性双重防护机制：基于歌唱声音转换的能力

    A Proactive and Dual Prevention Mechanism against Illegal Song Covers empowered by Singing Voice Conversion. (arXiv:2401.17133v1 [cs.SD])

    [http://arxiv.org/abs/2401.17133](http://arxiv.org/abs/2401.17133)

    这项工作提出了一种主动性的双重防护机制，通过引入人类无法察觉的扰动，干扰歌唱声音转换的生成过程，防止未经授权的基于歌唱声音转换的非法歌曲翻唱。该机制既扰乱了歌手身份，又扰乱了歌词，使得歌唱声音既不模仿目标歌手，也不保留原始歌词。

    

    歌唱声音转换(SVC)通过将一个歌手的歌唱声音转换成另一个目标歌手的歌唱声音，并使用原始歌词和旋律，自动化了歌曲翻唱。然而，这引发了对版权和公民权利的严重担忧。本研究提出了 SongBsAb，这是第一个主动性方法，用于减轻未经授权的基于 SVC 的非法歌曲翻唱。SongBsAb 在发布歌唱声音之前引入了人类无法察觉的扰动，这样当它们被使用时，SVC 的生成过程将被干扰，导致意外的歌唱声音。 SongBsAb 具有双重预防效果，引起歌手身份和歌词的混乱，即 SVC 覆盖的歌唱声音既不模仿目标歌手，也不保留原始歌词。为了提高扰动的不可察觉性，我们使用了一个以伴奏曲作为额外掩蔽者的基于心理声学模型的损失模型。

    Singing voice conversion (SVC) automates song covers by converting one singer's singing voice into another target singer's singing voice with the original lyrics and melody. However, it raises serious concerns about copyright and civil right infringements to multiple entities. This work proposes SongBsAb, the first proactive approach to mitigate unauthorized SVC-based illegal song covers. SongBsAb introduces human-imperceptible perturbations to singing voices before releasing them, so that when they are used, the generation process of SVC will be interfered, resulting in unexpected singing voices. SongBsAb features a dual prevention effect by causing both (singer) identity disruption and lyric disruption, namely, the SVC-covered singing voice neither imitates the target singer nor preserves the original lyrics. To improve the imperceptibility of perturbations, we refine a psychoacoustic model-based loss with the backing track as an additional masker, a unique accompanying element for s
    
[^21]: 通过分层循环切换状态模型发现同步时间序列中的群体动态

    Discovering group dynamics in synchronous time series via hierarchical recurrent switching-state models. (arXiv:2401.14973v1 [stat.ML])

    [http://arxiv.org/abs/2401.14973](http://arxiv.org/abs/2401.14973)

    通过分层的循环切换状态模型，我们可以无监督地同时解释系统级和个体级的动态，从而更好地建模同步时间序列中的群体动态。

    

    我们致力于对同一时间段内多个实体相互作用而产生的时间序列集合进行建模。最近的研究集中在建模个体时间序列方面对我们的预期应用是不足够的，其中集体系统级行为影响着个体实体的轨迹。为了解决这类问题，我们提出了一种新的分层切换状态模型，可以以无监督的方式训练，同时解释系统级和个体级的动态。我们采用了一个隐含的系统级离散状态马尔可夫链，驱动着隐含的实体级链，进而控制每个观测时间序列的动态。观测结果在实体和系统级的链之间进行反馈，通过依赖于上下文的状态转换来提高灵活性。我们的分层切换循环动力学模型可以通过封闭形式的变分坐标上升更新来学习，其在个体数量上呈线性扩展。

    We seek to model a collection of time series arising from multiple entities interacting over the same time period. Recent work focused on modeling individual time series is inadequate for our intended applications, where collective system-level behavior influences the trajectories of individual entities. To address such problems, we present a new hierarchical switching-state model that can be trained in an unsupervised fashion to simultaneously explain both system-level and individual-level dynamics. We employ a latent system-level discrete state Markov chain that drives latent entity-level chains which in turn govern the dynamics of each observed time series. Feedback from the observations to the chains at both the entity and system levels improves flexibility via context-dependent state transitions. Our hierarchical switching recurrent dynamical models can be learned via closed-form variational coordinate ascent updates to all latent chains that scale linearly in the number of indivi
    
[^22]: 二进制特征屏蔽优化用于特征选择

    Binary Feature Mask Optimization for Feature Selection. (arXiv:2401.12644v1 [cs.LG])

    [http://arxiv.org/abs/2401.12644](http://arxiv.org/abs/2401.12644)

    这个论文提出了一种新颖的特征选择框架，通过使用特征屏蔽方法来消除特征，而不是从数据集中移除它们。这种方法不需要重新训练机器学习模型，可以综合考虑特征子集的重要性，为通用机器学习模型的特征选择问题提供了一种新的解决方案。

    

    我们研究了通用机器学习模型的特征选择问题。我们引入了一种新颖的框架，该框架考虑了模型的预测结果来选择特征。我们的框架通过使用一种新颖的特征屏蔽方法，在特征选择过程中消除特征，而不是从数据集中完全移除它们。这使我们能够在特征选择过程中使用相同的机器学习模型，而不像其他特征选择方法那样需要在每次迭代中重新训练机器学习模型，因为数据集的维度不同。我们使用机器学习模型的预测结果来获取屏蔽操作符，这为模型的预测性能提供了对特征子集的全面观察。特征选择文献中存在各种方法。然而，没有研究引入一个针对通用机器学习模型的无需训练的框架，以整体考虑特征子集的重要性，而不是只关注单个特征的重要性。

    We investigate feature selection problem for generic machine learning (ML) models. We introduce a novel framework that selects features considering the predictions of the model. Our framework innovates by using a novel feature masking approach to eliminate the features during the selection process, instead of completely removing them from the dataset. This allows us to use the same ML model during feature selection, unlike other feature selection methods where we need to train the ML model again as the dataset has different dimensions on each iteration. We obtain the mask operator using the predictions of the ML model, which offers a comprehensive view on the subsets of the features essential for the predictive performance of the model. A variety of approaches exist in the feature selection literature. However, no study has introduced a training-free framework for a generic ML model to select features while considering the importance of the feature subsets as a whole, instead of focusi
    
[^23]: 具有结构化变分族的可证伸缩性黑盒变分推断

    Provably Scalable Black-Box Variational Inference with Structured Variational Families. (arXiv:2401.10989v1 [stat.ML])

    [http://arxiv.org/abs/2401.10989](http://arxiv.org/abs/2401.10989)

    本文研究了均值场变分族和满秩变分族之间的理论中间地带：结构化变分族，并通过理论证明结构化变分族可以在迭代复杂性上表现更好，缩放效果更好。

    

    已知具有满秩协方差逼近的变分族在黑盒变分推断中表现不佳，无论是从实证上还是理论上。事实上，最近对黑盒变分推断的计算复杂性结果表明，与均值场变分族相比，满秩变分族在问题的维度上扩展得很差。这对具有本地变量的分层贝叶斯模型尤为关键，它们的维度随着数据集的大小而增加。因此，迭代复杂性对数据集大小N存在明确的O(N^2)依赖。在本文中，我们探索了均值场变分族和满秩变分族之间的理论中间地带：结构化变分族。我们严格证明了某些尺度矩阵结构可以实现更好的迭代复杂性O(N)，从而与N的缩放更好地匹配。我们在现实中验证了我们的理论结果

    Variational families with full-rank covariance approximations are known not to work well in black-box variational inference (BBVI), both empirically and theoretically. In fact, recent computational complexity results for BBVI have established that full-rank variational families scale poorly with the dimensionality of the problem compared to e.g. mean field families. This is particularly critical to hierarchical Bayesian models with local variables; their dimensionality increases with the size of the datasets. Consequently, one gets an iteration complexity with an explicit $\mathcal{O}(N^2)$ dependence on the dataset size $N$. In this paper, we explore a theoretical middle ground between mean-field variational families and full-rank families: structured variational families. We rigorously prove that certain scale matrix structures can achieve a better iteration complexity of $\mathcal{O}(N)$, implying better scaling with respect to $N$. We empirically verify our theoretical results on l
    
[^24]: 物理约束卷积神经网络用于时空偏微分方程中的反问题

    Physics-constrained convolutional neural networks for inverse problems in spatiotemporal partial differential equations. (arXiv:2401.10306v1 [physics.flu-dyn])

    [http://arxiv.org/abs/2401.10306](http://arxiv.org/abs/2401.10306)

    本研究提出了一种物理约束卷积神经网络（PC-CNN），用于解决非线性且时空变化的偏微分方程中的两种反问题。该网络可以揭示受偏差影响的真实状态，并在给定稀疏信息的情况下以高分辨率重建解。

    

    我们提出了一种物理约束卷积神经网络（PC-CNN）来解决偏微分方程中两种类型的反问题，这些方程在空间和时间上都是非线性且变化的。在第一个反问题中，我们给出了受空间变化的系统误差（即偏差，也称为认识不确定性）偏移的数据。任务是从偏差数据中揭示真实状态，即PDE的解。在第二个反问题中，我们给出了PDE解的稀疏信息。任务是以高分辨率重建空间中的解。首先，我们介绍了PC-CNN，它通过简单的时间窗口方案约束PDE来处理时序数据。其次，我们分析了PC-CNN在从偏差数据中揭示解的性能。我们分析了线性和非线性对流扩散方程以及纳维-斯托克斯方程，后者描述了湍流流动的时空混沌动力学。

    We propose a physics-constrained convolutional neural network (PC-CNN) to solve two types of inverse problems in partial differential equations (PDEs), which are nonlinear and vary both in space and time. In the first inverse problem, we are given data that is offset by spatially varying systematic error (i.e., the bias, also known the epistemic uncertainty). The task is to uncover from the biased data the true state, which is the solution of the PDE. In the second inverse problem, we are given sparse information on the solution of a PDE. The task is to reconstruct the solution in space with high-resolution. First, we present the PC-CNN, which constrains the PDE with a simple time-windowing scheme to handle sequential data. Second, we analyse the performance of the PC-CNN for uncovering solutions from biased data. We analyse both linear and nonlinear convection-diffusion equations, and the Navier-Stokes equations, which govern the spatiotemporally chaotic dynamics of turbulent flows. W
    
[^25]: 临床试验结果预测中的不确定性量化

    Uncertainty Quantification on Clinical Trial Outcome Prediction. (arXiv:2401.03482v1 [cs.LG])

    [http://arxiv.org/abs/2401.03482](http://arxiv.org/abs/2401.03482)

    本研究将不确定性量化方法应用于临床试验结果预测，提高模型对微妙差异的识别能力，从而改善其整体性能。

    

    不确定性量化在机器学习的不同领域中的重要性日益被认识到。准确评估模型预测的不确定性可以帮助研究人员和从业人员更深入地理解和增加信心。这在医学诊断和药物发现领域尤为重要，因为可靠的预测直接影响研究质量和患者健康。本文提出将不确定性量化纳入临床试验结果预测中。我们的主要目标是提高模型辨别微妙差异的能力，从而显著改善其整体性能。我们采用了一种选择性分类方法来实现我们的目标，并将其与层次交互网络(HINT)无缝集成，HINT是临床试验预测建模的最前沿。选择性分类涵盖了一系列不确定性量化方法，使模型能够保留信息以供进一步分析。

    The importance of uncertainty quantification is increasingly recognized in the diverse field of machine learning. Accurately assessing model prediction uncertainty can help provide deeper understanding and confidence for researchers and practitioners. This is especially critical in medical diagnosis and drug discovery areas, where reliable predictions directly impact research quality and patient health.  In this paper, we proposed incorporating uncertainty quantification into clinical trial outcome predictions. Our main goal is to enhance the model's ability to discern nuanced differences, thereby significantly improving its overall performance.  We have adopted a selective classification approach to fulfill our objective, integrating it seamlessly with the Hierarchical Interaction Network (HINT), which is at the forefront of clinical trial prediction modeling. Selective classification, encompassing a spectrum of methods for uncertainty quantification, empowers the model to withhold de
    
[^26]: 论文标题：校准攻击：针对校准性的对抗攻击框架

    Calibration Attack: A Framework For Adversarial Attacks Targeting Calibration. (arXiv:2401.02718v1 [cs.LG])

    [http://arxiv.org/abs/2401.02718](http://arxiv.org/abs/2401.02718)

    校准攻击是一种新的对抗攻击框架，通过生成和组织攻击来使受害模型失去准确校准，而不影响其原始准确性。这对模型的可信度和基于置信分数的决策构成严重威胁。我们提出了四种校准攻击形式，并对常用的对抗防御和校准方法的有效性进行了研究。

    

    我们引入了一种名为校准攻击的新对抗攻击框架，其中攻击被生成和组织以使受害模型失去准确校准，同时不改变其原始准确性，从而严重危及模型的可信度和基于其置信分数的任何决策。具体而言，我们确定了四种新型校准攻击形式：低置信攻击、高置信攻击、最大失真攻击和随机置信攻击，适用于白盒和黑盒设置。然后，我们使用全面的数据集对典型的受害模型进行了这些新型攻击的测试，证明即使只进行相对较少的查询，攻击也能造成重大的校准错误。我们还提供了详细的分析以了解校准攻击的不同方面。在此基础上，我们研究了广泛使用的对抗防御和校准方法对这些攻击类型的有效性。

    We introduce a new framework of adversarial attacks, named calibration attacks, in which the attacks are generated and organized to trap victim models to be miscalibrated without altering their original accuracy, hence seriously endangering the trustworthiness of the models and any decision-making based on their confidence scores. Specifically, we identify four novel forms of calibration attacks: underconfidence attacks, overconfidence attacks, maximum miscalibration attacks, and random confidence attacks, in both the black-box and white-box setups. We then test these new attacks on typical victim models with comprehensive datasets, demonstrating that even with a relatively low number of queries, the attacks can create significant calibration mistakes. We further provide detailed analyses to understand different aspects of calibration attacks. Building on that, we investigate the effectiveness of widely used adversarial defences and calibration methods against these types of attacks, w
    
[^27]: 一个基础图模型

    A Foundation Graph Model. (arXiv:2311.03976v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2311.03976](http://arxiv.org/abs/2311.03976)

    本文提出了一个基于对抗性对比学习的基础图模型FoToM，该模型通过节点和边特征排除进行图预训练，在多个领域上实现了正向迁移，并取得了显著的性能提升。

    

    无监督图表示学习的主要优势是在数据或标签稀缺的情况下，可以对预训练模型进行微调。现有的方法是针对特定领域的，保持预训练和目标数据集之间的节点和边属性一致。这使得无法在其他领域进行迁移。能够在任意任务和领域上实现正向迁移的模型将成为第一个基础图模型。在这项工作中，我们使用对抗性对比学习提出了FoToM，一种基于节点和边特征排除的图预训练方法。我们使用FoToM在多个图领域上进行预训练，得到了第一个基础图模型。我们在来自多个领域的评估数据集上展示了正向迁移。在所有数据集上，性能最差时与有监督基线相当，76%的数据集在95%置信度下都显著优于有监督基线（P≤0.01），误差减少了8%至40%。

    The principal benefit of unsupervised graph representation learning is that a pre-trained model can be fine-tuned where data or labels are scarce. Existing approaches are domain specific, maintaining consistent node and edge attributes across the pre-training and target datasets. This precludes transfer to other domains. A model capable of positive transfer on arbitrary tasks and domains would represent the first foundation graph model.  In this work we use adversarial contrastive learning to present FoToM, a graph pre-training method based on node and edge feature exclusion. We use FoToM to pre-train models over multiple graph domains, producing the first foundation graph models. We demonstrate positive transfer on evaluation datasets from multiple domains, including domains not present in pre-training data. On all datasets performance is at worst on-par and on 76% significantly better than a supervised baseline ($P \leq 0.01$), with an 8 to 40% reduction in error at 95% confidence. C
    
[^28]: 批量校准：重新思考上下文学习和提示工程的校准方法

    Batch Calibration: Rethinking Calibration for In-Context Learning and Prompt Engineering. (arXiv:2309.17249v1 [cs.CL])

    [http://arxiv.org/abs/2309.17249](http://arxiv.org/abs/2309.17249)

    本研究提出了一种名为批量校准（BC）的方法，用于解决大型语言模型中提示脆弱性和偏见因素导致的性能下降问题。BC通过控制批量输入的上下文偏见，统一了现有的校准方法，并具有零-shot和仅推理的特点。

    

    提示和上下文学习已成为大型语言模型（LLM）的高效学习范式。然而，LLM存在提示脆弱性和各种偏见因素，包括但不限于格式、选择性的表达方式和上下文学习示例。为解决这个导致性能下降的问题，已经开发了校准方法来减轻这些偏见的影响并恢复LLM的性能。在这项工作中，我们首先对现有的校准方法进行了系统分析，提供了统一的观点并揭示了失败案例。受这些分析的启发，我们提出了批量校准（BC），这是一种简单而直观的方法，可以从批量输入中控制上下文偏见，统一了各种先前的方法，并有效地解决了上述问题。BC是零-shot、仅推理和额外成本可忽略。在少-shot设置中，我们进一步扩展BC以实现全部翻译

    Prompting and in-context learning (ICL) have become efficient learning paradigms for large language models (LLMs). However, LLMs suffer from prompt brittleness and various bias factors in the prompt, including but not limited to the formatting, the choice verbalizers, and the ICL examples. To address this problem that results in unexpected performance degradation, calibration methods have been developed to mitigate the effects of these biases while recovering LLM performance. In this work, we first conduct a systematic analysis of the existing calibration methods, where we both provide a unified view and reveal the failure cases. Inspired by these analyses, we propose Batch Calibration (BC), a simple yet intuitive method that controls the contextual bias from the batched input, unifies various prior approaches, and effectively addresses the aforementioned issues. BC is zero-shot, inference-only, and incurs negligible additional costs. In the few-shot setup, we further extend BC to allo
    
[^29]: 生成和评估合成纵向患者数据的方法：一项系统综述

    Methods for generating and evaluating synthetic longitudinal patient data: a systematic review. (arXiv:2309.12380v1 [stat.ME])

    [http://arxiv.org/abs/2309.12380](http://arxiv.org/abs/2309.12380)

    本文对生成和评估合成纵向患者数据的方法进行了系统综述，以解决医学领域中数据使用和隐私保护的问题。

    

    近年来数据的迅猛增长促进了各种统计和深度学习技术的发展和应用，加快了研究和开发活动。然而，并非所有行业都能从数据的增加中同等受益，部分原因是由于数据使用和隐私规定的法律限制，例如医学领域。为了解决这个问题，提出了各种统计披露和隐私保护方法，包括使用合成数据生成。合成数据是基于一些现有数据生成的，目的是尽可能地复制它们，并充当真实敏感数据的代理。本文对生成和评估合成纵向患者数据的方法进行了系统综述，这是医学领域中一种常见的数据类型。该综述遵循PRISMA指南，并涵盖了自2022年底以来的五个数据库的文献。本文描述了17种方法，从传统方法到深度学习方法。

    The proliferation of data in recent years has led to the advancement and utilization of various statistical and deep learning techniques, thus expediting research and development activities. However, not all industries have benefited equally from the surge in data availability, partly due to legal restrictions on data usage and privacy regulations, such as in medicine. To address this issue, various statistical disclosure and privacy-preserving methods have been proposed, including the use of synthetic data generation. Synthetic data are generated based on some existing data, with the aim of replicating them as closely as possible and acting as a proxy for real sensitive data. This paper presents a systematic review of methods for generating and evaluating synthetic longitudinal patient data, a prevalent data type in medicine. The review adheres to the PRISMA guidelines and covers literature from five databases until the end of 2022. The paper describes 17 methods, ranging from traditi
    
[^30]: 跨图像上下文对于Bongard问题很重要

    Cross-Image Context Matters for Bongard Problems. (arXiv:2309.03468v1 [cs.CV])

    [http://arxiv.org/abs/2309.03468](http://arxiv.org/abs/2309.03468)

    Bongard问题是一种需要从一组正负图像中推导出抽象概念并进行分类的智力测试，现有方法在Bongard问题中准确率较低。本研究发现，这是因为现有方法未能整合支持集合中的信息，而是仅依赖于单个支持图像的信息。我们提出了一种通过跨图像上下文来提高准确性的解决方案。

    

    目前的机器学习方法在解决Bongard问题时存在困难。Bongard问题是一种需要从一组正负“支持”图像中推导出抽象“概念”，然后对于新的查询图像进行分类，判断它是否描述了关键概念的智力测试。在用于自然图像Bongard问题的基准测试Bongard-HOI中，现有方法的准确率仅达到了66%（偶然准确率为50%）。低准确率通常归因于神经网络缺乏发现类似人类符号规则的能力。我们指出，许多现有方法由于一个更简单的问题而失去了准确性：它们没有将支持集合中的信息作为一个整体加入，而是依赖于从单个支持中提取的信息。这是一个关键问题，因为与涉及对象分类的少样本学习任务不同，一个典型的Bongard问题中的“关键概念”只能使用多个正例和多个反例来区分。我们探索了一种解决方案，通过跨图像上下文来提高准确性。

    Current machine learning methods struggle to solve Bongard problems, which are a type of IQ test that requires deriving an abstract "concept" from a set of positive and negative "support" images, and then classifying whether or not a new query image depicts the key concept. On Bongard-HOI, a benchmark for natural-image Bongard problems, existing methods have only reached 66% accuracy (where chance is 50%). Low accuracy is often attributed to neural nets' lack of ability to find human-like symbolic rules. In this work, we point out that many existing methods are forfeiting accuracy due to a much simpler problem: they do not incorporate information contained in the support set as a whole, and rely instead on information extracted from individual supports. This is a critical issue, because unlike in few-shot learning tasks concerning object classification, the "key concept" in a typical Bongard problem can only be distinguished using multiple positives and multiple negatives. We explore a
    
[^31]: MM-Vet: 评估大型多模态模型的综合能力

    MM-Vet: Evaluating Large Multimodal Models for Integrated Capabilities. (arXiv:2308.02490v1 [cs.AI])

    [http://arxiv.org/abs/2308.02490](http://arxiv.org/abs/2308.02490)

    MM-Vet是一个评估标准，用于评估大型多模态模型在复杂任务上的综合能力。该标准解决了如何结构化和评估复杂多模态任务、设计适用于不同问题和回答类型的评估指标以及如何提供模型洞察的问题。通过整合不同的核心视觉-语言能力，MM-Vet展示了有趣的能力和解决复杂任务的方法。

    

    我们提出了MM-Vet，一个评估标准，用于检查在复杂多模态任务上的大型多模态模型（LMM）的表现。最近的LMM展示了各种有趣的能力，例如解决书写在黑板上的数学问题，推理新闻图片中的事件和名人，以及解释视觉笑话。快速的模型进步给评估标准的开发带来了挑战。问题包括：（1）如何系统地构建和评估复杂的多模态任务；（2）如何设计适用于不同类型问题和回答的评估指标；（3）如何给出超出简单性能排名的模型洞察。为此，我们提出了MM-Vet，基于这样一个洞察：解决复杂任务的有趣能力通常通过一种通才模型能够整合不同的核心视觉-语言（VL）能力来实现。MM-Vet定义了6个核心VL能力，并检查了从这些能力组合中得出的16种有趣的整合方式。

    We propose MM-Vet, an evaluation benchmark that examines large multimodal models (LMMs) on complicated multimodal tasks. Recent LMMs have shown various intriguing abilities, such as solving math problems written on the blackboard, reasoning about events and celebrities in news images, and explaining visual jokes. Rapid model advancements pose challenges to evaluation benchmark development. Problems include: (1) How to systematically structure and evaluate the complicated multimodal tasks; (2) How to design evaluation metrics that work well across question and answer types; and (3) How to give model insights beyond a simple performance ranking. To this end, we present MM-Vet, designed based on the insight that the intriguing ability to solve complicated tasks is often achieved by a generalist model being able to integrate different core vision-language (VL) capabilities. MM-Vet defines 6 core VL capabilities and examines the 16 integrations of interest derived from the capability combin
    
[^32]: 从无效数据中学习：关于生成模型中的约束满足问题

    Learning from Invalid Data: On Constraint Satisfaction in Generative Models. (arXiv:2306.15166v1 [cs.LG])

    [http://arxiv.org/abs/2306.15166](http://arxiv.org/abs/2306.15166)

    本论文提出了一种新的训练机制，利用包含无效数据点的数据集进行生成模型的训练，以提高生成结果的精度和满足约束条件的能力。实验证明，与只使用有效数据点进行训练的标准模型相比，基于无效数据训练的模型明显优于标准模型。

    

    生成模型在视觉、语言和语音等领域取得了令人印象深刻的结果。然而，即使有大量的数据集，它们仍然在精度上存在困难，生成出物理上无效或事实上不正确的数据。当生成的数据必须满足约束条件时，这一问题尤为严重，例如，在工程设计中满足产品规格或者在自然场景中遵守物理定律。为了提高精度并保持多样性和保真度，我们提出了一种新的训练机制，利用包含无效数据点的数据集进行训练。我们的方法最小化了生成分布与有效先验之间的差异，同时最大化了与无效分布之间的差异。我们演示了将GAN和DDPM等生成模型与无效数据一起训练的方法明显优于仅使用有效数据点进行训练的标准模型。例如，我们的训练过程生成了……

    Generative models have demonstrated impressive results in vision, language, and speech. However, even with massive datasets, they struggle with precision, generating physically invalid or factually incorrect data. This is particularly problematic when the generated data must satisfy constraints, for example, to meet product specifications in engineering design or to adhere to the laws of physics in a natural scene. To improve precision while preserving diversity and fidelity, we propose a novel training mechanism that leverages datasets of constraint-violating data points, which we consider invalid. Our approach minimizes the divergence between the generative distribution and the valid prior while maximizing the divergence with the invalid distribution. We demonstrate how generative models like GANs and DDPMs that we augment to train with invalid data vastly outperform their standard counterparts which solely train on valid data points. For example, our training procedure generates up 
    
[^33]: 关于文本到图像扩散模型的架构压缩问题研究

    On Architectural Compression of Text-to-Image Diffusion Models. (arXiv:2305.15798v1 [cs.LG])

    [http://arxiv.org/abs/2305.15798](http://arxiv.org/abs/2305.15798)

    本文研究了如何通过架构压缩方法实现文本到图像生成模型的高效化，提出了一种块删除知识提取SDMs（BK-SDMs）方法，在减少采样步骤数量和利用网络量化的同时，可以显著减少模型的参数数量、MAC和延迟，最终实现了与使用更多资源训练的模型相竞争的效果。

    

    稳定扩散模型（SDMs）中出色的文本到图像（T2I）生成结果需要大量计算资源。为了解决这个问题，近期关于高效SDMs的研究将重点放在减少采样步骤的数量和利用网络量化上。与这些方向相反，本研究通过引入块删除知识提取SDMs（BK-SDMs），强调了经典架构压缩在通用T2I合成中的作用。我们从SDMs的U-Net中删除了几个残差和注意力块，使参数数量、每个采样步骤的MAC和延迟减少了超过30％。我们在单个A100 GPU上仅使用0.22M LAION对进行蒸馏预训练（少于全体训练对的0.1％）。尽管使用有限的资源进行训练，我们的紧凑型模型可以通过传递的知识模仿原始SDM，并在对抗较大的多十亿参数模型的情况下实现具有竞争力的结果。

    Exceptional text-to-image (T2I) generation results of Stable Diffusion models (SDMs) come with substantial computational demands. To resolve this issue, recent research on efficient SDMs has prioritized reducing the number of sampling steps and utilizing network quantization. Orthogonal to these directions, this study highlights the power of classical architectural compression for general-purpose T2I synthesis by introducing block-removed knowledge-distilled SDMs (BK-SDMs). We eliminate several residual and attention blocks from the U-Net of SDMs, obtaining over a 30% reduction in the number of parameters, MACs per sampling step, and latency. We conduct distillation-based pretraining with only 0.22M LAION pairs (fewer than 0.1% of the full training pairs) on a single A100 GPU. Despite being trained with limited resources, our compact models can imitate the original SDM by benefiting from transferred knowledge and achieve competitive results against larger multi-billion parameter models
    
[^34]: 正则化和多视角支持向量机学习的本地化

    Localisation of Regularised and Multiview Support Vector Machine Learning. (arXiv:2304.05655v1 [math.FA])

    [http://arxiv.org/abs/2304.05655](http://arxiv.org/abs/2304.05655)

    本文针对正则化和多视角支持向量机学习问题的本地化版本，证明了一些表示定理，研究了与损失函数和输入空间维度相关的特殊情况，特别是损失函数为 Gâteaux 可微函数时的情况。

    

    本文证明了 H.Q. Minh、L. Bazzani 和 V. Murino 在《机器学习研究》（Journal of Machine Learning Research）中介绍的一种涉及算子值正定核及其再生核希尔伯特空间的正则化和多视角支持向量机学习问题的本地化版本的一些表示定理。结果涉及到考虑凸或非凸损失函数以及有限或无限维输入空间的一般情况。我们展示了该一般框架允许一些特殊情况下的无限维输入空间和非凸损失函数，特别是当损失函数为 Gâteaux 可微函数时。对导致部分非线性问题的指数最小二乘损失函数进行了详细计算。

    We prove a few representer theorems for a localised version of the regularised and multiview support vector machine learning problem introduced by H.Q.~Minh, L.~Bazzani, and V.~Murino, \textit{Journal of Machine Learning Research}, \textbf{17}(2016) 1--72, that involves operator valued positive semidefinite kernels and their reproducing kernel Hilbert spaces. The results concern general cases when convex or nonconvex loss functions and finite or infinite dimensional input spaces are considered. We show that the general framework allows infinite dimensional input spaces and nonconvex loss functions for some special cases, in particular in case the loss functions are G\^ateaux differentiable. Detailed calculations are provided for the exponential least squares loss functions that leads to partially nonlinear problems.
    
[^35]: 一种用于正交约束下的非光滑组合优化的块坐标下降方法

    A Block Coordinate Descent Method for Nonsmooth Composite Optimization under Orthogonality Constraints. (arXiv:2304.03641v1 [math.OC])

    [http://arxiv.org/abs/2304.03641](http://arxiv.org/abs/2304.03641)

    本文提出了一种新的块坐标下降方法OBCD，用于解决具有正交约束的一般非光滑组合问题。 OBCD是一种可行的方法，具有低的计算复杂性，并且获得严格的收敛保证。

    

    具有正交约束的非光滑组合优化在统计学习和数据科学中有广泛的应用。由于其非凸性和非光滑性质，该问题通常很难求解。现有的解决方案受到以下一个或多个限制的限制：（i）它们是需要每次迭代高计算成本的全梯度方法；（ii）它们无法解决一般的非光滑组合问题；（iii）它们是不可行方法，并且只能在极限点处实现解的可行性；（iv）它们缺乏严格的收敛保证；（v）它们只能获得关键点的弱最优性。在本文中，我们提出了一种新的块坐标下降方法OBCD，用于解决正交约束下的一般非光滑组合问题。OBCD是一种可行的方法，具有低的计算复杂性。在每次迭代中，我们的算法会更新...

    Nonsmooth composite optimization with orthogonality constraints has a broad spectrum of applications in statistical learning and data science. However, this problem is generally challenging to solve due to its non-convex and non-smooth nature. Existing solutions are limited by one or more of the following restrictions: (i) they are full gradient methods that require high computational costs in each iteration; (ii) they are not capable of solving general nonsmooth composite problems; (iii) they are infeasible methods and can only achieve the feasibility of the solution at the limit point; (iv) they lack rigorous convergence guarantees; (v) they only obtain weak optimality of critical points. In this paper, we propose \textit{\textbf{OBCD}}, a new Block Coordinate Descent method for solving general nonsmooth composite problems under Orthogonality constraints. \textit{\textbf{OBCD}} is a feasible method with low computation complexity footprints. In each iteration, our algorithm updates $
    
[^36]: 基于矩阵自回归的联邦学习拜占庭容错聚合方案

    A Byzantine-Resilient Aggregation Scheme for Federated Learning via Matrix Autoregression on Client Updates. (arXiv:2303.16668v1 [cs.LG])

    [http://arxiv.org/abs/2303.16668](http://arxiv.org/abs/2303.16668)

    本文提出了FLANDERS，一种基于矩阵自回归的联邦学习聚合方案，可以识别恶意客户端，并提供了强大的拜占庭攻击防御。

    

    本文提出了FLANDERS，一种新颖的联邦学习（FL）聚合方案，可以抵御拜占庭攻击。FLANDERS将每个FL轮次中由客户端发送的本地模型更新视为矩阵值时间序列。然后，通过将实际观测与由矩阵自回归预测模型估计的观测进行比较，识别恶意客户端作为这个时间序列的异常值。在不同FL设置下对多个数据集进行的实验证明，FLANDERS在抵御拜占庭攻击方面与最强大的基线相匹配。此外，与现有的防御策略相比， FLANDERS即使在极其严重的攻击场景下仍然非常有效。

    In this work, we propose FLANDERS, a novel federated learning (FL) aggregation scheme robust to Byzantine attacks. FLANDERS considers the local model updates sent by clients at each FL round as a matrix-valued time series. Then, it identifies malicious clients as outliers of this time series by comparing actual observations with those estimated by a matrix autoregressive forecasting model. Experiments conducted on several datasets under different FL settings demonstrate that FLANDERS matches the robustness of the most powerful baselines against Byzantine clients. Furthermore, FLANDERS remains highly effective even under extremely severe attack scenarios, as opposed to existing defense strategies.
    
[^37]: 图像统计与人类感知之间的关联关系分离

    Disentangling the Link Between Image Statistics and Human Perception. (arXiv:2303.09874v1 [cs.CV])

    [http://arxiv.org/abs/2303.09874](http://arxiv.org/abs/2303.09874)

    本研究直接评估自然图像的概率，并分析它如何影响人类感知。通过展示具有更丰富统计特征的自然图像被感知为具有更大的显着性，论文提供了直接支持Barlow和Attneave理论的证据，并建立了一个新的框架，用于理解图像统计与知觉之间的关系。

    

    在20世纪50年代，霍勒斯巴洛和弗雷德阿特纳夫提出了感官系统和它们如何适应环境之间的关系：早期视觉的进化是为了最大限度地传递关于输入信号的信息。按照香农的定义，这些信息是通过自然场景中拍摄的图像的概率来描述的。由于计算能力的限制，以前无法直接准确地预测图像的概率。尽管这种想法的探索是间接的，主要基于图像密度的过度简化模型或系统设计方法，但这些方法在重现各种生理和心理物理现象方面取得了成功。在本文中，我们直接评估自然图像的概率，并分析它如何确定知觉灵敏度。我们使用与人类意见相关性很高的图像质量指标作为人类视觉的代理，以及一个先进的生成模型来直接估计自然图像的概率密度函数。我们的结果表明，根据Barlow和Attneave理论预测的图像统计与人类知觉之间存在系统性的关联。我们通过展示具有更丰富统计特征的自然图像被感知为具有更大的显着性来说明这一发现，这是通过视觉搜索实验测量的。我们的工作提供了直接支持Barlow和Attneave理论的证据，并建立了一个新的框架，用于理解图像统计与知觉之间的关系。

    In the 1950s Horace Barlow and Fred Attneave suggested a connection between sensory systems and how they are adapted to the environment: early vision evolved to maximise the information it conveys about incoming signals. Following Shannon's definition, this information was described using the probability of the images taken from natural scenes. Previously, direct accurate predictions of image probabilities were not possible due to computational limitations. Despite the exploration of this idea being indirect, mainly based on oversimplified models of the image density or on system design methods, these methods had success in reproducing a wide range of physiological and psychophysical phenomena. In this paper, we directly evaluate the probability of natural images and analyse how it may determine perceptual sensitivity. We employ image quality metrics that correlate well with human opinion as a surrogate of human vision, and an advanced generative model to directly estimate the probabil
    
[^38]: 旋转不变量量化用于模型压缩

    Rotation Invariant Quantization for Model Compression. (arXiv:2303.03106v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.03106](http://arxiv.org/abs/2303.03106)

    本研究提出了一种旋转不变量量化（RIQ）技术，可以在不同层次上实现混合精度量化，用于后训练神经网络模型压缩，并证明了其在压缩方面的优势。在多种模型和任务上进行了严格评估，取得了令人满意的结果。

    

    后训练神经网络（NN）模型压缩是一种将大型、消耗内存的模型部署到内存资源有限设备上的吸引人的方法。本研究探讨了NN模型压缩的速率-失真权衡。首先，我们提出了一种旋转不变量量化（RIQ）技术，它利用一个单一参数量化整个NN模型，在每个层次上得到不同的速率，即混合精度量化。然后，我们证明了我们的旋转不变量方法在压缩方面的优势。我们对RIQ进行了严格评估，并展示了它在各种模型和任务上的能力。例如，RIQ在预训练的VGG稠密和修剪模型上分别实现了19.4倍和52.9倍的压缩比，精度降低小于0.4%。代码可以在\url{https://github.com/ehaleva/RIQ}上找到。

    Post-training Neural Network (NN) model compression is an attractive approach for deploying large, memory-consuming models on devices with limited memory resources. In this study, we investigate the rate-distortion tradeoff for NN model compression. First, we suggest a Rotation-Invariant Quantization (RIQ) technique that utilizes a single parameter to quantize the entire NN model, yielding a different rate at each layer, i.e., mixed-precision quantization. Then, we prove that our rotation-invariant approach is optimal in terms of compression. We rigorously evaluate RIQ and demonstrate its capabilities on various models and tasks. For example, RIQ facilitates $\times 19.4$ and $\times 52.9$ compression ratios on pre-trained VGG dense and pruned models, respectively, with $<0.4\%$ accuracy degradation. Code is available in \url{https://github.com/ehaleva/RIQ}.
    
[^39]: 一种双层经验风险最小化算法的下界和近似最优算法

    A Lower Bound and a Near-Optimal Algorithm for Bilevel Empirical Risk Minimization. (arXiv:2302.08766v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.08766](http://arxiv.org/abs/2302.08766)

    该论文提出了一种双层经验风险最小化算法，使用的梯度计算次数 $O((n+m)^{\frac{1}{2}}\varepsilon^{-1})$，在样本复杂度方面是最优的。

    

    双层最优化问题越来越多地应用于机器学习中。在许多实际情况下，上层和下层目标对应于经验风险最小化问题，并因此具有总和结构。在这个背景下，我们提出了一个著名的SARAH算法的双层扩展。我们证明了该算法需要$\mathcal {O}((n+m)^{\frac{1}{2}}\varepsilon ^{-1})$次梯度计算才能实现$\varepsilon$稳定性，其中$n+m$是样本总数，这比先前所有的双层算法都要好。此外，我们提供了一个下界，用于得到双层问题的目标函数的近似稳定点所需的oracle调用次数。这个下界正是我们的算法所达到的，因此在样本复杂度方面是最优的。

    Bilevel optimization problems, which are problems where two optimization problems are nested, have more and more applications in machine learning. In many practical cases, the upper and the lower objectives correspond to empirical risk minimization problems and therefore have a sum structure. In this context, we propose a bilevel extension of the celebrated SARAH algorithm. We demonstrate that the algorithm requires $\mathcal{O}((n+m)^{\frac12}\varepsilon^{-1})$ gradient computations to achieve $\varepsilon$-stationarity with $n+m$ the total number of samples, which improves over all previous bilevel algorithms. Moreover, we provide a lower bound on the number of oracle calls required to get an approximate stationary point of the objective function of the bilevel problem. This lower bound is attained by our algorithm, which is therefore optimal in terms of sample complexity.
    
[^40]: 循环揭示了复杂时间序列的共享因果驱动者

    Recurrences reveal shared causal drivers of complex time series. (arXiv:2301.13516v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.13516](http://arxiv.org/abs/2301.13516)

    该研究开发了一种新的无监督学习算法，能够使用时间序列测量中的复现逐渐重构未被观察到的驱动信号，从而可靠地推断共享因果驱动者，其已在多个示例中进行验证。

    

    许多实验时间序列测量共享未被观察到的因果驱动器。例如，受转录因子靶向的基因、受大尺度大气环流影响的海洋流动，以及被下降神经元控制的电机电路。可靠地推断这种看不见的驱动力是必要的，以了解不同生物和工程系统中自上而下控制方案的间歇性本质。在这里，我们介绍了一种新的无监督学习算法，该算法使用时间序列测量中的复现逐渐重构未被观察到的驱动信号。借助于斜积动力系统的数学理论，我们确定了响应时间序列间共享的复现事件，这些事件隐含地定义了一个具有玻璃状结构的复现图。随着观察到的数据量或质量的改善，该复现图经历了一个渗流转变，表现为随机行走在诱导的景观上出现微弱的遍历性破裂 - 暴露出共享驱动信号作为少数参数的函数。我们在几个合成示例中展示了算法的性能。最后，我们将我们的方法应用于现实生态数据集，并确定了厄尔尼诺、季节性鱼类迁移和果蝇种群动态的驱动因素。

    Many experimental time series measurements share unobserved causal drivers. Examples include genes targeted by transcription factors, ocean flows influenced by large-scale atmospheric currents, and motor circuits steered by descending neurons. Reliably inferring this unseen driving force is necessary to understand the intermittent nature of top-down control schemes in diverse biological and engineered systems. Here, we introduce a new unsupervised learning algorithm that uses recurrences in time series measurements to gradually reconstruct an unobserved driving signal. Drawing on the mathematical theory of skew-product dynamical systems, we identify recurrence events shared across response time series, which implicitly define a recurrence graph with glass-like structure. As the amount or quality of observed data improves, this recurrence graph undergoes a percolation transition manifesting as weak ergodicity breaking for random walks on the induced landscape -- revealing the shared dri
    

