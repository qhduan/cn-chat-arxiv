# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [End-To-End Self-tuning Self-supervised Time Series Anomaly Detection](https://arxiv.org/abs/2404.02865) | 提出了TSAP方法来自动调整数据增强，为时间序列异常检测带来了端到端的自调节能力。 |
| [^2] | [Supervised Multiple Kernel Learning approaches for multi-omics data integration](https://arxiv.org/abs/2403.18355) | MKL方法提供了一种灵活有效的多组学数据集成方法，可以与复杂的监督式多组学整合方法竞争 |
| [^3] | [Joint chest X-ray diagnosis and clinical visual attention prediction with multi-stage cooperative learning: enhancing interpretability](https://arxiv.org/abs/2403.16970) | 该论文引入了一种新的深度学习框架，用于联合疾病诊断和胸部X光扫描对应视觉显著性图的预测，通过设计新颖的双编码器多任务UNet并利用多尺度特征融合分类器来提高计算辅助诊断的可解释性和质量。 |
| [^4] | [Learning from Reduced Labels for Long-Tailed Data](https://arxiv.org/abs/2403.16469) | 提出了一种名为Reduced Label的新型弱监督标签设置，能够高效地学习长尾数据，避免了尾部样本监督信息的下降，降低了标签成本 |
| [^5] | [Text clustering with LLM embeddings](https://arxiv.org/abs/2403.15112) | 研究表明，LLM嵌入能够捕捉结构化语言的细微差别，BERT在性能上领先于轻量级选项，增加嵌入维度和摘要技术并不一致地提高聚类效率 |
| [^6] | [A Physics-embedded Deep Learning Framework for Cloth Simulation](https://arxiv.org/abs/2403.12820) | 该论文提出了一种基于物理的深度学习框架，可以直接编码布料模拟的物理特征，实现快速和实时模拟，并在不使用新数据训练的情况下通过测试表现出与基线的一致性。 |
| [^7] | [Reliable uncertainty with cheaper neural network ensembles: a case study in industrial parts classification](https://arxiv.org/abs/2403.10182) | 研究在工业零部件分类中探讨了利用更便宜的神经网络集成实现可靠的不确定性估计的方法 |
| [^8] | [AutoGuide: Automated Generation and Selection of State-Aware Guidelines for Large Language Model Agents](https://arxiv.org/abs/2403.08978) | AutoGuide通过提取嵌入在离线数据中的知识，生成一组状态感知指南，从而弥合大型语言模型中的知识差距，为代理的决策过程提供有用的知识。 |
| [^9] | [Governance of Generative Artificial Intelligence for Companies](https://arxiv.org/abs/2403.08802) | 本综述填补了有关企业中生成式人工智能（GenAI）治理的研究空白，提出了一个框架，旨在利用业务机会并减轻与GenAI整合相关风险。 |
| [^10] | [A Generative Model of Symmetry Transformations](https://arxiv.org/abs/2403.01946) | 通过构建一种生成模型来明确捕捉数据中的对称变换，从而提高模型的泛化能力和稳健性。 |
| [^11] | [Using text embedding models and vector databases as text classifiers with the example of medical data](https://arxiv.org/abs/2402.16886) | 向量数据库和嵌入模型的应用为文本分类器提供了强大的方式来表达数据模式，特别是在医疗领域中开始有着广泛的应用。 |
| [^12] | [Expressive Higher-Order Link Prediction through Hypergraph Symmetry Breaking](https://arxiv.org/abs/2402.11339) | 通过引入预处理算法识别展现对称性的正则子超图，从而提高超图在高阶链接预测中的表达能力和区分能力。 |
| [^13] | [CultureLLM: Incorporating Cultural Differences into Large Language Models](https://arxiv.org/abs/2402.10946) | 提出了一种名为CultureLLM的成本效益高的解决方案，通过使用世界价值调查（WVS）作为种子数据，并通过提出的语义数据增强来将文化差异纳入大型语言模型中，成功微调得到了涵盖富裕和低资源语言的9种文化特定LLMs以及一个统一模型（CultureLLM-One）。 |
| [^14] | [Scalable Kernel Logistic Regression with Nystr\"om Approximation: Theoretical Analysis and Application to Discrete Choice Modelling](https://arxiv.org/abs/2402.06763) | 本文介绍了使用Nystr\"om近似方法解决大规模数据集上核逻辑回归的可扩展性问题。研究提供了理论分析并验证了不同的地标选择方法的性能。 |
| [^15] | [Pard: Permutation-Invariant Autoregressive Diffusion for Graph Generation](https://arxiv.org/abs/2402.03687) | PARD是一种将扩散模型与自回归方法相结合的置换不变性自回归扩散模型，通过使用图中的部分顺序以块逐块的自回归方式生成图。 |
| [^16] | [Normalizing flows as approximations of optimal transport maps via linear-control neural ODEs.](http://arxiv.org/abs/2311.01404) | 本文以线性控制神经ODE的流动作为归一化流构造最优传输映射的近似。通过离散最优耦合问题和数值方案，实现了对最优传输映射的近似。最终结果有助于构建深度神经网络中的可逆传输映射。 |
| [^17] | [Vibroacoustic Frequency Response Prediction with Query-based Operator Networks.](http://arxiv.org/abs/2310.05469) | 该论文提出了一个基于查询式操作网络的振动声学频响预测方法，并设计了一个用于代表性振动声学问题的结构化基准测试。该方法可以加速频响模拟，有助于设计优化和不确定性量化。 |
| [^18] | [Representation Learning for Sequential Volumetric Design Tasks.](http://arxiv.org/abs/2309.02583) | 本研究提出了一种顺序体积设计任务的表示学习方法，通过利用transformer模型从专家的设计序列中提取有用的表示来提高自动生成体积设计的质量，以及支持设计偏好评估和程序化设计生成。 |
| [^19] | [COMCAT: Towards Efficient Compression and Customization of Attention-Based Vision Models.](http://arxiv.org/abs/2305.17235) | 本文提出了一种高效的 Vision Transformer 压缩方法，在多头注意力层上进行了新的探究，相比当前最先进的剪枝方法表现更优，能够在使用更少参数的情况下提高模型精度。 |
| [^20] | [Synergies Between Federated Learning and O-RAN: Towards an Elastic Virtualized Architecture for Multiple Distributed Machine Learning Services.](http://arxiv.org/abs/2305.02109) | 本文研究了联邦学习在现代无线网络下的挑战，提出了一种方法称为动态多服务联邦学习（DMS-FL）来解决这个问题。同时，还提出了一种名为弹性虚拟化联邦学习（EV-FL）的分布式机器学习架构，来支持DMS-FL中的设计要求。 |
| [^21] | [Importance Weighted Expectation-Maximization for Protein Sequence Design.](http://arxiv.org/abs/2305.00386) | 本文提出了一种名为IsEM-Pro的方法，用于根据给定适应性标准生成蛋白质序列。在推理期间，从其潜在空间采样可以增加多样性，指导了探索高适应性区域。实验表明，相比先前最佳方法，IsEM-Pro的平均适应性得分至少高出55％，并生成了更多样化和新颖的蛋白质序列。 |
| [^22] | [The Descriptive Complexity of Graph Neural Networks.](http://arxiv.org/abs/2303.04613) | 研究分析了图神经网络（GNN）在布尔电路复杂性和描述性复杂性方面的能力，证明了多项式规模有界深度的GNN族族可以计算的图查询正是带计数和内置关系的一阶逻辑受保护的片断GFO+C所定义的，这将GNN放在电路复杂性类TC^0中。 |

# 详细

[^1]: 端到端自调节自监督时间序列异常检测

    End-To-End Self-tuning Self-supervised Time Series Anomaly Detection

    [https://arxiv.org/abs/2404.02865](https://arxiv.org/abs/2404.02865)

    提出了TSAP方法来自动调整数据增强，为时间序列异常检测带来了端到端的自调节能力。

    

    时间序列异常检测（TSAD）在监控环境传感器、行业KPI、患者生物标志物等方面有许多应用。TSAD的一个双重挑战是需要一种多功能且无监督模型，能够检测各种不同类型的时间序列异常（尖峰、不连续、趋势变化等），而不需要任何标记的数据。我们的工作旨在填补这一空白。我们引入了TSAP来执行TSA“自动驾驶”，可以端到端自动调整数据增强的超参数，自适应选择数据增强策略。

    arXiv:2404.02865v1 Announce Type: new  Abstract: Time series anomaly detection (TSAD) finds many applications such as monitoring environmental sensors, industry KPIs, patient biomarkers, etc. A two-fold challenge for TSAD is a versatile and unsupervised model that can detect various different types of time series anomalies (spikes, discontinuities, trend shifts, etc.) without any labeled data. Modern neural networks have outstanding ability in modeling complex time series. Self-supervised models in particular tackle unsupervised TSAD by transforming the input via various augmentations to create pseudo anomalies for training. However, their performance is sensitive to the choice of augmentation, which is hard to choose in practice, while there exists no effort in the literature on data augmentation tuning for TSAD without labels. Our work aims to fill this gap. We introduce TSAP for TSA "on autoPilot", which can (self-)tune augmentation hyperparameters end-to-end. It stands on two key c
    
[^2]: 监督多核学习方法用于多组学数据集成

    Supervised Multiple Kernel Learning approaches for multi-omics data integration

    [https://arxiv.org/abs/2403.18355](https://arxiv.org/abs/2403.18355)

    MKL方法提供了一种灵活有效的多组学数据集成方法，可以与复杂的监督式多组学整合方法竞争

    

    高通量技术的进展导致越来越多的组学数据集的可用性。多种异质数据源的集成目前是生物学和生物信息学领域的一个问题。多核学习（MKL）已被证明是一种灵活和有效的方法，可以考虑多组学输入的多样性，尽管它在基因组数据挖掘中是一种不常用的工具。我们提供了基于不同核融合策略的新颖MKL方法。为了从输入核的元核中学习，我们将无监督集成算法调整为支持向量机的监督任务。我们还测试了用于核融合和分类的深度学习架构。结果显示，基于MKL的模型可以与更复杂、最先进的监督式多组学整合方法竞争。多核学习为多组学基因组数据中的预测模型提供了一个自然的框架。

    arXiv:2403.18355v1 Announce Type: cross  Abstract: Advances in high-throughput technologies have originated an ever-increasing availability of omics datasets. The integration of multiple heterogeneous data sources is currently an issue for biology and bioinformatics. Multiple kernel learning (MKL) has shown to be a flexible and valid approach to consider the diverse nature of multi-omics inputs, despite being an underused tool in genomic data mining.We provide novel MKL approaches based on different kernel fusion strategies.To learn from the meta-kernel of input kernels, we adaptedunsupervised integration algorithms for supervised tasks with support vector machines.We also tested deep learning architectures for kernel fusion and classification.The results show that MKL-based models can compete with more complex, state-of-the-art, supervised multi-omics integrative approaches. Multiple kernel learning offers a natural framework for predictive models in multi-omics genomic data. Our resu
    
[^3]: 联合胸部X光诊断和临床视觉注意力预测的多阶段协作学习：增强可解释性

    Joint chest X-ray diagnosis and clinical visual attention prediction with multi-stage cooperative learning: enhancing interpretability

    [https://arxiv.org/abs/2403.16970](https://arxiv.org/abs/2403.16970)

    该论文引入了一种新的深度学习框架，用于联合疾病诊断和胸部X光扫描对应视觉显著性图的预测，通过设计新颖的双编码器多任务UNet并利用多尺度特征融合分类器来提高计算辅助诊断的可解释性和质量。

    

    随着深度学习成为计算辅助诊断的最新技术，自动决策的可解释性对临床部署至关重要。尽管在这一领域提出了各种方法，但在放射学筛查过程中临床医生的视觉注意力图为提供重要洞察提供了独特的资产，并有可能提高计算辅助诊断的质量。通过这篇论文，我们引入了一种新颖的深度学习框架，用于联合疾病诊断和胸部X光扫描对应视觉显著性图的预测。具体来说，我们设计了一种新颖的双编码器多任务UNet，利用了DenseNet201主干和基于残差和膨胀激励块的编码器来提取用于显著性图预测的多样特征，并使用多尺度特征融合分类器进行疾病分类。

    arXiv:2403.16970v1 Announce Type: cross  Abstract: As deep learning has become the state-of-the-art for computer-assisted diagnosis, interpretability of the automatic decisions is crucial for clinical deployment. While various methods were proposed in this domain, visual attention maps of clinicians during radiological screening offer a unique asset to provide important insights and can potentially enhance the quality of computer-assisted diagnosis. With this paper, we introduce a novel deep-learning framework for joint disease diagnosis and prediction of corresponding visual saliency maps for chest X-ray scans. Specifically, we designed a novel dual-encoder multi-task UNet, which leverages both a DenseNet201 backbone and a Residual and Squeeze-and-Excitation block-based encoder to extract diverse features for saliency map prediction, and a multi-scale feature-fusion classifier to perform disease classification. To tackle the issue of asynchronous training schedules of individual tasks
    
[^4]: 学习从减少标签的长尾数据中

    Learning from Reduced Labels for Long-Tailed Data

    [https://arxiv.org/abs/2403.16469](https://arxiv.org/abs/2403.16469)

    提出了一种名为Reduced Label的新型弱监督标签设置，能够高效地学习长尾数据，避免了尾部样本监督信息的下降，降低了标签成本

    

    长尾数据在现实世界的分类任务中普遍存在，并且严重依赖监督信息，这使得注释过程异常耗时且费力。然而，尽管减少标注成本是缓解标签成本的常见方法，但现有的弱监督学习方法很难充分保留尾部样本的监督信息，导致尾部类别的准确率下降。为了缓解这一问题，我们提出了一种名为Reduced Label的新型弱监督标签设置。所提出的标签设置不仅避免了尾部样本的监督信息下降，还减少了与长尾数据相关的标签成本。此外，我们提出了一个简单直观且高效的无偏框架，具有强大的理论保证，可以从这些Reduced Labels中学习。在包括Imag在内的基准数据集上进行了广泛的实验

    arXiv:2403.16469v1 Announce Type: new  Abstract: Long-tailed data is prevalent in real-world classification tasks and heavily relies on supervised information, which makes the annotation process exceptionally labor-intensive and time-consuming. Unfortunately, despite being a common approach to mitigate labeling costs, existing weakly supervised learning methods struggle to adequately preserve supervised information for tail samples, resulting in a decline in accuracy for the tail classes. To alleviate this problem, we introduce a novel weakly supervised labeling setting called Reduced Label. The proposed labeling setting not only avoids the decline of supervised information for the tail samples, but also decreases the labeling costs associated with long-tailed data. Additionally, we propose an straightforward and highly efficient unbiased framework with strong theoretical guarantees to learn from these Reduced Labels. Extensive experiments conducted on benchmark datasets including Imag
    
[^5]: 使用LLM嵌入进行文本聚类

    Text clustering with LLM embeddings

    [https://arxiv.org/abs/2403.15112](https://arxiv.org/abs/2403.15112)

    研究表明，LLM嵌入能够捕捉结构化语言的细微差别，BERT在性能上领先于轻量级选项，增加嵌入维度和摘要技术并不一致地提高聚类效率

    

    文本聚类是组织不断增长的数字内容的重要方法，有助于结构化和发现未分类数据中的隐藏模式。在这项研究中，我们调查了不同文本嵌入（特别是大型语言模型LLMs中使用的）和聚类算法如何影响文本数据集的聚类方式。进行了一系列实验以评估嵌入是如何影响聚类结果的，以及通过摘要进行降维和嵌入大小调整的作用。结果显示，LLM嵌入在捕获结构化语言的细微差别方面表现出色，而BERT在性能上领先于轻量级选项。此外，我们发现增加嵌入维度和摘要技术并不一致地提高聚类效率，这表明这些策略需要仔细分析才能在实际模型中使用。这些结果突出了一种

    arXiv:2403.15112v1 Announce Type: cross  Abstract: Text clustering is an important approach for organising the growing amount of digital content, helping to structure and find hidden patterns in uncategorised data. In this research, we investigated how different textual embeddings - particularly those used in large language models (LLMs) - and clustering algorithms affect how text datasets are clustered. A series of experiments were conducted to assess how embeddings influence clustering results, the role played by dimensionality reduction through summarisation, and embedding size adjustment. Results reveal that LLM embeddings excel at capturing the nuances of structured language, while BERT leads the lightweight options in performance. In addition, we find that increasing embedding dimensionality and summarisation techniques do not uniformly improve clustering efficiency, suggesting that these strategies require careful analysis to use in real-life models. These results highlight a co
    
[^6]: 一种基于物理的深度学习框架用于布料模拟

    A Physics-embedded Deep Learning Framework for Cloth Simulation

    [https://arxiv.org/abs/2403.12820](https://arxiv.org/abs/2403.12820)

    该论文提出了一种基于物理的深度学习框架，可以直接编码布料模拟的物理特征，实现快速和实时模拟，并在不使用新数据训练的情况下通过测试表现出与基线的一致性。

    

    精细的布料模拟长期以来一直是计算机图形学中所期望的。为改进受力交互、碰撞处理和数值积分，提出了各种方法。深度学习有潜力实现快速和实时模拟，但常见的神经网络结构通常需要大量参数来捕获布料动力学。本文提出了一种直接编码布料模拟物理特征的物理嵌入学习框架。卷积神经网络用于表示质点-弹簧系统的空间相关性，之后设计了三个分支来学习布料物理的线性、非线性和时间导数特征。该框架还可以通过传统模拟器或子神经网络与其他外部力和碰撞处理进行集成。模型在不使用新数据进行训练的情况下，在不同的布料动画案例中进行了测试。与基线的一致性

    arXiv:2403.12820v1 Announce Type: cross  Abstract: Delicate cloth simulations have long been desired in computer graphics. Various methods were proposed to improve engaged force interactions, collision handling, and numerical integrations. Deep learning has the potential to achieve fast and real-time simulation, but common neural network structures often demand many parameters to capture cloth dynamics. This paper proposes a physics-embedded learning framework that directly encodes physical features of cloth simulation. The convolutional neural network is used to represent spatial correlations of the mass-spring system, after which three branches are designed to learn linear, nonlinear, and time derivate features of cloth physics. The framework can also integrate with other external forces and collision handling through either traditional simulators or sub neural networks. The model is tested across different cloth animation cases, without training with new data. Agreement with baselin
    
[^7]: 用更便宜的神经网络集成实现可靠的不确定性：工业零部件分类案例研究

    Reliable uncertainty with cheaper neural network ensembles: a case study in industrial parts classification

    [https://arxiv.org/abs/2403.10182](https://arxiv.org/abs/2403.10182)

    研究在工业零部件分类中探讨了利用更便宜的神经网络集成实现可靠的不确定性估计的方法

    

    在运筹学(OR)中，预测模型经常会遇到数据分布与训练数据分布不同的场景。近年来，神经网络(NNs)在图像分类等领域的出色性能使其在OR中备受关注。然而，当面对OOD数据时，NNs往往会做出自信但不正确的预测。不确定性估计为自信的模型提供了一个解决方案，当输出应(不应)被信任时进行通信。因此，在OR领域中，NNs中的可靠不确定性量化至关重要。由多个独立NNs组成的深度集合已经成为一种有前景的方法，不仅提供强大的预测准确性，还能可靠地估计不确定性。然而，它们的部署由于较大的计算需求而具有挑战性。最近的基础研究提出了更高效的NN集成，即sna

    arXiv:2403.10182v1 Announce Type: new  Abstract: In operations research (OR), predictive models often encounter out-of-distribution (OOD) scenarios where the data distribution differs from the training data distribution. In recent years, neural networks (NNs) are gaining traction in OR for their exceptional performance in fields such as image classification. However, NNs tend to make confident yet incorrect predictions when confronted with OOD data. Uncertainty estimation offers a solution to overconfident models, communicating when the output should (not) be trusted. Hence, reliable uncertainty quantification in NNs is crucial in the OR domain. Deep ensembles, composed of multiple independent NNs, have emerged as a promising approach, offering not only strong predictive accuracy but also reliable uncertainty estimation. However, their deployment is challenging due to substantial computational demands. Recent fundamental research has proposed more efficient NN ensembles, namely the sna
    
[^8]: AutoGuide: 大型语言模型代理的自动生成和选择状态感知指南

    AutoGuide: Automated Generation and Selection of State-Aware Guidelines for Large Language Model Agents

    [https://arxiv.org/abs/2403.08978](https://arxiv.org/abs/2403.08978)

    AutoGuide通过提取嵌入在离线数据中的知识，生成一组状态感知指南，从而弥合大型语言模型中的知识差距，为代理的决策过程提供有用的知识。

    

    大型语言模型（LLMs）的主要局限性是它们对世界的理解受限。这给基于LLMs的代理带来了重大困难，特别是在预训练的LLMs缺乏足够知识的领域。在本文中，我们介绍了一个名为AutoGuide的新框架，通过利用离线经验中的隐含知识来弥合预训练LLMs中的知识差距。具体而言，AutoGuide通过提取一组状态感知指南有效地提取嵌入在离线数据中的知识。每个状态感知指南以简洁的自然语言表达，并遵循条件结构，清晰描述适用的状态。因此，由此产生的指南为向代理当前的决策过程提供有用的知识提供了一种原则性的方法。我们展示了我们的方法在顺序任务中大幅领先于竞争的基于LLMs的基线。

    arXiv:2403.08978v1 Announce Type: new  Abstract: The primary limitation of large language models (LLMs) is their restricted understanding of the world. This poses significant difficulties for LLM-based agents, particularly in domains where pre-trained LLMs lack sufficient knowledge. In this paper, we introduce a novel framework, called AutoGuide, that bridges the knowledge gap in pre-trained LLMs by leveraging implicit knowledge in offline experiences. Specifically, AutoGuide effectively extracts knowledge embedded in offline data by extracting a set of state-aware guidelines. Importantly, each state-aware guideline is expressed in concise natural language and follows a conditional structure, clearly describing the state where it is applicable. As such, the resulting guidelines enable a principled way to provide helpful knowledge pertinent to an agent's current decision-making process. We show that our approach outperforms competitive LLM-based baselines by a large margin in sequential
    
[^9]: 企业中生成式人工智能的治理

    Governance of Generative Artificial Intelligence for Companies

    [https://arxiv.org/abs/2403.08802](https://arxiv.org/abs/2403.08802)

    本综述填补了有关企业中生成式人工智能（GenAI）治理的研究空白，提出了一个框架，旨在利用业务机会并减轻与GenAI整合相关风险。

    

    生成式人工智能（GenAI），特别是像ChatGPT这样的大型语言模型，已迅速进入企业，但缺乏充分的治理，带来机遇和挑战。尽管对GenAI具有变革性质和监管措施的广泛讨论，但有限的研究涉及组织治理，包括技术和业务视角。本综述填补了这一空白，调查了最近的研究。它不仅仅是总结，还通过制定适用于企业内的GenAI治理框架来进行。我们的框架详细描述了范围、目标和治理机制，旨在利用业务机会并减轻与GenAI整合相关风险。该研究提供了一种专注于GenAI治理的方法，为企业在负责任的AI采用挑战中提供了实用见解。对于技术人员来说，也有助于拓宽他们的视角。

    arXiv:2403.08802v1 Announce Type: new  Abstract: Generative Artificial Intelligence (GenAI), specifically large language models like ChatGPT, has swiftly entered organizations without adequate governance, posing both opportunities and risks. Despite extensive debates on GenAI's transformative nature and regulatory measures, limited research addresses organizational governance, encompassing technical and business perspectives. This review paper fills this gap by surveying recent works. It goes beyond mere summarization by developing a framework for GenAI governance within companies. Our framework outlines the scope, objectives, and governance mechanisms tailored to harness business opportunities and mitigate risks associated with GenAI integration. This research contributes a focused approach to GenAI governance, offering practical insights for companies navigating the challenges of responsible AI adoption. It is also valuable for a technical audience to broaden their perspective as inc
    
[^10]: 一种对称变换生成模型

    A Generative Model of Symmetry Transformations

    [https://arxiv.org/abs/2403.01946](https://arxiv.org/abs/2403.01946)

    通过构建一种生成模型来明确捕捉数据中的对称变换，从而提高模型的泛化能力和稳健性。

    

    准确捕捉数据的对称变换可以导致具有强大泛化能力的高效模型，尽管涉及对称性的方法通常需要先验知识。最近在直接从数据集中学习这些对称性方面已取得了进展，但其中大部分工作集中在判别设置上。本文构建了一个生成模型，明确旨在捕捉数据中的对称性，从而产生一个以可解释方式学习数据中存在哪些对称性的模型。我们提供了一个简单的算法来有效学习我们的生成模型，并展示了其在仿射和颜色变换下捕捉对称性的能力。将我们的对称模型与现有的生成模型相结合，可以实现更高的边际测试对数似然和对数据稀疏性的稳健性。

    arXiv:2403.01946v1 Announce Type: new  Abstract: Correctly capturing the symmetry transformations of data can lead to efficient models with strong generalization capabilities, though methods incorporating symmetries often require prior knowledge. While recent advancements have been made in learning those symmetries directly from the dataset, most of this work has focused on the discriminative setting. In this paper, we construct a generative model that explicitly aims to capture symmetries in the data, resulting in a model that learns which symmetries are present in an interpretable way. We provide a simple algorithm for efficiently learning our generative model and demonstrate its ability to capture symmetries under affine and color transformations. Combining our symmetry model with existing generative models results in higher marginal test-log-likelihoods and robustness to data sparsification.
    
[^11]: 使用文本嵌入模型和向量数据库作为文本分类器的研究，以医疗数据为例

    Using text embedding models and vector databases as text classifiers with the example of medical data

    [https://arxiv.org/abs/2402.16886](https://arxiv.org/abs/2402.16886)

    向量数据库和嵌入模型的应用为文本分类器提供了强大的方式来表达数据模式，特别是在医疗领域中开始有着广泛的应用。

    

    大型语言模型（LLMs）的出现是令人兴奋的，并已在许多领域找到应用，但通常情况下，医学领域的标准要求非常高。与LLMs配合使用，向量嵌入模型和向量数据库提供了一种强大的方式来表达各种数据模式，这些数据模式容易被典型的机器学习模型所理解。除了方便地向这些向量数据库添加信息、知识和数据外，它们还提供了一个令人信服的理由，即将其应用于通常由人类完成的检索信息任务的各种领域。Google的研究人员开发了一个清晰的替代模型Med-PaLM，专门旨在与临床医师的医学知识水平匹配。在训练分类器和开发模型时，保持事实和减少偏见是至关重要的。在本文中，我们探讨了向量数据库和嵌入模型的应用

    arXiv:2402.16886v1 Announce Type: cross  Abstract: The advent of Large Language Models (LLMs) is promising and has found application in numerous fields, but as it often is with the medical field, the bar is typically quite high [5]. In tandem with LLMs, vector embedding models and vector databases provide a robust way of expressing numerous modes of data that are easily digestible by typical machine learning models. Along with the ease of adding information, knowledge, and data to these vector databases, they provide a compelling reason to apply them in numerous fields where the task of retrieving information is typically done by humans. Researchers at Google have developed a clear alternative model, Med-PaLM [6] specifically designed to match a clinician's level of accuracy when it comes to medical knowledge. When training classifiers, and developing models, it is imperative to maintain factuality and reduce bias [4]. Here, we explore the use of vector databases and embedding models a
    
[^12]: 通过超图对称性打破进行高阶链接预测

    Expressive Higher-Order Link Prediction through Hypergraph Symmetry Breaking

    [https://arxiv.org/abs/2402.11339](https://arxiv.org/abs/2402.11339)

    通过引入预处理算法识别展现对称性的正则子超图，从而提高超图在高阶链接预测中的表达能力和区分能力。

    

    一种超图由一组节点以及称为超边的节点子集合组成。更高阶链接预测是预测一个超图中是否存在缺失的超边的任务。为高阶链接预测学习的超边表示在同构下不失去区分能力时具有完全表达性。许多现有的超图表示学习器受到广义Weisfeiler Lehman-1（GWL-1）算法的表达能力限制，它是Weisfeiler Lehman-1算法的推广。然而，GWL-1的表达能力有限。事实上，具有相同GWL-1值节点的诱导子超图是无法区分的。此外，在超图上进行消息传递可能已经在GPU内存上变得计算昂贵。为了解决这些限制，我们设计了一种可以识别出展现对称性的特定正则子超图的预处理算法。

    arXiv:2402.11339v1 Announce Type: new  Abstract: A hypergraph consists of a set of nodes along with a collection of subsets of the nodes called hyperedges. Higher-order link prediction is the task of predicting the existence of a missing hyperedge in a hypergraph. A hyperedge representation learned for higher order link prediction is fully expressive when it does not lose distinguishing power up to an isomorphism. Many existing hypergraph representation learners, are bounded in expressive power by the Generalized Weisfeiler Lehman-1 (GWL-1) algorithm, a generalization of the Weisfeiler Lehman-1 algorithm. However, GWL-1 has limited expressive power. In fact, induced subhypergraphs with identical GWL-1 valued nodes are indistinguishable. Furthermore, message passing on hypergraphs can already be computationally expensive, especially on GPU memory. To address these limitations, we devise a preprocessing algorithm that can identify certain regular subhypergraphs exhibiting symmetry. Our p
    
[^13]: 将文化差异纳入大型语言模型的研究

    CultureLLM: Incorporating Cultural Differences into Large Language Models

    [https://arxiv.org/abs/2402.10946](https://arxiv.org/abs/2402.10946)

    提出了一种名为CultureLLM的成本效益高的解决方案，通过使用世界价值调查（WVS）作为种子数据，并通过提出的语义数据增强来将文化差异纳入大型语言模型中，成功微调得到了涵盖富裕和低资源语言的9种文化特定LLMs以及一个统一模型（CultureLLM-One）。

    

    大型语言模型（LLMs）被报道偏向于某些文化，因为训练数据主要来自英语语料库。由于多语种文化数据通常较难收集，现有的工作通过提示工程或特定文化的预训练来处理这一问题。然而，它们可能忽视了低资源文化的知识缺乏，并需要大量的计算资源。本文提出了CultureLLM，这是一个成本效益高的解决方案，可将文化差异纳入LLMs中。CultureLLM采用世界价值调查（WVS）作为种子数据，并通过提出的语义数据增强生成语义等效的训练数据。仅使用来自WVS的50个种子样本和增强数据，我们对9种包括富裕和低资源语言的文化特定LLMs和一个统一模型（CultureLLM-One）进行了微调。对60个与文化相关的数据集进行的大量实验表明，CultureLLM在增强LLM的文化特性方面取得了显著的成果。

    arXiv:2402.10946v1 Announce Type: cross  Abstract: Large language models (LLMs) are reported to be partial to certain cultures owing to the training data dominance from the English corpora. Since multilingual cultural data are often expensive to collect, existing efforts handle this by prompt engineering or culture-specific pre-training. However, they might overlook the knowledge deficiency of low-resource culture and require extensive computing resources. In this paper, we propose CultureLLM, a cost-effective solution to incorporate cultural differences into LLMs. CultureLLM adopts World Value Survey (WVS) as seed data and generates semantically equivalent training data via the proposed semantic data augmentation. Using only 50 seed samples from WVS with augmented data, we fine-tune culture-specific LLMs and one unified model (CultureLLM-One) for 9 cultures covering rich and low-resource languages. Extensive experiments on 60 culture-related datasets demonstrate that CultureLLM signif
    
[^14]: 使用Nystr\"om近似的可扩展核逻辑回归：理论分析和离散选择建模应用

    Scalable Kernel Logistic Regression with Nystr\"om Approximation: Theoretical Analysis and Application to Discrete Choice Modelling

    [https://arxiv.org/abs/2402.06763](https://arxiv.org/abs/2402.06763)

    本文介绍了使用Nystr\"om近似方法解决大规模数据集上核逻辑回归的可扩展性问题。研究提供了理论分析并验证了不同的地标选择方法的性能。

    

    将基于核的机器学习技术应用于使用大规模数据集的离散选择建模时，经常面临存储需求和模型中涉及的大量参数的挑战。这种复杂性影响了大规模模型的高效训练。本文通过引入Nystr\"om近似方法解决了可扩展性问题，用于大规模数据集上的核逻辑回归。研究首先进行了理论分析，其中：i) 对KLR解的集合进行了描述，ii) 给出了使用Nystr\"om近似的KLR解的上界，并最后描述了专门用于Nystr\"om KLR的优化算法的特化。之后，对Nystr\"om KLR进行了计算验证。测试了四种地标选择方法，包括基本均匀采样、k-means采样策略和基于杠杆得分的两种非均匀方法。这些策略的性能进行了评估。

    The application of kernel-based Machine Learning (ML) techniques to discrete choice modelling using large datasets often faces challenges due to memory requirements and the considerable number of parameters involved in these models. This complexity hampers the efficient training of large-scale models. This paper addresses these problems of scalability by introducing the Nystr\"om approximation for Kernel Logistic Regression (KLR) on large datasets. The study begins by presenting a theoretical analysis in which: i) the set of KLR solutions is characterised, ii) an upper bound to the solution of KLR with Nystr\"om approximation is provided, and finally iii) a specialisation of the optimisation algorithms to Nystr\"om KLR is described. After this, the Nystr\"om KLR is computationally validated. Four landmark selection methods are tested, including basic uniform sampling, a k-means sampling strategy, and two non-uniform methods grounded in leverage scores. The performance of these strategi
    
[^15]: Pard: 具有置换不变性的自回归扩散用于图生成

    Pard: Permutation-Invariant Autoregressive Diffusion for Graph Generation

    [https://arxiv.org/abs/2402.03687](https://arxiv.org/abs/2402.03687)

    PARD是一种将扩散模型与自回归方法相结合的置换不变性自回归扩散模型，通过使用图中的部分顺序以块逐块的自回归方式生成图。

    

    尽管自回归模型对于图的顺序敏感，但其简单有效，在图生成领域一直占据主导地位。然而，扩散模型因其置换不变性而越来越受关注。目前的图扩散模型一次性生成图，但需要额外的特征和成千上万步的去噪才能达到最佳性能。我们引入了PARD，一种将扩散模型与自回归方法相结合的置换不变性自回归扩散模型。PARD利用自回归模型的效果和效率，同时保持置换不变性，无需关注图的顺序敏感性。具体来说，我们发现与集合不同，图中的元素并不是完全无序的，节点和边有一个独特的部分顺序。利用这个部分顺序，PARD以块逐块的自回归方式生成图，其中每个块的概率为c。

    Graph generation has been dominated by autoregressive models due to their simplicity and effectiveness, despite their sensitivity to ordering. Yet diffusion models have garnered increasing attention, as they offer comparable performance while being permutation-invariant. Current graph diffusion models generate graphs in a one-shot fashion, but they require extra features and thousands of denoising steps to achieve optimal performance. We introduce PARD, a Permutation-invariant Auto Regressive Diffusion model that integrates diffusion models with autoregressive methods. PARD harnesses the effectiveness and efficiency of the autoregressive model while maintaining permutation invariance without ordering sensitivity. Specifically, we show that contrary to sets, elements in a graph are not entirely unordered and there is a unique partial order for nodes and edges. With this partial order, PARD generates a graph in a block-by-block, autoregressive fashion, where each block's probability is c
    
[^16]: 使用线性控制神经ODE将归一化流作为最优传输映射的近似

    Normalizing flows as approximations of optimal transport maps via linear-control neural ODEs. (arXiv:2311.01404v1 [math.OC])

    [http://arxiv.org/abs/2311.01404](http://arxiv.org/abs/2311.01404)

    本文以线性控制神经ODE的流动作为归一化流构造最优传输映射的近似。通过离散最优耦合问题和数值方案，实现了对最优传输映射的近似。最终结果有助于构建深度神经网络中的可逆传输映射。

    

    "归一化流"一词与通过深度神经网络构建概率测度之间的可逆传输映射相关。本文考虑将$W_2$-最优传输映射$T$恢复为线性控制神经ODE的流动的问题。我们首先展示了在合适的假设下，对于绝对连续测度$\mu,\nu\in\mathcal{P}(\mathbb{R}^n)$和受控向量场，最优传输映射包含在系统产生的流动的$C^0_c$闭包中。假设原始测度$\mu,\nu$的离散近似$\mu_N,\nu_N$可用，我们使用离散最优耦合$\gamma_N$来定义最优控制问题。通过$\Gamma$-收敛论证，我们证明其解对应于近似最优传输映射$T$的流动。最后，利用Pontryagin最大原理，我们提出了一种迭代数值方案来解决问题。

    The term "Normalizing Flows" is related to the task of constructing invertible transport maps between probability measures by means of deep neural networks. In this paper, we consider the problem of recovering the $W_2$-optimal transport map $T$ between absolutely continuous measures $\mu,\nu\in\mathcal{P}(\mathbb{R}^n)$ as the flow of a linear-control neural ODE. We first show that, under suitable assumptions on $\mu,\nu$ and on the controlled vector fields, the optimal transport map is contained in the $C^0_c$-closure of the flows generated by the system. Assuming that discrete approximations $\mu_N,\nu_N$ of the original measures $\mu,\nu$ are available, we use a discrete optimal coupling $\gamma_N$ to define an optimal control problem. With a $\Gamma$-convergence argument, we prove that its solutions correspond to flows that approximate the optimal transport map $T$. Finally, taking advantage of the Pontryagin Maximum Principle, we propose an iterative numerical scheme for the reso
    
[^17]: 基于查询式操作网络的振动声学频响预测

    Vibroacoustic Frequency Response Prediction with Query-based Operator Networks. (arXiv:2310.05469v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2310.05469](http://arxiv.org/abs/2310.05469)

    该论文提出了一个基于查询式操作网络的振动声学频响预测方法，并设计了一个用于代表性振动声学问题的结构化基准测试。该方法可以加速频响模拟，有助于设计优化和不确定性量化。

    

    理解飞机、汽车和房屋等机械结构中的振动声学波传播对保证用户的健康和舒适至关重要。为了分析这些系统，设计师和工程师主要考虑频域中的动态响应，这通过像有限元方法这样的昂贵数值模拟来计算。相比之下，基于数据的替代模型承诺加速这些模拟，从而促进设计优化、不确定性量化和设计空间探索等任务的实施。我们提出了一个结构化的基准测试用于代表性振动声学问题：预测带有不同形式镶边的振动板的频响。该基准测试包含了共计12,000个板几何形状以及相应的数值解，并引入了评估指标以量化预测质量。为了解决频响预测任务，我们提出了一种新颖的频率查询操作模型。

    Understanding vibroacoustic wave propagation in mechanical structures like airplanes, cars and houses is crucial to ensure health and comfort of their users. To analyze such systems, designers and engineers primarily consider the dynamic response in the frequency domain, which is computed through expensive numerical simulations like the finite element method. In contrast, data-driven surrogate models offer the promise of speeding up these simulations, thereby facilitating tasks like design optimization, uncertainty quantification, and design space exploration. We present a structured benchmark for a representative vibroacoustic problem: Predicting the frequency response for vibrating plates with varying forms of beadings. The benchmark features a total of 12,000 plate geometries with an associated numerical solution and introduces evaluation metrics to quantify the prediction quality. To address the frequency response prediction task, we propose a novel frequency query operator model, 
    
[^18]: 顺序体积设计任务的表示学习

    Representation Learning for Sequential Volumetric Design Tasks. (arXiv:2309.02583v1 [cs.LG])

    [http://arxiv.org/abs/2309.02583](http://arxiv.org/abs/2309.02583)

    本研究提出了一种顺序体积设计任务的表示学习方法，通过利用transformer模型从专家的设计序列中提取有用的表示来提高自动生成体积设计的质量，以及支持设计偏好评估和程序化设计生成。

    

    体积设计，也称为质量设计，是专业建筑设计中的第一步关键性任务，具有顺序性。由于体积设计过程复杂，顺序化设计过程中包含了对设计师有价值的信息。许多努力已经被投入到自动生成合理的体积设计上，但生成的设计解决方案的质量存在差异，并且评估一个设计解决方案要么需要一套过于全面的度量标准，要么需要昂贵的人力专业知识。而之前的方法主要关注学习最终设计，而不是顺序设计任务，我们提出利用专家或高性能设计序列的设计知识，并使用基于transformer的模型提取有用的表示。然后，我们提出利用所学的表示在关键的下游应用中，如设计偏好评估和程序化设计生成。我们开发了prefer

    Volumetric design, also called massing design, is the first and critical step in professional building design which is sequential in nature. As the volumetric design process is complex, the underlying sequential design process encodes valuable information for designers. Many efforts have been made to automatically generate reasonable volumetric designs, but the quality of the generated design solutions varies, and evaluating a design solution requires either a prohibitively comprehensive set of metrics or expensive human expertise. While previous approaches focused on learning only the final design instead of sequential design tasks, we propose to encode the design knowledge from a collection of expert or high-performing design sequences and extract useful representations using transformer-based models. Later we propose to utilize the learned representations for crucial downstream applications such as design preference evaluation and procedural design generation. We develop the prefere
    
[^19]: COMCAT：高效压缩和自定义注意力视觉模型

    COMCAT: Towards Efficient Compression and Customization of Attention-Based Vision Models. (arXiv:2305.17235v1 [cs.CV])

    [http://arxiv.org/abs/2305.17235](http://arxiv.org/abs/2305.17235)

    本文提出了一种高效的 Vision Transformer 压缩方法，在多头注意力层上进行了新的探究，相比当前最先进的剪枝方法表现更优，能够在使用更少参数的情况下提高模型精度。

    

    基于注意力机制的视觉模型，例如Vision Transformer（ViT）及其变体，在各种计算机视觉任务中表现出有希望的性能。然而，这些新兴的架构存在着模型尺寸大和高计算成本的问题，需要高效的模型压缩解决方案。本文探究了一种高效的压缩方法，以丰富获取紧凑的基于注意力机制的视觉模型的工具集。基于对多头注意力层的新见解，我们开发出了一种高效的ViT压缩解决方案，其表现优于最先进的剪枝方法。在ImageNet上对DeiT-small和DeiT-base模型进行压缩，我们的提议方法即使使用更少的参数，仍然能够实现比现有方法高0.45％和0.76％的top-1精度。

    Attention-based vision models, such as Vision Transformer (ViT) and its variants, have shown promising performance in various computer vision tasks. However, these emerging architectures suffer from large model sizes and high computational costs, calling for efficient model compression solutions. To date, pruning ViTs has been well studied, while other compression strategies that have been widely applied in CNN compression, e.g., model factorization, is little explored in the context of ViT compression. This paper explores an efficient method for compressing vision transformers to enrich the toolset for obtaining compact attention-based vision models. Based on the new insight on the multi-head attention layer, we develop a highly efficient ViT compression solution, which outperforms the state-of-the-art pruning methods. For compressing DeiT-small and DeiT-base models on ImageNet, our proposed approach can achieve 0.45% and 0.76% higher top-1 accuracy even with fewer parameters. Our fin
    
[^20]: 联邦学习与O-RAN的协同：面向多个分布式机器学习服务的弹性虚拟化架构

    Synergies Between Federated Learning and O-RAN: Towards an Elastic Virtualized Architecture for Multiple Distributed Machine Learning Services. (arXiv:2305.02109v1 [cs.NI])

    [http://arxiv.org/abs/2305.02109](http://arxiv.org/abs/2305.02109)

    本文研究了联邦学习在现代无线网络下的挑战，提出了一种方法称为动态多服务联邦学习（DMS-FL）来解决这个问题。同时，还提出了一种名为弹性虚拟化联邦学习（EV-FL）的分布式机器学习架构，来支持DMS-FL中的设计要求。

    

    联邦学习是最流行的分布式机器学习技术，但是在现代无线网络中实现联邦学习面临着许多挑战，主要包括网络条件的动态性、系统中多个联邦学习服务/任务的并存以及联邦学习服务与其他网络服务的并行执行等。针对这些挑战，本文提出了一种名为动态多服务联邦学习（DMS-FL）的联邦学习泛型架构，并通过提出一种新的分布式机器学习架构——弹性虚拟化联邦学习（EV-FL）来解决DMS-FL中的三个未探索的设计问题。

    Federated learning (FL) is the most popular distributed machine learning technique. However, implementation of FL over modern wireless networks faces key challenges caused by (i) dynamics of the network conditions, (ii) coexistence of multiple FL services/tasks in the system, and (iii) concurrent execution of FL services with other network services, which are not jointly considered in prior works. Motivated by these challenges, we introduce a generic FL paradigm over next-generation (NextG) networks, called dynamic multi-service FL (DMS-FL). We identify three unexplored design considerations in DMS-FL: (i) FL service operator accumulation, (ii) wireless resource fragmentation, and (iii) signal strength fluctuations. We take the first steps towards addressing these design considerations through proposing a novel distributed ML architecture called elastic virtualized FL (EV-FL). EV-FL unleashes the full potential of Open RAN (O-RAN) systems and introduces an elastic resource provisioning
    
[^21]: 蛋白质序列设计的重要性加权期望最大化方法

    Importance Weighted Expectation-Maximization for Protein Sequence Design. (arXiv:2305.00386v1 [q-bio.BM])

    [http://arxiv.org/abs/2305.00386](http://arxiv.org/abs/2305.00386)

    本文提出了一种名为IsEM-Pro的方法，用于根据给定适应性标准生成蛋白质序列。在推理期间，从其潜在空间采样可以增加多样性，指导了探索高适应性区域。实验表明，相比先前最佳方法，IsEM-Pro的平均适应性得分至少高出55％，并生成了更多样化和新颖的蛋白质序列。

    

    在生物和化学领域，设计具有所需生物功能的蛋白质序列非常重要。最近的机器学习方法使用代理序列-功能模型替代昂贵的湿实验验证。本文提出了一种名为IsEM-Pro的方法，用于根据给定的适应性标准生成蛋白质序列。它是一个潜在的生成模型，并受到另外一个学习的马尔可夫随机场结构特征的增强。研究者使用蒙特卡罗期望最大化方法（MCEM）来学习这个模型。在推理期间，从其潜在空间采样可以增加多样性，而其MRF特征则指导了探索高适应性区域。在八项蛋白质序列设计任务中的实验表明，我们的IsEM-Pro的平均适应性得分至少比先前最佳方法高55％，并且生成了更多样化和新颖的蛋白质序列。

    Designing protein sequences with desired biological function is crucial in biology and chemistry. Recent machine learning methods use a surrogate sequence-function model to replace the expensive wet-lab validation. How can we efficiently generate diverse and novel protein sequences with high fitness? In this paper, we propose IsEM-Pro, an approach to generate protein sequences towards a given fitness criterion. At its core, IsEM-Pro is a latent generative model, augmented by combinatorial structure features from a separately learned Markov random fields (MRFs). We develop an Monte Carlo Expectation-Maximization method (MCEM) to learn the model. During inference, sampling from its latent space enhances diversity while its MRFs features guide the exploration in high fitness regions. Experiments on eight protein sequence design tasks show that our IsEM-Pro outperforms the previous best methods by at least 55% on average fitness score and generates more diverse and novel protein sequences.
    
[^22]: 图神经网络的描述性复杂性

    The Descriptive Complexity of Graph Neural Networks. (arXiv:2303.04613v2 [cs.LO] UPDATED)

    [http://arxiv.org/abs/2303.04613](http://arxiv.org/abs/2303.04613)

    研究分析了图神经网络（GNN）在布尔电路复杂性和描述性复杂性方面的能力，证明了多项式规模有界深度的GNN族族可以计算的图查询正是带计数和内置关系的一阶逻辑受保护的片断GFO+C所定义的，这将GNN放在电路复杂性类TC^0中。

    

    我们分析了图神经网络（GNN）的布尔电路复杂性和描述性复杂性的能力。我们证明了多项式规模有界深度的GNN族族可以计算的图查询正是那些用带计数和内置关系的一阶逻辑受保护的片断GFO+C定义的。这将GNN放在电路复杂性类TC^0中。值得注意的是，GNN家族可以使用任意实数权值和包括标准ReLU、Logistic“sigmod”和双曲正切函数在内的广泛激活函数类。如果GNN被允许使用随机初始化和全局读取（这些都是GNN在实践中广泛使用的标准功能），它们可以计算与阈门的有界深度布尔电路完全相同的查询，即在TC^0中的查询。此外，我们展示了一个带分段线性激活和有理权重的单个GNN可以在不建造内部关系的情况下由GFO+C定义。

    We analyse the power of graph neural networks (GNNs) in terms of Boolean circuit complexity and descriptive complexity.  We prove that the graph queries that can be computed by a polynomial-size bounded-depth family of GNNs are exactly those definable in the guarded fragment GFO+C of first-order logic with counting and with built-in relations. This puts GNNs in the circuit complexity class TC^0. Remarkably, the GNN families may use arbitrary real weights and a wide class of activation functions that includes the standard ReLU, logistic "sigmod", and hyperbolic tangent functions. If the GNNs are allowed to use random initialisation and global readout (both standard features of GNNs widely used in practice), they can compute exactly the same queries as bounded depth Boolean circuits with threshold gates, that is, exactly the queries in TC^0.  Moreover, we show that queries computable by a single GNN with piecewise linear activations and rational weights are definable in GFO+C without bui
    

