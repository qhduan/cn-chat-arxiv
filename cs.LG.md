# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [VSTAR: Generative Temporal Nursing for Longer Dynamic Video Synthesis](https://arxiv.org/abs/2403.13501) | 提出了一种名为VSTAR的方法，通过引入生成时序护理（GTN）的概念，自动生成视频梗概并改善对时序动态的控制，从而实现生成更长、更动态的视频 |
| [^2] | [Align and Distill: Unifying and Improving Domain Adaptive Object Detection](https://arxiv.org/abs/2403.12029) | 引入了统一的基准测试和实现框架ALDI以及新的DAOD基准数据集CFC-DAOD，解决了领域自适应目标检测中的基准问题，并支持未来方法的发展。 |
| [^3] | [Level Set Teleportation: An Optimization Perspective](https://arxiv.org/abs/2403.03362) | 该论文从优化的角度研究了水平集传输，证明了在某些条件下水平集传输可以加速梯度方法的收敛速度，且提出了一种只需要Hessian-vector products的方法验证了该技术在实践中的有效性。 |
| [^4] | [Q-FOX Learning: Breaking Tradition in Reinforcement Learning](https://arxiv.org/abs/2402.16562) | Q-FOX学习是一种新颖的自动超参数调整方法，结合了FOX优化器和Q-learning算法，提出了使用新的目标函数来解决强化学习中超参数调整的问题。 |
| [^5] | [Accuracy-Preserving Calibration via Statistical Modeling on Probability Simplex](https://arxiv.org/abs/2402.13765) | 提出一种使用Concrete分布作为概率单纯形上的概率模型的保持精度的校准方法，并证明其在交叉熵损失上训练的DNN模型具有最优性，同时提出了一种有效的样本生成方法。 |
| [^6] | [StochGradAdam: Accelerating Neural Networks Training with Stochastic Gradient Sampling.](http://arxiv.org/abs/2310.17042) | StochGradAdam是一种利用随机梯度抽样加速神经网络训练的优化器，通过选择性梯度考虑，能够稳定收敛，提升鲁棒训练。在图像分类和分割任务中表现优异。 |
| [^7] | [C(NN)FD -- deep learning predictions of tip clearance variations on multi-stage axial compressors aerodynamic performance.](http://arxiv.org/abs/2310.04264) | 本文展示了一种用于实时预测多级轴向压缩机在燃气轮机中尖间隙变化对气动性能影响的深度学习框架，可与CFD基准相媲美的实时准确性，方便集成到燃气轮机的制造和构建过程中进行性能评估。 |
| [^8] | [Potential and limitations of random Fourier features for dequantizing quantum machine learning.](http://arxiv.org/abs/2309.11647) | 本文研究了随机傅里叶特征在去量化量子机器学习中的潜力与局限性，并在回归问题上确立了其高效去量化的必要和充分条件，并提出了PQC架构设计建议和识别了潜在量子优势的必要结构。 |
| [^9] | [Efficient Last-iterate Convergence Algorithms in Solving Games.](http://arxiv.org/abs/2308.11256) | 该论文研究了求解博弈中高效收敛算法的问题，通过分析乐观梯度下降上升（OGDA）和乐观乘法权重更新（OMWU）算法，以及基于奖励转化（RT）框架的算法，提出了解决这些问题的方法。 |
| [^10] | [Kernel Single Proxy Control for Deterministic Confounding.](http://arxiv.org/abs/2308.04585) | 本研究考虑了具有未观测混淆因素的因果效应估计问题，在结果是确定性生成的情况下，提出了一种使用单一代理变量的内核方法，通过两阶段回归和最大矩约束的方法可以一致估计因果效应，并在合成数据集上成功恢复了因果效应。 |
| [^11] | [On the Transition from Neural Representation to Symbolic Knowledge.](http://arxiv.org/abs/2308.02000) | 该论文提出了一种神经-符号过渡字典学习框架，可以将神经网络与符号思维进行结合。通过学习过渡表示，并自监督地发现隐含的谓词结构，以及通过博弈和强化学习调整学习到的原型，该框架可以实现对高维信息的压缩和符号表示的学习。 |
| [^12] | [Unfair Utilities and First Steps Towards Improving Them.](http://arxiv.org/abs/2306.00636) | 该论文提出了一个新的公平框架——考虑政策优化哪个效用，定义了信息价值公平，提出不应使用不满足这一标准的实用程序，并探讨了修改实用程序以满足此公平标准可能对最优政策产生的影响。 |
| [^13] | [Linear Neural Network Layers Promote Learning Single- and Multiple-Index Models.](http://arxiv.org/abs/2305.15598) | 本研究探究了过度参数化的深度神经网络的偏见，发现在ReLU网络中添加线性层有助于逼近具有低秩线性算子和低表示成本函数组成的函数，从而得到一个与低维子空间垂直方向近乎恒定的插值函数。 |
| [^14] | [Lower Bounds and Accelerated Algorithms in Distributed Stochastic Optimization with Communication Compression.](http://arxiv.org/abs/2305.07612) | 本文研究采用通信压缩的分布式随机优化算法的性能下限并提出了一种名为NEOLITHIC的新型通信压缩算法，通过加速收敛速率缩小下限和现有算法的差距。 |
| [^15] | [Emerging Synergies in Causality and Deep Generative Models: A Survey.](http://arxiv.org/abs/2301.12351) | 这项综述探讨了因果性和深度生成模型之间的新兴协同作用，阐明了将因果性原则融入DGM中的方法，以及在大规模生成模型中应用因果性的研究前沿。 |
| [^16] | [Imputation Strategies Under Clinical Presence: Impact on Algorithmic Fairness.](http://arxiv.org/abs/2208.06648) | 本文研究了填补选择对不同群体的重建误差和下游预测的算法公平性属性的影响。 |

# 详细

[^1]: VSTAR：用于生成长动态视频合成的时间护理

    VSTAR: Generative Temporal Nursing for Longer Dynamic Video Synthesis

    [https://arxiv.org/abs/2403.13501](https://arxiv.org/abs/2403.13501)

    提出了一种名为VSTAR的方法，通过引入生成时序护理（GTN）的概念，自动生成视频梗概并改善对时序动态的控制，从而实现生成更长、更动态的视频

    

    尽管在文本到视频（T2V）合成领域取得了巨大进展，但开源的T2V扩散模型难以生成具有动态变化和不断进化内容的较长视频。它们往往合成准静态视频，忽略了文本提示中涉及的必要随时间变化的视觉变化。与此同时，将这些模型扩展到实现更长、更动态的视频合成往往在计算上难以处理。为了解决这一挑战，我们引入了生成时序护理（GTN）的概念，旨在在推理过程中即时改变生成过程，以改善对时序动态的控制，并实现生成更长的视频。我们提出了一种GTN方法，名为VSTAR，它包括两个关键要素：1）视频梗概提示（VSP）-基于原始单个提示自动生成视频梗概，利用LLMs提供准确的文本指导，以实现对时序动态的精确控制。

    arXiv:2403.13501v1 Announce Type: cross  Abstract: Despite tremendous progress in the field of text-to-video (T2V) synthesis, open-sourced T2V diffusion models struggle to generate longer videos with dynamically varying and evolving content. They tend to synthesize quasi-static videos, ignoring the necessary visual change-over-time implied in the text prompt. At the same time, scaling these models to enable longer, more dynamic video synthesis often remains computationally intractable. To address this challenge, we introduce the concept of Generative Temporal Nursing (GTN), where we aim to alter the generative process on the fly during inference to improve control over the temporal dynamics and enable generation of longer videos. We propose a method for GTN, dubbed VSTAR, which consists of two key ingredients: 1) Video Synopsis Prompting (VSP) - automatic generation of a video synopsis based on the original single prompt leveraging LLMs, which gives accurate textual guidance to differe
    
[^2]: 对齐与提炼：统一和改进领域自适应目标检测

    Align and Distill: Unifying and Improving Domain Adaptive Object Detection

    [https://arxiv.org/abs/2403.12029](https://arxiv.org/abs/2403.12029)

    引入了统一的基准测试和实现框架ALDI以及新的DAOD基准数据集CFC-DAOD，解决了领域自适应目标检测中的基准问题，并支持未来方法的发展。

    

    目标检测器通常表现不佳于与其训练集不同的数据。最近，领域自适应目标检测（DAOD）方法已经展示了在应对这一挑战上的强大结果。遗憾的是，我们发现了系统化的基准测试陷阱，这些陷阱对过去的结果提出质疑并阻碍了进一步的进展：（a）由于基线不足导致性能高估，（b）不一致的实现实践阻止了方法的透明比较，（c）由于过时的骨干和基准测试缺乏多样性，导致缺乏普遍性。我们通过引入以下问题来解决这些问题：（1）一个统一的基准测试和实现框架，Align and Distill（ALDI），支持DAOD方法的比较并支持未来发展，（2）一个公平且现代的DAOD训练和评估协议，解决了基准测试的陷阱，（3）一个新的DAOD基准数据集，CFC-DAOD，能够在多样化的真实环境中进行评估。

    arXiv:2403.12029v1 Announce Type: cross  Abstract: Object detectors often perform poorly on data that differs from their training set. Domain adaptive object detection (DAOD) methods have recently demonstrated strong results on addressing this challenge. Unfortunately, we identify systemic benchmarking pitfalls that call past results into question and hamper further progress: (a) Overestimation of performance due to underpowered baselines, (b) Inconsistent implementation practices preventing transparent comparisons of methods, and (c) Lack of generality due to outdated backbones and lack of diversity in benchmarks. We address these problems by introducing: (1) A unified benchmarking and implementation framework, Align and Distill (ALDI), enabling comparison of DAOD methods and supporting future development, (2) A fair and modern training and evaluation protocol for DAOD that addresses benchmarking pitfalls, (3) A new DAOD benchmark dataset, CFC-DAOD, enabling evaluation on diverse real
    
[^3]: 水平集传输：优化的视角

    Level Set Teleportation: An Optimization Perspective

    [https://arxiv.org/abs/2403.03362](https://arxiv.org/abs/2403.03362)

    该论文从优化的角度研究了水平集传输，证明了在某些条件下水平集传输可以加速梯度方法的收敛速度，且提出了一种只需要Hessian-vector products的方法验证了该技术在实践中的有效性。

    

    我们研究水平集传输，这是一种优化子程序，旨在通过在目标函数的水平集上最大化梯度范数来加速梯度方法。由于下降引理暗示梯度下降（GD）使目标函数按梯度的平方范数下降，水平集传输最大化了这一步进保证。对于满足Hessian稳定性的凸函数，我们证明了GD与水平集传输获得了综合的次线性/线性收敛速度，这比在最优性差距较小时标准GD要快得多。与标准（强）凸设置形成鲜明对比的是，我们展示了水平集传输既不改善也不恶化收敛速度。为了实际评估传输，我们开发了一种只需要Hessian-向量乘积的投影梯度类型方法。我们使用这种方法显示，如果提供了梯度访问权限，水平集传输梯度方法具有更快的收敛速度。

    arXiv:2403.03362v1 Announce Type: new  Abstract: We study level set teleportation, an optimization sub-routine which seeks to accelerate gradient methods by maximizing the gradient norm on a level-set of the objective function. Since the descent lemma implies that gradient descent (GD) decreases the objective proportional to the squared norm of the gradient, level-set teleportation maximizes this one-step progress guarantee. For convex functions satisfying Hessian stability, we prove that GD with level-set teleportation obtains a combined sub-linear/linear convergence rate which is strictly faster than standard GD when the optimality gap is small. This is in sharp contrast to the standard (strongly) convex setting, where we show level-set teleportation neither improves nor worsens convergence rates. To evaluate teleportation in practice, we develop a projected-gradient-type method requiring only Hessian-vector products. We use this method to show that gradient methods with access to a 
    
[^4]: Q-FOX学习：颠覆传统的强化学习

    Q-FOX Learning: Breaking Tradition in Reinforcement Learning

    [https://arxiv.org/abs/2402.16562](https://arxiv.org/abs/2402.16562)

    Q-FOX学习是一种新颖的自动超参数调整方法，结合了FOX优化器和Q-learning算法，提出了使用新的目标函数来解决强化学习中超参数调整的问题。

    

    强化学习（RL）是人工智能（AI）的一个子集，代理通过与环境的交互来学习最佳动作，因此适用于不需要标记数据或直接监督的任务。 本文提出了一种名为Q-FOX的新颖自动调参方法，该方法使用了FOX优化器和常用的易于实现的RL Q-learning算法解决了调参的问题。此外，还提出了一个新的目标函数，该函数将奖励放在均方误差（MSE）和学习时间之上。

    arXiv:2402.16562v2 Announce Type: replace-cross  Abstract: Reinforcement learning (RL) is a subset of artificial intelligence (AI) where agents learn the best action by interacting with the environment, making it suitable for tasks that do not require labeled data or direct supervision. Hyperparameters (HP) tuning refers to choosing the best parameter that leads to optimal solutions in RL algorithms. Manual or random tuning of the HP may be a crucial process because variations in this parameter lead to changes in the overall learning aspects and different rewards. In this paper, a novel and automatic HP-tuning method called Q-FOX is proposed. This uses both the FOX optimizer, a new optimization method inspired by nature that mimics red foxes' hunting behavior, and the commonly used, easy-to-implement RL Q-learning algorithm to solve the problem of HP tuning. Moreover, a new objective function is proposed which prioritizes the reward over the mean squared error (MSE) and learning time (
    
[^5]: 通过概率单纯形上的统计建模实现保持精度的校准

    Accuracy-Preserving Calibration via Statistical Modeling on Probability Simplex

    [https://arxiv.org/abs/2402.13765](https://arxiv.org/abs/2402.13765)

    提出一种使用Concrete分布作为概率单纯形上的概率模型的保持精度的校准方法，并证明其在交叉熵损失上训练的DNN模型具有最优性，同时提出了一种有效的样本生成方法。

    

    基于深度神经网络（DNNs）的分类模型必须进行校准，以评估预测结果的可靠性。一些最近的校准方法采用了概率单纯形上的概率模型。然而，这些校准方法无法保持预训练模型的准确性，即使这些模型具有很高的分类准确性。我们提出了一种使用Concrete分布作为概率单纯形上的概率模型的保持精度的校准方法。我们在理论上证明，在交叉熵损失上训练的DNN模型具有Concrete分布参数的最优性。我们还提出了一种有效的方法，可以合成生成样本，用于在概率单纯形上训练概率模型。我们证明了所提出的方法在精度保持校准任务上可以优于以往的方法，使用基准测试。

    arXiv:2402.13765v1 Announce Type: new  Abstract: Classification models based on deep neural networks (DNNs) must be calibrated to measure the reliability of predictions. Some recent calibration methods have employed a probabilistic model on the probability simplex. However, these calibration methods cannot preserve the accuracy of pre-trained models, even those with a high classification accuracy. We propose an accuracy-preserving calibration method using the Concrete distribution as the probabilistic model on the probability simplex. We theoretically prove that a DNN model trained on cross-entropy loss has optimality as the parameter of the Concrete distribution. We also propose an efficient method that synthetically generates samples for training probabilistic models on the probability simplex. We demonstrate that the proposed method can outperform previous methods in accuracy-preserving calibration tasks using benchmarks.
    
[^6]: StochGradAdam: 利用随机梯度抽样加速神经网络训练

    StochGradAdam: Accelerating Neural Networks Training with Stochastic Gradient Sampling. (arXiv:2310.17042v1 [cs.LG])

    [http://arxiv.org/abs/2310.17042](http://arxiv.org/abs/2310.17042)

    StochGradAdam是一种利用随机梯度抽样加速神经网络训练的优化器，通过选择性梯度考虑，能够稳定收敛，提升鲁棒训练。在图像分类和分割任务中表现优异。

    

    在深度学习优化领域中，本文介绍了StochGradAdam优化器，这是对广受赞誉的Adam算法的新颖改进。StochGradAdam的核心是其梯度抽样技术。该方法不仅确保稳定收敛，而且利用选择性梯度考虑的优势，通过减轻噪声或异常数据的影响和增强损失函数空间的探索，提升了鲁棒训练。在图像分类和分割任务中，StochGradAdam表现出优于传统Adam优化器的性能。通过在每次迭代中精心选择一部分梯度进行抽样，该优化器能够有效应对复杂模型的管理。本文从数学基础到偏差校正策略全面探讨了StochGradAdam的方法，展示了深度学习训练技术的可期进展。

    In the rapidly advancing domain of deep learning optimization, this paper unveils the StochGradAdam optimizer, a novel adaptation of the well-regarded Adam algorithm. Central to StochGradAdam is its gradient sampling technique. This method not only ensures stable convergence but also leverages the advantages of selective gradient consideration, fostering robust training by potentially mitigating the effects of noisy or outlier data and enhancing the exploration of the loss landscape for more dependable convergence. In both image classification and segmentation tasks, StochGradAdam has demonstrated superior performance compared to the traditional Adam optimizer. By judiciously sampling a subset of gradients at each iteration, the optimizer is optimized for managing intricate models. The paper provides a comprehensive exploration of StochGradAdam's methodology, from its mathematical foundations to bias correction strategies, heralding a promising advancement in deep learning training tec
    
[^7]: C(NN)FD -- 多级轴向压缩机气动性能中尖间隙变化的深度学习预测

    C(NN)FD -- deep learning predictions of tip clearance variations on multi-stage axial compressors aerodynamic performance. (arXiv:2310.04264v1 [cs.LG])

    [http://arxiv.org/abs/2310.04264](http://arxiv.org/abs/2310.04264)

    本文展示了一种用于实时预测多级轴向压缩机在燃气轮机中尖间隙变化对气动性能影响的深度学习框架，可与CFD基准相媲美的实时准确性，方便集成到燃气轮机的制造和构建过程中进行性能评估。

    

    迄今为止，将深度学习方法应用于诸如CFD（计算流体力学）等物理模拟在工业上的重要性有限。本文展示了一种用于多级轴向压缩机在燃气轮机中尖间隙变化对气动性能的实时预测的深度学习框架的开发和应用。所提出的C(NN)FD架构经证明可扩展至工业应用，并达到与CFD基准相媲美的实时准确性。部署的模型可轻松集成到燃气轮机的制造和构建过程中，从而提供了分析评估性能影响并潜在减少昂贵物理测试要求的机会。

    Application of deep learning methods to physical simulations such as CFD (Computational Fluid Dynamics), have been so far of limited industrial relevance. This paper demonstrates the development and application of a deep learning framework for real-time predictions of the impact of tip clearance variations on the aerodynamic performance of multi-stage axial compressors in gas turbines. The proposed C(NN)FD architecture is proven to be scalable to industrial applications, and achieves in real-time accuracy comparable to the CFD benchmark. The deployed model, is readily integrated within the manufacturing and build process of gas turbines, thus providing the opportunity to analytically assess the impact on performance and potentially reduce requirements for expensive physical tests.
    
[^8]: 随机傅里叶特征在去量化量子机器学习中的潜力与局限性

    Potential and limitations of random Fourier features for dequantizing quantum machine learning. (arXiv:2309.11647v1 [quant-ph])

    [http://arxiv.org/abs/2309.11647](http://arxiv.org/abs/2309.11647)

    本文研究了随机傅里叶特征在去量化量子机器学习中的潜力与局限性，并在回归问题上确立了其高效去量化的必要和充分条件，并提出了PQC架构设计建议和识别了潜在量子优势的必要结构。

    

    量子机器学习是近期量子设备最广泛探索的应用之一。目前主要关注的是变分量子机器学习，其中参数化量子电路被用作学习模型。这些参数化量子电路模型具有丰富的结构，因此可能通过随机傅里叶特征进行高效的去量化。本文在回归问题上确立了随机傅里叶特征在变分量子机器学习中提供高效去量化的必要和充分条件。利用这些结果，我们提出了具体的参数化量子电路架构设计建议，以及识别了在回归问题中取得潜在量子优势的必要结构。

    Quantum machine learning is arguably one of the most explored applications of near-term quantum devices. Much focus has been put on notions of variational quantum machine learning where parameterized quantum circuits (PQCs) are used as learning models. These PQC models have a rich structure which suggests that they might be amenable to efficient dequantization via random Fourier features (RFF). In this work, we establish necessary and sufficient conditions under which RFF does indeed provide an efficient dequantization of variational quantum machine learning for regression. We build on these insights to make concrete suggestions for PQC architecture design, and to identify structures which are necessary for a regression problem to admit a potential quantum advantage via PQC based optimization.
    
[^9]: 在求解博弈中的高效收敛算法

    Efficient Last-iterate Convergence Algorithms in Solving Games. (arXiv:2308.11256v1 [cs.GT])

    [http://arxiv.org/abs/2308.11256](http://arxiv.org/abs/2308.11256)

    该论文研究了求解博弈中高效收敛算法的问题，通过分析乐观梯度下降上升（OGDA）和乐观乘法权重更新（OMWU）算法，以及基于奖励转化（RT）框架的算法，提出了解决这些问题的方法。

    

    无悔算法在学习两人零和标准型游戏和扩展型游戏的纳什均衡中很受欢迎。最近的许多研究考虑了最后一次迭代收敛的无悔算法。其中，最有名的两个算法是乐观梯度下降上升（OGDA）和乐观乘法权重更新（OMWU）。然而，OGDA的每次迭代复杂度很高。OMWU具有较低的每次迭代复杂度，但实验性能较差，并且它的收敛仅在纳什均衡唯一时成立。最近的研究提出了一种基于奖励转化（RT）框架用于MWU，它消除了唯一性条件，并且在与OMWU相同迭代次数的情况下实现了有竞争力的性能。不幸的是，基于RT的算法在相同迭代次数下表现不如OGDA，并且它们的收敛保证基于连续时间反馈假设，这在大多数情况下不成立。为了解决这些问题，我们对RT框架进行了更详细的分析。

    No-regret algorithms are popular for learning Nash equilibrium (NE) in two-player zero-sum normal-form games (NFGs) and extensive-form games (EFGs). Many recent works consider the last-iterate convergence no-regret algorithms. Among them, the two most famous algorithms are Optimistic Gradient Descent Ascent (OGDA) and Optimistic Multiplicative Weight Update (OMWU). However, OGDA has high per-iteration complexity. OMWU exhibits a lower per-iteration complexity but poorer empirical performance, and its convergence holds only when NE is unique. Recent works propose a Reward Transformation (RT) framework for MWU, which removes the uniqueness condition and achieves competitive performance with OMWU. Unfortunately, RT-based algorithms perform worse than OGDA under the same number of iterations, and their convergence guarantee is based on the continuous-time feedback assumption, which does not hold in most scenarios. To address these issues, we provide a closer analysis of the RT framework, w
    
[^10]: 决定性混淆下的内核单一代理控制

    Kernel Single Proxy Control for Deterministic Confounding. (arXiv:2308.04585v1 [stat.ML])

    [http://arxiv.org/abs/2308.04585](http://arxiv.org/abs/2308.04585)

    本研究考虑了具有未观测混淆因素的因果效应估计问题，在结果是确定性生成的情况下，提出了一种使用单一代理变量的内核方法，通过两阶段回归和最大矩约束的方法可以一致估计因果效应，并在合成数据集上成功恢复了因果效应。

    

    本文考虑具有未观测混淆因素的因果效应估计问题，其中我们观测到与混淆因素相关的代理变量。尽管代理因果学习（PCL）使用两个代理变量来恢复真实的因果效应，我们证明如果结果是确定性生成的，则使用单个代理变量就足以进行因果估计，并概括了控制结果校准法（COCA）。我们提出了两种基于内核的方法：一种基于两阶段回归方法，另一种基于最大矩约束方法。我们证明了这两种方法都可以一致地估计因果效应，并通过合成数据集的实证实验成功地恢复了因果效应。

    We consider the problem of causal effect estimation with an unobserved confounder, where we observe a proxy variable that is associated with the confounder. Although Proxy Causal Learning (PCL) uses two proxy variables to recover the true causal effect, we show that a single proxy variable is sufficient for causal estimation if the outcome is generated deterministically, generalizing Control Outcome Calibration Approach (COCA). We propose two kernel-based methods for this setting: the first based on the two-stage regression approach, and the second based on a maximum moment restriction approach. We prove that both approaches can consistently estimate the causal effect, and we empirically demonstrate that we can successfully recover the causal effect on a synthetic dataset.
    
[^11]: 从神经表示到符号知识的过渡

    On the Transition from Neural Representation to Symbolic Knowledge. (arXiv:2308.02000v1 [cs.AI])

    [http://arxiv.org/abs/2308.02000](http://arxiv.org/abs/2308.02000)

    该论文提出了一种神经-符号过渡字典学习框架，可以将神经网络与符号思维进行结合。通过学习过渡表示，并自监督地发现隐含的谓词结构，以及通过博弈和强化学习调整学习到的原型，该框架可以实现对高维信息的压缩和符号表示的学习。

    

    弥合神经表示与符号表示之间的巨大差距可能使符号思维从本质上融入神经网络。受人类如何逐渐从通过知觉和环境交互学习到的原型符号构建复杂的符号表示的启发，我们提出了一种神经-符号过渡字典学习（TDL）框架，该框架使用EM算法学习数据的过渡表示，将输入的高维视觉部分信息压缩到一组张量作为神经变量，并自监督地发现隐含的谓词结构。我们通过将输入分解视为合作博弈来实现框架，使用扩散模型学习谓词，并通过RL基于扩散模型的马尔可夫性质进一步调整学习到的原型，以融入主观因素。

    Bridging the huge disparity between neural and symbolic representation can potentially enable the incorporation of symbolic thinking into neural networks from essence. Motivated by how human gradually builds complex symbolic representation from the prototype symbols that are learned through perception and environmental interactions. We propose a Neural-Symbolic Transitional Dictionary Learning (TDL) framework that employs an EM algorithm to learn a transitional representation of data that compresses high-dimension information of visual parts of an input into a set of tensors as neural variables and discover the implicit predicate structure in a self-supervised way. We implement the framework with a diffusion model by regarding the decomposition of input as a cooperative game, then learn predicates by prototype clustering. We additionally use RL enabled by the Markovian of diffusion models to further tune the learned prototypes by incorporating subjective factors. Extensive experiments 
    
[^12]: 不公平的实用程序及其改进的第一步

    Unfair Utilities and First Steps Towards Improving Them. (arXiv:2306.00636v1 [stat.ML])

    [http://arxiv.org/abs/2306.00636](http://arxiv.org/abs/2306.00636)

    该论文提出了一个新的公平框架——考虑政策优化哪个效用，定义了信息价值公平，提出不应使用不满足这一标准的实用程序，并探讨了修改实用程序以满足此公平标准可能对最优政策产生的影响。

    

    许多公平标准对政策或预测器的选择进行限制。在这项工作中，我们提出了一个不同的思考公平的框架：我们考虑政策正在优化哪个效用，而不是限制政策或预测器的选择。我们定义了信息价值公平，并建议不使用不满足此标准的实用程序。我们描述了如何修改实用程序以满足这种公平标准，并讨论了这可能对相应的最优政策产生的影响。

    Many fairness criteria constrain the policy or choice of predictors. In this work, we propose a different framework for thinking about fairness: Instead of constraining the policy or choice of predictors, we consider which utility a policy is optimizing for. We define value of information fairness and propose to not use utilities that do not satisfy this criterion. We describe how to modify a utility to satisfy this fairness criterion and discuss the consequences this might have on the corresponding optimal policies.
    
[^13]: 线性神经网络层促进学习单指数和多指数模型

    Linear Neural Network Layers Promote Learning Single- and Multiple-Index Models. (arXiv:2305.15598v1 [cs.LG])

    [http://arxiv.org/abs/2305.15598](http://arxiv.org/abs/2305.15598)

    本研究探究了过度参数化的深度神经网络的偏见，发现在ReLU网络中添加线性层有助于逼近具有低秩线性算子和低表示成本函数组成的函数，从而得到一个与低维子空间垂直方向近乎恒定的插值函数。

    

    本文探究了深度大于两层的过度参数化神经网络的隐含偏见。我们的框架考虑了一类深度不同但容量相同的网络，它们具有不同的显式定义的表示成本。神经网络架构诱导的函数的表示成本是网络表示该函数所需的平方权重之和的最小值；它反映了与该架构相关的函数空间偏差。结果表明，将线性层添加到ReLU网络会产生一个表示成本，这有利于使用两层网络来逼近由低秩线性算子和具有低表示成本的函数组成的函数。具体来说，使用神经网络以最小的表示成本拟合训练数据会得到一个与低维子空间垂直方向近乎恒定的插值函数。

    This paper explores the implicit bias of overparameterized neural networks of depth greater than two layers. Our framework considers a family of networks of varying depths that all have the same capacity but different implicitly defined representation costs. The representation cost of a function induced by a neural network architecture is the minimum sum of squared weights needed for the network to represent the function; it reflects the function space bias associated with the architecture. Our results show that adding linear layers to a ReLU network yields a representation cost that favors functions that can be approximated by a low-rank linear operator composed with a function with low representation cost using a two-layer network. Specifically, using a neural network to fit training data with minimum representation cost yields an interpolating function that is nearly constant in directions orthogonal to a low-dimensional subspace. This means that the learned network will approximate
    
[^14]: 通信压缩下的分布式随机优化中的下限和加速算法

    Lower Bounds and Accelerated Algorithms in Distributed Stochastic Optimization with Communication Compression. (arXiv:2305.07612v1 [cs.LG])

    [http://arxiv.org/abs/2305.07612](http://arxiv.org/abs/2305.07612)

    本文研究采用通信压缩的分布式随机优化算法的性能下限并提出了一种名为NEOLITHIC的新型通信压缩算法，通过加速收敛速率缩小下限和现有算法的差距。

    

    通信压缩是减轻分布式随机优化中计算节点间信息交换量的重要策略。本文研究了采用通信压缩的分布式随机优化算法的性能下限，并关注两种主要类型的压缩器：无偏和压缩型，并解决了可以通过这些压缩器获得的最佳收敛速率问题。本文针对六种不同设置，结合强凸、一般凸或非凸函数，并用无偏或压缩型压缩器建立了分布式随机优化的收敛速率下限。我们提出了一种名为NEOLITHIC的新型通信压缩算法，通过加速收敛速率相比经典方法，缩小了下限和现有算法的差距。理论分析和数值实验提供了关于分布式随机优化中通信压缩算法的最优性能的见解。

    Communication compression is an essential strategy for alleviating communication overhead by reducing the volume of information exchanged between computing nodes in large-scale distributed stochastic optimization. Although numerous algorithms with convergence guarantees have been obtained, the optimal performance limit under communication compression remains unclear.  In this paper, we investigate the performance limit of distributed stochastic optimization algorithms employing communication compression. We focus on two main types of compressors, unbiased and contractive, and address the best-possible convergence rates one can obtain with these compressors. We establish the lower bounds for the convergence rates of distributed stochastic optimization in six different settings, combining strongly-convex, generally-convex, or non-convex functions with unbiased or contractive compressor types. To bridge the gap between lower bounds and existing algorithms' rates, we propose NEOLITHIC, a n
    
[^15]: 因果性和深度生成模型中的新兴协同作用：一项综述

    Emerging Synergies in Causality and Deep Generative Models: A Survey. (arXiv:2301.12351v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.12351](http://arxiv.org/abs/2301.12351)

    这项综述探讨了因果性和深度生成模型之间的新兴协同作用，阐明了将因果性原则融入DGM中的方法，以及在大规模生成模型中应用因果性的研究前沿。

    

    在人工智能领域，了解和建模数据生成过程（DGP）的追求至关重要。深度生成模型（DGM）在捕捉复杂数据分布方面表现出色，但通常在泛化能力和可解释性方面表现不足。而因果性则提供了一种结构化的方法来理解驱动数据生成的机制，并突显了这些过程中固有的因果效应动力学。虽然因果性在可解释性和外推能力方面表现出色，但却面临着高维空间中的复杂性。意识到它们之间的协同潜力，我们深入探讨了因果性和DGM的交汇点。我们阐明了因果性原则在DGM中的整合，探讨了使用DGM进行因果识别的方法，并对因果性在大规模生成模型中的新兴研究前沿，尤其是大型语言模型（LLM）中的生成性问题提供了见解。我们介绍了方法论，突出了开放的挑战和机会。

    In the field of artificial intelligence (AI), the quest to understand and model data-generating processes (DGPs) is of paramount importance. Deep generative models (DGMs) have proven adept in capturing complex data distributions but often fall short in generalization and interpretability. On the other hand, causality offers a structured lens to comprehend the mechanisms driving data generation and highlights the causal-effect dynamics inherent in these processes. While causality excels in interpretability and the ability to extrapolate, it grapples with intricacies of high-dimensional spaces. Recognizing the synergistic potential, we delve into the confluence of causality and DGMs. We elucidate the integration of causal principles within DGMs, investigate causal identification using DGMs, and navigate an emerging research frontier of causality in large-scale generative models, particularly generative large language models (LLMs). We offer insights into methodologies, highlight open cha
    
[^16]: 在临床存在下的填补策略：对算法公平性的影响

    Imputation Strategies Under Clinical Presence: Impact on Algorithmic Fairness. (arXiv:2208.06648v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2208.06648](http://arxiv.org/abs/2208.06648)

    本文研究了填补选择对不同群体的重建误差和下游预测的算法公平性属性的影响。

    

    机器学习可能会强化数据中的偏见，而我们在这个工作中提出，数据中缺失的内容也会产生偏见。在医疗领域，偏见已经在医疗历史上留下了深深的烙印，导致边缘化群体受到不平等的护理。缺失数据中的模式通常反映了这些群体的差异，但是特定群体缺失的算法公平性影响还不太清楚。尽管其潜在影响巨大，但填补往往被忽视为一个预处理步骤，而关注点放在了重建误差的减少和整体性能上，忽略了填补如何对不同群体产生影响。我们的工作研究了填补选择对不同群体的重建误差和下游预测的算法公平性属性的影响。

    Machine learning risks reinforcing biases present in data, and, as we argue in this work, in what is absent from data. In healthcare, biases have marked medical history, leading to unequal care affecting marginalised groups. Patterns in missing data often reflect these group discrepancies, but the algorithmic fairness implications of group-specific missingness are not well understood. Despite its potential impact, imputation is often an overlooked preprocessing step, with attention placed on the reduction of reconstruction error and overall performance, ignoring how imputation can affect groups differently. Our work studies how imputation choices affect reconstruction errors across groups and algorithmic fairness properties of downstream predictions.
    

