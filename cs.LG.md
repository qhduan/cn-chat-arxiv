# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Swarm Characteristics Classification Using Neural Networks](https://arxiv.org/abs/2403.19572) | 本文研究了使用监督神经网络时间序列分类（NN TSC）预测军事背景下群体自主体的关键属性和战术，以及展示了NN TSC在快速推断攻击群体情报方面的有效性。 |
| [^2] | [A Transfer Attack to Image Watermarks](https://arxiv.org/abs/2403.15365) | 水印领域的研究表明，即使在攻击者无法访问水印模型或检测API的情况下，水印基础的AI生成图像检测器也无法抵抗对抗攻击。 |
| [^3] | [Describe-and-Dissect: Interpreting Neurons in Vision Networks with Language Models](https://arxiv.org/abs/2403.13771) | 提出了一种新颖的方法 Describe-and-Dissect（DnD），利用多模态深度学习生成复杂的自然语言描述，无需标记的训练数据或预定义的概念选择，并且通过广泛的定性和定量分析显示优于先前的工作。 |
| [^4] | [Addressing the Regulatory Gap: Moving Towards an EU AI Audit Ecosystem Beyond the AIA by Including Civil Society](https://arxiv.org/abs/2403.07904) | 提出了一个融合合规和监督的AI审计生态系统，强调了DSA和AIA监管框架中存在的监管空白，并要求AIA为研究人员和社会公民提供数据和模型访问权限 |
| [^5] | [Stacking as Accelerated Gradient Descent](https://arxiv.org/abs/2403.04978) | Stacking提出了一种理论解释，即实现了Nesterov的加速梯度下降形式，并证明对于某些深度线性残差网络，提供了加速训练。 |
| [^6] | [Sampling-based Distributed Training with Message Passing Neural Network](https://arxiv.org/abs/2402.15106) | 该论文介绍了一种基于采样和分布式训练的消息传递神经网络（MPNN），能够有效解决边缘图神经网络在节点数量增加时的扩展挑战。 |
| [^7] | [Scalable Decentralized Algorithms for Online Personalized Mean Estimation](https://arxiv.org/abs/2402.12812) | 本研究提出了一种可扩展的分散算法框架，使代理能够自组织成图，并提出了两种协同均值估计算法，解决了每个代理在学习模型的同时识别具有相似分布客户的挑战。 |
| [^8] | [Understanding Self-Distillation and Partial Label Learning in Multi-Class Classification with Label Noise](https://arxiv.org/abs/2402.10482) | 自蒸馏在多类别分类中扮演着标签平均化的角色，有助于模型关注与特定实例相关的特征簇以预测标签，但随着蒸馏轮次增加，性能会降低。此外，在标签噪声情景下自蒸馏被证明是有效的，找到了实现100%分类准确率所需的最小蒸馏轮次。 |
| [^9] | [Heterophily-Aware Fair Recommendation using Graph Convolutional Networks](https://arxiv.org/abs/2402.03365) | 本文提出了一种利用图卷积网络的公平推荐系统，名为HetroFair，旨在提高项目侧的公平性。HetroFair使用公平注意力和异质性特征加权两个组件来生成具有公平性意识的嵌入。 |
| [^10] | [Castor: Causal Temporal Regime Structure Learning.](http://arxiv.org/abs/2311.01412) | “Castor”是一个用于学习多元时间序列数据中因果关系的框架，能够综合学习各个区域的因果图。它通过最大化得分函数来推断区域的数量，并学习每个区域中的线性或非线性因果关系。 |
| [^11] | [AUTOPARLLM: GNN-Guided Automatic Code Parallelization using Large Language Models.](http://arxiv.org/abs/2310.04047) | AUTOPARLLM是一个用于自动发现并生成顺序编写程序并行版本的框架，其中包括一个基于GNN的并行性发现模块和一个基于LLM的代码生成器。 |
| [^12] | [PILOT: A Pre-Trained Model-Based Continual Learning Toolbox.](http://arxiv.org/abs/2309.07117) | 本论文介绍了一个名为PILOT的基于预训练模型的持续学习工具箱，为在处理流式数据并适应新数据到来的现实场景中，利用预训练模型进行增量学习提供了一种有前景的方法。 |
| [^13] | [Robotic Table Tennis: A Case Study into a High Speed Learning System.](http://arxiv.org/abs/2309.03315) | 本研究深入研究了一种真实世界的机器人学习系统，该系统能够与人类进行数百次的乒乓球回合，并且能够精确地将球返回到预定的目标位置。该系统整合了感知子系统、高速低延迟机器人控制器、仿真范例、自动重置真实世界环境等功能，并对系统的设计决策和重要性进行了详细描述。 |
| [^14] | [MRI Field-transfer Reconstruction with Limited Data: Regularization by Neural Style Transfer.](http://arxiv.org/abs/2308.10968) | 本论文通过使用神经风格转换进行正规化，实现了在有限数据条件下从低质量图像重建高质量图像的目标。实验结果验证了该方法在临床MRI扫描中的有效性和潜力。 |
| [^15] | [Finite Element Operator Network for Solving Parametric PDEs.](http://arxiv.org/abs/2308.04690) | 本文提出了一种新方法，通过有限元算子网络（FEONet）解决参数PDE。它结合了深度学习和传统数值方法，展示了在没有输入-输出训练数据的情况下解决参数PDE的有效性，并在准确度、泛化性和计算灵活性方面优于现有方法。 |
| [^16] | [ArrayBot: Reinforcement Learning for Generalizable Distributed Manipulation through Touch.](http://arxiv.org/abs/2306.16857) | ArrayBot通过强化学习实现了通用分布式操作，通过对动作空间的重新定义和采用触觉观察训练，其控制策略不仅能够推广到未见过的物体形状，还能在实际机器人中进行转移，展示了巨大的潜力。 |
| [^17] | [CARSO: Counter-Adversarial Recall of Synthetic Observations.](http://arxiv.org/abs/2306.06081) | 本文提出了一种新的图像分类的对抗性防御机制CARSO，该方法可以比最先进的对抗性训练更好地保护分类器，通过利用生成模型进行对抗净化来进行最终分类，并成功地保护自己免受未预见的威胁和最终攻击。 |
| [^18] | [Layer-level activation mechanism.](http://arxiv.org/abs/2306.04940) | 去噪声更好，表现更好的分层级别激活机制 |
| [^19] | [On the Computational Cost of Stochastic Security.](http://arxiv.org/abs/2305.07973) | 本文探究了使用长期持续蒙特卡罗模拟是否能提高能量模型的质量，并通过增加计算预算改进了模型的校准性和对抗鲁棒性。 |
| [^20] | [FakET: Simulating Cryo-Electron Tomograms with Neural Style Transfer.](http://arxiv.org/abs/2304.02011) | 本文提出了一种使用加性噪声和神经风格迁移技术来模拟电子显微镜正向算子，以解决深度学习方法需要大量训练数据集的问题。该方法在粒子定位和分类任务上表现良好。 |

# 详细

[^1]: 使用神经网络对群体特性进行分类

    Swarm Characteristics Classification Using Neural Networks

    [https://arxiv.org/abs/2403.19572](https://arxiv.org/abs/2403.19572)

    本文研究了使用监督神经网络时间序列分类（NN TSC）预测军事背景下群体自主体的关键属性和战术，以及展示了NN TSC在快速推断攻击群体情报方面的有效性。

    

    理解群体自主体的特性对于国防和安全应用至关重要。本文介绍了使用监督神经网络时间序列分类（NN TSC）来预测军事环境中群体自主体的关键属性和战术的研究。具体地，NN TSC被应用于推断两个二进制属性 - 通信和比例导航 - 这两者结合定义了四种互斥的群体战术。我们发现文献中对于使用神经网络进行群体分类存在一定的空白，并展示了NN TSC在快速推断有关攻击群体情报以指导反制动作方面的有效性。通过模拟的群体对战，我们评估了NN TSC在观察窗口要求、噪声鲁棒性和对群体规模的可扩展性方面的性能。关键发现显示NN能够使用较短的观察窗口以97%的准确率预测群体行为。

    arXiv:2403.19572v1 Announce Type: new  Abstract: Understanding the characteristics of swarming autonomous agents is critical for defense and security applications. This article presents a study on using supervised neural network time series classification (NN TSC) to predict key attributes and tactics of swarming autonomous agents for military contexts. Specifically, NN TSC is applied to infer two binary attributes - communication and proportional navigation - which combine to define four mutually exclusive swarm tactics. We identify a gap in literature on using NNs for swarm classification and demonstrate the effectiveness of NN TSC in rapidly deducing intelligence about attacking swarms to inform counter-maneuvers. Through simulated swarm-vs-swarm engagements, we evaluate NN TSC performance in terms of observation window requirements, noise robustness, and scalability to swarm size. Key findings show NNs can predict swarm behaviors with 97% accuracy using short observation windows of
    
[^2]: 一种针对图像水印的转移攻击

    A Transfer Attack to Image Watermarks

    [https://arxiv.org/abs/2403.15365](https://arxiv.org/abs/2403.15365)

    水印领域的研究表明，即使在攻击者无法访问水印模型或检测API的情况下，水印基础的AI生成图像检测器也无法抵抗对抗攻击。

    

    水印已被广泛应用于工业领域，用于检测由人工智能生成的图像。文献中对这种基于水印的检测器在白盒和黑盒环境下对抗攻击的稳健性有很好的理解。然而，在无盒环境下的稳健性却知之甚少。具体来说，多项研究声称图像水印在这种环境下是稳健的。在这项工作中，我们提出了一种新的转移对抗攻击来针对无盒环境下的图像水印。我们的转移攻击向带水印的图像添加微扰，以躲避被攻击者训练的多个替代水印模型，并且经过扰动的带水印图像也能躲避目标水印模型。我们的主要贡献是理论上和经验上展示了，基于水印的人工智能生成图像检测器即使攻击者没有访问水印模型或检测API，也不具有对抗攻击的稳健性。

    arXiv:2403.15365v1 Announce Type: cross  Abstract: Watermark has been widely deployed by industry to detect AI-generated images. The robustness of such watermark-based detector against evasion attacks in the white-box and black-box settings is well understood in the literature. However, the robustness in the no-box setting is much less understood. In particular, multiple studies claimed that image watermark is robust in such setting. In this work, we propose a new transfer evasion attack to image watermark in the no-box setting. Our transfer attack adds a perturbation to a watermarked image to evade multiple surrogate watermarking models trained by the attacker itself, and the perturbed watermarked image also evades the target watermarking model. Our major contribution is to show that, both theoretically and empirically, watermark-based AI-generated image detector is not robust to evasion attacks even if the attacker does not have access to the watermarking model nor the detection API.
    
[^3]: 使用语言模型解释视觉网络中的神经元：描述与解剖

    Describe-and-Dissect: Interpreting Neurons in Vision Networks with Language Models

    [https://arxiv.org/abs/2403.13771](https://arxiv.org/abs/2403.13771)

    提出了一种新颖的方法 Describe-and-Dissect（DnD），利用多模态深度学习生成复杂的自然语言描述，无需标记的训练数据或预定义的概念选择，并且通过广泛的定性和定量分析显示优于先前的工作。

    

    在本文中，我们提出了Describe-and-Dissect（DnD），一种新颖的方法，用于描述视觉网络中隐藏神经元的作用。DnD利用多模态深度学习的最新进展，生成复杂的自然语言描述，无需标记的训练数据或预定义的概念选择。此外，DnD是无需训练的，这意味着我们不训练任何新模型，未来可以轻松利用更强大的通用模型。我们进行了广泛的定性和定量分析，表明DnD通过提供更高质量的神经元描述优于先前的工作。具体而言，我们的方法平均提供最高质量的标签，并且被选为神经元的最佳解释的概率是最佳基线的两倍多。

    arXiv:2403.13771v1 Announce Type: cross  Abstract: In this paper, we propose Describe-and-Dissect (DnD), a novel method to describe the roles of hidden neurons in vision networks. DnD utilizes recent advancements in multimodal deep learning to produce complex natural language descriptions, without the need for labeled training data or a predefined set of concepts to choose from. Additionally, DnD is training-free, meaning we don't train any new models and can easily leverage more capable general purpose models in the future. We have conducted extensive qualitative and quantitative analysis to show that DnD outperforms prior work by providing higher quality neuron descriptions. Specifically, our method on average provides the highest quality labels and is more than 2 times as likely to be selected as the best explanation for a neuron than the best baseline.
    
[^4]: 正视监管空白：通过纳入社会公民打造超越AIA的欧盟AI审计生态系统

    Addressing the Regulatory Gap: Moving Towards an EU AI Audit Ecosystem Beyond the AIA by Including Civil Society

    [https://arxiv.org/abs/2403.07904](https://arxiv.org/abs/2403.07904)

    提出了一个融合合规和监督的AI审计生态系统，强调了DSA和AIA监管框架中存在的监管空白，并要求AIA为研究人员和社会公民提供数据和模型访问权限

    

    欧洲立法机构提出了数字服务法案（DSA）和人工智能法案（AIA）来规范平台和人工智能（AI）产品。本文审查了第三方审计在这两项法律中的地位以及在多大程度上提供模型和数据的访问权限。通过考虑审计生态系统中第三方审计和第三方数据访问的价值，我们发现了一个监管空白，即《人工智能法案》没有为研究人员和社会公民提供数据访问权限。我们对文献的贡献包括：（1）定义了一个融合合规和监督的AI审计生态系统。（2）强调了DSA和AIA监管框架中存在的监管空白，阻碍了AI审计生态系统的建立。（3）强调研究和社会公民的第三方审计必须成为该生态系统的一部分，并要求AIA包括数据和模型访问权限。

    arXiv:2403.07904v1 Announce Type: cross  Abstract: The European legislature has proposed the Digital Services Act (DSA) and Artificial Intelligence Act (AIA) to regulate platforms and Artificial Intelligence (AI) products. We review to what extent third-party audits are part of both laws and to what extent access to models and data is provided. By considering the value of third-party audits and third-party data access in an audit ecosystem, we identify a regulatory gap in that the Artificial Intelligence Act does not provide access to data for researchers and civil society. Our contributions to the literature include: (1) Defining an AI audit ecosystem that incorporates compliance and oversight. (2) Highlighting a regulatory gap within the DSA and AIA regulatory framework, preventing the establishment of an AI audit ecosystem. (3) Emphasizing that third-party audits by research and civil society must be part of that ecosystem and demand that the AIA include data and model access for ce
    
[^5]: Stacking作为加速梯度下降算法

    Stacking as Accelerated Gradient Descent

    [https://arxiv.org/abs/2403.04978](https://arxiv.org/abs/2403.04978)

    Stacking提出了一种理论解释，即实现了Nesterov的加速梯度下降形式，并证明对于某些深度线性残差网络，提供了加速训练。

    

    Stacking是一种启发式技术，通过逐渐增加层数并通过从旧层复制参数来初始化新层，用于训练深度残差网络，已经被证明在提高深度神经网络训练效率方面非常成功。本文提出了对于Stacking有效性的理论解释：即，Stacking实现了Nesterov的加速梯度下降的一种形式。该理论还涵盖了诸如提升方法中构建的加法集成等更简单的模型，并为每一轮提升过程中初始化新分类器的类似广泛使用的实用启发式提供了解释。我们还证明了对于某些深度线性残差网络，通过对Nesterov的加速梯度方法的一个新的潜能函数分析，Stacking确实提供了加速训练，从而允许更新中的误差。我们进行了概念验证实验来验证我们的理论。

    arXiv:2403.04978v1 Announce Type: new  Abstract: Stacking, a heuristic technique for training deep residual networks by progressively increasing the number of layers and initializing new layers by copying parameters from older layers, has proven quite successful in improving the efficiency of training deep neural networks. In this paper, we propose a theoretical explanation for the efficacy of stacking: viz., stacking implements a form of Nesterov's accelerated gradient descent. The theory also covers simpler models such as the additive ensembles constructed in boosting methods, and provides an explanation for a similar widely-used practical heuristic for initializing the new classifier in each round of boosting. We also prove that for certain deep linear residual networks, stacking does provide accelerated training, via a new potential function analysis of the Nesterov's accelerated gradient method which allows errors in updates. We conduct proof-of-concept experiments to validate our
    
[^6]: 基于采样的消息传递神经网络分布式训练

    Sampling-based Distributed Training with Message Passing Neural Network

    [https://arxiv.org/abs/2402.15106](https://arxiv.org/abs/2402.15106)

    该论文介绍了一种基于采样和分布式训练的消息传递神经网络（MPNN），能够有效解决边缘图神经网络在节点数量增加时的扩展挑战。

    

    在这项研究中，我们介绍了一种基于域分解的消息传递神经网络（MPNN）分布式训练和推断方法。我们的目标是解决随着节点数量增加而扩展边缘图神经网络的挑战。通过我们的分布式训练方法，结合Nystrom-近似采样技术，我们提出了一种可扩展的图神经网络，称为DS-MPNN（其中D和S分别代表分布式和采样），能够扩展到$O(10^5)$个节点。我们在两个案例上验证了我们的采样和分布式训练方法：（a）Darcy流数据集和（b）2-D机翼的稳态RANS模拟，提供了与单GPU实现和基于节点的图卷积网络（GCNs）的比较。DS-MPNN模型表现出与单GPU实现相当的准确性，能够容纳比单个GPU实现更多数量的节点。

    arXiv:2402.15106v1 Announce Type: new  Abstract: In this study, we introduce a domain-decomposition-based distributed training and inference approach for message-passing neural networks (MPNN). Our objective is to address the challenge of scaling edge-based graph neural networks as the number of nodes increases. Through our distributed training approach, coupled with Nystr\"om-approximation sampling techniques, we present a scalable graph neural network, referred to as DS-MPNN (D and S standing for distributed and sampled, respectively), capable of scaling up to $O(10^5)$ nodes. We validate our sampling and distributed training approach on two cases: (a) a Darcy flow dataset and (b) steady RANS simulations of 2-D airfoils, providing comparisons with both single-GPU implementation and node-based graph convolution networks (GCNs). The DS-MPNN model demonstrates comparable accuracy to single-GPU implementation, can accommodate a significantly larger number of nodes compared to the single-
    
[^7]: 可扩展的分散算法用于在线个性化均值估计

    Scalable Decentralized Algorithms for Online Personalized Mean Estimation

    [https://arxiv.org/abs/2402.12812](https://arxiv.org/abs/2402.12812)

    本研究提出了一种可扩展的分散算法框架，使代理能够自组织成图，并提出了两种协同均值估计算法，解决了每个代理在学习模型的同时识别具有相似分布客户的挑战。

    

    在许多情况下，代理缺乏足够的数据直接学习模型。与其他代理合作可能有所帮助，但当本地数据分布不同时，会引入偏差-方差权衡。一个关键挑战是每个代理在学习模型的同时识别具有相似分布的客户，这个问题主要仍未解决。本研究着眼于一个简化版本的普遍问题，即每个代理随时间从实值分布中收集样本来估计其均值。现有算法面临着不切实际的空间和时间复杂度（与代理数量A的平方成正比）。为了解决可扩展性挑战，我们提出了一个框架，代理自组织成一个图，使得每个代理只能与选定数量的对等体r进行通信。我们介绍了两种协作均值估计算法：一种灵感来源于信念传播，另一种采用基于共识的方法。

    arXiv:2402.12812v1 Announce Type: new  Abstract: In numerous settings, agents lack sufficient data to directly learn a model. Collaborating with other agents may help, but it introduces a bias-variance trade-off, when local data distributions differ. A key challenge is for each agent to identify clients with similar distributions while learning the model, a problem that remains largely unresolved. This study focuses on a simplified version of the overarching problem, where each agent collects samples from a real-valued distribution over time to estimate its mean. Existing algorithms face impractical space and time complexities (quadratic in the number of agents A). To address scalability challenges, we propose a framework where agents self-organize into a graph, allowing each agent to communicate with only a selected number of peers r. We introduce two collaborative mean estimation algorithms: one draws inspiration from belief propagation, while the other employs a consensus-based appr
    
[^8]: 理解带有标签噪音的多类别分类中的自蒸馏和部分标签学习

    Understanding Self-Distillation and Partial Label Learning in Multi-Class Classification with Label Noise

    [https://arxiv.org/abs/2402.10482](https://arxiv.org/abs/2402.10482)

    自蒸馏在多类别分类中扮演着标签平均化的角色，有助于模型关注与特定实例相关的特征簇以预测标签，但随着蒸馏轮次增加，性能会降低。此外，在标签噪声情景下自蒸馏被证明是有效的，找到了实现100%分类准确率所需的最小蒸馏轮次。

    

    自蒸馏（SD）是使用教师模型的输出训练学生模型的过程，两个模型共享相同的架构。我们的研究从理论上考察了使用交叉熵损失的多类别分类中的SD，探索了多轮SD和具有精炼教师输出的SD，这些灵感来自部分标签学习（PLL）。通过推导学生模型输出的封闭形式解，我们发现SD本质上是在具有高特征相关性的实例之间进行标签平均。最初有益的平均化有助于模型专注于与给定实例相关联的特征簇以预测标签。然而，随着蒸馏轮次的增加，性能会下降。此外，我们展示了SD在标签噪声情景中的有效性，并确定实现100%分类准确率所需的标签损坏条件和最小蒸馏轮次数。

    arXiv:2402.10482v1 Announce Type: new  Abstract: Self-distillation (SD) is the process of training a student model using the outputs of a teacher model, with both models sharing the same architecture. Our study theoretically examines SD in multi-class classification with cross-entropy loss, exploring both multi-round SD and SD with refined teacher outputs, inspired by partial label learning (PLL). By deriving a closed-form solution for the student model's outputs, we discover that SD essentially functions as label averaging among instances with high feature correlations. Initially beneficial, this averaging helps the model focus on feature clusters correlated with a given instance for predicting the label. However, it leads to diminishing performance with increasing distillation rounds. Additionally, we demonstrate SD's effectiveness in label noise scenarios and identify the label corruption condition and minimum number of distillation rounds needed to achieve 100% classification accur
    
[^9]: 利用图卷积网络的異质友善推荐方法

    Heterophily-Aware Fair Recommendation using Graph Convolutional Networks

    [https://arxiv.org/abs/2402.03365](https://arxiv.org/abs/2402.03365)

    本文提出了一种利用图卷积网络的公平推荐系统，名为HetroFair，旨在提高项目侧的公平性。HetroFair使用公平注意力和异质性特征加权两个组件来生成具有公平性意识的嵌入。

    

    近年来，图神经网络（GNNs）已成为提高推荐系统准确性和性能的流行工具。现代推荐系统不仅设计为为最终用户服务，还要让其他参与者（如项目和项目供应商）从中受益。这些参与者可能具有不同或冲突的目标和利益，这引发了对公平性和流行度偏差考虑的需求。基于GNN的推荐方法也面临不公平性和流行度偏差的挑战，其归一化和聚合过程受到这些挑战的影响。在本文中，我们提出了一种公平的基于GNN的推荐系统，称为HetroFair，旨在提高项目侧的公平性。HetroFair使用两个独立的组件生成具有公平性意识的嵌入：i）公平注意力，它在GNN的归一化过程中结合了点积，以减少节点度数的影响；ii）异质性特征加权，为不同的特征分配不同的权重。

    In recent years, graph neural networks (GNNs) have become a popular tool to improve the accuracy and performance of recommender systems. Modern recommender systems are not only designed to serve the end users, but also to benefit other participants, such as items and items providers. These participants may have different or conflicting goals and interests, which raise the need for fairness and popularity bias considerations. GNN-based recommendation methods also face the challenges of unfairness and popularity bias and their normalization and aggregation processes suffer from these challenges. In this paper, we propose a fair GNN-based recommender system, called HetroFair, to improve items' side fairness. HetroFair uses two separate components to generate fairness-aware embeddings: i) fairness-aware attention which incorporates dot product in the normalization process of GNNs, to decrease the effect of nodes' degrees, and ii) heterophily feature weighting to assign distinct weights to 
    
[^10]: Castor: 因果时序区域结构学习

    Castor: Causal Temporal Regime Structure Learning. (arXiv:2311.01412v1 [cs.LG])

    [http://arxiv.org/abs/2311.01412](http://arxiv.org/abs/2311.01412)

    “Castor”是一个用于学习多元时间序列数据中因果关系的框架，能够综合学习各个区域的因果图。它通过最大化得分函数来推断区域的数量，并学习每个区域中的线性或非线性因果关系。

    

    揭示多元时间序列数据之间的因果关系是一个重要且具有挑战性的目标，涉及到从气候科学到医疗保健等各个学科的广泛范围。这些数据包含线性或非线性关系，并且通常遵循多个先验未知的区域。现有的因果发现方法可以从具有已知区域的异构数据中推断出摘要因果图，但在全面学习区域和相应的因果图方面存在不足。在本文中，我们介绍了CASTOR，这是一个新颖的框架，旨在学习由不同因果图统治的各种异构时间序列数据中的因果关系。通过EM算法通过最大化一个得分函数，CASTOR推断出区域的数量并学习每个区域中的线性或非线性因果关系。我们展示了CASTOR的稳健收敛性质，特别突出了其有效性。

    The task of uncovering causal relationships among multivariate time series data stands as an essential and challenging objective that cuts across a broad array of disciplines ranging from climate science to healthcare. Such data entails linear or non-linear relationships, and usually follow multiple a priori unknown regimes. Existing causal discovery methods can infer summary causal graphs from heterogeneous data with known regimes, but they fall short in comprehensively learning both regimes and the corresponding causal graph. In this paper, we introduce CASTOR, a novel framework designed to learn causal relationships in heterogeneous time series data composed of various regimes, each governed by a distinct causal graph. Through the maximization of a score function via the EM algorithm, CASTOR infers the number of regimes and learns linear or non-linear causal relationships in each regime. We demonstrate the robust convergence properties of CASTOR, specifically highlighting its profic
    
[^11]: AUTOPARLLM：使用大型语言模型的GNN引导的自动代码并行化

    AUTOPARLLM: GNN-Guided Automatic Code Parallelization using Large Language Models. (arXiv:2310.04047v1 [cs.LG])

    [http://arxiv.org/abs/2310.04047](http://arxiv.org/abs/2310.04047)

    AUTOPARLLM是一个用于自动发现并生成顺序编写程序并行版本的框架，其中包括一个基于GNN的并行性发现模块和一个基于LLM的代码生成器。

    

    并行化顺序编写的程序是一项具有挑战性的任务。即使是经验丰富的开发人员也需要花费相当多的时间来寻找并行性机会，然后实际编写顺序编写程序的并行版本。为了解决这个问题，我们提出了AUTOPARLLM，一个用于自动发现并行性并生成顺序编写程序的并行版本的框架。我们的框架包括两个主要组件：i）基于异构图神经网络（GNN）的并行性发现和并行模式检测模块，以及ii）基于LLM的代码生成器，用于生成顺序程序的并行对应版本。我们使用GNN学习程序的流敏感特征，以识别顺序程序中的并行区域，并使用GNN的结果构建增强提示，以供LLM基础生成器最终产生顺序程序的并行对应版本。我们在11个应用上评估了AUTOPARLLM

    Parallelizing sequentially written programs is a challenging task. Even experienced developers need to spend considerable time finding parallelism opportunities and then actually writing parallel versions of sequentially written programs. To address this issue, we present AUTOPARLLM, a framework for automatically discovering parallelism and generating the parallel version of the sequentially written program. Our framework consists of two major components: i) a heterogeneous Graph Neural Network (GNN) based parallelism discovery and parallel pattern detection module, and ii) an LLM-based code generator to generate the parallel counterpart of the sequential programs. We use the GNN to learn the flow-aware characteristics of the programs to identify parallel regions in sequential programs and then construct an enhanced prompt using the GNN's results for the LLM-based generator to finally produce the parallel counterparts of the sequential programs. We evaluate AUTOPARLLM on 11 application
    
[^12]: PILOT：一个基于预训练模型的持续学习工具箱

    PILOT: A Pre-Trained Model-Based Continual Learning Toolbox. (arXiv:2309.07117v1 [cs.LG])

    [http://arxiv.org/abs/2309.07117](http://arxiv.org/abs/2309.07117)

    本论文介绍了一个名为PILOT的基于预训练模型的持续学习工具箱，为在处理流式数据并适应新数据到来的现实场景中，利用预训练模型进行增量学习提供了一种有前景的方法。

    

    传统机器学习可以有效地解决各种问题，但主要在封闭环境中运作，处理流式数据时存在局限性。作为解决方案，增量学习应运而生，用于处理涉及新数据到来的现实场景。最近，预训练在不断取得重要进展，并引起了众多研究人员的关注。这些预训练模型（PTMs）的强大性能为开发能够有效适应现实场景的持续学习算法提供了有希望的途径。因此，探索在增量学习中利用PTMs已经成为必需。本文介绍了一个名为PILOT的基于预训练模型的持续学习工具箱。一方面，PILOT实施了一些基于预训练模型的最新班级增量学习算法，如L2P、DualPrompt和CODA-Prompt。另一方面，PILOT也适应了典型的班级增量学习场景。

    While traditional machine learning can effectively tackle a wide range of problems, it primarily operates within a closed-world setting, which presents limitations when dealing with streaming data. As a solution, incremental learning emerges to address real-world scenarios involving new data's arrival. Recently, pre-training has made significant advancements and garnered the attention of numerous researchers. The strong performance of these pre-trained models (PTMs) presents a promising avenue for developing continual learning algorithms that can effectively adapt to real-world scenarios. Consequently, exploring the utilization of PTMs in incremental learning has become essential. This paper introduces a pre-trained model-based continual learning toolbox known as PILOT. On the one hand, PILOT implements some state-of-the-art class-incremental learning algorithms based on pre-trained models, such as L2P, DualPrompt, and CODA-Prompt. On the other hand, PILOT also fits typical class-incre
    
[^13]: 机器人乒乓球：一个高速学习系统的案例研究

    Robotic Table Tennis: A Case Study into a High Speed Learning System. (arXiv:2309.03315v1 [cs.RO])

    [http://arxiv.org/abs/2309.03315](http://arxiv.org/abs/2309.03315)

    本研究深入研究了一种真实世界的机器人学习系统，该系统能够与人类进行数百次的乒乓球回合，并且能够精确地将球返回到预定的目标位置。该系统整合了感知子系统、高速低延迟机器人控制器、仿真范例、自动重置真实世界环境等功能，并对系统的设计决策和重要性进行了详细描述。

    

    我们展示了一个真实世界的机器人学习系统的深入研究，此前的工作已经表明该系统能够与人类进行数百次的乒乓球回合，并且能够精确地将球返回到预定的目标位置。该系统结合了高度优化的感知子系统、高速低延迟的机器人控制器、防止现实世界中损坏并能够进行零-shot转移策略训练的仿真范例，以及自动重置真实世界环境，使自主训练和评估在物理机器人上成为可能。我们通过详细描述整个系统，包括通常不广泛传播的大量设计决策，并结合一系列研究来阐明缓解各种延迟源的重要性、考虑训练和部署分布变化、感知系统的稳健性、策略超参数的敏感性和动作空间选择等方面的重要性。视频展示了系统的组件。

    We present a deep-dive into a real-world robotic learning system that, in previous work, was shown to be capable of hundreds of table tennis rallies with a human and has the ability to precisely return the ball to desired targets. This system puts together a highly optimized perception subsystem, a high-speed low-latency robot controller, a simulation paradigm that can prevent damage in the real world and also train policies for zero-shot transfer, and automated real world environment resets that enable autonomous training and evaluation on physical robots. We complement a complete system description, including numerous design decisions that are typically not widely disseminated, with a collection of studies that clarify the importance of mitigating various sources of latency, accounting for training and deployment distribution shifts, robustness of the perception system, sensitivity to policy hyper-parameters, and choice of action space. A video demonstrating the components of the sys
    
[^14]: 使用有限数据的MRI场转移重建：通过神经风格转换进行正规化

    MRI Field-transfer Reconstruction with Limited Data: Regularization by Neural Style Transfer. (arXiv:2308.10968v1 [cs.CV])

    [http://arxiv.org/abs/2308.10968](http://arxiv.org/abs/2308.10968)

    本论文通过使用神经风格转换进行正规化，实现了在有限数据条件下从低质量图像重建高质量图像的目标。实验结果验证了该方法在临床MRI扫描中的有效性和潜力。

    

    最近的研究表明，使用基于深度学习模型的MRI重建取得了成功。然而，大多数报告的方法都需要在特定任务的大规模数据集上进行训练。通过降噪（RED）正规化是一种将降噪器作为图像重建先验的通用流程。RED的潜力已经在多个与图像相关的任务（如降噪、去模糊和超分辨率）中得到了证明。本文提出了一种通过神经风格转换（RNST）方法进行正规化的方法，进一步利用神经转移和降噪引擎的先验信息。这使得RNST能够从有噪声的低质量图像中重建出高质量图像，图像风格和有限数据不同。我们使用1.5T和3T的临床MRI扫描验证了RNST，并且显示RNST可以显著提高图像质量。我们的结果突显了RNST框架在MRI重建和有限数据重建任务中的能力。

    Recent works have demonstrated success in MRI reconstruction using deep learning-based models. However, most reported approaches require training on a task-specific, large-scale dataset. Regularization by denoising (RED) is a general pipeline which embeds a denoiser as a prior for image reconstruction. The potential of RED has been demonstrated for multiple image-related tasks such as denoising, deblurring and super-resolution. In this work, we propose a regularization by neural style transfer (RNST) method to further leverage the priors from the neural transfer and denoising engine. This enables RNST to reconstruct a high-quality image from a noisy low-quality image with different image styles and limited data. We validate RNST with clinical MRI scans from 1.5T and 3T and show that RNST can significantly boost image quality. Our results highlight the capability of the RNST framework for MRI reconstruction and the potential for reconstruction tasks with limited data.
    
[^15]: 用于解决参数PDE的有限元算子网络

    Finite Element Operator Network for Solving Parametric PDEs. (arXiv:2308.04690v1 [math.NA])

    [http://arxiv.org/abs/2308.04690](http://arxiv.org/abs/2308.04690)

    本文提出了一种新方法，通过有限元算子网络（FEONet）解决参数PDE。它结合了深度学习和传统数值方法，展示了在没有输入-输出训练数据的情况下解决参数PDE的有效性，并在准确度、泛化性和计算灵活性方面优于现有方法。

    

    偏微分方程（PDE）是我们理解和预测物理、工程和金融等众多领域自然现象的基础。然而，解决参数PDE是一项复杂的任务，需要高效的数值方法。在本文中，我们提出了一种通过有限元算子网络（FEONet）解决参数PDE的新方法。我们的方法结合了深度学习和传统数值方法，特别是有限元法，以在没有任何配对的输入-输出训练数据的情况下解决参数PDE。我们在几个基准问题上展示了我们方法的效果，并且表明它在准确度、泛化性和计算灵活性方面优于现有的最先进方法。我们的FEONet框架在模拟具有不同边界条件和复杂域的各种领域中显示出潜力。

    Partial differential equations (PDEs) underlie our understanding and prediction of natural phenomena across numerous fields, including physics, engineering, and finance. However, solving parametric PDEs is a complex task that necessitates efficient numerical methods. In this paper, we propose a novel approach for solving parametric PDEs using a Finite Element Operator Network (FEONet). Our proposed method leverages the power of deep learning in conjunction with traditional numerical methods, specifically the finite element method, to solve parametric PDEs in the absence of any paired input-output training data. We demonstrate the effectiveness of our approach on several benchmark problems and show that it outperforms existing state-of-the-art methods in terms of accuracy, generalization, and computational flexibility. Our FEONet framework shows potential for application in various fields where PDEs play a crucial role in modeling complex domains with diverse boundary conditions and sin
    
[^16]: ArrayBot: 通过触觉实现通用分布式操作的强化学习

    ArrayBot: Reinforcement Learning for Generalizable Distributed Manipulation through Touch. (arXiv:2306.16857v1 [cs.RO])

    [http://arxiv.org/abs/2306.16857](http://arxiv.org/abs/2306.16857)

    ArrayBot通过强化学习实现了通用分布式操作，通过对动作空间的重新定义和采用触觉观察训练，其控制策略不仅能够推广到未见过的物体形状，还能在实际机器人中进行转移，展示了巨大的潜力。

    

    我们介绍了ArrayBot，这是一个由16×16的竖向滑动柱和触觉传感器组成的分布式操作系统，可以同时支持、感知和操作桌面上的物体。为了实现通用分布式操作，我们利用强化学习算法自动发现控制策略。面对大量冗余的动作，我们提出考虑空间局部动作图块和频域中低频动作来重新定义动作空间。通过这个重新定义的动作空间，我们训练强化学习代理，只通过触觉观察即可重新定位不同的物体。令人惊讶的是，我们发现发现的策略不仅可以推广到模拟器中看不见的物体形状，而且可以在物理机器人上进行转移而不需要任何域随机化。利用部署的策略，我们展示了丰富的真实世界操作任务，展示了其巨大潜力。

    We present ArrayBot, a distributed manipulation system consisting of a $16 \times 16$ array of vertically sliding pillars integrated with tactile sensors, which can simultaneously support, perceive, and manipulate the tabletop objects. Towards generalizable distributed manipulation, we leverage reinforcement learning (RL) algorithms for the automatic discovery of control policies. In the face of the massively redundant actions, we propose to reshape the action space by considering the spatially local action patch and the low-frequency actions in the frequency domain. With this reshaped action space, we train RL agents that can relocate diverse objects through tactile observations only. Surprisingly, we find that the discovered policy can not only generalize to unseen object shapes in the simulator but also transfer to the physical robot without any domain randomization. Leveraging the deployed policy, we present abundant real-world manipulation tasks, illustrating the vast potential of
    
[^17]: CARSO: 对抗性合成观测的反对抗性召回

    CARSO: Counter-Adversarial Recall of Synthetic Observations. (arXiv:2306.06081v1 [cs.CV])

    [http://arxiv.org/abs/2306.06081](http://arxiv.org/abs/2306.06081)

    本文提出了一种新的图像分类的对抗性防御机制CARSO，该方法可以比最先进的对抗性训练更好地保护分类器，通过利用生成模型进行对抗净化来进行最终分类，并成功地保护自己免受未预见的威胁和最终攻击。

    

    本文提出了一种新的对抗性防御机制CARSO，用于图像分类，灵感来自认知神经科学的线索。该方法与对抗训练具有协同互补性，并依赖于被攻击分类器的内部表示的知识。通过利用生成模型进行对抗净化，该方法采样输入的重构来进行最终分类。在各种图像数据集和分类器体系结构上进行的实验评估表明，CARSO能够比最先进的对抗性训练更好地保护分类器——同时具有可接受的清洁准确度损失。此外，防御体系结构成功地保护自己免受未预见的威胁和最终攻击。代码和预训练模型可在https://github.com/获得。

    In this paper, we propose a novel adversarial defence mechanism for image classification -- CARSO -- inspired by cues from cognitive neuroscience. The method is synergistically complementary to adversarial training and relies on knowledge of the internal representation of the attacked classifier. Exploiting a generative model for adversarial purification, conditioned on such representation, it samples reconstructions of inputs to be finally classified. Experimental evaluation by a well-established benchmark of varied, strong adaptive attacks, across diverse image datasets and classifier architectures, shows that CARSO is able to defend the classifier significantly better than state-of-the-art adversarial training alone -- with a tolerable clean accuracy toll. Furthermore, the defensive architecture succeeds in effectively shielding itself from unforeseen threats, and end-to-end attacks adapted to fool stochastic defences. Code and pre-trained models are available at https://github.com/
    
[^18]: 分层级别激活机制

    Layer-level activation mechanism. (arXiv:2306.04940v1 [cs.LG])

    [http://arxiv.org/abs/2306.04940](http://arxiv.org/abs/2306.04940)

    去噪声更好，表现更好的分层级别激活机制

    

    本文提出了一种新颖的激活机制，旨在建立分层级别激活功能（LayerAct）。这些功能旨在通过减少输入偏移所导致的激活输出的分层级波动来降低传统元素级激活功能的噪音鲁棒性。此外，LayerAct功能实现了类似于零的平均激活输出，而不限制激活输出空间。我们进行了分析和实验，证明LayerAct功能在噪声鲁棒性方面优于元素级激活功能，并且经验证明这些功能的平均激活结果类似于零。在三个基准图像分类任务的实验结果表明，在处理嘈杂的图像数据集时，LayerAct功能比元素级激活功能表现更好，而在大多数情况下，清洁数据集的表现也是优越的。

    In this work, we propose a novel activation mechanism aimed at establishing layer-level activation (LayerAct) functions. These functions are designed to be more noise-robust compared to traditional element-level activation functions by reducing the layer-level fluctuation of the activation outputs due to shift in inputs. Moreover, the LayerAct functions achieve a zero-like mean activation output without restricting the activation output space. We present an analysis and experiments demonstrating that LayerAct functions exhibit superior noise-robustness compared to element-level activation functions, and empirically show that these functions have a zero-like mean activation. Experimental results on three benchmark image classification tasks show that LayerAct functions excel in handling noisy image datasets, outperforming element-level activation functions, while the performance on clean datasets is also superior in most cases.
    
[^19]: 论随机安全性的计算成本

    On the Computational Cost of Stochastic Security. (arXiv:2305.07973v1 [cs.LG])

    [http://arxiv.org/abs/2305.07973](http://arxiv.org/abs/2305.07973)

    本文探究了使用长期持续蒙特卡罗模拟是否能提高能量模型的质量，并通过增加计算预算改进了模型的校准性和对抗鲁棒性。

    

    我们探讨了使用朗之万动力学的长期持续蒙特卡罗模拟是否会提高基于能量的模型（EBM）所达到的表征质量。我们考虑一种方案，其中使用训练过的EBM的扩散过程的蒙特卡罗模拟，用于提高独立分类器网络的对抗鲁棒性和校准分数。我们的结果表明，在持续对比散度的计算预算增加吉布斯采样的情况下，改进了模型的校准性和对抗鲁棒性，澄清了实现有效从连续能量势中进行吉布斯采样的新量子和经典硬件和软件的实际价值。

    We investigate whether long-run persistent chain Monte Carlo simulation of Langevin dynamics improves the quality of the representations achieved by energy-based models (EBM). We consider a scheme wherein Monte Carlo simulation of a diffusion process using a trained EBM is used to improve the adversarial robustness and the calibration score of an independent classifier network. Our results show that increasing the computational budget of Gibbs sampling in persistent contrastive divergence improves the calibration and adversarial robustness of the model, elucidating the practical merit of realizing new quantum and classical hardware and software for efficient Gibbs sampling from continuous energy potentials.
    
[^20]: FakET: 利用神经风格迁移模拟冷冻电子断层图像

    FakET: Simulating Cryo-Electron Tomograms with Neural Style Transfer. (arXiv:2304.02011v1 [cs.LG])

    [http://arxiv.org/abs/2304.02011](http://arxiv.org/abs/2304.02011)

    本文提出了一种使用加性噪声和神经风格迁移技术来模拟电子显微镜正向算子，以解决深度学习方法需要大量训练数据集的问题。该方法在粒子定位和分类任务上表现良好。

    

    粒子定位和分类是计算显微学中最基本的问题之一。近年来，深度学习方法在这些任务中取得了巨大成功。这些监督式学习方法的一个关键缺点是它们需要大量的训练数据集，通常是与模拟透射电子显微镜物理的复杂数值正向模型中的粒子模型结合生成的。这些模型的计算机实现非常耗费计算资源，限制了它们的适用范围。本文提出了一种基于加性噪声和神经风格迁移技术模拟电子显微镜正向算子的简单方法。我们使用目前最先进的已经建立的状态之一对定位和分类任务进行评估，显示出与基准测试相当的性能。与以前的方法不同，我们的方法加速了运算，显著减少了计算成本。

    Particle localization and -classification constitute two of the most fundamental problems in computational microscopy. In recent years, deep learning based approaches have been introduced for these tasks with great success. A key shortcoming of these supervised learning methods is their need for large training data sets, typically generated from particle models in conjunction with complex numerical forward models simulating the physics of transmission electron microscopes. Computer implementations of such forward models are computationally extremely demanding and limit the scope of their applicability. In this paper we propose a simple method for simulating the forward operator of an electron microscope based on additive noise and Neural Style Transfer techniques. We evaluate the method on localization and classification tasks using one of the established state-of-the-art architectures showing performance on par with the benchmark. In contrast to previous approaches, our method acceler
    

