# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Data-centric Prediction Explanation via Kernelized Stein Discrepancy](https://arxiv.org/abs/2403.15576) | 该论文提出了一种基于内核化斯坦不相容性的数据中心预测解释方法，通过利用内核函数识别提供最佳预测支持给测试点的训练样本，取得了优异性能。 |
| [^2] | [Controlled Training Data Generation with Diffusion Models](https://arxiv.org/abs/2403.15309) | 提出了一种使用扩散模型生成控制训练数据的方法，通过两个反馈机制，一方面使用监督模型反馈找到对抗性提示词实现图像生成，另一方面通过引导使生成过程朝向特定目标分布。 |
| [^3] | [Carbon Footprint Reduction for Sustainable Data Centers in Real-Time](https://arxiv.org/abs/2403.14092) | 我们提出了一种Data Center Carbon Footprint Reduction (DC-CFR) 多代理强化学习（MARL）框架，旨在实时优化数据中心以减少碳足迹。 |
| [^4] | [Bridge the Modality and Capacity Gaps in Vision-Language Model Selection](https://arxiv.org/abs/2403.13797) | 本文分析了在语言-Only VLM选择中的两个固有挑战：「模态差距」和「能力差距」，并提出了VLM选择中弥合这两个差距的方法 |
| [^5] | [Usable XAI: 10 Strategies Towards Exploiting Explainability in the LLM Era](https://arxiv.org/abs/2403.08946) | 在大型语言模型时代，为了适应其复杂性和先进能力，我们引入了可用的XAI概念，通过积极增强LLMs在实际环境中的生产力和适用性，实现XAI方法论的重大转变。 |
| [^6] | [Scalable Density-based Clustering with Random Projections](https://arxiv.org/abs/2402.15679) | sDBSCAN是一种利用随机投影进行高维密度聚类的算法，在速度和准确性上显著优于其他算法。 |
| [^7] | [Fine-Tuning, Prompting, In-Context Learning and Instruction-Tuning: How Many Labelled Samples Do We Need?](https://arxiv.org/abs/2402.12819) | 专门模型通常只需少量标记样本（100-1000个）就能与通用模型持平甚至更好，取决于任务的复杂性和结果的变化。 |
| [^8] | [Can Tree Based Approaches Surpass Deep Learning in Anomaly Detection? A Benchmarking Study](https://arxiv.org/abs/2402.07281) | 本文通过一项基准研究评估了多种基于机器学习的异常检测算法，包括树结构方法和深度学习方法，并揭示了深度学习神话的真相。 |
| [^9] | [SVQ: Sparse Vector Quantization for Spatiotemporal Forecasting](https://arxiv.org/abs/2312.03406) | SVQ是一种利用稀疏回归实现简明表示的稀疏向量量化技术，通过保留关键细节和滤除噪声来提高时空预测性能。在实验中，SVQ在五个空间-时间基准数据集上取得了最先进的结果。 |
| [^10] | [Diversity-aware clustering: Computational Complexity and Approximation Algorithms.](http://arxiv.org/abs/2401.05502) | 本研究讨论了多样性感知聚类问题，在选择聚类中心时要考虑多个属性，同时最小化聚类目标。我们提出了针对不同聚类目标的参数化近似算法，这些算法在保证聚类质量的同时，具有紧确的近似比。 |
| [^11] | [CEFL: Carbon-Efficient Federated Learning.](http://arxiv.org/abs/2310.17972) | 该论文介绍了一种称为CEFL的碳高效联邦学习方法，通过使用自适应的成本感知策略来优化FL模型训练的任意成本度量，并成功实现了碳排放减少93％和训练时间减少50％的效果。 |
| [^12] | [Symphony of experts: orchestration with adversarial insights in reinforcement learning.](http://arxiv.org/abs/2310.16473) | 这篇论文介绍了一种利用专家策略进行决策指导的编排方法，通过将对抗性设置中的后悔边界结果转移到表格设置下的编排中，推广了自然策略梯度的分析，并提供了关于样本复杂度的洞察。这种方法的关键点在于其透明的证明。在随机匹配玩具模型中进行了模拟实验。 |
| [^13] | [Cross-Lingual Consistency of Factual Knowledge in Multilingual Language Models.](http://arxiv.org/abs/2310.10378) | 本论文研究了多语言预训练语言模型中事实知识的跨语言一致性，提出了一种新的度量方法，并通过分析模型大小、语言配对等因素发现了影响一致性的因素。实验结果表明，增加模型大小可以提高准确性，但不会改善跨语言一致性。 |
| [^14] | [OmniDrones: An Efficient and Flexible Platform for Reinforcement Learning in Drone Control.](http://arxiv.org/abs/2309.12825) | OmniDrones是一个专为无人机控制中的强化学习而设计的高效灵活平台，采用自下而上设计方法，并提供一系列基准任务和无人机学习工具。这个平台有助于将强化学习应用于实际无人机系统的研究。 |
| [^15] | [Multicollinearity Resolution Based on Machine Learning: A Case Study of Carbon Emissions in Sichuan Province.](http://arxiv.org/abs/2309.01115) | 本研究使用机器学习方法解决了多重共线性问题，针对四川省的碳排放情况进行了案例研究。研究结果确定了行业分组，评估了排放驱动因素，并提出了科学的减排策略，以改善情况。 |
| [^16] | [The CausalBench challenge: A machine learning contest for gene network inference from single-cell perturbation data.](http://arxiv.org/abs/2308.15395) | CausalBench挑战赛是一个机器学习竞赛，旨在构建基因网络推断的最新方法。参与者利用大规模遗传干扰数据提升了先进方法的性能。 |
| [^17] | [Geometry-Aware Approaches for Balancing Performance and Theoretical Guarantees in Linear Bandits.](http://arxiv.org/abs/2306.14872) | 本文提出了一种新的数据驱动技术，跟踪不确定度椭球体的几何形状，为线性赌博机算法建立实例相关的频率后悔界，并实现了平衡算法性能与理论保证的效果。 |
| [^18] | [Securing Visually-Aware Recommender Systems: An Adversarial Image Reconstruction and Detection Framework.](http://arxiv.org/abs/2306.07992) | 本文提出了一种对抗图像重构及检测框架来保护视觉感知推荐系统，能够防御局部扰动为特征的对抗攻击并且能够在干净和对抗性图像上进行训练来检测对抗性图像。 |
| [^19] | [Agent Performing Autonomous Stock Trading under Good and Bad Situations.](http://arxiv.org/abs/2306.03985) | 本文介绍了使用深度强化学习方法训练机器代理来自主执行股票交易的研究，并在不同市场环境下进行了评估。 |
| [^20] | [Differentially Private Synthetic Data via Foundation Model APIs 1: Images.](http://arxiv.org/abs/2305.15560) | 该论文提出了基于API的方法生成密切类似于原始私有数据的差分隐私（DP）合成数据，可以更轻松地部署。使用Private Evolution（PE）框架生成DP合成图像，结合了差分隐私、进化算法和元学习的技术，可以在保护隐私的同时生成既为DP又与原始图像外观相似的合成图像，并在流行的图像数据集上表现优异。 |
| [^21] | [Physics of Language Models: Part 1, Context-Free Grammar.](http://arxiv.org/abs/2305.13673) | 本研究探究了生成式语言模型如何学习上下文无关文法（CFG），并通过构造人造数据证明了预训练transformers可以学会生成具有接近完美准确度和显着多样性的句子。研究发现transformer内部的隐藏状态隐含而精确地编码了CFG结构，学会形成类似动态规划的“边界到边界”的注意力。此外，还研究了标准CFG的扩展，例如概率CFG和线性CFG，并证明transformers也可以学会这些扩展语法结构。 |
| [^22] | [AUTO: Adaptive Outlier Optimization for Online Test-Time OOD Detection.](http://arxiv.org/abs/2303.12267) | 本文提出了一个称为AUTO的方法，在在线测试时利用未标记的在线数据直接提高OOD检测性能。该方法自适应地优化网络参数并在线检测OOD样本，取得了优于现有方法的结果。 |
| [^23] | [Constrained Adversarial Learning and its applicability to Automated Software Testing: a systematic review.](http://arxiv.org/abs/2303.07546) | 本综述研究了受限对抗学习方法和自动化软件测试中受限数据生成方法的最新技术应用，探讨将这些方法整合至测试工具中以提高数字系统的鲁棒性和弹性。 |
| [^24] | [Increasing Fairness via Combination with Learning Guarantees.](http://arxiv.org/abs/2301.10813) | 该论文提出了一种公平质量度量方法，名为判别风险，旨在反映个体和群体公平性。此外，研究者还讨论了公平性是否可以在理论上得到保证。 |
| [^25] | [DPM-Solver++: Fast Solver for Guided Sampling of Diffusion Probabilistic Models.](http://arxiv.org/abs/2211.01095) | DPM-Solver++是一种快速求解器，在扩散概率模型的引导采样中表现出色，可加快样本生成速度。 |
| [^26] | [On the Generalized Likelihood Ratio Test and One-Class Classifiers.](http://arxiv.org/abs/2210.12494) | 本文考虑了一类分类器和广义似然比检验的问题，证明了多层感知器神经网络和支持向量机模型在收敛时会表现为广义似然比检验。同时，作者还展示了一类最小二乘SVM在收敛时也能达到广义似然比检验的效果。 |

# 详细

[^1]: 基于内核化斯坦不相容性的数据中心预测解释

    Data-centric Prediction Explanation via Kernelized Stein Discrepancy

    [https://arxiv.org/abs/2403.15576](https://arxiv.org/abs/2403.15576)

    该论文提出了一种基于内核化斯坦不相容性的数据中心预测解释方法，通过利用内核函数识别提供最佳预测支持给测试点的训练样本，取得了优异性能。

    

    现有的基于示例的预测解释方法通常通过模型的参数或潜在表示来连接测试和训练数据点。尽管这些方法提供了有关模型预测原因的线索，但它们经常表现出固有的缺陷，比如产生显着的计算开销或生成粗粒度的解释。本文提出了一种高精度和数据中心的解释（HD-Explain），这是一种利用内核化斯坦不相容性（KSD）属性的简单预测解释方法。具体来说，KSD唯一地为经过训练的模型定义了一个参数化的内核函数，用于编码与模型相关的数据相关性。通过利用内核函数，可以有效地识别提供最佳预测支持给测试点的训练样本。我们在多个分类领域进行了彻底的分析和实验，结果表明HD-Explain取得了优异的性能。

    arXiv:2403.15576v1 Announce Type: new  Abstract: Existing example-based prediction explanation methods often bridge test and training data points through the model's parameters or latent representations. While these methods offer clues to the causes of model predictions, they often exhibit innate shortcomings, such as incurring significant computational overhead or producing coarse-grained explanations. This paper presents a Highly-precise and Data-centric Explanation (HD-Explain), a straightforward prediction explanation method exploiting properties of Kernelized Stein Discrepancy (KSD). Specifically, the KSD uniquely defines a parameterized kernel function for a trained model that encodes model-dependent data correlation. By leveraging the kernel function, one can identify training samples that provide the best predictive support to a test point efficiently. We conducted thorough analyses and experiments across multiple classification domains, where we show that HD-Explain outperform
    
[^2]: 使用扩散模型生成控制训练数据

    Controlled Training Data Generation with Diffusion Models

    [https://arxiv.org/abs/2403.15309](https://arxiv.org/abs/2403.15309)

    提出了一种使用扩散模型生成控制训练数据的方法，通过两个反馈机制，一方面使用监督模型反馈找到对抗性提示词实现图像生成，另一方面通过引导使生成过程朝向特定目标分布。

    

    在这项工作中，我们提出了一种方法，可以控制文本到图像生成模型以生成训练数据，专门用于监督学习。与之前那些采用开环方法并预先定义提示词来使用语言模型或人类专业知识生成新数据的作品不同，我们开发了一种自动闭环系统，其中包括两个反馈机制。第一个机制使用来自给定监督模型的反馈，并找到导致图像生成最大化模型损失的对抗提示词。虽然这些对抗提示词导致了经过模型训练的多样化数据生成，但它们并不知道目标分布，这可能效率低下。因此，我们引入第二个反馈机制，将生成过程引导到特定目标分布。我们称将这两个机制结合起来的方法为引导对抗提示词。我们在不同任务上进行评估。

    arXiv:2403.15309v1 Announce Type: cross  Abstract: In this work, we present a method to control a text-to-image generative model to produce training data specifically "useful" for supervised learning. Unlike previous works that employ an open-loop approach and pre-define prompts to generate new data using either a language model or human expertise, we develop an automated closed-loop system which involves two feedback mechanisms. The first mechanism uses feedback from a given supervised model and finds adversarial prompts that result in image generations that maximize the model loss. While these adversarial prompts result in diverse data informed by the model, they are not informed of the target distribution, which can be inefficient. Therefore, we introduce the second feedback mechanism that guides the generation process towards a certain target distribution. We call the method combining these two mechanisms Guided Adversarial Prompts. We perform our evaluations on different tasks, da
    
[^3]: 可持续数据中心实时减少碳足迹

    Carbon Footprint Reduction for Sustainable Data Centers in Real-Time

    [https://arxiv.org/abs/2403.14092](https://arxiv.org/abs/2403.14092)

    我们提出了一种Data Center Carbon Footprint Reduction (DC-CFR) 多代理强化学习（MARL）框架，旨在实时优化数据中心以减少碳足迹。

    

    随着机器学习工作负载显著增加能源消耗，碳排放低的可持续数据中心正成为全球政府和企业关注的重点。为了实现这一目标，需要在冷却和IT负载中进行功耗优化的范式转变，基于可再生能源在电网中的可用性来调整灵活负载，利用数据中心不间断电源中的电池存储，使用协作代理。这些优化策略之间的复杂关系以及它们对变化的外部因素（如天气和电网碳排放强度）的依赖使得这是一个困难的问题。目前缺乏一个能够在动态实际环境中同时优化所有这些目标的实时控制器。我们提出了一种数据中心碳足迹减少（DC-CFR）多代理强化学习（MARL）框架，能够优化多个角度的数据中心。

    arXiv:2403.14092v1 Announce Type: cross  Abstract: As machine learning workloads significantly increase energy consumption, sustainable data centers with low carbon emissions are becoming a top priority for governments and corporations worldwide. This requires a paradigm shift in optimizing power consumption in cooling and IT loads, shifting flexible loads based on the availability of renewable energy in the power grid, and leveraging battery storage from the uninterrupted power supply in data centers, using collaborative agents. The complex association between these optimization strategies and their dependencies on variable external factors like weather and the power grid carbon intensity makes this a hard problem. Currently, a real-time controller to optimize all these goals simultaneously in a dynamic real-world setting is lacking. We propose a Data Center Carbon Footprint Reduction (DC-CFR) multi-agent Reinforcement Learning (MARL) framework that optimizes data centers for the mult
    
[^4]: 弥合视觉-语言模型选择中的模态差距和能力差距

    Bridge the Modality and Capacity Gaps in Vision-Language Model Selection

    [https://arxiv.org/abs/2403.13797](https://arxiv.org/abs/2403.13797)

    本文分析了在语言-Only VLM选择中的两个固有挑战：「模态差距」和「能力差距」，并提出了VLM选择中弥合这两个差距的方法

    

    视觉语言模型（VLMs）通过将图像与文本类别名称配对，在零样本图像分类方面表现出色。预训练的VLMs的不断增加使得特定任务的VLM选择更有可能标识出适合的VLM。因此，一种有前途的零样本图像分类策略是从VLM动物园中选择最合适的预训练VLM，仅依赖目标数据集的文本数据而无需访问数据集的图像。本文分析了这种仅语言VLM选择中两个固有挑战：「模态差距」——VLM在两个不同模态下的嵌入之间的差异，使得文本成为图像的一个不太可靠的替代品；「能力差距」——VLM的整体排名与其在目标数据集的排名之间存在差异，阻碍了直接从模型的整体表现来预测其数据集特定性能。我们提出了VLM选择

    arXiv:2403.13797v1 Announce Type: new  Abstract: Vision Language Models (VLMs) excel in zero-shot image classification by pairing images with textual category names. The expanding variety of Pre-Trained VLMs enhances the likelihood of identifying a suitable VLM for specific tasks. Thus, a promising zero-shot image classification strategy is selecting the most appropriate Pre-Trained VLM from the VLM Zoo, relying solely on the text data of the target dataset without access to the dataset's images. In this paper, we analyze two inherent challenges in assessing the ability of a VLM in this Language-Only VLM selection: the "Modality Gap" -- the disparity in VLM's embeddings across two different modalities, making text a less reliable substitute for images; and the "Capability Gap" -- the discrepancy between the VLM's overall ranking and its ranking for target dataset, hindering direct prediction of a model's dataset-specific performance from its general performance. We propose VLM Selectio
    
[^5]: 可用的XAI：在LLM时代利用可解释性的10个策略

    Usable XAI: 10 Strategies Towards Exploiting Explainability in the LLM Era

    [https://arxiv.org/abs/2403.08946](https://arxiv.org/abs/2403.08946)

    在大型语言模型时代，为了适应其复杂性和先进能力，我们引入了可用的XAI概念，通过积极增强LLMs在实际环境中的生产力和适用性，实现XAI方法论的重大转变。

    

    可解释人工智能（XAI）指的是提供人类可理解的洞见，揭示人工智能模型的运作方式的技术。最近，XAI的重点正被扩展到常常因为不透明而备受批评的大型语言模型（LLMs）。这一拓展需要对XAI方法论进行显著转变，因为有两个原因。首先，许多现有的XAI方法无法直接应用于LLMs，因为它们的复杂性和先进能力。其次，随着LLMs越来越广泛地应用于不同行业应用中，XAI的角色从仅仅打开“黑匣子”转变为积极增强LLMs在实际环境中的生产力和适用性。与此同时，不同于传统机器学习模型仅作为XAI洞见的被动接受者，LLMs的独特能力能够相互增强XAI。因此，在本文中，我们通过分析（1）...

    arXiv:2403.08946v1 Announce Type: cross  Abstract: Explainable AI (XAI) refers to techniques that provide human-understandable insights into the workings of AI models. Recently, the focus of XAI is being extended towards Large Language Models (LLMs) which are often criticized for their lack of transparency. This extension calls for a significant transformation in XAI methodologies because of two reasons. First, many existing XAI methods cannot be directly applied to LLMs due to their complexity advanced capabilities. Second, as LLMs are increasingly deployed across diverse industry applications, the role of XAI shifts from merely opening the "black box" to actively enhancing the productivity and applicability of LLMs in real-world settings. Meanwhile, unlike traditional machine learning models that are passive recipients of XAI insights, the distinct abilities of LLMs can reciprocally enhance XAI. Therefore, in this paper, we introduce Usable XAI in the context of LLMs by analyzing (1)
    
[^6]: 使用随机投影的可扩展密度聚类

    Scalable Density-based Clustering with Random Projections

    [https://arxiv.org/abs/2402.15679](https://arxiv.org/abs/2402.15679)

    sDBSCAN是一种利用随机投影进行高维密度聚类的算法，在速度和准确性上显著优于其他算法。

    

    我们提出了一种名为sDBSCAN的算法，在高维空间中使用余弦距离进行可扩展的密度聚类。通过利用随机投影的保邻特性，sDBSCAN能够快速识别核心点及其邻域，这是密度聚类的主要障碍。在理论上，sDBSCAN在较轻的条件下以高概率输出类似于DBSCAN的聚类结构。为了进一步促进sDBSCAN，我们提出了sOPTICS，这是一种用于交互式探索内在聚类结构的可扩展OPTICS。我们还通过随机核特征将sDBSCAN和sOPTICS扩展到L2、L1、$\chi^2$和Jensen-Shannon距离。在实证方面，sDBSCAN在真实世界的百万数据集上比许多其他聚类算法显著更快，并提供更高的准确性。在这些数据集上，sDBSCAN和sOPTICS在几分钟内运行，而scikit-learn的对应算法需要数小时或由于内存不足而无法运行。

    arXiv:2402.15679v1 Announce Type: new  Abstract: We present sDBSCAN, a scalable density-based clustering algorithm in high dimensions with cosine distance. Utilizing the neighborhood-preserving property of random projections, sDBSCAN can quickly identify core points and their neighborhoods, the primary hurdle of density-based clustering. Theoretically, sDBSCAN outputs a clustering structure similar to DBSCAN under mild conditions with high probability. To further facilitate sDBSCAN, we present sOPTICS, a scalable OPTICS for interactive exploration of the intrinsic clustering structure. We also extend sDBSCAN and sOPTICS to L2, L1, $\chi^2$, and Jensen-Shannon distances via random kernel features. Empirically, sDBSCAN is significantly faster and provides higher accuracy than many other clustering algorithms on real-world million-point data sets. On these data sets, sDBSCAN and sOPTICS run in a few minutes, while the scikit-learn's counterparts demand several hours or cannot run due to m
    
[^7]: 微调、提示、上下文学习和指导微调：我们需要多少标记样本？

    Fine-Tuning, Prompting, In-Context Learning and Instruction-Tuning: How Many Labelled Samples Do We Need?

    [https://arxiv.org/abs/2402.12819](https://arxiv.org/abs/2402.12819)

    专门模型通常只需少量标记样本（100-1000个）就能与通用模型持平甚至更好，取决于任务的复杂性和结果的变化。

    

    当解决具有有限标记数据的任务时，研究人员可以选择使用通用的大型语言模型而不进行进一步更新，或者使用少量示例来调整专门的较小模型。 当有足够的标记可用时，专门的模型在许多自然语言处理任务上表现优于通用模型。 在这项工作中，我们旨在调查专门模型需要多少标记样本才能实现这种出色的性能，同时考虑结果的变化。观察提示、上下文学习、微调和指导微调的行为，识别它们在增加不同复杂性任务的标记训练样本数量时的收支平衡点，我们发现专门模型通常只需少量样本（100-1000个）就能与通用模型持平甚至更好。 同时，所需的标记数据量强烈依赖于任务的复杂性和结果的变化。

    arXiv:2402.12819v1 Announce Type: cross  Abstract: When solving a task with limited labelled data, researchers can either use a general large language model without further update, or use the few examples to tune a specialised smaller model. When enough labels are available, the specialised models outperform the general ones on many NLP tasks. In this work, we aim to investigate how many labelled samples are required for the specialised models to achieve this superior performance, while taking the results variance into consideration. Observing the behaviour of prompting, in-context learning, fine-tuning and instruction-tuning, identifying their break-even points when increasing number of labelled training samples across three tasks of varying complexity, we find that the specialised models often need only few samples ($100-1000$) to be on par or better than the general ones. At the same time, the amount of required labelled data strongly depends on the task complexity and results varia
    
[^8]: 《基于树结构方法的异常检测能否超越深度学习？一项基准研究》

    Can Tree Based Approaches Surpass Deep Learning in Anomaly Detection? A Benchmarking Study

    [https://arxiv.org/abs/2402.07281](https://arxiv.org/abs/2402.07281)

    本文通过一项基准研究评估了多种基于机器学习的异常检测算法，包括树结构方法和深度学习方法，并揭示了深度学习神话的真相。

    

    在确保服务连续性时，复杂的关键任务系统中检测异常情况至关重要。由于异常事件被认为是罕见事件，因此从操作数据中检测异常情况面临着类别分布不平衡问题的挑战。本文通过全面的基准研究评估了多种基于机器学习的异常检测算法。论文通过对各种异常检测算法的公正比较做出了重大贡献，包括经典机器学习方法、各种基于树结构的方法、深度学习和异常点检测方法。论文使用了104个公开可用的和少数专有的工业系统数据集，增强了研究的多样性，使算法性能的评估更加真实，并强调了对实际场景的适应性的重要性。论文揭示了深度学习神话的真相。

    Detection of anomalous situations for complex mission-critical systems holds paramount importance when their service continuity needs to be ensured. A major challenge in detecting anomalies from the operational data arises due to the imbalanced class distribution problem since the anomalies are supposed to be rare events. This paper evaluates a diverse array of machine learning-based anomaly detection algorithms through a comprehensive benchmark study. The paper contributes significantly by conducting an unbiased comparison of various anomaly detection algorithms, spanning classical machine learning including various tree-based approaches to deep learning and outlier detection methods. The inclusion of 104 publicly available and a few proprietary industrial systems datasets enhances the diversity of the study, allowing for a more realistic evaluation of algorithm performance and emphasizing the importance of adaptability to real-world scenarios. The paper dispels the deep learning myth
    
[^9]: SVQ: 稀疏向量量化用于时空预测

    SVQ: Sparse Vector Quantization for Spatiotemporal Forecasting

    [https://arxiv.org/abs/2312.03406](https://arxiv.org/abs/2312.03406)

    SVQ是一种利用稀疏回归实现简明表示的稀疏向量量化技术，通过保留关键细节和滤除噪声来提高时空预测性能。在实验中，SVQ在五个空间-时间基准数据集上取得了最先进的结果。

    

    时空预测在许多领域中都是关键，取得好的预测结果需要找到微妙的模式并滤除噪声。为了解决这个问题，我们介绍了稀疏回归向量量化（SVQ）这一新技术，它利用稀疏回归来实现简明表示，这一方法在理论和实践上都比传统的基于聚类的向量量化方法更有优势。这种方法使用回归模型保留原始向量的关键细节，同时通过稀疏设计滤除噪声。此外，我们使用两层MLP和一个广泛的码本来近似稀疏回归过程。这种方法不仅大大降低了计算成本，还使得SVQ具有可微性和训练简易性，从而显著提高了性能。我们在五个空间-时间基准数据集上进行的实证研究表明，SVQ取得了最先进的结果。具体来说，在

    Spatio-temporal forecasting, pivotal in numerous fields, hinges on the delicate equilibrium between isolating nuanced patterns and sifting out noise. To tackle this, we introduce Sparse Regression-based Vector Quantization (SVQ), a novel technique that leverages sparse regression for succinct representation, an approach theoretically and practically favored over classical clustering-based vector quantization methods. This approach preserves critical details from the original vectors using a regression model while filtering out noise via sparse design. Moreover, we approximate the sparse regression process using a blend of a two-layer MLP and an extensive codebook. This approach not only substantially cuts down on computational costs but also grants SVQ differentiability and training simplicity, resulting in a notable enhancement of performance. Our empirical studies on five spatial-temporal benchmark datasets demonstrate that SVQ achieves state-of-the-art results. Specifically, on the 
    
[^10]: 多样性感知聚类：计算复杂性和近似算法

    Diversity-aware clustering: Computational Complexity and Approximation Algorithms. (arXiv:2401.05502v1 [cs.DS])

    [http://arxiv.org/abs/2401.05502](http://arxiv.org/abs/2401.05502)

    本研究讨论了多样性感知聚类问题，在选择聚类中心时要考虑多个属性，同时最小化聚类目标。我们提出了针对不同聚类目标的参数化近似算法，这些算法在保证聚类质量的同时，具有紧确的近似比。

    

    在这项工作中，我们研究了多样性感知聚类问题，其中数据点与多个属性相关联，形成交叉的组。聚类解决方案需要确保从每个组中选择最少数量的聚类中心，同时最小化聚类目标，可以是$k$-中位数，$k$-均值或$k$-供应商。我们提出了参数化近似算法，近似比分别为$1+\frac{2}{e}$，$1+\frac{8}{e}$和$3$，用于多样性感知$k$-中位数，多样性感知$k$-均值和多样性感知$k$-供应商。这些近似比在假设Gap-ETH和FPT $\neq$ W[2]的情况下是紧确的。对于公平$k$-中位数和公平$k$-均值的不相交工厂组，我们提出了参数化近似算法，近似比分别为$1+\frac{2}{e}$和$1+\frac{8}{e}$。对于具有不相交工厂组的公平$k$-供应商，我们提出了一个多项式时间近似算法，因子为$3$。

    In this work, we study diversity-aware clustering problems where the data points are associated with multiple attributes resulting in intersecting groups. A clustering solution need to ensure that a minimum number of cluster centers are chosen from each group while simultaneously minimizing the clustering objective, which can be either $k$-median, $k$-means or $k$-supplier. We present parameterized approximation algorithms with approximation ratios $1+ \frac{2}{e}$, $1+\frac{8}{e}$ and $3$ for diversity-aware $k$-median, diversity-aware $k$-means and diversity-aware $k$-supplier, respectively. The approximation ratios are tight assuming Gap-ETH and FPT $\neq$ W[2]. For fair $k$-median and fair $k$-means with disjoint faicility groups, we present parameterized approximation algorithm with approximation ratios $1+\frac{2}{e}$ and $1+\frac{8}{e}$, respectively. For fair $k$-supplier with disjoint facility groups, we present a polynomial-time approximation algorithm with factor $3$, improv
    
[^11]: CEFL：碳高效的联邦学习

    CEFL: Carbon-Efficient Federated Learning. (arXiv:2310.17972v1 [cs.LG])

    [http://arxiv.org/abs/2310.17972](http://arxiv.org/abs/2310.17972)

    该论文介绍了一种称为CEFL的碳高效联邦学习方法，通过使用自适应的成本感知策略来优化FL模型训练的任意成本度量，并成功实现了碳排放减少93％和训练时间减少50％的效果。

    

    联邦学习（FL）通过将机器学习（ML）训练分布在许多边缘设备上，以减少数据传输开销和保护数据隐私。由于FL模型训练可能涉及数百万个设备，因此需要大量资源，因此之前的工作一直致力于提高其资源效率以优化时间至准确性。然而，之前的工作通常将所有资源视为相同，而实际上它们可能产生大不相同的成本，这反而激发了优化成本至准确性的动机。为了解决这个问题，我们设计了CEFL，它使用自适应的成本感知客户选择策略，在训练FL模型时优化任意成本度量。我们的策略扩展并结合了基于效用的客户选择和关键学习期的先前工作，使其具有成本感知性。我们通过设计碳高效的FL来演示CEFL，在这里能源的碳强度是成本，并且显示它可以将碳排放减少93％，并将训练时间减少50％，与随机客户相比。

    Federated Learning (FL) distributes machine learning (ML) training across many edge devices to reduce data transfer overhead and protect data privacy. Since FL model training may span millions of devices and is thus resource-intensive, prior work has focused on improving its resource efficiency to optimize time-to-accuracy. However, prior work generally treats all resources the same, while, in practice, they may incur widely different costs, which instead motivates optimizing cost-to-accuracy. To address the problem, we design CEFL, which uses adaptive cost-aware client selection policies to optimize an arbitrary cost metric when training FL models. Our policies extend and combine prior work on utility-based client selection and critical learning periods by making them cost-aware. We demonstrate CEFL by designing carbon-efficient FL, where energy's carbon-intensity is the cost, and show that it i) reduces carbon emissions by 93\% and reduces training time by 50% compared to random clie
    
[^12]: 专家的交响曲：在强化学习中运用对抗性洞察力的编排

    Symphony of experts: orchestration with adversarial insights in reinforcement learning. (arXiv:2310.16473v1 [cs.LG])

    [http://arxiv.org/abs/2310.16473](http://arxiv.org/abs/2310.16473)

    这篇论文介绍了一种利用专家策略进行决策指导的编排方法，通过将对抗性设置中的后悔边界结果转移到表格设置下的编排中，推广了自然策略梯度的分析，并提供了关于样本复杂度的洞察。这种方法的关键点在于其透明的证明。在随机匹配玩具模型中进行了模拟实验。

    

    结构化强化学习利用具有优势特性的策略以达到更好的性能，特别是在探索具有挑战性的场景中。我们通过编排的概念来探索这一领域，其中一组（少量）专家策略指导决策；我们的第一个贡献是建立了此建模。然后，我们通过从对抗性设置中转移后悔边界结果，在表格设置下建立了编排的价值函数后悔边界。我们将对 Agarwal 等人 [2021, 第5.3节] 中自然策略梯度的分析推广并扩展到任意对抗性聚合策略。我们还将其扩展到估计优势函数的情况，提供了关于期望值和高概率下样本复杂度的洞察。我们方法的一个关键点在于其相对于现有方法而言证明较为透明。最后，我们针对随机匹配玩具模型进行了模拟实验。

    Structured reinforcement learning leverages policies with advantageous properties to reach better performance, particularly in scenarios where exploration poses challenges. We explore this field through the concept of orchestration, where a (small) set of expert policies guides decision-making; the modeling thereof constitutes our first contribution. We then establish value-functions regret bounds for orchestration in the tabular setting by transferring regret-bound results from adversarial settings. We generalize and extend the analysis of natural policy gradient in Agarwal et al. [2021, Section 5.3] to arbitrary adversarial aggregation strategies. We also extend it to the case of estimated advantage functions, providing insights into sample complexity both in expectation and high probability. A key point of our approach lies in its arguably more transparent proofs compared to existing methods. Finally, we present simulations for a stochastic matching toy model.
    
[^13]: 跨语言多语言模型中事实知识的跨语言一致性

    Cross-Lingual Consistency of Factual Knowledge in Multilingual Language Models. (arXiv:2310.10378v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.10378](http://arxiv.org/abs/2310.10378)

    本论文研究了多语言预训练语言模型中事实知识的跨语言一致性，提出了一种新的度量方法，并通过分析模型大小、语言配对等因素发现了影响一致性的因素。实验结果表明，增加模型大小可以提高准确性，但不会改善跨语言一致性。

    

    多语言大规模预训练语言模型（PLM）显示存储了大量的事实知识，但在不同语言之间存在较大的变化。为了确保不同语言背景的用户从同一个模型中获得一致的反馈，我们研究了各种多语言PLM中事实知识的跨语言一致性（CLC）。为此，我们提出了一种基于排序的一致性（RankC）度量，用于独立于准确性评估跨语言间的知识一致性。利用这个度量方法，我们对决定CLC的因素进行了深入分析，包括模型层面和语言对层面。在其他结果中，我们发现增加模型大小可以提高大多数语言中的事实探测准确性，但不能改善跨语言一致性。最后，我们通过模型编辑在PLMs中插入新的事实关联进行了一个CLC的案例研究。对一小部分事实进行了实验。

    Multilingual large-scale Pretrained Language Models (PLMs) have been shown to store considerable amounts of factual knowledge, but large variations are observed across languages. With the ultimate goal of ensuring that users with different language backgrounds obtain consistent feedback from the same model, we study the cross-lingual consistency (CLC) of factual knowledge in various multilingual PLMs. To this end, we propose a Ranking-based Consistency (RankC) metric to evaluate knowledge consistency across languages independently from accuracy. Using this metric, we conduct an in-depth analysis of the determining factors for CLC, both at model level and at language-pair level. Among other results, we find that increasing model size leads to higher factual probing accuracy in most languages, but does not improve cross-lingual consistency. Finally, we conduct a case study on CLC when new factual associations are inserted in the PLMs via model editing. Results on a small sample of facts 
    
[^14]: OmniDrones：一种用于无人机控制中的高效灵活的强化学习平台

    OmniDrones: An Efficient and Flexible Platform for Reinforcement Learning in Drone Control. (arXiv:2309.12825v1 [cs.RO])

    [http://arxiv.org/abs/2309.12825](http://arxiv.org/abs/2309.12825)

    OmniDrones是一个专为无人机控制中的强化学习而设计的高效灵活平台，采用自下而上设计方法，并提供一系列基准任务和无人机学习工具。这个平台有助于将强化学习应用于实际无人机系统的研究。

    

    在这项工作中，我们介绍了OmniDrones，这是一个专为无人机控制中的强化学习而设计的高效灵活的平台，建立在Nvidia的Omniverse Isaac Sim上。它采用自下而上的设计方法，使用户可以轻松地设计和实验各种应用场景，并在GPU并行化仿真之上进行模拟。它还提供一系列基准任务，涵盖单个无人机悬停到多驱动系统跟踪等各种挑战。总之，我们提出了一个开源的无人机仿真平台，配备了一套用于无人机学习的工具。它包括4个无人机模型，5种传感器模式，4种控制模式，10多个基准任务以及一些常用的强化学习基准模型。为了展示OmniDrones的能力并支持未来的研究，我们还提供了这些基准任务的初步结果。我们希望这个平台能够促进将强化学习应用于实际无人机系统的进一步研究。

    In this work, we introduce OmniDrones, an efficient and flexible platform tailored for reinforcement learning in drone control, built on Nvidia's Omniverse Isaac Sim. It employs a bottom-up design approach that allows users to easily design and experiment with various application scenarios on top of GPU-parallelized simulations. It also offers a range of benchmark tasks, presenting challenges ranging from single-drone hovering to over-actuated system tracking. In summary, we propose an open-sourced drone simulation platform, equipped with an extensive suite of tools for drone learning. It includes 4 drone models, 5 sensor modalities, 4 control modes, over 10 benchmark tasks, and a selection of widely used RL baselines. To showcase the capabilities of OmniDrones and to support future research, we also provide preliminary results on these benchmark tasks. We hope this platform will encourage further studies on applying RL to practical drone systems.
    
[^15]: 基于机器学习的多重共线性解决方案：四川省碳排放案例研究

    Multicollinearity Resolution Based on Machine Learning: A Case Study of Carbon Emissions in Sichuan Province. (arXiv:2309.01115v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2309.01115](http://arxiv.org/abs/2309.01115)

    本研究使用机器学习方法解决了多重共线性问题，针对四川省的碳排放情况进行了案例研究。研究结果确定了行业分组，评估了排放驱动因素，并提出了科学的减排策略，以改善情况。

    

    本研究使用矩阵归一化对四川省46个关键产业2000-2019年的能源消耗数据进行预处理。DBSCAN聚类识别了16个特征类别以客观地分组行业。接下来，采用罚函数回归模型，以应对过拟合控制、高维数据处理和特征选择等复杂能源数据处理的优势。结果表明，煤炭周围的第二个聚类因生产需求而产生的排放量最高。以汽油和焦炭为中心的聚类的排放量也很显著。基于此，减排建议包括清洁煤技术、交通管理、钢铁中的煤电替代和行业标准化。该研究引入了无监督学习的方法来客观选择因素，并旨在探索新的减排途径。总而言之，本研究确定了行业分组，评估了排放驱动因素，并提出了科学的减排策略以进一步改善情况。

    This study preprocessed 2000-2019 energy consumption data for 46 key Sichuan industries using matrix normalization. DBSCAN clustering identified 16 feature classes to objectively group industries. Penalized regression models were then applied for their advantages in overfitting control, high-dimensional data processing, and feature selection - well-suited for the complex energy data. Results showed the second cluster around coal had highest emissions due to production needs. Emissions from gasoline-focused and coke-focused clusters were also significant. Based on this, emission reduction suggestions included clean coal technologies, transportation management, coal-electricity replacement in steel, and industry standardization. The research introduced unsupervised learning to objectively select factors and aimed to explore new emission reduction avenues. In summary, the study identified industry groupings, assessed emissions drivers, and proposed scientific reduction strategies to bette
    
[^16]: CausalBench挑战赛：基于单细胞干扰数据的基因网络推断的机器学习竞赛

    The CausalBench challenge: A machine learning contest for gene network inference from single-cell perturbation data. (arXiv:2308.15395v1 [cs.LG])

    [http://arxiv.org/abs/2308.15395](http://arxiv.org/abs/2308.15395)

    CausalBench挑战赛是一个机器学习竞赛，旨在构建基因网络推断的最新方法。参与者利用大规模遗传干扰数据提升了先进方法的性能。

    

    在药物发现中，绘制细胞系统内基因之间的相互作用关系是关键的早期步骤。这有助于制定关于可能被未来药物靶向的分子机制的假设。CausalBench挑战是一项邀请机器学习社区来推进构建基因-基因相互作用网络的最新技术的倡议。这些网络是从大规模真实世界的单细胞数据集中推导出来的，这些数据集经过不同类型的干扰。这些网络对于理解疾病生物学的因果机制至关重要。参与者利用CausalBench基准测试框架，任务是提升先进方法利用大规模遗传干扰数据的能力。本报告分析和总结了挑战赛期间提交的方法，以描绘竞赛期间技术发展的部分情况。

    In drug discovery, mapping interactions between genes within cellular systems is a crucial early step. This helps formulate hypotheses regarding molecular mechanisms that could potentially be targeted by future medicines. The CausalBench Challenge was an initiative to invite the machine learning community to advance the state of the art in constructing gene-gene interaction networks. These networks, derived from large-scale, real-world datasets of single cells under various perturbations, are crucial for understanding the causal mechanisms underlying disease biology. Using the framework provided by the CausalBench benchmark, participants were tasked with enhancing the capacity of the state of the art methods to leverage large-scale genetic perturbation data. This report provides an analysis and summary of the methods submitted during the challenge to give a partial image of the state of the art at the time of the challenge. The winning solutions significantly improved performance compa
    
[^17]: 线性赌博机中平衡性能与理论保证的几何感知方法

    Geometry-Aware Approaches for Balancing Performance and Theoretical Guarantees in Linear Bandits. (arXiv:2306.14872v1 [cs.LG])

    [http://arxiv.org/abs/2306.14872](http://arxiv.org/abs/2306.14872)

    本文提出了一种新的数据驱动技术，跟踪不确定度椭球体的几何形状，为线性赌博机算法建立实例相关的频率后悔界，并实现了平衡算法性能与理论保证的效果。

    

    本文受线性赌博机算法表现良好的实证性能与悲观理论后悔界之间的不一致性启发，提出一种新的数据驱动技术，跟踪不确定度椭球体的几何形状，为包括贪心、OFUL和汤普森抽样算法在内的广泛算法类建立实例相关的频率后悔界，在保留基本算法大部分优良特性的同时“校正”基本算法在某些实例中表现差的问题，实现了渐近最优后悔界。我们通过仿真实验验证了该方法的有效性。

    This paper is motivated by recent developments in the linear bandit literature, which have revealed a discrepancy between the promising empirical performance of algorithms such as Thompson sampling and Greedy, when compared to their pessimistic theoretical regret bounds. The challenge arises from the fact that while these algorithms may perform poorly in certain problem instances, they generally excel in typical instances. To address this, we propose a new data-driven technique that tracks the geometry of the uncertainty ellipsoid, enabling us to establish an instance-dependent frequentist regret bound for a broad class of algorithms, including Greedy, OFUL, and Thompson sampling. This result empowers us to identify and ``course-correct" instances in which the base algorithms perform poorly. The course-corrected algorithms achieve the minimax optimal regret of order $\tilde{\mathcal{O}}(d\sqrt{T})$, while retaining most of the desirable properties of the base algorithms. We present sim
    
[^18]: 安全的视觉感知推荐系统：一种对抗图像重构及检测框架

    Securing Visually-Aware Recommender Systems: An Adversarial Image Reconstruction and Detection Framework. (arXiv:2306.07992v1 [cs.CV])

    [http://arxiv.org/abs/2306.07992](http://arxiv.org/abs/2306.07992)

    本文提出了一种对抗图像重构及检测框架来保护视觉感知推荐系统，能够防御局部扰动为特征的对抗攻击并且能够在干净和对抗性图像上进行训练来检测对抗性图像。

    

    随着富含图片等视觉数据与物品关联度增加，视觉感知推荐系统（VARS）已被广泛应用于不同应用领域。最近的研究表明，VARS易受到物品-图像对抗攻击的攻击，这些攻击向与这些物品关联的干净图像添加人类无法感知的扰动。对VARS的攻击为广泛使用VARS的许多应用（如电子商务和社交网络）带来新的安全挑战。如何保护VARS免受此类对抗攻击成为一个关键的问题。目前，尚缺乏系统地研究如何设计针对VARS视觉攻击的安全防御策略。本文提出了一种对抗图像重构及检测框架来保护VARS，我们的方法可以同时(1)通过基于全局视觉传输的图像重构来防御以局部扰动为特征的对抗攻击，(2)使用在少量干净和对抗性图像上训练的检测模型来检测对抗性图像。实验结果表明，我们的框架能够有效地防御各种物品-图像对抗攻击对VARS的影响。

    With rich visual data, such as images, becoming readily associated with items, visually-aware recommendation systems (VARS) have been widely used in different applications. Recent studies have shown that VARS are vulnerable to item-image adversarial attacks, which add human-imperceptible perturbations to the clean images associated with those items. Attacks on VARS pose new security challenges to a wide range of applications such as e-Commerce and social networks where VARS are widely used. How to secure VARS from such adversarial attacks becomes a critical problem. Currently, there is still a lack of systematic study on how to design secure defense strategies against visual attacks on VARS. In this paper, we attempt to fill this gap by proposing an adversarial image reconstruction and detection framework to secure VARS. Our proposed method can simultaneously (1) secure VARS from adversarial attacks characterized by local perturbations by image reconstruction based on global vision tra
    
[^19]: 机器代理在良性和恶性情境下的自主股票交易

    Agent Performing Autonomous Stock Trading under Good and Bad Situations. (arXiv:2306.03985v1 [cs.LG])

    [http://arxiv.org/abs/2306.03985](http://arxiv.org/abs/2306.03985)

    本文介绍了使用深度强化学习方法训练机器代理来自主执行股票交易的研究，并在不同市场环境下进行了评估。

    

    股票交易是财务管理的一种流行方式。然而，市场和经济环境不稳定，通常不能预测。此外，从事股票交易需要时间和精力来分析、制定策略和做出决策。如果一个机器代理能够辅助甚至执行分析和建模过去数据，然后生成自主交易策略，那将是方便和有效的。近年来，强化学习已被证明在涉及基于时间序列数据的决策制定策略达到目标的各种任务中具有鲁棒性。在本项目中，我们开发了一个模拟股票交易环境的管道，并使用深度强化学习方法，包括深度Q学习、深度SARSA和策略梯度方法，训练了一个机器代理来自动化股票交易过程。我们在相对良好（2021年之前）和恶劣（2021年-2022年）情况下评估了我们的平台。

    Stock trading is one of the popular ways for financial management. However, the market and the environment of economy is unstable and usually not predictable. Furthermore, engaging in stock trading requires time and effort to analyze, create strategies, and make decisions. It would be convenient and effective if an agent could assist or even do the task of analyzing and modeling the past data and then generate a strategy for autonomous trading. Recently, reinforcement learning has been shown to be robust in various tasks that involve achieving a goal with a decision making strategy based on time-series data. In this project, we have developed a pipeline that simulates the stock trading environment and have trained an agent to automate the stock trading process with deep reinforcement learning methods, including deep Q-learning, deep SARSA, and the policy gradient method. We evaluate our platform during relatively good (before 2021) and bad (2021 - 2022) situations. The stocks we've eva
    
[^20]: 基于 Foundation Model APIs 的差分隐私合成数据：图片

    Differentially Private Synthetic Data via Foundation Model APIs 1: Images. (arXiv:2305.15560v1 [cs.CV])

    [http://arxiv.org/abs/2305.15560](http://arxiv.org/abs/2305.15560)

    该论文提出了基于API的方法生成密切类似于原始私有数据的差分隐私（DP）合成数据，可以更轻松地部署。使用Private Evolution（PE）框架生成DP合成图像，结合了差分隐私、进化算法和元学习的技术，可以在保护隐私的同时生成既为DP又与原始图像外观相似的合成图像，并在流行的图像数据集上表现优异。

    

    在当前数据驱动的世界中，生成密切类似于原始私有数据的差分隐私（DP）合成数据是一种可扩展的方法，可减轻隐私问题。与当前为此任务训练定制模型的做法相反，我们旨在通过API生成DP合成数据（DPSDA），其中我们将基础模型视为黑盒并只利用其推理API。这些基于API的、无需训练的方法更容易部署，如最近 API 应用程序的激增所证明的那样。这些方法还可以利用可通过其推理API访问其权重未发布的大型基础模型的能力。但是，由于模型访问更加严格，还需保护API提供商的隐私，这将带来更大的挑战。在本文中，我们提出了一个称为 Private Evolution（PE）的新框架，以解决这个问题，并展示了其在使用基础模型API生成DP合成图像方面的初始实现。PE结合了差分隐私、进化算法和元学习的技术，有效地生成既为DP又与原始图像外观相似的合成图像。我们还在流行的图像数据集如CIFAR-10上评估了我们的框架，并显示我们的方法在效用和隐私方面优于现有的DP图像生成方法。

    Generating differentially private (DP) synthetic data that closely resembles the original private data without leaking sensitive user information is a scalable way to mitigate privacy concerns in the current data-driven world. In contrast to current practices that train customized models for this task, we aim to generate DP Synthetic Data via APIs (DPSDA), where we treat foundation models as blackboxes and only utilize their inference APIs. Such API-based, training-free approaches are easier to deploy as exemplified by the recent surge in the number of API-based apps. These approaches can also leverage the power of large foundation models which are accessible via their inference APIs while the model weights are unreleased. However, this comes with greater challenges due to strictly more restrictive model access and the additional need to protect privacy from the API provider.  In this paper, we present a new framework called Private Evolution (PE) to solve this problem and show its ini
    
[^21]: 语言模型的物理学：第一部分，上下文无关文法。

    Physics of Language Models: Part 1, Context-Free Grammar. (arXiv:2305.13673v1 [cs.CL])

    [http://arxiv.org/abs/2305.13673](http://arxiv.org/abs/2305.13673)

    本研究探究了生成式语言模型如何学习上下文无关文法（CFG），并通过构造人造数据证明了预训练transformers可以学会生成具有接近完美准确度和显着多样性的句子。研究发现transformer内部的隐藏状态隐含而精确地编码了CFG结构，学会形成类似动态规划的“边界到边界”的注意力。此外，还研究了标准CFG的扩展，例如概率CFG和线性CFG，并证明transformers也可以学会这些扩展语法结构。

    

    我们设计了实验来研究生成式语言模型（例如GPT）如何学习上下文无关文法（CFG）-具有树状结构的多样化语言系统，可捕捉许多自然语言，程序和人类逻辑的方面。CFG与下推自动机一样困难，可能是模棱两可的，因此验证字符串是否满足规则需要动态规划。我们构造了人造数据，并证明即使对于非常具有挑战性的CFG，预训练transformers也可以学会生成具有接近完美准确度和显着多样性的句子。更重要的是，我们深入探讨了transformers学习CFG背后的物理原理。我们发现transformer内部的隐藏状态隐含而精确地编码了CFG结构（如在子树边界上精确定位树节点信息），并学会形成类似动态规划的“边界到边界”的注意力。我们还涵盖了一些标准CFG的扩展，例如概率CFG和线性CFG，并展示transformers也可以学会这些扩展语法结构。我们的工作揭示了语言模型的内部工作原理，并为未来的模型设计和分析提供了启示。

    We design experiments to study $\textit{how}$ generative language models, like GPT, learn context-free grammars (CFGs) -- diverse language systems with a tree-like structure capturing many aspects of natural languages, programs, and human logics. CFGs are as hard as pushdown automata, and can be ambiguous so that verifying if a string satisfies the rules requires dynamic programming. We construct synthetic data and demonstrate that even for very challenging CFGs, pre-trained transformers can learn to generate sentences with near-perfect accuracy and remarkable $\textit{diversity}$.  More importantly, we delve into the $\textit{physical principles}$ behind how transformers learns CFGs. We discover that the hidden states within the transformer implicitly and $\textit{precisely}$ encode the CFG structure (such as putting tree node information exactly on the subtree boundary), and learn to form "boundary to boundary" attentions that resemble dynamic programming. We also cover some extensio
    
[^22]: 自适应离群值优化：用于在线测试时OOD检测的方法

    AUTO: Adaptive Outlier Optimization for Online Test-Time OOD Detection. (arXiv:2303.12267v1 [cs.LG])

    [http://arxiv.org/abs/2303.12267](http://arxiv.org/abs/2303.12267)

    本文提出了一个称为AUTO的方法，在在线测试时利用未标记的在线数据直接提高OOD检测性能。该方法自适应地优化网络参数并在线检测OOD样本，取得了优于现有方法的结果。

    

    在开放世界的应用中，OOD（out-of-distribution）检测是部署机器学习模型的一个关键方面。经验证明，使用辅助离群值训练可以显著提高OOD检测性能。然而，这些离群值通常与测试OOD数据存在分布差距，并且不能覆盖所有可能的测试OOD情况。此外，结合这些离群值还会增加训练的负担。本文提出了一种称为测试时OOD检测的新范式，该范式直接利用未标记的在线数据，以提高OOD检测性能。虽然这种范式很高效，但它也面临着诸如灾难性遗忘等挑战。为了解决这些挑战，我们提出了自适应离群值优化（AUTO），它由内外感知滤波器、ID存储器和语义一致的目标组成。AUTO自适应地从测试数据中挖掘伪ID和伪OOD样本，利用它们来优化网络参数并在线检测OOD样本。实验结果表明，AUTO在各种基准和数据集上始终优于现有方法。

    Out-of-distribution (OOD) detection is a crucial aspect of deploying machine learning models in open-world applications. Empirical evidence suggests that training with auxiliary outliers substantially improves OOD detection. However, such outliers typically exhibit a distribution gap compared to the test OOD data and do not cover all possible test OOD scenarios. Additionally, incorporating these outliers introduces additional training burdens. In this paper, we introduce a novel paradigm called test-time OOD detection, which utilizes unlabeled online data directly at test time to improve OOD detection performance. While this paradigm is efficient, it also presents challenges such as catastrophic forgetting. To address these challenges, we propose adaptive outlier optimization (AUTO), which consists of an in-out-aware filter, an ID memory bank, and a semantically-consistent objective. AUTO adaptively mines pseudo-ID and pseudo-OOD samples from test data, utilizing them to optimize netwo
    
[^23]: 受限对抗学习及其在自动化软件测试中的应用：系统综述（arXiv:2303.07546v1 [cs.SE]）

    Constrained Adversarial Learning and its applicability to Automated Software Testing: a systematic review. (arXiv:2303.07546v1 [cs.SE])

    [http://arxiv.org/abs/2303.07546](http://arxiv.org/abs/2303.07546)

    本综述研究了受限对抗学习方法和自动化软件测试中受限数据生成方法的最新技术应用，探讨将这些方法整合至测试工具中以提高数字系统的鲁棒性和弹性。

    

    每种新技术都会增加隐含的漏洞，让越来越多的网络攻击者利用。自动化软件测试可以成为快速分析数千行代码的有前途的解决方案，通过生成和略微修改功能特定的测试数据来遇到多个漏洞和攻击向量。这个过程与受限对抗学习方法生成的受限性对抗性示例相似，因此将这些方法整合到自动化测试工具中可能会有显着的好处。因此，本系统综述侧重于限制数据生成方法在对抗学习和软件测试中的应用的当前最新技术，旨在指导研究人员和开发人员使用对抗学习方法增强测试工具，提高数字系统的弹性和鲁棒性。对于对抗机器学习的发现受限制的数据生成应用是系统化的。

    Every novel technology adds hidden vulnerabilities ready to be exploited by a growing number of cyber-attacks. Automated software testing can be a promising solution to quickly analyze thousands of lines of code by generating and slightly modifying function-specific testing data to encounter a multitude of vulnerabilities and attack vectors. This process draws similarities to the constrained adversarial examples generated by adversarial learning methods, so there could be significant benefits to the integration of these methods in automated testing tools. Therefore, this systematic review is focused on the current state-of-the-art of constrained data generation methods applied for adversarial learning and software testing, aiming to guide researchers and developers to enhance testing tools with adversarial learning methods and improve the resilience and robustness of their digital systems. The found constrained data generation applications for adversarial machine learning were systemat
    
[^24]: 通过学习保证提高公平性

    Increasing Fairness via Combination with Learning Guarantees. (arXiv:2301.10813v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.10813](http://arxiv.org/abs/2301.10813)

    该论文提出了一种公平质量度量方法，名为判别风险，旨在反映个体和群体公平性。此外，研究者还讨论了公平性是否可以在理论上得到保证。

    

    随着机器学习系统在越来越多的现实场景中得到广泛应用，对于隐藏在机器学习模型中的潜在歧视的担忧正在增加。许多技术已经被开发出来以增强公平性，包括常用的群体公平性度量和几种结合集成学习的公平感知方法。然而，现有的公平度量只能关注其中之一，即群体公平性或个体公平性，它们之间的硬性兼容性暗示了即使其中之一得到满足，仍可能存在偏见。此外，现有的提升公平性的机制通常只提供经验结果来证明其有效性，但很少有论文讨论公平性是否可以在理论上得到保证。为了解决这些问题，本文提出了一种公平质量度量方法——判别风险，以反映个体和群体公平性两个方面。此外，我们还研究了p...

    The concern about underlying discrimination hidden in ML models is increasing, as ML systems have been widely applied in more and more real-world scenarios and any discrimination hidden in them will directly affect human life. Many techniques have been developed to enhance fairness including commonly-used group fairness measures and several fairness-aware methods combining ensemble learning. However, existing fairness measures can only focus on one aspect -- either group or individual fairness, and the hard compatibility among them indicates a possibility of remaining biases even if one of them is satisfied. Moreover, existing mechanisms to boost fairness usually present empirical results to show validity, yet few of them discuss whether fairness can be boosted with certain theoretical guarantees. To address these issues, we propose a fairness quality measure named discriminative risk in this paper to reflect both individual and group fairness aspects. Furthermore, we investigate the p
    
[^25]: DPM-Solver++：用于引导采样的快速扩散概率模型求解器

    DPM-Solver++: Fast Solver for Guided Sampling of Diffusion Probabilistic Models. (arXiv:2211.01095v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.01095](http://arxiv.org/abs/2211.01095)

    DPM-Solver++是一种快速求解器，在扩散概率模型的引导采样中表现出色，可加快样本生成速度。

    

    扩散概率模型 (DPMs) 在高分辨率图像合成等领域表现出色，而 DPM 生成高质量样本所需的关键技术之一是引导采样。现有的快速采样器 DDIM 在引导采样方面表现良好，但需要 100 至 250 步才能生成高质量样本。本文提出了 DPM-Solver++，一种用于加速引导采样的高阶求解器。

    Diffusion probabilistic models (DPMs) have achieved impressive success in high-resolution image synthesis, especially in recent large-scale text-to-image generation applications. An essential technique for improving the sample quality of DPMs is guided sampling, which usually needs a large guidance scale to obtain the best sample quality. The commonly-used fast sampler for guided sampling is DDIM, a first-order diffusion ODE solver that generally needs 100 to 250 steps for high-quality samples. Although recent works propose dedicated high-order solvers and achieve a further speedup for sampling without guidance, their effectiveness for guided sampling has not been well-tested before. In this work, we demonstrate that previous high-order fast samplers suffer from instability issues, and they even become slower than DDIM when the guidance scale grows large. To further speed up guided sampling, we propose DPM-Solver++, a high-order solver for the guided sampling of DPMs. DPM-Solver++ solv
    
[^26]: 关于广义似然比检验和一类分类器

    On the Generalized Likelihood Ratio Test and One-Class Classifiers. (arXiv:2210.12494v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.12494](http://arxiv.org/abs/2210.12494)

    本文考虑了一类分类器和广义似然比检验的问题，证明了多层感知器神经网络和支持向量机模型在收敛时会表现为广义似然比检验。同时，作者还展示了一类最小二乘SVM在收敛时也能达到广义似然比检验的效果。

    

    一类分类（OCC）是决定观察样本是否属于目标类的问题。我们考虑在包含目标类样本的数据集上学习一个表现为广义似然比检验（GLRT）的OCC模型的问题。当目标类的统计信息可用时，GLRT解决了相同的问题。GLRT是一个众所周知且在特定条件下可证明最佳的分类器。为此，我们考虑了多层感知器神经网络（NN）和支持向量机（SVM）模型。它们使用人工数据集训练为两类分类器，其中替代类使用在目标类数据集的定义域上均匀生成的随机样本。我们证明，在适当的假设下，模型在大数据集上收敛到了GLRT。此外，我们还展示了具有适当核函数的一类最小二乘SVM（OCLSSVM）在收敛时表现为GLRT。

    One-class classification (OCC) is the problem of deciding whether an observed sample belongs to a target class. We consider the problem of learning an OCC model that performs as the generalized likelihood ratio test (GLRT), given a dataset containing samples of the target class. The GLRT solves the same problem when the statistics of the target class are available. The GLRT is a well-known and provably optimal (under specific assumptions) classifier. To this end, we consider both the multilayer perceptron neural network (NN) and the support vector machine (SVM) models. They are trained as two-class classifiers using an artificial dataset for the alternative class, obtained by generating random samples, uniformly over the domain of the target-class dataset. We prove that, under suitable assumptions, the models converge (with a large dataset) to the GLRT. Moreover, we show that the one-class least squares SVM (OCLSSVM) with suitable kernels at convergence performs as the GLRT. Lastly, we
    

