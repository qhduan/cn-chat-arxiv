# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Simple Mechanisms for Representing, Indexing and Manipulating Concepts.](http://arxiv.org/abs/2310.12143) | 通过查看概念的矩阵统计量，生成一个概念的具体表示或签名，可以用于发现概念之间的结构并递归产生更高级的概念，同时可以通过概念的签名来找到相关的共同主题。 |
| [^2] | [An Evaluation on Large Language Model Outputs: Discourse and Memorization.](http://arxiv.org/abs/2304.08637) | 评估了九个大语言模型的输出，发现其中80％包含记忆数据，但包含最多记忆内容的输出更可能是高质量的。提出了缓解策略以降低记忆文本率。 |

# 详细

[^1]: 简单机制用于表示、索引和操作概念

    Simple Mechanisms for Representing, Indexing and Manipulating Concepts. (arXiv:2310.12143v1 [cs.LG])

    [http://arxiv.org/abs/2310.12143](http://arxiv.org/abs/2310.12143)

    通过查看概念的矩阵统计量，生成一个概念的具体表示或签名，可以用于发现概念之间的结构并递归产生更高级的概念，同时可以通过概念的签名来找到相关的共同主题。

    

    深度网络通常通过分类器学习概念，这涉及设置模型并通过梯度下降训练它以适应具有标记概念的数据。我们将提出一个不同的观点，即可以通过查看概念的矩阵矩阵统计量来生成概念的具体表示或签名。这些签名可以用于发现一组概念的结构，并且可以通过从这些签名中学习该结构来递归地产生更高级的概念。当概念"相交"时，概念的签名可以用于在一些相关的"相交"概念中找到一个共同的主题。这个过程可以用于保持一个概念字典，以便输入能够正确识别并被路由到与输入的(潜在)生成相关的概念集合中。

    Deep networks typically learn concepts via classifiers, which involves setting up a model and training it via gradient descent to fit the concept-labeled data. We will argue instead that learning a concept could be done by looking at its moment statistics matrix to generate a concrete representation or signature of that concept. These signatures can be used to discover structure across the set of concepts and could recursively produce higher-level concepts by learning this structure from those signatures. When the concepts are `intersected', signatures of the concepts can be used to find a common theme across a number of related `intersected' concepts. This process could be used to keep a dictionary of concepts so that inputs could correctly identify and be routed to the set of concepts involved in the (latent) generation of the input.
    
[^2]: 大型语言模型输出的评估：话语和记忆

    An Evaluation on Large Language Model Outputs: Discourse and Memorization. (arXiv:2304.08637v1 [cs.CL])

    [http://arxiv.org/abs/2304.08637](http://arxiv.org/abs/2304.08637)

    评估了九个大语言模型的输出，发现其中80％包含记忆数据，但包含最多记忆内容的输出更可能是高质量的。提出了缓解策略以降低记忆文本率。

    

    我们对九个最广泛可用的大型语言模型（LLMs）生成的各种输出进行了经验性评估。我们使用现成的工具进行分析，发现在与输出病态（例如，反事实和逻辑上的错误陈述）以及不保持主题等方面的关系中，记忆文本百分比、独特文本百分比和整体输出质量之间存在相关性。总体而言，80.0％的输出包含记忆数据，但包含最多记忆内容的输出也更有可能被认为具有高质量。我们讨论和评估了缓解策略，并显示，在评估的模型中，输出的记忆文本率有所降低。最后，我们就学习、记忆和评估优质文本的潜在影响进行了讨论。

    We present an empirical evaluation of various outputs generated by nine of the most widely-available large language models (LLMs). Our analysis is done with off-the-shelf, readily-available tools. We find a correlation between percentage of memorized text, percentage of unique text, and overall output quality, when measured with respect to output pathologies such as counterfactual and logically-flawed statements, and general failures like not staying on topic. Overall, 80.0% of the outputs evaluated contained memorized data, but outputs containing the most memorized content were also more likely to be considered of high quality. We discuss and evaluate mitigation strategies, showing that, in the models evaluated, the rate of memorized text being output is reduced. We conclude with a discussion on potential implications around what it means to learn, to memorize, and to evaluate quality text.
    

