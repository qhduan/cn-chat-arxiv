# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [CBQ: Cross-Block Quantization for Large Language Models](https://rss.arxiv.org/abs/2312.07950) | CBQ是一种用于大型语言模型的跨块重构型后训练量化方法。CBQ通过使用同源重构方案来建立块间的长程依赖关系，最小化误差积累。CBQ还采用了粗到精的预处理策略和自适应的取整技术，使其能够有效处理极端异常值并提高整体量化精度。 |
| [^2] | [Few-Shot Cross-System Anomaly Trace Classification for Microservice-based systems](https://arxiv.org/abs/2403.18998) | 提出了针对微服务系统的少样本异常跟踪分类的新框架，利用多头注意力自编码器构建系统特定的跟踪表示，并应用基于Transformer编码器的模型无关元学习进行高效分类。 |
| [^3] | [ELLEN: Extremely Lightly Supervised Learning For Efficient Named Entity Recognition](https://arxiv.org/abs/2403.17385) | ELLEN是一种简单而强大的神经符号方法，将微调语言模型与语言规则相结合，在极其轻监督的情况下取得了非常强劲的命名实体识别性能。 |
| [^4] | [ChatDBG: An AI-Powered Debugging Assistant](https://arxiv.org/abs/2403.16354) | ChatDBG是第一个AI-Powered调试助手，通过将大型语言模型集成到传统调试器中，实现了程序员与调试器之间的协作对话，能够处理复杂问题、执行根本原因分析，并探索开放性查询。 |
| [^5] | [Re-Simulation-based Self-Supervised Learning for Pre-Training Foundation Models](https://arxiv.org/abs/2403.07066) | 提出了一种新颖的基于重新模拟的自监督学习策略RS3L，通过介入模拟过程并重新模拟事件实现，生成一组涵盖所有物理驱动变化的数据增强，从而促进基础模型的发展，并展示了预训练R3SL在下游任务中表现出强大性能。 |
| [^6] | [Signature Isolation Forest](https://arxiv.org/abs/2403.04405) | 介绍了一种新颖的异常检测算法"Signature Isolation Forest"，利用粗路径理论的签名变换去除了Functional Isolation Forest的线性内积和词典选择方面的限制。 |
| [^7] | [Parameterized quantum comb and simpler circuits for reversing unknown qubit-unitary operations](https://arxiv.org/abs/2403.03761) | 通过优化参数化量子电路，我们开发了一个简化的协议，用于逆转未知量子比特酉操作，将辅助比特开销减少到3，显示了量子梳结构的实用性和PQComb在解决复杂量子任务中的潜力。 |
| [^8] | [Stability-Aware Training of Neural Network Interatomic Potentials with Differentiable Boltzmann Estimators](https://arxiv.org/abs/2402.13984) | 提出了稳定性感知Boltzmann估计器（StABlE）训练方法，结合传统监督训练和参考系统可观察量，用于生成稳定且准确的神经网络原子间势。 |
| [^9] | [Rethinking Semi-Supervised Imbalanced Node Classification from Bias-Variance Decomposition](https://arxiv.org/abs/2310.18765) | 本文提出了一种新的方法来解决图神经网络中的类别不平衡问题。该方法将不平衡节点分类和偏差-方差分解相结合，利用图扩充技术估计方差，并通过正则项减轻不平衡的影响。在多个基准数据集上进行的测试结果表明，该方法在各种不平衡场景中优于现有最先进的方法，并为解决GNN中的不平衡节点分类问题提供了一种新颖的理论视角。 |
| [^10] | [Manifold GCN: Diffusion-based Convolutional Neural Network for Manifold-valued Graphs.](http://arxiv.org/abs/2401.14381) | 本研究提出了两个用于具有流形值特征的图的神经网络层。这些层具有对节点排列和特征流形的等变性，并在深度学习任务中显示出有益的归纳偏差。 |
| [^11] | [Enhancing selectivity using Wasserstein distance based reweighing.](http://arxiv.org/abs/2401.11562) | 我们设计了一种使用Wasserstein距离进行加权的算法，在标记的数据集上训练神经网络可以逼近在其他数据集上训练得到的结果。我们证明了算法可以输出接近最优的加权，且算法简单可扩展。我们的算法可以有意地引入分布偏移进行多目标优化。作为应用实例，我们训练了一个神经网络来识别对细胞信号传导的MAP激酶具有非结合性的小分子结合物。 |
| [^12] | [D-STGCNT: A Dense Spatio-Temporal Graph Conv-GRU Network based on transformer for assessment of patient physical rehabilitation.](http://arxiv.org/abs/2401.06150) | D-STGCNT是一种新的模型，结合了STGCN和transformer的架构，用于自动评估患者身体康复锻炼。它通过将骨架数据视为图形，并检测关键关节，在处理时空数据方面具有高效性。该模型通过密集连接和GRU机制来处理大型3D骨架输入，有效建立时空动态模型。transformer的注意力机制对于评估康复锻炼非常有用。 |
| [^13] | [Machine Learning and Feature Ranking for Impact Fall Detection Event Using Multisensor Data.](http://arxiv.org/abs/2401.05407) | 本论文通过对多传感器数据进行彻底的预处理和特征选择，成功应用机器学习模型实现了冲击坠落检测，取得了较高的准确率。 |
| [^14] | [Reinforcing POD based model reduction techniques in reaction-diffusion complex networks using stochastic filtering and pattern recognition.](http://arxiv.org/abs/2307.09762) | 该论文提出了一种算法框架，通过将模式识别和随机滤波理论的技术结合起来，强化了基于POD的反应扩散复杂网络模型简化技术，在受扰动输入的情况下提高了代理模型的准确性。 |
| [^15] | [The Adaptive $\tau$-Lasso: Its Robustness and Oracle Properties.](http://arxiv.org/abs/2304.09310) | 本文提出了一种新型鲁棒的自适应 $\tau$-Lasso 估计器，同时采用自适应 $\ell_1$-范数惩罚项以降低真实回归系数的偏差。它具有变量选择一致性和真实支持下回归向量的渐近正态性的最优性质，假定已知真实回归向量的支持。 |

# 详细

[^1]: 跨块量化：用于大型语言模型的跨块量化方法

    CBQ: Cross-Block Quantization for Large Language Models

    [https://rss.arxiv.org/abs/2312.07950](https://rss.arxiv.org/abs/2312.07950)

    CBQ是一种用于大型语言模型的跨块重构型后训练量化方法。CBQ通过使用同源重构方案来建立块间的长程依赖关系，最小化误差积累。CBQ还采用了粗到精的预处理策略和自适应的取整技术，使其能够有效处理极端异常值并提高整体量化精度。

    

    后训练量化（PTQ）在以极低成本压缩大型语言模型（LLM）方面起着重要作用。然而，现有的PTQ方法只关注处理单个层或单个块内的异常值，忽略了块之间的依赖关系，在低位设置中导致严重的性能下降。本文提出了一种基于块间重构的跨块PTQ方法CBQ。CBQ采用了一种同源重构方案来实现块间的长程依赖关系，以最小化误差积累。此外，CBQ还结合了一种粗到精的预处理策略（CFP）来抑制权重和激活值的异常值，并配合一种自适应的LoRA取整技术实现精确的权重量化。这些创新使CBQ不仅能够有效处理极端异常值，还能提高整体量化精度。广泛的实验证明，CBQ在低位量化（W4A4，W4A8等）方面具有优越性能。

    Post-training quantization (PTQ) has played a key role in compressing large language models (LLMs) with ultra-low costs. However, existing PTQ methods only focus on handling the outliers within one layer or one block, which ignores the dependency of blocks and leads to severe performance degradation in low-bit settings. In this paper, we propose CBQ, a cross-block reconstruction-based PTQ method for LLMs. CBQ employs a cross-block dependency using a homologous reconstruction scheme, establishing long-range dependencies across multiple blocks to minimize error accumulation. Furthermore, CBQ incorporates a coarse-to-fine preprocessing (CFP) strategy for suppressing weight and activation outliers, coupled with an adaptive LoRA-Rounding technique for precise weight quantization. These innovations enable CBQ to not only handle extreme outliers effectively but also improve overall quantization accuracy. Extensive experiments show that CBQ achieves superior low-bit quantization (W4A4, W4A8, W
    
[^2]: 微服务系统的少样本跨系统异常跟踪分类

    Few-Shot Cross-System Anomaly Trace Classification for Microservice-based systems

    [https://arxiv.org/abs/2403.18998](https://arxiv.org/abs/2403.18998)

    提出了针对微服务系统的少样本异常跟踪分类的新框架，利用多头注意力自编码器构建系统特定的跟踪表示，并应用基于Transformer编码器的模型无关元学习进行高效分类。

    

    微服务系统（MSS）由于其复杂和动态的特性可能在各种故障类别中出现故障。为了有效处理故障，AIOps工具利用基于跟踪的异常检测和根本原因分析。本文提出了一个新颖的框架，用于微服务系统的少样本异常跟踪分类。我们的框架包括两个主要组成部分：（1）多头注意力自编码器用于构建系统特定的跟踪表示，从而实现（2）基于Transformer编码器的模型无关元学习，以进行有效和高效的少样本异常跟踪分类。该框架在两个代表性的MSS，Trainticket和OnlineBoutique上进行了评估，使用开放数据集。结果表明，我们的框架能够调整学到的知识，以对新的、未见的新颖故障类别的异常跟踪进行分类，无论是在最初训练的同一系统内，还是在其他系统中。

    arXiv:2403.18998v1 Announce Type: cross  Abstract: Microservice-based systems (MSS) may experience failures in various fault categories due to their complex and dynamic nature. To effectively handle failures, AIOps tools utilize trace-based anomaly detection and root cause analysis. In this paper, we propose a novel framework for few-shot abnormal trace classification for MSS. Our framework comprises two main components: (1) Multi-Head Attention Autoencoder for constructing system-specific trace representations, which enables (2) Transformer Encoder-based Model-Agnostic Meta-Learning to perform effective and efficient few-shot learning for abnormal trace classification. The proposed framework is evaluated on two representative MSS, Trainticket and OnlineBoutique, with open datasets. The results show that our framework can adapt the learned knowledge to classify new, unseen abnormal traces of novel fault categories both within the same system it was initially trained on and even in the 
    
[^3]: ELLEN: 非常轻监督学习用于高效命名实体识别

    ELLEN: Extremely Lightly Supervised Learning For Efficient Named Entity Recognition

    [https://arxiv.org/abs/2403.17385](https://arxiv.org/abs/2403.17385)

    ELLEN是一种简单而强大的神经符号方法，将微调语言模型与语言规则相结合，在极其轻监督的情况下取得了非常强劲的命名实体识别性能。

    

    在这项工作中，我们重新审视了半监督命名实体识别（NER）问题，侧重于极其轻量级的监督，包括仅包含每类别10个示例的词汇表。我们引入了ELLEN，这是一种简单、完全模块化的神经符号方法，它将经过微调的语言模型与语言规则相结合。这些规则包括“一个话语一个意义”这样的见解，使用掩码语言模型作为无监督NER，利用词性标签识别和消除未标记实体作为假负例，以及关于分类器置信度得分在局部和全局背景下的其他直觉。在使用上述词汇表极小监督的情况下，ELLEN在CoNLL-2003数据集上取得了非常强大的性能。它还在文献中常用的相同监督设置（即，训练数据的5%）下，优于大多数现有（且更为复杂）的半监督NER方法。

    arXiv:2403.17385v1 Announce Type: cross  Abstract: In this work, we revisit the problem of semi-supervised named entity recognition (NER) focusing on extremely light supervision, consisting of a lexicon containing only 10 examples per class. We introduce ELLEN, a simple, fully modular, neuro-symbolic method that blends fine-tuned language models with linguistic rules. These rules include insights such as ''One Sense Per Discourse'', using a Masked Language Model as an unsupervised NER, leveraging part-of-speech tags to identify and eliminate unlabeled entities as false negatives, and other intuitions about classifier confidence scores in local and global context. ELLEN achieves very strong performance on the CoNLL-2003 dataset when using the minimal supervision from the lexicon above. It also outperforms most existing (and considerably more complex) semi-supervised NER methods under the same supervision settings commonly used in the literature (i.e., 5% of the training data). Further, 
    
[^4]: ChatDBG: 一种基于人工智能的调试助手

    ChatDBG: An AI-Powered Debugging Assistant

    [https://arxiv.org/abs/2403.16354](https://arxiv.org/abs/2403.16354)

    ChatDBG是第一个AI-Powered调试助手，通过将大型语言模型集成到传统调试器中，实现了程序员与调试器之间的协作对话，能够处理复杂问题、执行根本原因分析，并探索开放性查询。

    

    本文介绍了ChatDBG，这是第一个基于人工智能的调试助手。ChatDBG集成了大型语言模型(LLMs)，显著增强了传统调试器的功能和用户友好性。ChatDBG允许程序员与调试器进行协作对话，使他们能够提出关于程序状态的复杂问题，对崩溃或断言失败进行根本原因分析，并探索诸如“为什么x为空？”之类的开放性查询。为了处理这些查询，ChatDBG授予LLM自主权，通过发出命令来浏览堆栈和检查程序状态进行调试；然后报告其发现并将控制权交还给程序员。我们的ChatDBG原型与标准调试器集成，包括LLDB、GDB和WinDBG用于本地代码以及用于Python的Pdb。我们在各种代码集合上进行了评估，包括具有已知错误的C/C++代码和一套Python代码。

    arXiv:2403.16354v1 Announce Type: cross  Abstract: This paper presents ChatDBG, the first AI-powered debugging assistant. ChatDBG integrates large language models (LLMs) to significantly enhance the capabilities and user-friendliness of conventional debuggers. ChatDBG lets programmers engage in a collaborative dialogue with the debugger, allowing them to pose complex questions about program state, perform root cause analysis for crashes or assertion failures, and explore open-ended queries like "why is x null?". To handle these queries, ChatDBG grants the LLM autonomy to take the wheel and drive debugging by issuing commands to navigate through stacks and inspect program state; it then reports its findings and yields back control to the programmer. Our ChatDBG prototype integrates with standard debuggers including LLDB, GDB, and WinDBG for native code and Pdb for Python. Our evaluation across a diverse set of code, including C/C++ code with known bugs and a suite of Python code includi
    
[^5]: 基于重新模拟的自监督学习用于预训练基础模型

    Re-Simulation-based Self-Supervised Learning for Pre-Training Foundation Models

    [https://arxiv.org/abs/2403.07066](https://arxiv.org/abs/2403.07066)

    提出了一种新颖的基于重新模拟的自监督学习策略RS3L，通过介入模拟过程并重新模拟事件实现，生成一组涵盖所有物理驱动变化的数据增强，从而促进基础模型的发展，并展示了预训练R3SL在下游任务中表现出强大性能。

    

    自监督学习（SSL）是训练现代大型机器学习模型的核心，提供了一种学习强大表示的方案，可用于各种下游任务。然而，SSL策略必须适应所需的训练数据类型和下游任务。我们提出了RS3L，一种新颖的基于模拟的SSL策略，采用重新模拟的方法来驱动对比学习的数据增强。通过介入模拟过程的中间并重新运行介入之后的模拟组件，我们生成一个事件的多个实现，从而产生一组涵盖模拟器中所有物理驱动变化的增强。通过使用高能物理实验，我们探讨了这种策略如何促进基础模型的发展；我们展示了R3SL预训练如何在下游任务中实现强大的性能，例如区分任务。

    arXiv:2403.07066v1 Announce Type: cross  Abstract: Self-Supervised Learning (SSL) is at the core of training modern large machine learning models, providing a scheme for learning powerful representations that can be used in a variety of downstream tasks. However, SSL strategies must be adapted to the type of training data and downstream tasks required. We propose RS3L, a novel simulation-based SSL strategy that employs a method of re-simulation to drive data augmentation for contrastive learning. By intervening in the middle of the simulation process and re-running simulation components downstream of the intervention, we generate multiple realizations of an event, thus producing a set of augmentations covering all physics-driven variations available in the simulator. Using experiments from high-energy physics, we explore how this strategy may enable the development of a foundation model; we show how R3SL pre-training enables powerful performance in downstream tasks such as discriminati
    
[^6]: Signature Isolation Forest

    Signature Isolation Forest

    [https://arxiv.org/abs/2403.04405](https://arxiv.org/abs/2403.04405)

    介绍了一种新颖的异常检测算法"Signature Isolation Forest"，利用粗路径理论的签名变换去除了Functional Isolation Forest的线性内积和词典选择方面的限制。

    

    Functional Isolation Forest (FIF)是一种针对功能数据设计的最新一流异常检测(AD)算法。它依赖于一种树分区过程，通过将每个曲线观测投影到通过线性内积绘制的词典上来计算异常得分。本文通过引入“Signature Isolation Forest”，一种利用粗路径理论签名变换的新颖AD算法类，来解决这些挑战。我们的目标是通过提出两种算法来消除FIF施加的限制，这两种算法特别针对FIF内积的线性性和词典的选择。

    arXiv:2403.04405v1 Announce Type: cross  Abstract: Functional Isolation Forest (FIF) is a recent state-of-the-art Anomaly Detection (AD) algorithm designed for functional data. It relies on a tree partition procedure where an abnormality score is computed by projecting each curve observation on a drawn dictionary through a linear inner product. Such linear inner product and the dictionary are a priori choices that highly influence the algorithm's performances and might lead to unreliable results, particularly with complex datasets. This work addresses these challenges by introducing \textit{Signature Isolation Forest}, a novel AD algorithm class leveraging the rough path theory's signature transform. Our objective is to remove the constraints imposed by FIF through the proposition of two algorithms which specifically target the linearity of the FIF inner product and the choice of the dictionary. We provide several numerical experiments, including a real-world applications benchmark sho
    
[^7]: 参数化量子梳和简化电路用于逆转未知量子比特-酉操作

    Parameterized quantum comb and simpler circuits for reversing unknown qubit-unitary operations

    [https://arxiv.org/abs/2403.03761](https://arxiv.org/abs/2403.03761)

    通过优化参数化量子电路，我们开发了一个简化的协议，用于逆转未知量子比特酉操作，将辅助比特开销减少到3，显示了量子梳结构的实用性和PQComb在解决复杂量子任务中的潜力。

    

    Quantum comb是量子信息处理中表征复杂量子协议的重要工具。在这项工作中，我们引入了PQComb，一个利用参数化量子电路探索量子梳在一般量子过程转换任务及其他方面能力的框架。通过优化PQComb进行未知酉演化的时间反漞模拟，我们开发出了一种更简单的未知量子比特酉反演协议，将比现有方法[Yoshida, Soeda, Murao, PRL 131, 120602, 2023]的辅助比特开销从6减少到3。这展示了量子梳结构的实用性，展示了PQComb在解决复杂量子任务方面的潜力。我们的结果为PQComb在量子计算和量子信息中更广泛的应用铺平了道路，强调了它在解决量子机器学习中的多样问题时的多功能性。

    arXiv:2403.03761v1 Announce Type: cross  Abstract: Quantum comb is an essential tool for characterizing complex quantum protocols in quantum information processing. In this work, we introduce PQComb, a framework leveraging parameterized quantum circuits to explore the capabilities of quantum combs for general quantum process transformation tasks and beyond. By optimizing PQComb for time-reversal simulations of unknown unitary evolutions, we develop a simpler protocol for unknown qubit unitary inversion that reduces the ancilla qubit overhead from 6 to 3 compared to the existing method in [Yoshida, Soeda, Murao, PRL 131, 120602, 2023]. This demonstrates the utility of quantum comb structures and showcases PQComb's potential for solving complex quantum tasks. Our results pave the way for broader PQComb applications in quantum computing and quantum information, emphasizing its versatility for tackling diverse problems in quantum machine learning.
    
[^8]: 具有可微Boltzmann估计器的神经网络原子间势的稳定性训练

    Stability-Aware Training of Neural Network Interatomic Potentials with Differentiable Boltzmann Estimators

    [https://arxiv.org/abs/2402.13984](https://arxiv.org/abs/2402.13984)

    提出了稳定性感知Boltzmann估计器（StABlE）训练方法，结合传统监督训练和参考系统可观察量，用于生成稳定且准确的神经网络原子间势。

    

    神经网络原子间势（NNIPs）是分子动力学（MD）模拟中的一种吸引人的替代方法。然而，它们可能产生不稳定的模拟，采样非物理状态，从而限制了其在对模拟长时间尺度现象建模中的实用性。为解决这些挑战，我们提出了稳定性感知Boltzmann估计器（StABlE）训练，这是一种多模式训练过程，结合了传统监督训练和参考系统可观察量，以产生稳定且准确的NNIPs。StABlE训练通过迭代运行MD模拟以寻找不稳定区域，并通过与参考可观察量的监督来纠正这些不稳定性。该训练过程由Boltzmann估计器支持，该估计器允许对系统可观察量训练神经网络所需的梯度进行高效计算，并能检测全局和局部

    arXiv:2402.13984v1 Announce Type: new  Abstract: Neural network interatomic potentials (NNIPs) are an attractive alternative to ab-initio methods for molecular dynamics (MD) simulations. However, they can produce unstable simulations which sample unphysical states, limiting their usefulness for modeling phenomena occurring over longer timescales. To address these challenges, we present Stability-Aware Boltzmann Estimator (StABlE) Training, a multi-modal training procedure which combines conventional supervised training from quantum-mechanical energies and forces with reference system observables, to produce stable and accurate NNIPs. StABlE Training iteratively runs MD simulations to seek out unstable regions, and corrects the instabilities via supervision with a reference observable. The training procedure is enabled by the Boltzmann Estimator, which allows efficient computation of gradients required to train neural networks to system observables, and can detect both global and local 
    
[^9]: 重新思考基于偏差-方差分解的半监督不平衡节点分类问题

    Rethinking Semi-Supervised Imbalanced Node Classification from Bias-Variance Decomposition

    [https://arxiv.org/abs/2310.18765](https://arxiv.org/abs/2310.18765)

    本文提出了一种新的方法来解决图神经网络中的类别不平衡问题。该方法将不平衡节点分类和偏差-方差分解相结合，利用图扩充技术估计方差，并通过正则项减轻不平衡的影响。在多个基准数据集上进行的测试结果表明，该方法在各种不平衡场景中优于现有最先进的方法，并为解决GNN中的不平衡节点分类问题提供了一种新颖的理论视角。

    

    本文介绍了一种新的方法来解决图神经网络（GNN）中的类别不平衡问题。我们的方法将不平衡节点分类和偏差-方差分解相结合，建立了一个将数据不平衡与模型方差密切相关的理论框架。我们还利用图扩充技术来估计方差，并设计了一个正则项来减轻不平衡的影响。我们在多个基准数据集上进行了详尽的测试，包括自然不平衡的数据集和公开划分的类别不平衡数据集，结果表明我们的方法在各种不平衡场景中优于现有最先进的方法。该工作为解决GNN中的不平衡节点分类问题提供了一种新颖的理论视角。

    This paper introduces a new approach to address the issue of class imbalance in graph neural networks (GNNs) for learning on graph-structured data. Our approach integrates imbalanced node classification and Bias-Variance Decomposition, establishing a theoretical framework that closely relates data imbalance to model variance. We also leverage graph augmentation technique to estimate the variance, and design a regularization term to alleviate the impact of imbalance. Exhaustive tests are conducted on multiple benchmarks, including naturally imbalanced datasets and public-split class-imbalanced datasets, demonstrating that our approach outperforms state-of-the-art methods in various imbalanced scenarios. This work provides a novel theoretical perspective for addressing the problem of imbalanced node classification in GNNs.
    
[^10]: 面向流形值图的扩散卷积神经网络：多重难题图神经网络层

    Manifold GCN: Diffusion-based Convolutional Neural Network for Manifold-valued Graphs. (arXiv:2401.14381v1 [cs.LG])

    [http://arxiv.org/abs/2401.14381](http://arxiv.org/abs/2401.14381)

    本研究提出了两个用于具有流形值特征的图的神经网络层。这些层具有对节点排列和特征流形的等变性，并在深度学习任务中显示出有益的归纳偏差。

    

    我们提出了两种用于具有Riemannian流形特征的图上的图神经网络层。第一，基于流形值图的扩散方程，我们构建了一个扩散层，可以应用于任意数量的节点和图连接模式。第二，我们通过将向量神经元框架的思想转化到我们的一般设置中，建立了一个切线多层感知器。这两个层对节点排列和特征流形的等变具有响应，这些特性在许多深度学习任务中已被证明具有有益的归纳偏差。我们在合成数据上以及在右侧海马三角网格上分类阿尔茨海默病的数值实例表明我们建立的层具有非常好的性能。

    We propose two graph neural network layers for graphs with features in a Riemannian manifold. First, based on a manifold-valued graph diffusion equation, we construct a diffusion layer that can be applied to an arbitrary number of nodes and graph connectivity patterns. Second, we model a tangent multilayer perceptron by transferring ideas from the vector neuron framework to our general setting. Both layers are equivariant with respect to node permutations and isometries of the feature manifold. These properties have been shown to lead to a beneficial inductive bias in many deep learning tasks. Numerical examples on synthetic data as well as on triangle meshes of the right hippocampus to classify Alzheimer's disease demonstrate the very good performance of our layers.
    
[^11]: 使用Wasserstein距离进行加权以增强选择性

    Enhancing selectivity using Wasserstein distance based reweighing. (arXiv:2401.11562v1 [stat.ML])

    [http://arxiv.org/abs/2401.11562](http://arxiv.org/abs/2401.11562)

    我们设计了一种使用Wasserstein距离进行加权的算法，在标记的数据集上训练神经网络可以逼近在其他数据集上训练得到的结果。我们证明了算法可以输出接近最优的加权，且算法简单可扩展。我们的算法可以有意地引入分布偏移进行多目标优化。作为应用实例，我们训练了一个神经网络来识别对细胞信号传导的MAP激酶具有非结合性的小分子结合物。

    

    给定两个标记数据集𝒮和𝒯，我们设计了一种简单高效的贪婪算法来对损失函数进行加权，使得在𝒮上训练得到的神经网络权重的极限分布逼近在𝒯上训练得到的极限分布。在理论方面，我们证明了当输入数据集的度量熵有界时，我们的贪婪算法输出接近最优的加权，即网络权重的两个不变分布在总变差距离上可以证明接近。此外，该算法简单可扩展，并且我们还证明了算法的效率上界。我们的算法可以有意地引入分布偏移以进行（软）多目标优化。作为一个动机应用，我们训练了一个神经网络来识别对MNK2（一种细胞信号传导的MAP激酶）具有非结合性的小分子结合物。

    Given two labeled data-sets $\mathcal{S}$ and $\mathcal{T}$, we design a simple and efficient greedy algorithm to reweigh the loss function such that the limiting distribution of the neural network weights that result from training on $\mathcal{S}$ approaches the limiting distribution that would have resulted by training on $\mathcal{T}$.  On the theoretical side, we prove that when the metric entropy of the input data-sets is bounded, our greedy algorithm outputs a close to optimal reweighing, i.e., the two invariant distributions of network weights will be provably close in total variation distance. Moreover, the algorithm is simple and scalable, and we prove bounds on the efficiency of the algorithm as well.  Our algorithm can deliberately introduce distribution shift to perform (soft) multi-criteria optimization. As a motivating application, we train a neural net to recognize small molecule binders to MNK2 (a MAP Kinase, responsible for cell signaling) which are non-binders to MNK1
    
[^12]: D-STGCNT:一种基于transformer的密集时空图卷积GRU网络用于评估患者身体康复

    D-STGCNT: A Dense Spatio-Temporal Graph Conv-GRU Network based on transformer for assessment of patient physical rehabilitation. (arXiv:2401.06150v1 [eess.IV])

    [http://arxiv.org/abs/2401.06150](http://arxiv.org/abs/2401.06150)

    D-STGCNT是一种新的模型，结合了STGCN和transformer的架构，用于自动评估患者身体康复锻炼。它通过将骨架数据视为图形，并检测关键关节，在处理时空数据方面具有高效性。该模型通过密集连接和GRU机制来处理大型3D骨架输入，有效建立时空动态模型。transformer的注意力机制对于评估康复锻炼非常有用。

    

    本文解决了自动评估无临床监督情况下患者进行身体康复锻炼的挑战。其目标是提供质量评分以确保正确执行和获得期望结果。为实现这一目标，引入了一种新的基于图结构的模型，Dense Spatio-Temporal Graph Conv-GRU Network with Transformer。该模型结合了改进的STGCN和transformer架构，用于高效处理时空数据。其关键思想是将骨架数据视为图形，并检测每个康复锻炼中起主要作用的关节。密集连接和GRU机制用于快速处理大型3D骨架输入并有效建模时空动态。transformer编码器的注意机制侧重于输入序列的相关部分，使其在评估康复锻炼方面非常有用。

    This paper tackles the challenge of automatically assessing physical rehabilitation exercises for patients who perform the exercises without clinician supervision. The objective is to provide a quality score to ensure correct performance and achieve desired results. To achieve this goal, a new graph-based model, the Dense Spatio-Temporal Graph Conv-GRU Network with Transformer, is introduced. This model combines a modified version of STGCN and transformer architectures for efficient handling of spatio-temporal data. The key idea is to consider skeleton data respecting its non-linear structure as a graph and detecting joints playing the main role in each rehabilitation exercise. Dense connections and GRU mechanisms are used to rapidly process large 3D skeleton inputs and effectively model temporal dynamics. The transformer encoder's attention mechanism focuses on relevant parts of the input sequence, making it useful for evaluating rehabilitation exercises. The evaluation of our propose
    
[^13]: 机器学习和特征排序在多传感器数据的冲击坠落检测事件中的应用

    Machine Learning and Feature Ranking for Impact Fall Detection Event Using Multisensor Data. (arXiv:2401.05407v1 [eess.SP])

    [http://arxiv.org/abs/2401.05407](http://arxiv.org/abs/2401.05407)

    本论文通过对多传感器数据进行彻底的预处理和特征选择，成功应用机器学习模型实现了冲击坠落检测，取得了较高的准确率。

    

    个人的跌倒，特别是老年人，可能导致严重的伤害和并发症。在跌倒事件中检测冲击瞬间对于及时提供帮助和减少负面影响至关重要。在这项工作中，我们通过对多传感器数据集应用彻底的预处理技术来解决这个挑战，目的是消除噪音并提高数据质量。此外，我们还使用特征选择过程来识别多传感器UP-FALL数据集中最相关的特征，从而提高机器学习模型的性能和效率。然后，我们使用多个传感器的结果数据信息评估各种机器学习模型在检测冲击瞬间方面的效率。通过大量实验，我们使用各种评估指标评估了我们方法的准确性。我们的结果在冲击检测方面取得了较高的准确率，展示了利用多传感器数据信息的能力。

    Falls among individuals, especially the elderly population, can lead to serious injuries and complications. Detecting impact moments within a fall event is crucial for providing timely assistance and minimizing the negative consequences. In this work, we aim to address this challenge by applying thorough preprocessing techniques to the multisensor dataset, the goal is to eliminate noise and improve data quality. Furthermore, we employ a feature selection process to identify the most relevant features derived from the multisensor UP-FALL dataset, which in turn will enhance the performance and efficiency of machine learning models. We then evaluate the efficiency of various machine learning models in detecting the impact moment using the resulting data information from multiple sensors. Through extensive experimentation, we assess the accuracy of our approach using various evaluation metrics. Our results achieve high accuracy rates in impact detection, showcasing the power of leveraging 
    
[^14]: 通过随机滤波和模式识别强化基于POD的反应扩散复杂网络模型简化技术

    Reinforcing POD based model reduction techniques in reaction-diffusion complex networks using stochastic filtering and pattern recognition. (arXiv:2307.09762v1 [cs.CE])

    [http://arxiv.org/abs/2307.09762](http://arxiv.org/abs/2307.09762)

    该论文提出了一种算法框架，通过将模式识别和随机滤波理论的技术结合起来，强化了基于POD的反应扩散复杂网络模型简化技术，在受扰动输入的情况下提高了代理模型的准确性。

    

    复杂网络被用于建模许多现实世界系统，然而这些系统的维度使得其分析变得困难。在这种情况下，可以使用POD等降维技术。然而，这些模型容易受输入数据扰动的影响。我们提出了一种算法框架，将模式识别和随机滤波理论的技术结合起来，以增强这些模型的输出。研究结果表明，我们的方法可以在受扰动输入的情况下提高代理模型的准确性。深度神经网络(DNNs)容易受到对抗性攻击，然而最近的研究发现，神经常微分方程(ODEs)在特定应用中表现出鲁棒性。我们将我们的算法框架与基于神经ODE的方法进行了基准比较。

    Complex networks are used to model many real-world systems. However, the dimensionality of these systems can make them challenging to analyze. Dimensionality reduction techniques like POD can be used in such cases. However, these models are susceptible to perturbations in the input data. We propose an algorithmic framework that combines techniques from pattern recognition (PR) and stochastic filtering theory to enhance the output of such models. The results of our study show that our method can improve the accuracy of the surrogate model under perturbed inputs. Deep Neural Networks (DNNs) are susceptible to adversarial attacks. However, recent research has revealed that neural Ordinary Differential Equations (ODEs) exhibit robustness in specific applications. We benchmark our algorithmic framework with a Neural ODE-based approach as a reference.
    
[^15]: 自适应 $\tau$-Lasso：其健壮性和最优性质。

    The Adaptive $\tau$-Lasso: Its Robustness and Oracle Properties. (arXiv:2304.09310v1 [stat.ML])

    [http://arxiv.org/abs/2304.09310](http://arxiv.org/abs/2304.09310)

    本文提出了一种新型鲁棒的自适应 $\tau$-Lasso 估计器，同时采用自适应 $\ell_1$-范数惩罚项以降低真实回归系数的偏差。它具有变量选择一致性和真实支持下回归向量的渐近正态性的最优性质，假定已知真实回归向量的支持。

    

    本文介绍了一种用于分析高维数据集的新型正则化鲁棒 $\tau$-回归估计器，以应对响应变量和协变量的严重污染。我们称这种估计器为自适应 $\tau$-Lasso，它对异常值和高杠杆点具有鲁棒性，同时采用自适应 $\ell_1$-范数惩罚项来减少真实回归系数的偏差。具体而言，该自适应 $\ell_1$-范数惩罚项为每个回归系数分配一个权重。对于固定数量的预测变量 $p$，我们显示出自适应 $\tau$-Lasso 具有变量选择一致性和真实支持下回归向量的渐近正态性的最优性质，假定已知真实回归向量的支持。然后我们通过有限样本断点和影响函数来表征其健壮性。我们进行了广泛的模拟来比较不同的估计器的性能。

    This paper introduces a new regularized version of the robust $\tau$-regression estimator for analyzing high-dimensional data sets subject to gross contamination in the response variables and covariates. We call the resulting estimator adaptive $\tau$-Lasso that is robust to outliers and high-leverage points and simultaneously employs adaptive $\ell_1$-norm penalty term to reduce the bias associated with large true regression coefficients. More specifically, this adaptive $\ell_1$-norm penalty term assigns a weight to each regression coefficient. For a fixed number of predictors $p$, we show that the adaptive $\tau$-Lasso has the oracle property with respect to variable-selection consistency and asymptotic normality for the regression vector corresponding to the true support, assuming knowledge of the true regression vector support. We then characterize its robustness via the finite-sample breakdown point and the influence function. We carry-out extensive simulations to compare the per
    

