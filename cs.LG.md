# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Bigger is not Always Better: Scaling Properties of Latent Diffusion Models](https://arxiv.org/abs/2404.01367) | 在研究潜在扩散模型的规模特性时发现，较小的模型在相同推理预算下往往比较大的模型更有效地生成高质量结果。 |
| [^2] | [SciNews: From Scholarly Complexities to Public Narratives -- A Dataset for Scientific News Report Generation](https://arxiv.org/abs/2403.17768) | 科学新闻报道生成的自动化提高了学术见解的可访问性，该研究提出了一个包含学术出版物和相应科学新闻报道的数据集，用于探索自动生成科学新闻报道的可能性。 |
| [^3] | [Resource and Mobility Management in Hybrid LiFi and WiFi Networks: A User-Centric Learning Approach](https://arxiv.org/abs/2403.16823) | 研究了在混合LiFi和WiFi网络中基于用户中心的负载平衡方法，以解决现有网络中心化方法在处理移动性方面的问题。 |
| [^4] | [Easy-to-Hard Generalization: Scalable Alignment Beyond Human Supervision](https://arxiv.org/abs/2403.09472) | 通过从更简单的任务学习，实现对更难推理任务的有效泛化，提出了一种可扩展对齐方法。 |
| [^5] | [A Benchmark of Domain-Adapted Large Language Models for Generating Brief Hospital Course Summaries](https://arxiv.org/abs/2403.05720) | 介绍了一个新的基准测试，评估了用于生成简要住院病程摘要的大语言模型在健康保健领域中的性能并提出相应的自适应策略 |
| [^6] | [Sculpting Molecules in 3D: A Flexible Substructure Aware Framework for Text-Oriented Molecular Optimization](https://arxiv.org/abs/2403.03425) | 提出了一种通过多模态引导生成/优化任务解决分子设计问题的创新方法。 |
| [^7] | [Right on Time: Revising Time Series Models by Constraining their Explanations](https://arxiv.org/abs/2402.12921) | 引入了准时到位（RioT）方法，通过使模型解释在时间和频率域之间交互，并利用反馈来约束模型，有效地解决了时间序列数据中的混杂因素问题。 |
| [^8] | [Guided Quantum Compression for Higgs Identification](https://arxiv.org/abs/2402.09524) | Higgs鉴别的引导量子压缩模型将预处理和量子分类算法统一为可训练模型，解决了量子机器学习中使用自动编码器导致分类性能降低的问题，能够有效鉴别LHC中的希格斯玻色子。 |
| [^9] | [Seeing is not always believing: The Space of Harmless Perturbations](https://arxiv.org/abs/2402.02095) | 在深度神经网络中，我们发现了一种无害扰动空间的存在，这种扰动不会影响网络对原始图像的输出。我们证明了在输入维度超过输出维度的情况下，存在一个连续的无害扰动子空间。我们还解决了一族通用扰动，这些扰动一致地影响网络输出。我们的工作揭示了深度神经网络与人类感知之间的差异，即深度神经网络对人类认为重要的扰动可能不会影响其识别能力。 |
| [^10] | [What Will My Model Forget? Forecasting Forgotten Examples in Language Model Refinement](https://arxiv.org/abs/2402.01865) | 本文研究了语言模型更新中的遗忘现象，提出了一种预测上游实例遗忘的方法，以改进重播过程的可控性和解释性。根据预训练实例的预-softmax对数几率分数变化与在线学习实例的相似性，提出了一种部分可解释的预测模型，在BART模型上表现良好但在T5模型上失败。此外，还展示了基于内积的黑盒分类器。 |
| [^11] | [Class Distribution Shifts in Zero-Shot Learning: Learning Robust Representations](https://arxiv.org/abs/2311.18575) | 本文提出了一个模型来处理零样本学习中的类别分布转移问题，该模型假设转移原因在训练过程中是未知的属性。通过引入基于分层抽样的框架构建合成数据环境，我们能够将类别分布转移看作分布外问题，并提出了一种学习鲁棒表示的算法。实验结果表明，我们的方法在不同类别分布上的泛化能力显著提高。 |
| [^12] | [Dynamical softassign and adaptive parameter tuning for graph matching](https://arxiv.org/abs/2208.08233) | 本文提出了一种图匹配算法，结合了自适应步长参数和动态softassign策略，能够提高收敛性和效率，特别适用于完全连接的图匹配问题。 |
| [^13] | [Mitigating Feature Gap for Adversarial Robustness by Feature Disentanglement.](http://arxiv.org/abs/2401.14707) | 这项研究提出了一种通过特征解缠来缓解对抗鲁棒性中特征差距的方法，该方法明确建模和消除导致特征差距的潜在特征，有效提升了鲁棒性。 |
| [^14] | [eipy: An Open-Source Python Package for Multi-modal Data Integration using Heterogeneous Ensembles.](http://arxiv.org/abs/2401.09582) | eipy是一个开源Python包，用于开发多模态数据集成分类模型。它提供了严格和用户友好的框架，并通过嵌套交叉验证来评估并选择最佳的集成方法。 |
| [^15] | [Approximating Langevin Monte Carlo with ResNet-like Neural Network architectures.](http://arxiv.org/abs/2311.03242) | 本论文提出了一种使用类似ResNet的神经网络架构来近似Langevin Monte Carlo算法，通过将来自简单参考分布的样本映射到目标分布的样本中来进行采样，具有较好的逼近速度和表达性。 |
| [^16] | [Expecting The Unexpected: Towards Broad Out-Of-Distribution Detection.](http://arxiv.org/abs/2308.11480) | 这项研究对机器学习中分布外检测方法进行了评估，发现现有方法在检测未知类别方面表现出色，但在遇到其他类型的分布变化时性能不稳定。 |
| [^17] | [Universal Fuzzing via Large Language Models.](http://arxiv.org/abs/2308.04748) | 本文介绍了Fuzz4All，这是第一个能够针对许多不同的输入语言和这些语言的许多不同功能进行模糊测试的通用工具。 |
| [^18] | [Good Lattice Training: Physics-Informed Neural Networks Accelerated by Number Theory.](http://arxiv.org/abs/2307.13869) | 本研究提出了一种新的物理信息神经网络训练方法，受数论方法启发，通过选择适当的插值点来提高解决偏微分方程的准确性和效率。 |
| [^19] | [Nonparametric Classification on Low Dimensional Manifolds using Overparameterized Convolutional Residual Networks.](http://arxiv.org/abs/2307.01649) | 本文研究了卷积残差网络在非参数分类任务中的性能。研究表明，通过使用权重衰减的ConvResNeXts，可以隐含地实现对模块的稀疏性，从而使网络能够适应低维流形的平滑性和结构，并高效地学习函数。 |
| [^20] | [ChatGPT vs Human-authored Text: Insights into Controllable Text Summarization and Sentence Style Transfer.](http://arxiv.org/abs/2306.07799) | 本文旨在系统地检查ChatGPT在两个可控生成任务中的表现，即ChatGPT能否适应不同的目标受众和写作风格。研究发现，人类产生的文体变化比ChatGPT表现出的更大，而生成的文本在一些特征上与人类样本有所不同，有时会包含事实错误或幻觉。 |
| [^21] | [Gode -- Integrating Biochemical Knowledge Graph into Pre-training Molecule Graph Neural Network.](http://arxiv.org/abs/2306.01631) | 本研究提出了一种新的方法，在分子结构和生物医学知识图谱中集成多个领域信息，通过自我监督策略预先训练更广泛和更强大的表示，并在化学属性预测任务上展示出出色的性能。 |
| [^22] | [Incorporating Distributions of Discourse Structure for Long Document Abstractive Summarization.](http://arxiv.org/abs/2305.16784) | 本文提出了一种名为'RSTformer'的摘要模型，该模型全面融合了话语关系类型和不确定性，并以修辞结构理论为基础，经过严格评估，表现明显优于现有的模型。 |
| [^23] | [Score-Based Multimodal Autoencoders.](http://arxiv.org/abs/2305.15708) | 本文提出了一种基于分数模型的多模态自编码器，通过联合建模单模态VAE的潜在空间实现了对多模态数据的一致性整合，提高了多模态VAE的生成性能。 |
| [^24] | [Non-Parametric Learning of Stochastic Differential Equations with Fast Rates of Convergence.](http://arxiv.org/abs/2305.15557) | 提出了一种新的非参数方法，用于识别随机微分方程中的漂移和扩散系数，该方法具有快速的收敛率，使得学习速率随着未知系数的光滑度增加而变得更加紧密。 |
| [^25] | [ERM++: An Improved Baseline for Domain Generalization.](http://arxiv.org/abs/2304.01973) | ERM++是一个用于域通用性的改进基准方法，通过更好地利用训练数据、模型参数选择和权重空间正则化等关键技术，在多个数据集上比标准ERM更有效，同时计算复杂度更低，表现也优于最先进方法。 |
| [^26] | [Keep the Conversation Going: Fixing 162 out of 337 bugs for $0.42 each using ChatGPT.](http://arxiv.org/abs/2304.00385) | 提出了一个名为ChatRepair的新型自动程序修复方法，与传统的“生成和验证”范式不同，它能够通过对话风格实现即时反馈，从而显着提高漏洞修复的效率和补丁的准确性。 |
| [^27] | [Revisiting the Plastic Surgery Hypothesis via Large Language Models.](http://arxiv.org/abs/2303.10494) | 本论文重新审视了自动程序修复中的整形手术假设，并提出使用大型语言模型进行APR的新方法，主要解决了传统APR工具在不同项目中无法产生多样化修补程序的问题。 |
| [^28] | [Mathematical analysis of singularities in the diffusion model under the submanifold assumption.](http://arxiv.org/abs/2301.07882) | 本文提供了扩散模型中漂移项的数学分析。通过次流形假设，提出一种新的目标函数和相关的损失函数，可处理低维流形上的奇异数据分布，解决了均值漂移函数和得分函数渐近发散的问题。 |
| [^29] | [CADet: Fully Self-Supervised Out-Of-Distribution Detection With Contrastive Learning.](http://arxiv.org/abs/2210.01742) | 本文介绍了一种使用自监督对比学习进行带有对比学习的全自主分布检测的方法，能够同时检测未见过的类别和对抗性扰动样本。通过将自监督对比学习与最大均值差异（MMD）相结合，提出了CADet方法，该方法通过利用同一样本的对比变换之间的相似性进行OOD检测，并在对抗性扰动的识别方面比现有方法表现更好。 |

# 详细

[^1]: 大并非总是更好：潜在扩散模型的规模特性

    Bigger is not Always Better: Scaling Properties of Latent Diffusion Models

    [https://arxiv.org/abs/2404.01367](https://arxiv.org/abs/2404.01367)

    在研究潜在扩散模型的规模特性时发现，较小的模型在相同推理预算下往往比较大的模型更有效地生成高质量结果。

    

    我们研究了潜在扩散模型（LDMs）的规模特性，重点关注它们的采样效率。尽管改进的网络架构和推理算法已经证明可以有效提升扩散模型的采样效率，但模型大小的作用——采样效率的关键决定因素——尚未受到彻底的审查。通过对已建立的文本到图像扩散模型的实证分析，我们进行了深入研究，探讨了模型大小如何影响在不同采样步骤下的采样效率。我们的发现揭示了一个令人惊讶的趋势：在给定推理预算下运行时，较小的模型经常胜过其较大的等价物在生成高质量结果上。此外，我们扩展了研究，通过应用各种扩散采样器，探索不同的下游任务，评估后精馏模型，以及进行比较，来展示这些发现的普适性。

    arXiv:2404.01367v1 Announce Type: cross  Abstract: We study the scaling properties of latent diffusion models (LDMs) with an emphasis on their sampling efficiency. While improved network architecture and inference algorithms have shown to effectively boost sampling efficiency of diffusion models, the role of model size -- a critical determinant of sampling efficiency -- has not been thoroughly examined. Through empirical analysis of established text-to-image diffusion models, we conduct an in-depth investigation into how model size influences sampling efficiency across varying sampling steps. Our findings unveil a surprising trend: when operating under a given inference budget, smaller models frequently outperform their larger equivalents in generating high-quality results. Moreover, we extend our study to demonstrate the generalizability of the these findings by applying various diffusion samplers, exploring diverse downstream tasks, evaluating post-distilled models, as well as compar
    
[^2]: 从学术复杂性到公众叙事：科学新闻报道生成的数据集

    SciNews: From Scholarly Complexities to Public Narratives -- A Dataset for Scientific News Report Generation

    [https://arxiv.org/abs/2403.17768](https://arxiv.org/abs/2403.17768)

    科学新闻报道生成的自动化提高了学术见解的可访问性，该研究提出了一个包含学术出版物和相应科学新闻报道的数据集，用于探索自动生成科学新闻报道的可能性。

    

    科学新闻报道作为一个桥梁，巧妙地将复杂的研究文章翻译成与更广泛的公众 resonant 的报道。这种叙事的自动生成增强了学术见解的可访问性。在本文中，我们提出了一个新的语料库来促进这种范式的发展。我们的语料库包括九个学科领域中学术出版物及其相应科学新闻报道的平行编译。为了证明我们数据集的实用性和可靠性，我们进行了广泛分析，突出了科学新闻叙事和学术文稿之间的可读性和简洁性差异。我们使用最先进的文本生成模型基准测试我们的数据集。评估过程包括自动评估和人工评估，为未来探索自动生成科学新闻报道打下了基础。

    arXiv:2403.17768v1 Announce Type: cross  Abstract: Scientific news reports serve as a bridge, adeptly translating complex research articles into reports that resonate with the broader public. The automated generation of such narratives enhances the accessibility of scholarly insights. In this paper, we present a new corpus to facilitate this paradigm development. Our corpus comprises a parallel compilation of academic publications and their corresponding scientific news reports across nine disciplines. To demonstrate the utility and reliability of our dataset, we conduct an extensive analysis, highlighting the divergences in readability and brevity between scientific news narratives and academic manuscripts. We benchmark our dataset employing state-of-the-art text generation models. The evaluation process involves both automatic and human evaluation, which lays the groundwork for future explorations into the automated generation of scientific news reports. The dataset and code related 
    
[^3]: 混合LiFi和WiFi网络中的资源和移动管理：基于用户中心的学习方法

    Resource and Mobility Management in Hybrid LiFi and WiFi Networks: A User-Centric Learning Approach

    [https://arxiv.org/abs/2403.16823](https://arxiv.org/abs/2403.16823)

    研究了在混合LiFi和WiFi网络中基于用户中心的负载平衡方法，以解决现有网络中心化方法在处理移动性方面的问题。

    

    混合光通信（LiFi）和无线局域网（WiFi）网络（HLWNets）是一种新兴的室内无线通信范式，结合了LiFi的宽展光谱优势和WiFi的无处不在的覆盖优势。然而，负载平衡（LB）成为这种混合网络资源管理的关键挑战。现有的负载平衡方法大多是网络中心化的，依赖中央单元一次性为所有用户制定解决方案。因此，不论用户的移动状态如何，解决方案都需要同步更新所有用户。这会影响网络性能的两个方面：i）当更新频率较低时，会影响快速移动用户的连接性；ii）当更新频率较高时，会导致对于慢速移动用户不必要的切换以及巨大的反馈成本。受此启发，我们研究了允许用户更新其

    arXiv:2403.16823v1 Announce Type: cross  Abstract: Hybrid light fidelity (LiFi) and wireless fidelity (WiFi) networks (HLWNets) are an emerging indoor wireless communication paradigm, which combines the advantages of the capacious optical spectra of LiFi and ubiquitous coverage of WiFi. Meanwhile, load balancing (LB) becomes a key challenge in resource management for such hybrid networks. The existing LB methods are mostly network-centric, relying on a central unit to make a solution for the users all at once. Consequently, the solution needs to be updated for all users at the same pace, regardless of their moving status. This would affect the network performance in two aspects: i) when the update frequency is low, it would compromise the connectivity of fast-moving users; ii) when the update frequency is high, it would cause unnecessary handovers as well as hefty feedback costs for slow-moving users. Motivated by this, we investigate user-centric LB which allows users to update their 
    
[^4]: 易于难的泛化：超越人类监督的可扩展对齐

    Easy-to-Hard Generalization: Scalable Alignment Beyond Human Supervision

    [https://arxiv.org/abs/2403.09472](https://arxiv.org/abs/2403.09472)

    通过从更简单的任务学习，实现对更难推理任务的有效泛化，提出了一种可扩展对齐方法。

    

    当前人工智能对齐方法依赖于人类提供的演示或判断，由于这种方法，AI系统学习到的能力将受到人类能力的上界限制。这就带来了一个具有挑战性的研究问题：当系统的能力超过人类水平时，我们如何继续改进这些系统？本文在解决难度推理任务（如4-5级数学问题）的背景下回答了这个问题，通过从更简单的任务（如1-3级数学问题）中学习人类注释，我们将其称为“易于难的泛化”。我们的关键观点是，一个在更简单任务的监督下训练的评估器（奖励模型）可以有效地用于评分更难任务的候选解决方案，从而促进在不同难度任务间的易于难的泛化。基于这一观点，我们提出了一种新的可扩展对齐方法，首先训练处理督导

    arXiv:2403.09472v1 Announce Type: cross  Abstract: Current AI alignment methodologies rely on human-provided demonstrations or judgments, and the learned capabilities of AI systems would be upper-bounded by human capabilities as a result. This raises a challenging research question: How can we keep improving the systems when their capabilities have surpassed the levels of humans? This paper answers this question in the context of tackling hard reasoning tasks (e.g., level 4-5 MATH problems) via learning from human annotations on easier tasks (e.g., level 1-3 MATH problems), which we term as \textit{easy-to-hard generalization}. Our key insight is that an evaluator (reward model) trained on supervisions for easier tasks can be effectively used for scoring candidate solutions of harder tasks and hence facilitating easy-to-hard generalization over different levels of tasks. Based on this insight, we propose a novel approach to scalable alignment, which firstly trains the process-supervise
    
[^5]: 用于生成简要住院病程摘要的领域自适应大语言模型的基准测试

    A Benchmark of Domain-Adapted Large Language Models for Generating Brief Hospital Course Summaries

    [https://arxiv.org/abs/2403.05720](https://arxiv.org/abs/2403.05720)

    介绍了一个新的基准测试，评估了用于生成简要住院病程摘要的大语言模型在健康保健领域中的性能并提出相应的自适应策略

    

    简要住院病程（BHC）摘要是通过总结临床记录而生成的常见临床文件。虽然大型语言模型（LLMs）在自动化实际任务方面展现出显著能力，但它们在医疗应用（如BHC合成）中的能力尚未得到展示。为了使LLMs能够适应BHC合成，我们引入了一个新颖的基准测试，其中包含从MIMIC-IV记录中提取的经过预处理的数据集，封装了临床记录和简要住院病程（BHC）对。我们评估了两个通用LLMs和三个医疗领域适应的LLMs的性能，以改进从临床记录生成BHC。我们使用临床记录作为输入来生成BHC，采用基于提示的（使用上下文学习）和基于微调的自适应策略来应用于三个开源LLMs（Clinical-T5-Large，Llama2-13B，FLAN-UL2）和两个专有LLMs（GPT-3.5，GPT-4）。我们定量评估了性能。

    arXiv:2403.05720v1 Announce Type: cross  Abstract: Brief hospital course (BHC) summaries are common clinical documents generated by summarizing clinical notes. While large language models (LLMs) depict remarkable capabilities in automating real-world tasks, their capabilities for healthcare applications such as BHC synthesis have not been shown. To enable the adaptation of LLMs for BHC synthesis, we introduce a novel benchmark consisting of a pre-processed dataset extracted from MIMIC-IV notes, encapsulating clinical note, and brief hospital course (BHC) pairs. We assess the performance of two general-purpose LLMs and three healthcare-adapted LLMs to improve BHC synthesis from clinical notes. Using clinical notes as input for generating BHCs, we apply prompting-based (using in-context learning) and fine-tuning-based adaptation strategies to three open-source LLMs (Clinical-T5-Large, Llama2-13B, FLAN-UL2) and two proprietary LLMs (GPT-3.5, GPT-4). We quantitatively evaluate the performa
    
[^6]: 在3D中塑造分子：面向文本的分子优化灵活子结构感知框架

    Sculpting Molecules in 3D: A Flexible Substructure Aware Framework for Text-Oriented Molecular Optimization

    [https://arxiv.org/abs/2403.03425](https://arxiv.org/abs/2403.03425)

    提出了一种通过多模态引导生成/优化任务解决分子设计问题的创新方法。

    

    通过将深度学习，特别是AI-Generated Content，与从第一原理计算中得出的高质量数据相结合，已经成为改变科学研究格局的一种有前途的途径。然而，设计既包含多模态先验知识又具有关键和复杂性的分子药物或材料的挑战依然是一项关键而复杂的工作。本文提出了一种创新方法来解决这一逆设计问题，将其构造为一种多模态导向生成/优化任务。我们提出的解决方案涉及一个面向文本-结构对齐的对称扩散框架，用于实现分子生成/优化任务，即3DToMolo.

    arXiv:2403.03425v1 Announce Type: new  Abstract: The integration of deep learning, particularly AI-Generated Content, with high-quality data derived from ab initio calculations has emerged as a promising avenue for transforming the landscape of scientific research. However, the challenge of designing molecular drugs or materials that incorporate multi-modality prior knowledge remains a critical and complex undertaking. Specifically, achieving a practical molecular design necessitates not only meeting the diversity requirements but also addressing structural and textural constraints with various symmetries outlined by domain experts. In this article, we present an innovative approach to tackle this inverse design problem by formulating it as a multi-modality guidance generation/optimization task. Our proposed solution involves a textural-structure alignment symmetric diffusion framework for the implementation of molecular generation/optimization tasks, namely 3DToMolo. 3DToMolo aims to 
    
[^7]: 准时到位：通过限制时间序列模型的解释来修订它们

    Right on Time: Revising Time Series Models by Constraining their Explanations

    [https://arxiv.org/abs/2402.12921](https://arxiv.org/abs/2402.12921)

    引入了准时到位（RioT）方法，通过使模型解释在时间和频率域之间交互，并利用反馈来约束模型，有效地解决了时间序列数据中的混杂因素问题。

    

    深度时间序列模型的可靠性经常会受到其依赖混杂因素的倾向的损害，这可能导致误导性结果。我们的新记录的、自然混杂的数据集P2S来自真实的机械生产线，强调了这一点。为了解决时间序列数据中的混杂因素的挑战性问题，我们引入了准时到位（RioT）。我们的方法使模型解释在时间和频率域之间进行交互。然后利用两个域内的解释反馈来约束模型，使其远离标注的混杂因素。在处理时间序列数据集中混杂因素方面，双域交互策略至关重要。我们凭经验证明，RioT能够有效地引导模型远离P2S以及流行的时间序列分类和预测数据集中的错误原因。

    arXiv:2402.12921v1 Announce Type: new  Abstract: The reliability of deep time series models is often compromised by their tendency to rely on confounding factors, which may lead to misleading results. Our newly recorded, naturally confounded dataset named P2S from a real mechanical production line emphasizes this. To tackle the challenging problem of mitigating confounders in time series data, we introduce Right on Time (RioT). Our method enables interactions with model explanations across both the time and frequency domain. Feedback on explanations in both domains is then used to constrain the model, steering it away from the annotated confounding factors. The dual-domain interaction strategy is crucial for effectively addressing confounders in time series datasets. We empirically demonstrate that RioT can effectively guide models away from the wrong reasons in P2S as well as popular time series classification and forecasting datasets.
    
[^8]: Higgs鉴别的引导量子压缩

    Guided Quantum Compression for Higgs Identification

    [https://arxiv.org/abs/2402.09524](https://arxiv.org/abs/2402.09524)

    Higgs鉴别的引导量子压缩模型将预处理和量子分类算法统一为可训练模型，解决了量子机器学习中使用自动编码器导致分类性能降低的问题，能够有效鉴别LHC中的希格斯玻色子。

    

    arXiv：2402.09524v1 公告类型：交叉摘要：量子机器学习提供了一种基本新颖且有前景的数据分析方法。然而，许多数据集对当前可用的量子计算机来说过于复杂。因此，传统上，量子机器学习应用通过使用降维算法（如自动编码器）在通过量子模型之前对数据进行预处理。我们展示了使用经典自动编码器作为独立的预处理步骤可以显著降低量子机器学习算法的分类性能。为了改善这个问题，我们设计了一种将预处理和量子分类算法统一到单个可训练模型中的架构：引导量子压缩模型。通过使用该模型在LHC的质子-质子碰撞中鉴别希格斯玻色子的实用性得到了证明，而传统方法则无效。

    arXiv:2402.09524v1 Announce Type: cross  Abstract: Quantum machine learning provides a fundamentally novel and promising approach to analyzing data. However, many data sets are too complex for currently available quantum computers. Consequently, quantum machine learning applications conventionally resort to dimensionality reduction algorithms, e.g., auto-encoders, before passing data through the quantum models. We show that using a classical auto-encoder as an independent preprocessing step can significantly decrease the classification performance of a quantum machine learning algorithm. To ameliorate this issue, we design an architecture that unifies the preprocessing and quantum classification algorithms into a single trainable model: the guided quantum compression model. The utility of this model is demonstrated by using it to identify the Higgs boson in proton-proton collisions at the LHC, where the conventional approach proves ineffective. Conversely, the guided quantum compressio
    
[^9]: 眼见未必为实：无害扰动空间的探索

    Seeing is not always believing: The Space of Harmless Perturbations

    [https://arxiv.org/abs/2402.02095](https://arxiv.org/abs/2402.02095)

    在深度神经网络中，我们发现了一种无害扰动空间的存在，这种扰动不会影响网络对原始图像的输出。我们证明了在输入维度超过输出维度的情况下，存在一个连续的无害扰动子空间。我们还解决了一族通用扰动，这些扰动一致地影响网络输出。我们的工作揭示了深度神经网络与人类感知之间的差异，即深度神经网络对人类认为重要的扰动可能不会影响其识别能力。

    

    在深度神经网络的背景下，我们揭示了一种无害扰动空间的存在，即扰动会使网络输出完全不变。无论这些扰动在应用于图像时的大小如何，只要它们位于无害扰动空间内，就不会对原始图像的网络输出产生影响。具体而言，对于网络中的任何线性层，输入维度$n$超过输出维度$m$的情况下，我们证明了连续无害扰动子空间的存在，其维度为$(n-m)$。受此启发，我们解决了一族一致影响网络输出的通用扰动，而不论它们的大小如何。基于这些理论发现，我们探索了无害扰动在保护隐私数据使用方面的应用。我们的工作揭示了深度神经网络与人类感知之间的差异，即被人类捕捉到的重要扰动可能不会影响深度神经网络的识别能力。

    In the context of deep neural networks, we expose the existence of a harmless perturbation space, where perturbations leave the network output entirely unaltered. Perturbations within this harmless perturbation space, regardless of their magnitude when applied to images, exhibit no impact on the network's outputs of the original images. Specifically, given any linear layer within the network, where the input dimension $n$ exceeds the output dimension $m$, we demonstrate the existence of a continuous harmless perturbation subspace with a dimension of $(n-m)$. Inspired by this, we solve for a family of general perturbations that consistently influence the network output, irrespective of their magnitudes. With these theoretical findings, we explore the application of harmless perturbations for privacy-preserving data usage. Our work reveals the difference between DNNs and human perception that the significant perturbations captured by humans may not affect the recognition of DNNs. As a re
    
[^10]: 我的模型会忘记什么？语言模型改进中的被遗忘实例预测

    What Will My Model Forget? Forecasting Forgotten Examples in Language Model Refinement

    [https://arxiv.org/abs/2402.01865](https://arxiv.org/abs/2402.01865)

    本文研究了语言模型更新中的遗忘现象，提出了一种预测上游实例遗忘的方法，以改进重播过程的可控性和解释性。根据预训练实例的预-softmax对数几率分数变化与在线学习实例的相似性，提出了一种部分可解释的预测模型，在BART模型上表现良好但在T5模型上失败。此外，还展示了基于内积的黑盒分类器。

    

    在实际应用中，语言模型会出现错误。然而，仅仅通过将模型更新为纠正错误实例，会导致灾难性的遗忘，更新后的模型在指导微调或上游训练阶段中学到的实例上出现错误。随机重播上游数据的效果不令人满意，往往伴随着较高的方差和较差的可控性。为了改善重播过程的可控性和解释性，我们试图预测由于模型更新而遗忘的上游实例。我们根据一组在线学习的实例和相应被遗忘的上游预训练实例训练预测模型。我们提出了一种部分可解释的预测模型，该模型基于这样的观察结果：预训练实例的预-softmax对数几率分数的变化类似于在线学习实例的变化，这在BART模型上表现出不错的效果，但在T5模型上失败。我们进一步展示了基于内积的黑盒分类器

    Language models deployed in the wild make errors. However, simply updating the model with the corrected error instances causes catastrophic forgetting -- the updated model makes errors on instances learned during the instruction tuning or upstream training phase. Randomly replaying upstream data yields unsatisfactory performance and often comes with high variance and poor controllability. To this end, we try to forecast upstream examples that will be forgotten due to a model update for improved controllability of the replay process and interpretability. We train forecasting models given a collection of online learned examples and corresponding forgotten upstream pre-training examples. We propose a partially interpretable forecasting model based on the observation that changes in pre-softmax logit scores of pretraining examples resemble that of online learned examples, which performs decently on BART but fails on T5 models. We further show a black-box classifier based on inner products 
    
[^11]: 零样本学习中的类别分布转移：学习鲁棒表示

    Class Distribution Shifts in Zero-Shot Learning: Learning Robust Representations

    [https://arxiv.org/abs/2311.18575](https://arxiv.org/abs/2311.18575)

    本文提出了一个模型来处理零样本学习中的类别分布转移问题，该模型假设转移原因在训练过程中是未知的属性。通过引入基于分层抽样的框架构建合成数据环境，我们能够将类别分布转移看作分布外问题，并提出了一种学习鲁棒表示的算法。实验结果表明，我们的方法在不同类别分布上的泛化能力显著提高。

    

    类别分布转移对零样本分类器来说尤为具有挑战性，因为它们依赖于从训练类别学到的表示，但部署在新的、未知的类别上。常见的类别分布转移原因是与类别相关的属性的改变，比如在人物识别中的种族或性别。在这项工作中，我们提出并分析了一个采用这个设置的模型，假设在训练过程中未知导致转移的属性。为了解决学习对这种转移鲁棒的数据表示的挑战，我们引入了一种基于分层抽样的框架来构建合成数据环境。尽管两种设置之间存在关键差异，但这个框架使我们能够将零样本学习中的类别分布转移转化为分布外问题。因此，我们提出了一种学习鲁棒表示的算法，并展示了我们的方法在模拟和真实数据集上显著改善了对不同类别分布的泛化能力。

    Class distribution shifts are particularly challenging for zero-shot classifiers, which rely on representations learned from training classes but are deployed on new, unseen ones. Common causes for such shifts are changes in attributes associated with classes, such as race or gender in person identification. In this work, we propose and analyze a model that adopts this setting, assuming that the attribute responsible for the shift is unknown during training. To address the challenge of learning data representations robust to such shifts, we introduce a framework based on hierarchical sampling to construct synthetic data environments. Despite key differences between the settings, this framework allows us to formulate class distribution shifts in zero-shot learning as out-of-distribution problems. Consequently, we present an algorithm for learning robust representations, and show that our approach significantly improves generalization to diverse class distributions in both simulations an
    
[^12]: 图匹配的动态softassign和自适应参数调整

    Dynamical softassign and adaptive parameter tuning for graph matching

    [https://arxiv.org/abs/2208.08233](https://arxiv.org/abs/2208.08233)

    本文提出了一种图匹配算法，结合了自适应步长参数和动态softassign策略，能够提高收敛性和效率，特别适用于完全连接的图匹配问题。

    

    本文研究了一种称为约束梯度方法的图匹配问题的统一框架。在该框架内的流行算法包括递归分配（GA）、整数投影固定点法（IPFP）和双随机投影固定点法（DSPFP）。 这些算法在步长参数和约束算子上有所不同。我们提出的自适应步长参数可以保证基础算法的收敛性，增强它们的效率和准确性。初步分析表明，在完全连接的图匹配中，最优步长参数有很高的概率为1。其次，我们提出了一种动态策略来处理softassign这一流行约束算子在节点基数和溢出风险方面的敏感性。 结合自适应步长参数和动态softassign，我们提出了一种新颖的图匹配算法：softas

    arXiv:2208.08233v3 Announce Type: replace-cross  Abstract: This paper studies a unified framework for graph matching problems called the constrained gradient method. Popular algorithms within this framework include graduated assignment (GA), integer projected fixed-point method (IPFP), and doubly stochastic projected fixed-point method (DSPFP). These algorithms differ from the step size parameter and constrained operator. Our contributed adaptive step size parameter can guarantee the underlying algorithms' convergence and enhance their efficiency and accuracy. A preliminary analysis suggests that the optimal step size parameter has a high probability of being 1 in fully connected graph matching. Secondly, we propose a dynamic strategy for softassign, a popular constrained operator, to address its sensitivity concerning nodes' cardinality and risk of overflow. Combining the adaptive step size parameter and the dynamical softassign, we propose a novel graph matching algorithm: the softas
    
[^13]: 通过特征解缠来缓解对抗鲁棒性中的特征差距

    Mitigating Feature Gap for Adversarial Robustness by Feature Disentanglement. (arXiv:2401.14707v1 [cs.CV])

    [http://arxiv.org/abs/2401.14707](http://arxiv.org/abs/2401.14707)

    这项研究提出了一种通过特征解缠来缓解对抗鲁棒性中特征差距的方法，该方法明确建模和消除导致特征差距的潜在特征，有效提升了鲁棒性。

    

    深度神经网络对对抗样本很容易受到攻击。对抗微调方法旨在通过对已经在自然情况下进行预训练的模型进行对抗式微调来提升对抗鲁棒性。然而，我们发现对抗样本中的一些潜在特征被对抗扰动所混淆，并导致自然样本和对抗样本在最后一层隐藏层的特征之间出现意外增加的差距。为了解决这个问题，我们提出了一种基于解缠的方法来明确建模和进一步消除导致特征差距的潜在特征。具体而言，我们引入了特征解缠器，将对抗样本的潜在特征与对抗样本的特征分离开来，从而通过消除潜在特征来提升鲁棒性。此外，我们通过将预训练模型中的特征与对抗样本在微调模型中的特征对齐，进一步从自然样本的特征中获益，避免混淆。

    Deep neural networks are vulnerable to adversarial samples. Adversarial fine-tuning methods aim to enhance adversarial robustness through fine-tuning the naturally pre-trained model in an adversarial training manner. However, we identify that some latent features of adversarial samples are confused by adversarial perturbation and lead to an unexpectedly increasing gap between features in the last hidden layer of natural and adversarial samples. To address this issue, we propose a disentanglement-based approach to explicitly model and further remove the latent features that cause the feature gap. Specifically, we introduce a feature disentangler to separate out the latent features from the features of the adversarial samples, thereby boosting robustness by eliminating the latent features. Besides, we align features in the pre-trained model with features of adversarial samples in the fine-tuned model, to further benefit from the features from natural samples without confusion. Empirical 
    
[^14]: eipy: 一种用于异构集成的多模态数据开源Python包

    eipy: An Open-Source Python Package for Multi-modal Data Integration using Heterogeneous Ensembles. (arXiv:2401.09582v1 [cs.LG])

    [http://arxiv.org/abs/2401.09582](http://arxiv.org/abs/2401.09582)

    eipy是一个开源Python包，用于开发多模态数据集成分类模型。它提供了严格和用户友好的框架，并通过嵌套交叉验证来评估并选择最佳的集成方法。

    

    本文介绍了eipy，一种用于开发有效的多模态异构集成分类的开源Python包。eipy同时提供了一个严格而用户友好的框架，通过系统评估它们在嵌套交叉验证中的性能来比较和选择最佳的多模态数据集成和预测建模方法。该包旨在利用类似scikit-learn的估计器作为组件来构建多模态预测模型。eipy的最新用户指南，包括API参考和教程，请参阅https://eipy.readthedocs.io。该项目的主要存储库位于GitHub上的https://github.com/GauravPandeyLab/eipy。

    In this paper, we introduce eipy--an open-source Python package for developing effective, multi-modal heterogeneous ensembles for classification. eipy simultaneously provides both a rigorous, and user-friendly framework for comparing and selecting the best-performing multi-modal data integration and predictive modeling methods by systematically evaluating their performance using nested cross-validation. The package is designed to leverage scikit-learn-like estimators as components to build multi-modal predictive models. An up-to-date user guide, including API reference and tutorials, for eipy is maintained at https://eipy.readthedocs.io . The main repository for this project can be found on GitHub at https://github.com/GauravPandeyLab/eipy .
    
[^15]: 使用类似ResNet的神经网络架构近似Langevin Monte Carlo

    Approximating Langevin Monte Carlo with ResNet-like Neural Network architectures. (arXiv:2311.03242v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2311.03242](http://arxiv.org/abs/2311.03242)

    本论文提出了一种使用类似ResNet的神经网络架构来近似Langevin Monte Carlo算法，通过将来自简单参考分布的样本映射到目标分布的样本中来进行采样，具有较好的逼近速度和表达性。

    

    我们通过构建一个神经网络，将来自简单参考分布（如标准正态分布）的样本映射到目标分布的样本中，从而从给定的目标分布中进行采样。为此，我们提出使用受Langevin Monte Carlo (LMC)算法启发的神经网络架构。基于LMC扰动结果，在Wasserstein-2距离上，我们展示了该架构对于平滑的对数凹目标分布的逼近速度。分析严重依赖于扰动LMC过程的中间度量的亚高斯性概念。特别地，我们根据不同扰动假设推导出了中间方差代理的增长界限。此外，我们提出了一种类似于深度残差神经网络的架构，并推导出了近似样本与目标分布映射的表达性结果。

    We sample from a given target distribution by constructing a neural network which maps samples from a simple reference, e.g. the standard normal distribution, to samples from the target. To that end, we propose using a neural network architecture inspired by the Langevin Monte Carlo (LMC) algorithm. Based on LMC perturbation results, we show approximation rates of the proposed architecture for smooth, log-concave target distributions measured in the Wasserstein-$2$ distance. The analysis heavily relies on the notion of sub-Gaussianity of the intermediate measures of the perturbed LMC process. In particular, we derive bounds on the growth of the intermediate variance proxies under different assumptions on the perturbations. Moreover, we propose an architecture similar to deep residual neural networks and derive expressivity results for approximating the sample to target distribution map.
    
[^16]: 对广泛的分布外检测的期望：期望之外的未知数据

    Expecting The Unexpected: Towards Broad Out-Of-Distribution Detection. (arXiv:2308.11480v1 [cs.LG])

    [http://arxiv.org/abs/2308.11480](http://arxiv.org/abs/2308.11480)

    这项研究对机器学习中分布外检测方法进行了评估，发现现有方法在检测未知类别方面表现出色，但在遇到其他类型的分布变化时性能不稳定。

    

    提高部署的机器学习系统的可靠性通常涉及开发方法来检测分布外（OOD）的输入。然而，现有研究常常狭窄地关注训练集中缺失的类别样本，忽略了其他类型的可能分布变化。这种限制降低了这些方法在现实场景中的适用性，因为系统会遇到各种各样的异常输入。在本研究中，我们将五种不同类型的分布变化进行分类，并对最近的OOD检测方法在每一种分布变化上进行了关键评估。我们以BROAD（Benchmarking Resilience Over Anomaly Diversity）的名义公开发布我们的基准。我们的研究发现这些方法在检测未知类别方面表现出色，但在遇到其他类型的分布变化时性能不一致。换句话说，它们只能可靠地检测到它们特别设计来预期的意外输入。

    Improving the reliability of deployed machine learning systems often involves developing methods to detect out-of-distribution (OOD) inputs. However, existing research often narrowly focuses on samples from classes that are absent from the training set, neglecting other types of plausible distribution shifts. This limitation reduces the applicability of these methods in real-world scenarios, where systems encounter a wide variety of anomalous inputs. In this study, we categorize five distinct types of distribution shifts and critically evaluate the performance of recent OOD detection methods on each of them. We publicly release our benchmark under the name BROAD (Benchmarking Resilience Over Anomaly Diversity). Our findings reveal that while these methods excel in detecting unknown classes, their performance is inconsistent when encountering other types of distribution shifts. In other words, they only reliably detect unexpected inputs that they have been specifically designed to expec
    
[^17]: 通过大型语言模型实现通用模糊测试

    Universal Fuzzing via Large Language Models. (arXiv:2308.04748v1 [cs.SE])

    [http://arxiv.org/abs/2308.04748](http://arxiv.org/abs/2308.04748)

    本文介绍了Fuzz4All，这是第一个能够针对许多不同的输入语言和这些语言的许多不同功能进行模糊测试的通用工具。

    

    模糊测试在发现各种软件系统中的漏洞和脆弱性方面取得了巨大成功。接受编程或形式语言作为输入的测试系统（SUTs），如编译器，运行时引擎，约束求解器和具有可访问API的软件库，尤其重要，因为它们是软件开发的基本构建块。然而，针对这些系统的现有模糊测试工具通常针对特定语言，因此无法轻易应用于其他语言甚至同一语言的其他版本。此外，现有模糊测试工具生成的输入通常局限于输入语言的特定功能，因此很难揭示与其他功能相关的漏洞或新功能。本文提出了Fuzz4All，这是第一个通用的模糊测试工具，它可以针对许多不同的输入语言和这些语言的许多不同功能进行测试。Fuzz4All的关键思想是利用大型语言模型（LLMs）作为输入生成器。

    Fuzzing has achieved tremendous success in discovering bugs and vulnerabilities in various software systems. Systems under test (SUTs) that take in programming or formal language as inputs, e.g., compilers, runtime engines, constraint solvers, and software libraries with accessible APIs, are especially important as they are fundamental building blocks of software development. However, existing fuzzers for such systems often target a specific language, and thus cannot be easily applied to other languages or even other versions of the same language. Moreover, the inputs generated by existing fuzzers are often limited to specific features of the input language, and thus can hardly reveal bugs related to other or new features. This paper presents Fuzz4All, the first fuzzer that is universal in the sense that it can target many different input languages and many different features of these languages. The key idea behind Fuzz4All is to leverage large language models (LLMs) as an input genera
    
[^18]: 优良格训练: 借助数论加速的物理信息神经网络

    Good Lattice Training: Physics-Informed Neural Networks Accelerated by Number Theory. (arXiv:2307.13869v1 [cs.LG])

    [http://arxiv.org/abs/2307.13869](http://arxiv.org/abs/2307.13869)

    本研究提出了一种新的物理信息神经网络训练方法，受数论方法启发，通过选择适当的插值点来提高解决偏微分方程的准确性和效率。

    

    物理信息神经网络(PINNs)提供了一种新颖高效的解决偏微分方程(PDEs)的方法。它们的成功在于物理信息损失函数，该函数训练神经网络以满足给定点上的PDE，并对解进行逼近。然而，PDE的解在本质上是无限维的，并且输出与解之间的距离是定义在整个域上的积分。因此，物理信息损失函数仅提供有限的逼近。在选择合适的插值点方面则变得至关重要，尽管这一方面经常被忽视。在本文中，我们提出了一种新的技术，称为优良格训练(GLT)，用于PINNs，受数值分析中的数论方法的启发。GLT提供了一组即使在少量点和多维空间中也非常有效的插值点。我们的实验表明，GLT只需要2-20倍的点数

    Physics-informed neural networks (PINNs) offer a novel and efficient approach to solving partial differential equations (PDEs). Their success lies in the physics-informed loss, which trains a neural network to satisfy a given PDE at specific points and to approximate the solution. However, the solutions to PDEs are inherently infinite-dimensional, and the distance between the output and the solution is defined by an integral over the domain. Therefore, the physics-informed loss only provides a finite approximation, and selecting appropriate collocation points becomes crucial to suppress the discretization errors, although this aspect has often been overlooked. In this paper, we propose a new technique called good lattice training (GLT) for PINNs, inspired by number theoretic methods for numerical analysis. GLT offers a set of collocation points that are effective even with a small number of points and for multi-dimensional spaces. Our experiments demonstrate that GLT requires 2--20 tim
    
[^19]: 低维流形上过参数化卷积残差网络的非参数分类

    Nonparametric Classification on Low Dimensional Manifolds using Overparameterized Convolutional Residual Networks. (arXiv:2307.01649v1 [cs.LG])

    [http://arxiv.org/abs/2307.01649](http://arxiv.org/abs/2307.01649)

    本文研究了卷积残差网络在非参数分类任务中的性能。研究表明，通过使用权重衰减的ConvResNeXts，可以隐含地实现对模块的稀疏性，从而使网络能够适应低维流形的平滑性和结构，并高效地学习函数。

    

    卷积残差神经网络(ConvResNets)虽然过参数化，但在实践中能够获得显著的预测性能，这不能被常规智慧很好地解释。为了弥合这一差距，我们从非参数分类的角度研究了使用权重衰减训练的ConvResNeXts（覆盖ConvResNets作为一种特殊情况）的性能。我们的分析允许ConvResNeXts中有无限多的构建模块，并显示权重衰减隐含地强制这些模块的稀疏性。具体而言，我们考虑在低维流形上的平滑目标函数，然后证明ConvResNeXts可以适应函数的平滑性和低维结构，并且能够高效地学习函数而不受维度诅咒的困扰。我们的发现部分证明了过参数化的ConvResNeXts相对于常规机器学习模型的优势。

    Convolutional residual neural networks (ConvResNets), though overparameterized, can achieve remarkable prediction performance in practice, which cannot be well explained by conventional wisdom. To bridge this gap, we study the performance of ConvResNeXts, which cover ConvResNets as a special case, trained with weight decay from the perspective of nonparametric classification. Our analysis allows for infinitely many building blocks in ConvResNeXts, and shows that weight decay implicitly enforces sparsity on these blocks. Specifically, we consider a smooth target function supported on a low-dimensional manifold, then prove that ConvResNeXts can adapt to the function smoothness and low-dimensional structures and efficiently learn the function without suffering from the curse of dimensionality. Our findings partially justify the advantage of overparameterized ConvResNeXts over conventional machine learning models.
    
[^20]: ChatGPT与人工撰写文本：可控文本摘要和句子风格转移的洞察

    ChatGPT vs Human-authored Text: Insights into Controllable Text Summarization and Sentence Style Transfer. (arXiv:2306.07799v1 [cs.CL])

    [http://arxiv.org/abs/2306.07799](http://arxiv.org/abs/2306.07799)

    本文旨在系统地检查ChatGPT在两个可控生成任务中的表现，即ChatGPT能否适应不同的目标受众和写作风格。研究发现，人类产生的文体变化比ChatGPT表现出的更大，而生成的文本在一些特征上与人类样本有所不同，有时会包含事实错误或幻觉。

    

    大规模语言模型（如ChatGPT）以其出色的能力从简短的自然语言提示生成连贯的文本引起了媒体的重视。本文旨在系统地检查ChatGPT在两个可控生成任务中的表现，即ChatGPT能否适应不同的目标受众（专家与一般人）和写作风格（正式与非正式）。此外，我们评估了生成文本的忠实度，并将模型的表现与人工撰写的文本进行了比较。我们的研究发现，人类产生的文体变化比ChatGPT表现出的更大，而生成的文本在诸如单词类型分布等几个特征上与人类样本有所不同。此外，我们发现当 ChatGPT 将文本适应特定风格时，有时会包含事实错误或幻觉。

    Large-scale language models, like ChatGPT, have garnered significant media attention and stunned the public with their remarkable capacity for generating coherent text from short natural language prompts. In this paper, we aim to conduct a systematic inspection of ChatGPT's performance in two controllable generation tasks, with respect to ChatGPT's ability to adapt its output to different target audiences (expert vs. layman) and writing styles (formal vs. informal). Additionally, we evaluate the faithfulness of the generated text, and compare the model's performance with human-authored texts. Our findings indicate that the stylistic variations produced by humans are considerably larger than those demonstrated by ChatGPT, and the generated texts diverge from human samples in several characteristics, such as the distribution of word types. Moreover, we observe that ChatGPT sometimes incorporates factual errors or hallucinations when adapting the text to suit a specific style.
    
[^21]: Gode -- 将生物化学知识图谱集成到分子图神经网络的预训练中

    Gode -- Integrating Biochemical Knowledge Graph into Pre-training Molecule Graph Neural Network. (arXiv:2306.01631v1 [cs.LG])

    [http://arxiv.org/abs/2306.01631](http://arxiv.org/abs/2306.01631)

    本研究提出了一种新的方法，在分子结构和生物医学知识图谱中集成多个领域信息，通过自我监督策略预先训练更广泛和更强大的表示，并在化学属性预测任务上展示出出色的性能。

    

    分子属性的准确预测对于促进创新治疗方法的发展和理解化学物质和生物系统之间复杂的相互作用至关重要。本研究提出了一种新的方法，将单个分子结构的图表示与生物医学知识图谱 (KG) 的多个领域信息进行集成。通过集成两个级别的信息，我们可以使用自我监督策略预先训练更广泛和更强大的表示，用于分子级和 KG 级预测任务。在性能评估方面，我们在 11 个具有挑战性的化学属性预测任务上微调我们预先训练的模型。我们的框架的结果表明，我们微调的模型优于现有的最先进的模型。

    The precise prediction of molecular properties holds paramount importance in facilitating the development of innovative treatments and comprehending the intricate interplay between chemicals and biological systems. In this study, we propose a novel approach that integrates graph representations of individual molecular structures with multi-domain information from biomedical knowledge graphs (KGs). Integrating information from both levels, we can pre-train a more extensive and robust representation for both molecule-level and KG-level prediction tasks with our novel self-supervision strategy. For performance evaluation, we fine-tune our pre-trained model on 11 challenging chemical property prediction tasks. Results from our framework demonstrate our fine-tuned models outperform existing state-of-the-art models.
    
[^22]: 结合话语结构分布的长文本自动摘要方法

    Incorporating Distributions of Discourse Structure for Long Document Abstractive Summarization. (arXiv:2305.16784v1 [cs.CL])

    [http://arxiv.org/abs/2305.16784](http://arxiv.org/abs/2305.16784)

    本文提出了一种名为'RSTformer'的摘要模型，该模型全面融合了话语关系类型和不确定性，并以修辞结构理论为基础，经过严格评估，表现明显优于现有的模型。

    

    对于文本摘要，话语结构在辨识文本核心内容方面起着关键作用。可惜的是，之前将修辞结构理论（RST）引入基于transformer的自动摘要模型的研究仅考虑了核心部分的注释，从而忽略了各种不同类型的话语关系。本文提出了一种名为'RSTformer'的新型摘要模型，该模型全面融合了话语关系类型和不确定性。我们的RST-attention机制是基于文档级修辞结构的Longformer框架的扩展。经过严格评估，本文提出的模型表现明显优于现有的模型，凸显出其在多个自动评估指标和人工评估上的卓越表现。

    For text summarization, the role of discourse structure is pivotal in discerning the core content of a text. Regrettably, prior studies on incorporating Rhetorical Structure Theory (RST) into transformer-based summarization models only consider the nuclearity annotation, thereby overlooking the variety of discourse relation types. This paper introduces the 'RSTformer', a novel summarization model that comprehensively incorporates both the types and uncertainty of rhetorical relations. Our RST-attention mechanism, rooted in document-level rhetorical structure, is an extension of the recently devised Longformer framework. Through rigorous evaluation, the model proposed herein exhibits significant superiority over state-of-the-art models, as evidenced by its notable performance on several automatic metrics and human evaluation.
    
[^23]: 基于分数的多模态自编码器

    Score-Based Multimodal Autoencoders. (arXiv:2305.15708v1 [cs.LG])

    [http://arxiv.org/abs/2305.15708](http://arxiv.org/abs/2305.15708)

    本文提出了一种基于分数模型的多模态自编码器，通过联合建模单模态VAE的潜在空间实现了对多模态数据的一致性整合，提高了多模态VAE的生成性能。

    

    多模态变分自编码器是一类能够在潜在空间中构建可处理后验的有前途的生成模型，特别适用于多种模态的数据。但随着模态数量的增加，每一个模态的生成质量都会降低。本文提出了一种新的方法，通过使用基于分数的模型联合建模单模态VAE的潜在空间，以增强多模态VAE的生成性能。分数模型的作用是通过学习潜在变量之间的相关性来实现多模态的一致性。因此，我们的模型结合了单模态VAE卓越的生成质量和对不同模态的一致性整合。

    Multimodal Variational Autoencoders (VAEs) represent a promising group of generative models that facilitate the construction of a tractable posterior within the latent space, given multiple modalities. Daunhawer et al. (2022) demonstrate that as the number of modalities increases, the generative quality of each modality declines. In this study, we explore an alternative approach to enhance the generative performance of multimodal VAEs by jointly modeling the latent space of unimodal VAEs using score-based models (SBMs). The role of the SBM is to enforce multimodal coherence by learning the correlation among the latent variables. Consequently, our model combines the superior generative quality of unimodal VAEs with coherent integration across different modalities.
    
[^24]: 非参数学习具有快速收敛率的随机微分方程

    Non-Parametric Learning of Stochastic Differential Equations with Fast Rates of Convergence. (arXiv:2305.15557v1 [cs.LG])

    [http://arxiv.org/abs/2305.15557](http://arxiv.org/abs/2305.15557)

    提出了一种新的非参数方法，用于识别随机微分方程中的漂移和扩散系数，该方法具有快速的收敛率，使得学习速率随着未知系数的光滑度增加而变得更加紧密。

    

    我们提出了一种新颖的非参数学习范式来识别非线性随机微分方程的漂移和扩散系数，该范式依赖于状态的离散时间观测。其关键思想是将相应的Fokker-Planck方程的基于RKHS的近似拟合到这些观测值，从而得出理论学习速率的估计值，这与以往的工作不同，当未知漂移和扩散系数的光滑度越高时，理论估计值越来越紧。由于我们的方法是基于内核的，因此离线预处理可以在原则上得到有效的数值实现。

    We propose a novel non-parametric learning paradigm for the identification of drift and diffusion coefficients of non-linear stochastic differential equations, which relies upon discrete-time observations of the state. The key idea essentially consists of fitting a RKHS-based approximation of the corresponding Fokker-Planck equation to such observations, yielding theoretical estimates of learning rates which, unlike previous works, become increasingly tighter when the regularity of the unknown drift and diffusion coefficients becomes higher. Our method being kernel-based, offline pre-processing may in principle be profitably leveraged to enable efficient numerical implementation.
    
[^25]: ERM++：用于域通用性的改进基准方法

    ERM++: An Improved Baseline for Domain Generalization. (arXiv:2304.01973v1 [cs.LG])

    [http://arxiv.org/abs/2304.01973](http://arxiv.org/abs/2304.01973)

    ERM++是一个用于域通用性的改进基准方法，通过更好地利用训练数据、模型参数选择和权重空间正则化等关键技术，在多个数据集上比标准ERM更有效，同时计算复杂度更低，表现也优于最先进方法。

    

    多源域通用性（DG）衡量分类器对于它没有接受过训练的新数据分布的泛化能力，并考虑了多个训练域。虽然已经提出了几种多源DG方法，但是它们在训练过程中使用域标签增加了额外的复杂性。最近的研究表明，经过良好调整的经验风险最小化（ERM）训练过程，即在源域上简单地最小化经验风险，可以胜过大多数现有的DG方法。我们确定了几个关键候选技术，以进一步提高ERM的性能，例如更好地利用训练数据、模型参数选择和权重空间正则化。我们将结果称为ERM ++，并展示它相对于标准ERM在五个多源数据集上将DG的性能显着提高了5％以上，并且尽管计算复杂度更低，但击败了最先进的方法。此外，我们还证明了ERM ++在WILDS-FMOW数据集上的有效性。

    Multi-source Domain Generalization (DG) measures a classifier's ability to generalize to new distributions of data it was not trained on, given several training domains. While several multi-source DG methods have been proposed, they incur additional complexity during training by using domain labels. Recent work has shown that a well-tuned Empirical Risk Minimization (ERM) training procedure, that is simply minimizing the empirical risk on the source domains, can outperform most existing DG methods. We identify several key candidate techniques to further improve ERM performance, such as better utilization of training data, model parameter selection, and weight-space regularization. We call the resulting method ERM++, and show it significantly improves the performance of DG on five multi-source datasets by over 5% compared to standard ERM, and beats state-of-the-art despite being less computationally expensive. Additionally, we demonstrate the efficacy of ERM++ on the WILDS-FMOW dataset,
    
[^26]: 让对话继续：使用ChatGPT仅以0.42美元的价格修复了337个漏洞中的162个

    Keep the Conversation Going: Fixing 162 out of 337 bugs for $0.42 each using ChatGPT. (arXiv:2304.00385v1 [cs.SE])

    [http://arxiv.org/abs/2304.00385](http://arxiv.org/abs/2304.00385)

    提出了一个名为ChatRepair的新型自动程序修复方法，与传统的“生成和验证”范式不同，它能够通过对话风格实现即时反馈，从而显着提高漏洞修复的效率和补丁的准确性。

    

    自动程序修复（APR）旨在自动生成有关有漏洞程序的修补程序。最近的APR工作集中于利用现代的大型语言模型（LLMs）直接生成APR的补丁。这种基于LLM的APR工具的工作方法是首先构建一个由原始有漏洞代码构建的输入提示，然后查询LLM生成补丁。虽然基于LLM的APR工具能够实现最先进的结果，但它仍然遵循“生成和验证”修复范式，即首先生成大量的补丁，然后逐个验证每个补丁。这不仅会导致许多重复的不正确的补丁，而且还会错过测试失败中的关键信息以及可行的补丁信息。为了解决这些局限性，我们提出了ChatRepair，这是第一种完全自动化的对话驱动的APR方法，它将补丁生成与即时反馈交替进行，以以对话风格执行APR。ChatRepair首先将相关的测试失败信息馈入LLM中，然后在补丁生成过程中使用交互式对话，以集中方式生成补丁。此外，ChatRepair还利用了测试结果中的关键信息，以生成更好的补丁。

    Automated Program Repair (APR) aims to automatically generate patches for buggy programs. Recent APR work has been focused on leveraging modern Large Language Models (LLMs) to directly generate patches for APR. Such LLM-based APR tools work by first constructing an input prompt built using the original buggy code and then queries the LLM to generate patches. While the LLM-based APR tools are able to achieve state-of-the-art results, it still follows the classic Generate and Validate repair paradigm of first generating lots of patches and then validating each one afterwards. This not only leads to many repeated patches that are incorrect but also miss the crucial information in test failures as well as in plausible patches.  To address these limitations, we propose ChatRepair, the first fully automated conversation-driven APR approach that interleaves patch generation with instant feedback to perform APR in a conversational style. ChatRepair first feeds the LLM with relevant test failur
    
[^27]: 通过大型语言模型重新审视整形手术假设

    Revisiting the Plastic Surgery Hypothesis via Large Language Models. (arXiv:2303.10494v1 [cs.SE])

    [http://arxiv.org/abs/2303.10494](http://arxiv.org/abs/2303.10494)

    本论文重新审视了自动程序修复中的整形手术假设，并提出使用大型语言模型进行APR的新方法，主要解决了传统APR工具在不同项目中无法产生多样化修补程序的问题。

    

    自动化程序修复（APR）旨在自动生成输入错误程序的补丁。传统APR工具通常专注于特定的错误类型和修复方式，通过使用模板、启发式和正式规范。然而，这些技术在错误类型和修补程序的多样化方面存在限制。因此，研究人员设计了各种基于学习的APR工具，最近的工作集中在直接使用大型语言模型（LLMs）进行APR。虽然基于LLM的APR工具能够在许多修复数据集上实现最先进的性能，但用于直接修复的LLMs并没有完全了解项目特定信息，如独特的变量或方法名称。整形手术假设是APR的一个著名的见解，它指出修复错误的代码部分通常已经存在于同一项目中。传统的APR工具主要通过设计手动或基于启发的方法来利用整形手术假设。

    Automated Program Repair (APR) aspires to automatically generate patches for an input buggy program. Traditional APR tools typically focus on specific bug types and fixes through the use of templates, heuristics, and formal specifications. However, these techniques are limited in terms of the bug types and patch variety they can produce. As such, researchers have designed various learning-based APR tools with recent work focused on directly using Large Language Models (LLMs) for APR. While LLM-based APR tools are able to achieve state-of-the-art performance on many repair datasets, the LLMs used for direct repair are not fully aware of the project-specific information such as unique variable or method names.  The plastic surgery hypothesis is a well-known insight for APR, which states that the code ingredients to fix the bug usually already exist within the same project. Traditional APR tools have largely leveraged the plastic surgery hypothesis by designing manual or heuristic-based a
    
[^28]: 基于次流形假设下扩散模型奇异性的数学分析

    Mathematical analysis of singularities in the diffusion model under the submanifold assumption. (arXiv:2301.07882v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.07882](http://arxiv.org/abs/2301.07882)

    本文提供了扩散模型中漂移项的数学分析。通过次流形假设，提出一种新的目标函数和相关的损失函数，可处理低维流形上的奇异数据分布，解决了均值漂移函数和得分函数渐近发散的问题。

    

    本文提供了机器学习中扩散模型的数学分析。以条件期望表示反向采样流程的漂移项，其中涉及数据分布和前向扩散。训练过程旨在通过最小化与条件期望相关的均方残差来寻找此类漂移函数。使用前向扩散的Green函数的小时间近似，我们证明了DDPM中的解析均值漂移函数和SGM中的得分函数在采样过程的最后阶段，对于像那些集中在低维流形上的奇异数据分布而言，渐近地发散，因此难以通过网络进行逼近。为了克服这个困难，我们推导出了一个新的目标函数和相关的损失函数，即使在处理奇异数据分布时仍然保持有界。我们通过几个数值实验来说明理论发现。

    This paper provide several mathematical analyses of the diffusion model in machine learning. The drift term of the backwards sampling process is represented as a conditional expectation involving the data distribution and the forward diffusion. The training process aims to find such a drift function by minimizing the mean-squared residue related to the conditional expectation. Using small-time approximations of the Green's function of the forward diffusion, we show that the analytical mean drift function in DDPM and the score function in SGM asymptotically blow up in the final stages of the sampling process for singular data distributions such as those concentrated on lower-dimensional manifolds, and is therefore difficult to approximate by a network. To overcome this difficulty, we derive a new target function and associated loss, which remains bounded even for singular data distributions. We illustrate the theoretical findings with several numerical examples.
    
[^29]: CADet:全自监督对比学习用于带有对比学习的全自主分布检测

    CADet: Fully Self-Supervised Out-Of-Distribution Detection With Contrastive Learning. (arXiv:2210.01742v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.01742](http://arxiv.org/abs/2210.01742)

    本文介绍了一种使用自监督对比学习进行带有对比学习的全自主分布检测的方法，能够同时检测未见过的类别和对抗性扰动样本。通过将自监督对比学习与最大均值差异（MMD）相结合，提出了CADet方法，该方法通过利用同一样本的对比变换之间的相似性进行OOD检测，并在对抗性扰动的识别方面比现有方法表现更好。

    

    处理带有分布之外（OOD）样本已成为机器学习系统在现实世界部署中的主要问题。本文探讨了使用自监督对比学习同时检测两种类型的OOD样本：未见过的类别和对抗性扰动。首先，我们将自监督对比学习与最大均值差异（MMD）双样本检验相结合。这种方法使我们能够鲁棒地测试两个独立样本集是否来自相同的分布，并且我们证明了相较于之前的工作，它在区分CIFAR-10和CIFAR-10.1时具有更高的置信度。在此成功的基础上，我们引入了CADet（对比异常检测），一种用于单样本OOD检测的新方法。CADet借鉴了MMD的思想，但利用了同一样本的对比变换之间的相似性。CADet在识别被对抗性扰动干扰的样本方面胜过现有的对抗检测方法。

    Handling out-of-distribution (OOD) samples has become a major stake in the real-world deployment of machine learning systems. This work explores the use of self-supervised contrastive learning to the simultaneous detection of two types of OOD samples: unseen classes and adversarial perturbations. First, we pair self-supervised contrastive learning with the maximum mean discrepancy (MMD) two-sample test. This approach enables us to robustly test whether two independent sets of samples originate from the same distribution, and we demonstrate its effectiveness by discriminating between CIFAR-10 and CIFAR-10.1 with higher confidence than previous work. Motivated by this success, we introduce CADet (Contrastive Anomaly Detection), a novel method for OOD detection of single samples. CADet draws inspiration from MMD, but leverages the similarity between contrastive transformations of a same sample. CADet outperforms existing adversarial detection methods in identifying adversarially perturbed
    

