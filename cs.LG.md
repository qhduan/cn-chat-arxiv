# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Understanding the Functional Roles of Modelling Components in Spiking Neural Networks](https://arxiv.org/abs/2403.16674) | 系统研究揭示了尖峰神经网络中滤泄、重置和循环等建模组件在平衡记忆保留、时间处理和动态建模方面的功能角色。 |
| [^2] | [CapsLorentzNet: Integrating Physics Inspired Features with Graph Convolution](https://arxiv.org/abs/2403.11826) | 引入胶囊层的架构修改，配合图神经网络，实现了将受物理启发的特征整合进分析，为高级对象标记提供了新思路。 |
| [^3] | [PALM: Pushing Adaptive Learning Rate Mechanisms for Continual Test-Time Adaptation](https://arxiv.org/abs/2403.10650) | 本研究通过对模型预测不确定性的量化来选择需要进一步适应的层，从而克服了持续测试时间自适应方法中由于伪标签引起的不准确性困扰。 |
| [^4] | [A Mathematical Framework for the Problem of Security for Cognition in Neurotechnology](https://arxiv.org/abs/2403.07945) | 本文提出了一个数学框架，名为认知安全，用于描述和分析神经技术对个体认知隐私和自治可能产生的影响，解决了相关问题描述和分析的障碍。 |
| [^5] | [Merino: Entropy-driven Design for Generative Language Models on IoT Devices](https://arxiv.org/abs/2403.07921) | 在本文中，我们提出了一个新颖的信息熵框架，用于设计手机友好的生成式语言模型，通过最大化transformer解码器的熵来在计算预算内，成功设计了MeRino模型，在移动设置下展现出与当前最先进的自回归transformer模型竞争性能的特点 |
| [^6] | [Physics-Transfer Learning for Material Strength Screening](https://arxiv.org/abs/2403.07526) | 提出了使用物理迁移框架来学习晶体塑性物理并从原子模拟中预测Peierls应力的方法。 |
| [^7] | [Grid Monitoring and Protection with Continuous Point-on-Wave Measurements and Generative AI](https://arxiv.org/abs/2403.06942) | 提出了基于连续时序测量和生成人工智能的电网监测和控制系统，通过数据压缩和故障检测，实现了对传统监控系统的进步。 |
| [^8] | [KnowAgent: Knowledge-Augmented Planning for LLM-Based Agents](https://arxiv.org/abs/2403.03101) | KnowAgent引入了显式动作知识，通过动作知识库和知识型自学习策略来增强LLM的规划能力，从而改善语言Agent的规划表现。 |
| [^9] | [Temporal Logic Specification-Conditioned Decision Transformer for Offline Safe Reinforcement Learning](https://arxiv.org/abs/2402.17217) | 提出了时间逻辑规范条件化决策转换器（SDT）框架，结合信号时间逻辑（STL）和决策转换器（DT）的能力，比现有方法在离线安全强化学习中学习出更好的安全高奖励策略。 |
| [^10] | [Studying the Impact of Stochasticity on the Evaluation of Deep Neural Networks for Forest-Fire Prediction](https://arxiv.org/abs/2402.15163) | 该论文首次系统研究了在随机假设下评估深度神经网络用于森林火灾预测的影响，发现评估对统计的忠实度是在高度随机场景下的可靠替代方法。 |
| [^11] | [Vehicle-group-based Crash Risk Formation and Propagation Analysis for Expressways](https://arxiv.org/abs/2402.12415) | 本研究基于车辆组作为分析对象，探讨了考虑车辆组和道路段特征的风险形成和传播机制，识别出影响碰撞风险的关键因素。 |
| [^12] | [Decentralized Sporadic Federated Learning: A Unified Methodology with Generalized Convergence Guarantees](https://arxiv.org/abs/2402.03448) | 本文提出了一种称为分散式间歇联邦学习（DSpodFL）的方法，它统一了分布式梯度下降（DGD）、随机闲话（RG）和分散式联邦平均（DFedAvg）等著名的分散优化方法。根据分析结果，DSpodFL能够在更一般的假设下达到几何收敛速率与最佳性差距的匹配。经过实验验证了该方法的有效性。 |
| [^13] | [Large Language Model Distilling Medication Recommendation Model](https://arxiv.org/abs/2402.02803) | 本研究旨在利用大型语言模型改进药物推荐方法，以解决传统模型在医学数据语义理解和新患者处方推荐方面的挑战。 |
| [^14] | [LiPO: Listwise Preference Optimization through Learning-to-Rank](https://arxiv.org/abs/2402.01878) | 本研究提出了一种名为LiPO的框架，用于将语言模型对齐问题定义为一个列表型排序问题。通过从排名列表中学习，该框架可以使策略更有效地学习到可行的响应。 |
| [^15] | [Compelling ReLU Network Initialization and Training to Leverage Exponential Scaling with Depth](https://arxiv.org/abs/2311.18022) | 该论文提出了一种新的训练策略，通过重新参数化网络权重，使得神经网络的指数数量的激活模式得以展现，从而得到远远超过随机初始化的结果。 |
| [^16] | [MAPPING: Debiasing Graph Neural Networks for Fair Node Classification with Limited Sensitive Information Leakage.](http://arxiv.org/abs/2401.12824) | 本文提出了一种使用有限敏感信息泄露的去偏置图神经网络进行公平节点分类的方法，该方法克服了非独立同分布图结构中的拓扑依赖问题，并构建了一个模型无关的去偏置框架，以防止下游误用并提高训练的可靠性。 |
| [^17] | [CreINNs: Credal-Set Interval Neural Networks for Uncertainty Estimation in Classification Tasks.](http://arxiv.org/abs/2401.05043) | CreINNs是一种用于分类任务的Credal-Set Interval Neural Networks，通过保留传统的区间神经网络结构，捕捉权重不确定性，并使用概率区间的数学框架预测可信区间。实验结果表明，CreINNs在不确定性估计方面优于变分贝叶斯神经网络和深度集成，并且具有较低的计算复杂度和模型大小。 |
| [^18] | [Invertible Solution of Neural Differential Equations for Analysis of Irregularly-Sampled Time Series.](http://arxiv.org/abs/2401.04979) | 我们提出了一种可逆解决非规则采样时间序列的神经微分方程分析方法，通过引入神经流的概念，我们的方法既保证了可逆性又降低了计算负担，并且在分类和插值任务中表现出了优异的性能。 |
| [^19] | [Push it to the Demonstrated Limit: Multimodal Visuotactile Imitation Learning with Force Matching.](http://arxiv.org/abs/2311.01248) | 本研究利用视觉触觉传感器和模仿学习相结合，通过配对优化触觉力量曲线和简化传感器应用，对接触丰富的操作任务进行了研究。 |
| [^20] | [Knowledge-Infused Prompting: Assessing and Advancing Clinical Text Data Generation with Large Language Models.](http://arxiv.org/abs/2311.00287) | 本文提出了一种通过大型语言模型进行临床文本生成的创新方法ClinGen，该方法将外部领域特定的知识和语言模型结合起来，提高了临床自然语言处理任务的性能，并丰富了样本的多样性。 |
| [^21] | [Submodel Partitioning in Hierarchical Federated Learning: Algorithm Design and Convergence Analysis.](http://arxiv.org/abs/2310.17890) | 本文提出了一种针对分层联邦学习的新方法：分层独立子模型训练（HIST）。该方法通过将全局模型划分为不相交的子模型，并在分层结构中分布，以降低边缘设备上的计算、通信和存储负担，同时节约资源。 |
| [^22] | [Field-level simulation-based inference with galaxy catalogs: the impact of systematic effects.](http://arxiv.org/abs/2310.15234) | 本文提出了一种使用星系目录进行场级别的基于模拟的推断方法，能够鲁棒地推断出宇宙学参数，解决了观测受到的系统效应的影响。 |
| [^23] | [Closed-Form Diffusion Models.](http://arxiv.org/abs/2310.12395) | 本研究提出了一种闭式扩散模型，通过显式平滑的闭式得分函数来生成新样本，无需训练，且在消费级CPU上能够实现与神经SGMs相竞争的采样速度。 |
| [^24] | [Effect of hyperparameters on variable selection in random forests.](http://arxiv.org/abs/2309.06943) | 这项研究评估了随机森林中超参数对变量选择的影响，在高维组学研究中，适当设置RF超参数对选择重要变量具有重要意义。 |
| [^25] | [The Challenges of Machine Learning for Trust and Safety: A Case Study on Misinformation Detection.](http://arxiv.org/abs/2308.12215) | 本研究通过虚假信息检测为例，检查了机器学习在信任与安全问题中学术与实践之间的脱节，并发现了文献中存在的严重不足之处，包括任务不符合在线服务面临的挑战、数据集和模型评估不真实、评估不独立于模型训练等。在此基础上，提出了评估机器学习应用于信任与安全问题的建议。 |
| [^26] | [PAC Neural Prediction Set Learning to Quantify the Uncertainty of Generative Language Models.](http://arxiv.org/abs/2307.09254) | 本文提出了一种使用神经网络来量化生成式语言模型不确定性的PAC神经预测集学习方法，通过在多种语言数据集和模型上的实验证明，相比于标准基准方法，我们的方法平均提高了63％的量化不确定性。 |
| [^27] | [Random-Set Convolutional Neural Network (RS-CNN) for Epistemic Deep Learning.](http://arxiv.org/abs/2307.05772) | 这篇论文提出了一种新的随机集合卷积神经网络（RS-CNN）用于分类，通过预测信念函数而不是概率矢量集合，以表示模型的置信度和认识不确定性。基于认识论深度学习方法，该模型能够估计由有限训练集引起的认识不确定性。 |
| [^28] | [SDC-HSDD-NDSA: Structure Detecting Cluster by Hierarchical Secondary Directed Differential with Normalized Density and Self-Adaption.](http://arxiv.org/abs/2307.00677) | 本文提出了一种基于密度的聚类算法，能够检测到高密度区域中的结构，具有先前算法所不具备的能力。 |
| [^29] | [Generalizable One-shot Rope Manipulation with Parameter-Aware Policy.](http://arxiv.org/abs/2306.09872) | GenORM通过增加可变形绳索参数和使用各种可变形绳索的模拟训练操作策略，实现利用一次真实演示处理不同可形变绳索，从而节省演示时间和提高适用性。 |
| [^30] | [Reevaluating Loss Functions: Enhancing Robustness to Label Noise in Deep Learning Models.](http://arxiv.org/abs/2306.05497) | 本文研究了使用噪声鲁棒损失函数增强深度学习模型对标签噪声的鲁棒性，并提出了一种无需超参数调整的新技术：包括输出偏置。 |
| [^31] | [Sources of Uncertainty in Machine Learning -- A Statisticians' View.](http://arxiv.org/abs/2305.16703) | 本文讨论了机器学习中不确定性的来源和类型，从统计学家的视角出发，分类别介绍了随机性和认知性不确定性的概念，证明了不确定性来源各异，不可简单归为两类。同时，与统计学概念进行类比，探讨不确定性在机器学习中的作用。 |
| [^32] | [DiFaReli : Diffusion Face Relighting.](http://arxiv.org/abs/2304.09479) | DiFaReli提出了一种新方法，通过利用条件扩散隐式模型解码解耦的光编码以及从现成的估算器推断出的与3D形状和面部身份相关的其他编码，能够处理单视角的野外环境下的人脸重照，无需光线舞台数据、多视图图像或光照基础事实，实验表明其效果优于现有方法。 |
| [^33] | [Almost Surely $\sqrt{T}$ Regret Bound for Adaptive LQR.](http://arxiv.org/abs/2301.05537) | 本文提出了一种自适应LQR控制器，在几乎必然的情况下具有 $\tilde{ \mathcal{O}}(\sqrt{T})$ 后悔上限证明，且具有断电机制保证安全并对性能影响很小。 |
| [^34] | [Collective Intelligence for 2D Push Manipulation with Mobile Robots.](http://arxiv.org/abs/2211.15136) | 本研究利用基于软体物理模拟器的规划器和基于注意力的神经网络，实现了移动机器人2D协作推动操作中的集体智能，比传统方法具有更好的性能并具备环境自适应能力。 |
| [^35] | [R2C-GAN: Restore-to-Classify GANs for Blind X-Ray Restoration and COVID-19 Classification.](http://arxiv.org/abs/2209.14770) | R2C-GAN是一种用于盲目X射线恢复和COVID-19分类的生成对抗网络，通过图像恢复提高X射线图像质量，并实现更高的诊断性能。 |

# 详细

[^1]: 理解尖峰神经网络中建模组件的功能角色

    Understanding the Functional Roles of Modelling Components in Spiking Neural Networks

    [https://arxiv.org/abs/2403.16674](https://arxiv.org/abs/2403.16674)

    系统研究揭示了尖峰神经网络中滤泄、重置和循环等建模组件在平衡记忆保留、时间处理和动态建模方面的功能角色。

    

    受大脑神经回路启发，尖峰神经网络（SNNs）在实现高计算效率和生物保真度方面很有前景。然而，优化SNNs相当困难，因为其建模组件的功能角色仍不清楚。通过设计和评估经典模型的几个变体，我们系统研究了滤泄、重置和循环这些关键建模组件在基于漏积分放电（LIF）的SNNs中的功能角色。通过大量实验，我们演示了这些组件如何影响SNNs的准确性、泛化性和稳健性。具体来说，我们发现滤泄在平衡记忆保留和稳健性方面起着至关重要的作用，重置机制对于不间断的时间处理和计算效率至关重要，而循环则丰富了模型复杂动态的能力，但会损害稳健性。

    arXiv:2403.16674v1 Announce Type: cross  Abstract: Spiking neural networks (SNNs), inspired by the neural circuits of the brain, are promising in achieving high computational efficiency with biological fidelity. Nevertheless, it is quite difficult to optimize SNNs because the functional roles of their modelling components remain unclear. By designing and evaluating several variants of the classic model, we systematically investigate the functional roles of key modelling components, leakage, reset, and recurrence, in leaky integrate-and-fire (LIF) based SNNs. Through extensive experiments, we demonstrate how these components influence the accuracy, generalization, and robustness of SNNs. Specifically, we find that the leakage plays a crucial role in balancing memory retention and robustness, the reset mechanism is essential for uninterrupted temporal processing and computational efficiency, and the recurrence enriches the capability to model complex dynamics at a cost of robustness degr
    
[^2]: CapsLorentzNet: 将受物理启发的特征与图卷积相整合

    CapsLorentzNet: Integrating Physics Inspired Features with Graph Convolution

    [https://arxiv.org/abs/2403.11826](https://arxiv.org/abs/2403.11826)

    引入胶囊层的架构修改，配合图神经网络，实现了将受物理启发的特征整合进分析，为高级对象标记提供了新思路。

    

    随着先进机器学习技术的出现，提升对象标记已经取得了显著进展。本文通过引入与各种图神经网络（GNN）架构兼容的新颖架构修改，进一步推动了这一领域的发展。我们的方法主张在标准GNN中替换传统解码块以集成胶囊层。这些胶囊是具有向量激活的神经元组。这些向量的方向表示被研究对象的重要属性，其大小表征被研究对象是否属于由胶囊代表的类别。此外，胶囊网络结合了一种通过重构机制进行正则化，促进了专家设计的高级特征无缝融入分析。我们已经研究了我们的架构与LorentzNet架构在夸克胶子方面的实用性。

    arXiv:2403.11826v1 Announce Type: cross  Abstract: With the advent of advanced machine learning techniques, boosted object tagging has witnessed significant progress. In this article, we take this field further by introducing novel architectural modifications compatible with a wide array of Graph Neural Network (GNN) architectures. Our approach advocates for integrating capsule layers, replacing the conventional decoding blocks in standard GNNs. These capsules are a group of neurons with vector activations. The orientation of these vectors represents important properties of the objects under study, with their magnitude characterizing whether the object under study belongs to the class represented by the capsule. Moreover, capsule networks incorporate a regularization by reconstruction mechanism, facilitating the seamless integration of expert-designed high-level features into the analysis. We have studied the usefulness of our architecture with the LorentzNet architecture for quark-glu
    
[^3]: PALM：推进用于持续测试时间自适应的自适应学习率机制

    PALM: Pushing Adaptive Learning Rate Mechanisms for Continual Test-Time Adaptation

    [https://arxiv.org/abs/2403.10650](https://arxiv.org/abs/2403.10650)

    本研究通过对模型预测不确定性的量化来选择需要进一步适应的层，从而克服了持续测试时间自适应方法中由于伪标签引起的不准确性困扰。

    

    实际环境中的视觉模型面临领域分布的快速转变，导致识别性能下降。持续测试时间自适应（CTTA）直接根据测试数据调整预训练的源判别模型以适应这些不断变化的领域。一种高度有效的CTTA方法涉及应用逐层自适应学习率，并选择性地调整预训练层。然而，它受到领域转移估计不准确和由伪标签引起的不准确性所困扰。在这项工作中，我们旨在通过识别层来克服这些限制，通过对模型预测不确定性的量化来选择层，而无须依赖伪标签。我们利用梯度的大小作为一个度量标准，通过反向传播softmax输出与均匀分布之间的KL散度来计算，以选择需要进一步适应的层。随后，仅属于这些层的参数将被进一步适应。

    arXiv:2403.10650v1 Announce Type: cross  Abstract: Real-world vision models in dynamic environments face rapid shifts in domain distributions, leading to decreased recognition performance. Continual test-time adaptation (CTTA) directly adjusts a pre-trained source discriminative model to these changing domains using test data. A highly effective CTTA method involves applying layer-wise adaptive learning rates, and selectively adapting pre-trained layers. However, it suffers from the poor estimation of domain shift and the inaccuracies arising from the pseudo-labels. In this work, we aim to overcome these limitations by identifying layers through the quantification of model prediction uncertainty without relying on pseudo-labels. We utilize the magnitude of gradients as a metric, calculated by backpropagating the KL divergence between the softmax output and a uniform distribution, to select layers for further adaptation. Subsequently, for the parameters exclusively belonging to these se
    
[^4]: 一个解决神经技术认知安全问题的数学框架

    A Mathematical Framework for the Problem of Security for Cognition in Neurotechnology

    [https://arxiv.org/abs/2403.07945](https://arxiv.org/abs/2403.07945)

    本文提出了一个数学框架，名为认知安全，用于描述和分析神经技术对个体认知隐私和自治可能产生的影响，解决了相关问题描述和分析的障碍。

    

    近年来神经技术的快速发展在神经技术和安全之间创造了一个新兴的关键交叉点。植入式设备、非侵入式监测和非侵入式治疗都带来了违反个体认知隐私和自治的前景。越来越多的科学家和医生呼吁解决这一问题 -- 我们称之为认知安全 -- 但应用工作受到限制。阻碍科学和工程努力解决认知安全问题的一个主要障碍是缺乏清晰描述和分析相关问题的手段。在本文中，我们开发了认知安全，这是一个数学框架，通过借鉴多个领域的方法和结果，实现这种描述和分析。我们展示了一些对认知安全有重要影响的统计特性，然后提出描述...

    arXiv:2403.07945v1 Announce Type: cross  Abstract: The rapid advancement in neurotechnology in recent years has created an emerging critical intersection between neurotechnology and security. Implantable devices, non-invasive monitoring, and non-invasive therapies all carry with them the prospect of violating the privacy and autonomy of individuals' cognition. A growing number of scientists and physicians have made calls to address this issue -- which we term Cognitive Security -- but applied efforts have been limited. A major barrier hampering scientific and engineering efforts to address Cognitive Security is the lack of a clear means of describing and analyzing relevant problems. In this paper we develop Cognitive Security, a mathematical framework which enables such description and analysis by drawing on methods and results from multiple fields. We demonstrate certain statistical properties which have significant implications for Cognitive Security, and then present descriptions of
    
[^5]: Merino：基于熵驱动的IoT设备上生成式语言模型设计

    Merino: Entropy-driven Design for Generative Language Models on IoT Devices

    [https://arxiv.org/abs/2403.07921](https://arxiv.org/abs/2403.07921)

    在本文中，我们提出了一个新颖的信息熵框架，用于设计手机友好的生成式语言模型，通过最大化transformer解码器的熵来在计算预算内，成功设计了MeRino模型，在移动设置下展现出与当前最先进的自回归transformer模型竞争性能的特点

    

    大规模生成式语言模型（LLMs）作为人工智能现代时代的革命性进步，然而，直接部署LLMs在资源受限的硬件上，比如物联网（IoT）设备，由于其高计算成本而变得困难。在本文中，我们提出了一个新颖的信息熵框架，用于设计手机友好的生成式语言模型。我们的主要设计范式是在给定的计算预算内最大化transformer解码器的熵。整个设计过程涉及解决一个数学规划（MP）问题，可以在几分钟内在CPU上完成，使其几乎是零成本的。我们评估了我们设计的模型MeRino，在九个NLP下游任务上展示了它们在移动设置下对抗当前最先进的自回归transformer模型的竞争性表现。值得注意的是，MeRino在移动设置下获得了类似或更好的零性能表现

    arXiv:2403.07921v1 Announce Type: cross  Abstract: Generative Large Language Models (LLMs) stand as a revolutionary advancement in the modern era of artificial intelligence (AI). However, directly deploying LLMs in resource-constrained hardware, such as Internet-of-Things (IoT) devices, is difficult due to their high computational cost. In this paper, we propose a novel information-entropy framework for designing mobile-friendly generative language models. Our key design paradigm is to maximize the entropy of transformer decoders within the given computational budgets. The whole design procedure involves solving a mathematical programming (MP) problem, which can be done on the CPU within minutes, making it nearly zero-cost. We evaluate our designed models, termed MeRino, across nine NLP downstream tasks, showing their competitive performance against the state-of-the-art autoregressive transformer models under the mobile setting. Notably, MeRino achieves similar or better zero performan
    
[^6]: 物理学迁移学习用于材料强度筛选

    Physics-Transfer Learning for Material Strength Screening

    [https://arxiv.org/abs/2403.07526](https://arxiv.org/abs/2403.07526)

    提出了使用物理迁移框架来学习晶体塑性物理并从原子模拟中预测Peierls应力的方法。

    

    材料强度，像许多自然科学中的问题一样，涵盖多个长度和时间尺度，并且解决方案必须在准确性和性能之间取得平衡。Peierls应力是晶体塑性中的一个中心概念，通过位错对塑性流动的阻力来衡量强度。确定Peierls应力涉及到弹性晶格响应和晶体滑移能量景观的多尺度性质。通过第一性原理计算通过Peierls应力的材料强度筛选对于位错的非局部特性而言在计算上很难，并且没有包含在最先进的计算材料数据库中。在这项工作中，我们提出了一个物理迁移框架，从经验性原子模拟中学习晶体塑性的物理规律，然后预测Peierls应力从化学准确的基于密度泛函理论的计算中。

    arXiv:2403.07526v1 Announce Type: cross  Abstract: The strength of materials, like many problems in the natural sciences, spans multiple length and time scales, and the solution has to balance accuracy and performance. Peierls stress is one of the central concepts in crystal plasticity that measures the strength through the resistance of a dislocation to plastic flow. The determination of Peierls stress involves a multiscale nature depending on both elastic lattice responses and the energy landscape of crystal slips. Material screening by strength via the Peierls stress from first-principles calculations is computationally intractable for the nonlocal characteristics of dislocations, and not included in the state-of-the-art computational material databases. In this work, we propose a physics-transfer framework to learn the physics of crystal plasticity from empirical atomistic simulations and then predict the Peierls stress from chemically accurate density functional theory-based calcu
    
[^7]: 使用连续时序测量和生成人工智能进行电网监测和保护

    Grid Monitoring and Protection with Continuous Point-on-Wave Measurements and Generative AI

    [https://arxiv.org/abs/2403.06942](https://arxiv.org/abs/2403.06942)

    提出了基于连续时序测量和生成人工智能的电网监测和控制系统，通过数据压缩和故障检测，实现了对传统监控系统的进步。

    

    本文提出了一个下一代电网监测和控制系统的案例，利用生成人工智能（AI）、机器学习和统计推断方面的最新进展。我们提出了一种基于连续时序测量和AI支持的数据压缩和故障检测的监测和控制框架，超越了先前基于SCADA和同步相量技术构建的广域监测系统的发展。

    arXiv:2403.06942v1 Announce Type: cross  Abstract: Purpose This article presents a case for a next-generation grid monitoring and control system, leveraging recent advances in generative artificial intelligence (AI), machine learning, and statistical inference. Advancing beyond earlier generations of wide-area monitoring systems built upon supervisory control and data acquisition (SCADA) and synchrophasor technologies, we argue for a monitoring and control framework based on the streaming of continuous point-on-wave (CPOW) measurements with AI-powered data compression and fault detection.   Methods and Results: The architecture of the proposed design originates from the Wiener-Kallianpur innovation representation of a random process that transforms causally a stationary random process into an innovation sequence with independent and identically distributed random variables. This work presents a generative AI approach that (i) learns an innovation autoencoder that extracts innovation se
    
[^8]: KnowAgent: 知识增强规划用于基于LLM的Agent

    KnowAgent: Knowledge-Augmented Planning for LLM-Based Agents

    [https://arxiv.org/abs/2403.03101](https://arxiv.org/abs/2403.03101)

    KnowAgent引入了显式动作知识，通过动作知识库和知识型自学习策略来增强LLM的规划能力，从而改善语言Agent的规划表现。

    

    大型语言模型(LLMs)在复杂推理任务中表现出巨大潜力，但在处理更复杂的挑战时仍有所不足，特别是与环境互动通过生成可执行动作时。这种不足主要来自于语言Agent中缺乏内置动作知识，导致在任务求解过程中无法有效引导规划轨迹，从而导致规划幻觉。为了解决这个问题，我们引入了KnowAgent，一种旨在通过整合显式动作知识来增强LLM规划能力的新方法。具体而言，KnowAgent采用了一个动作知识库和一个知识型自学习策略来限制规划过程中的行动路径，实现更合理的轨迹合成，进而提高语言Agent的计划性能。基于HotpotQA和ALFWorld的实验结果基于不同的主干模型。

    arXiv:2403.03101v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have demonstrated great potential in complex reasoning tasks, yet they fall short when tackling more sophisticated challenges, especially when interacting with environments through generating executable actions. This inadequacy primarily stems from the lack of built-in action knowledge in language agents, which fails to effectively guide the planning trajectories during task solving and results in planning hallucination. To address this issue, we introduce KnowAgent, a novel approach designed to enhance the planning capabilities of LLMs by incorporating explicit action knowledge. Specifically, KnowAgent employs an action knowledge base and a knowledgeable self-learning strategy to constrain the action path during planning, enabling more reasonable trajectory synthesis, and thereby enhancing the planning performance of language agents. Experimental results on HotpotQA and ALFWorld based on various backbone m
    
[^9]: 离线安全强化学习中的时间逻辑规范条件化决策转换器

    Temporal Logic Specification-Conditioned Decision Transformer for Offline Safe Reinforcement Learning

    [https://arxiv.org/abs/2402.17217](https://arxiv.org/abs/2402.17217)

    提出了时间逻辑规范条件化决策转换器（SDT）框架，结合信号时间逻辑（STL）和决策转换器（DT）的能力，比现有方法在离线安全强化学习中学习出更好的安全高奖励策略。

    

    离线安全强化学习旨在从固定数据集训练一个满足约束的策略。本文提出了一种新颖的框架，即时间逻辑规范条件化决策转换器（SDT），它利用信号时间逻辑（STL）的表达能力来指定代理应该遵循的复杂时间规则，以及决策转换器（DT）的顺序建模能力。对DSRL基准测试的实证评估表明，与现有方法相比，SDT在学习安全高奖励策略方面具有更好的能力。

    arXiv:2402.17217v1 Announce Type: cross  Abstract: Offline safe reinforcement learning (RL) aims to train a constraint satisfaction policy from a fixed dataset. Current state-of-the-art approaches are based on supervised learning with a conditioned policy. However, these approaches fall short in real-world applications that involve complex tasks with rich temporal and logical structures. In this paper, we propose temporal logic Specification-conditioned Decision Transformer (SDT), a novel framework that harnesses the expressive power of signal temporal logic (STL) to specify complex temporal rules that an agent should follow and the sequential modeling capability of Decision Transformer (DT). Empirical evaluations on the DSRL benchmarks demonstrate the better capacity of SDT in learning safe and high-reward policies compared with existing approaches. In addition, SDT shows good alignment with respect to different desired degrees of satisfaction of the STL specification that it is condi
    
[^10]: 研究随机性对深度神经网络在森林火灾预测中评估的影响

    Studying the Impact of Stochasticity on the Evaluation of Deep Neural Networks for Forest-Fire Prediction

    [https://arxiv.org/abs/2402.15163](https://arxiv.org/abs/2402.15163)

    该论文首次系统研究了在随机假设下评估深度神经网络用于森林火灾预测的影响，发现评估对统计的忠实度是在高度随机场景下的可靠替代方法。

    

    本文首次系统研究了在随机假设下评估深度神经网络（DNNs）用于离散动力系统，重点关注野火预测。我们开发了一个框架来研究随机性对两类评估指标的影响：基于分类的指标，评估对观察地面真相（GT）的忠实度，以及适当的得分规则，测试对统计的忠实度。我们的研究结果表明，在高度随机的情况下，评估对统计的忠实度是一个可靠的替代方案。我们将我们的分析扩展到现实世界的森林火灾数据，突显了传统森林火灾预测评估方法中的局限性，并建议可解释的适用于随机性的替代方法。

    arXiv:2402.15163v1 Announce Type: cross  Abstract: This paper presents the first systematic study of the evaluation of Deep Neural Networks (DNNs) for discrete dynamical systems under stochastic assumptions, with a focus on wildfire prediction. We develop a framework to study the impact of stochasticity on two classes of evaluation metrics: classification-based metrics, which assess fidelity to observed ground truth (GT), and proper scoring rules, which test fidelity-to-statistic. Our findings reveal that evaluating for fidelity-to-statistic is a reliable alternative in highly stochastic scenarios. We extend our analysis to real-world wildfire data, highlighting limitations in traditional wildfire prediction evaluation methods, and suggest interpretable stochasticity-compatible alternatives.
    
[^11]: 基于车辆组的高速公路碰撞风险形成和传播分析

    Vehicle-group-based Crash Risk Formation and Propagation Analysis for Expressways

    [https://arxiv.org/abs/2402.12415](https://arxiv.org/abs/2402.12415)

    本研究基于车辆组作为分析对象，探讨了考虑车辆组和道路段特征的风险形成和传播机制，识别出影响碰撞风险的关键因素。

    

    先前的研究主要将路段上的碰撞数量或可能性与交通参数或路段的几何特征联系起来，通常忽略了车辆连续运动和与附近车辆的互动对其影响。通信技术的进步赋予了从周围车辆收集驾驶信息的能力，使得研究基于车辆组的碰撞风险成为可能。基于高分辨率车辆轨迹数据，本研究以车辆组作为分析对象，探讨了考虑车辆组和道路段特征的风险形成和传播机制。确定了几个影响碰撞风险的关键因素，包括过去的高风险车辆组状态、复杂的车辆行为、大型车辆的高百分比、车辆组内频繁变道以及特定的道路几何形状。

    arXiv:2402.12415v1 Announce Type: new  Abstract: Previous studies in predicting crash risk primarily associated the number or likelihood of crashes on a road segment with traffic parameters or geometric characteristics of the segment, usually neglecting the impact of vehicles' continuous movement and interactions with nearby vehicles. Advancements in communication technologies have empowered driving information collected from surrounding vehicles, enabling the study of group-based crash risks. Based on high-resolution vehicle trajectory data, this research focused on vehicle groups as the subject of analysis and explored risk formation and propagation mechanisms considering features of vehicle groups and road segments. Several key factors contributing to crash risks were identified, including past high-risk vehicle-group states, complex vehicle behaviors, high percentage of large vehicles, frequent lane changes within a vehicle group, and specific road geometries. A multinomial logisti
    
[^12]: 分散式间歇联邦学习：具有广义收敛保证的统一方法

    Decentralized Sporadic Federated Learning: A Unified Methodology with Generalized Convergence Guarantees

    [https://arxiv.org/abs/2402.03448](https://arxiv.org/abs/2402.03448)

    本文提出了一种称为分散式间歇联邦学习（DSpodFL）的方法，它统一了分布式梯度下降（DGD）、随机闲话（RG）和分散式联邦平均（DFedAvg）等著名的分散优化方法。根据分析结果，DSpodFL能够在更一般的假设下达到几何收敛速率与最佳性差距的匹配。经过实验验证了该方法的有效性。

    

    分散式联邦学习（DFL）近来受到了重要的研究关注，涵盖了模型更新和模型聚合这两个关键联邦学习过程都由客户端进行的设置。在本文中，我们提出了分散式间歇联邦学习（DSpodFL），这是一种DFL方法，它在这两个过程中广义化了间歇性的概念，建模了在实际DFL设置中出现的不同形式的异质性的影响。DSpodFL将许多着名的分散优化方法，如分布式梯度下降（DGD），随机闲话（RG）和分散式联邦平均（DFedAvg），统一到一个建模框架下。我们对DSpodFL的收敛行为进行了分析，显示出可以在更一般的假设下，将几何收敛速率与有限的最佳性差距相匹配。通过实验证明：

    Decentralized Federated Learning (DFL) has received significant recent research attention, capturing settings where both model updates and model aggregations -- the two key FL processes -- are conducted by the clients. In this work, we propose Decentralized Sporadic Federated Learning ($\texttt{DSpodFL}$), a DFL methodology which generalizes the notion of sporadicity in both of these processes, modeling the impact of different forms of heterogeneity that manifest in realistic DFL settings. $\texttt{DSpodFL}$ unifies many of the prominent decentralized optimization methods, e.g., distributed gradient descent (DGD), randomized gossip (RG), and decentralized federated averaging (DFedAvg), under a single modeling framework. We analytically characterize the convergence behavior of $\texttt{DSpodFL}$, showing, among other insights, that we can match a geometric convergence rate to a finite optimality gap under more general assumptions than in existing works. Through experiments, we demonstra
    
[^13]: 大型语言模型蒸馏药物推荐模型

    Large Language Model Distilling Medication Recommendation Model

    [https://arxiv.org/abs/2402.02803](https://arxiv.org/abs/2402.02803)

    本研究旨在利用大型语言模型改进药物推荐方法，以解决传统模型在医学数据语义理解和新患者处方推荐方面的挑战。

    

    药物推荐是智能医疗系统中的重要方面，它根据患者特定的健康需求来推荐最合适的药物。然而，目前使用的许多复杂模型往往忽视医学数据的细微语义，而只是过度依赖标识。此外，这些模型在处理首次访问医院的患者的情况时面临重大挑战，因为它们缺乏之前的处方历史可以参考。为了解决这些问题，我们利用大型语言模型（LLMs）强大的语义理解和输入不可知的特性。我们的研究旨在利用LLMs改进现有的药物推荐方法。在本文中，我们介绍了一种新颖的方法，称为大型语言模型蒸馏药物推荐（LEADER）。我们首先创建合适的提示模板，使LLMs能够有效地推荐药物。

    The recommendation of medication is a vital aspect of intelligent healthcare systems, as it involves prescribing the most suitable drugs based on a patient's specific health needs. Unfortunately, many sophisticated models currently in use tend to overlook the nuanced semantics of medical data, while only relying heavily on identities. Furthermore, these models face significant challenges in handling cases involving patients who are visiting the hospital for the first time, as they lack prior prescription histories to draw upon. To tackle these issues, we harness the powerful semantic comprehension and input-agnostic characteristics of Large Language Models (LLMs). Our research aims to transform existing medication recommendation methodologies using LLMs. In this paper, we introduce a novel approach called Large Language Model Distilling Medication Recommendation (LEADER). We begin by creating appropriate prompt templates that enable LLMs to suggest medications effectively. However, the
    
[^14]: LiPO: 通过学习排序进行列表型偏好优化

    LiPO: Listwise Preference Optimization through Learning-to-Rank

    [https://arxiv.org/abs/2402.01878](https://arxiv.org/abs/2402.01878)

    本研究提出了一种名为LiPO的框架，用于将语言模型对齐问题定义为一个列表型排序问题。通过从排名列表中学习，该框架可以使策略更有效地学习到可行的响应。

    

    将语言模型与人工反馈进行对齐是控制其在实际应用中行为的关键。最近的一些策略优化方法，如DPO和SLiC，成为传统的来自人类反馈的增强学习方法的有希望的替代方案。实际上，人工反馈通常以对多个响应进行排序的格式提供，以摊销阅读提示的成本。多个响应也可以通过奖励模型或AI反馈进行排序。缺少关于直接适应响应列表的研究。在这项工作中，我们将语言模型对齐问题定义为一个列表型排序问题，并描述了列表型偏好优化（LiPO）框架，在给定提示的情况下，策略可以从一个排名列表中更有效地学习可行响应。这种观点与学习排序（LTR）形成明确的联系，其中大多数现有的偏好优化工作可以映射到现有的排名目标，特别是

    Aligning language models (LMs) with curated human feedback is critical to control their behaviors in real-world applications. Several recent policy optimization methods, such as DPO and SLiC, serve as promising alternatives to the traditional Reinforcement Learning from Human Feedback (RLHF) approach. In practice, human feedback often comes in a format of a ranked list over multiple responses to amortize the cost of reading prompt. Multiple responses can also be ranked by reward models or AI feedback. There lacks such a study on directly fitting upon a list of responses. In this work, we formulate the LM alignment as a listwise ranking problem and describe the Listwise Preference Optimization (LiPO) framework, where the policy can potentially learn more effectively from a ranked list of plausible responses given the prompt. This view draws an explicit connection to Learning-to-Rank (LTR), where most existing preference optimization work can be mapped to existing ranking objectives, esp
    
[^15]: 利用指数尺度的深度强化ReLU网络初始化和训练

    Compelling ReLU Network Initialization and Training to Leverage Exponential Scaling with Depth

    [https://arxiv.org/abs/2311.18022](https://arxiv.org/abs/2311.18022)

    该论文提出了一种新的训练策略，通过重新参数化网络权重，使得神经网络的指数数量的激活模式得以展现，从而得到远远超过随机初始化的结果。

    

    ReLU激活的神经网络可以看作是分段线性函数的组合。对于这样的网络，随着深度的增加，表达在输入域上的不同线性区域的数量有可能以指数级增长，但当初始参数选择随机时，不太可能出现这种情况。这种不良的尺度能够导致即使是简单函数也需要使用过大的模型来近似。为了解决这个问题，我们引入了一种新的训练策略：首先以一种方式重新参数化网络权重，使得指数数量的激活模式得以展现。在这些新参数上进行训练可以得到一个初始解，稍后通过更新底层模型权重来改进。这种方法使我们能够产生比随机初始化对应的函数逼近好几个数量级的结果。

    A neural network with ReLU activations may be viewed as a composition of piecewise linear functions. For such networks, the number of distinct linear regions expressed over the input domain has the potential to scale exponentially with depth, but it is not expected to do so when the initial parameters are chosen randomly. This poor scaling can necessitate the use of overly large models to approximate even simple functions. To address this issue, we introduce a novel training strategy: we first reparameterize the network weights in a manner that forces an exponential number of activation patterns to manifest. Training first on these new parameters provides an initial solution that can later be refined by updating the underlying model weights. This approach allows us to produce function approximations that are several orders of magnitude better than their randomly initialized counterparts.
    
[^16]: MAPPING: 使用有限敏感信息泄露的去偏置图神经网络进行公平节点分类

    MAPPING: Debiasing Graph Neural Networks for Fair Node Classification with Limited Sensitive Information Leakage. (arXiv:2401.12824v1 [cs.LG])

    [http://arxiv.org/abs/2401.12824](http://arxiv.org/abs/2401.12824)

    本文提出了一种使用有限敏感信息泄露的去偏置图神经网络进行公平节点分类的方法，该方法克服了非独立同分布图结构中的拓扑依赖问题，并构建了一个模型无关的去偏置框架，以防止下游误用并提高训练的可靠性。

    

    尽管在各种基于网络的应用中取得了显著的成功，但图神经网络（GNN）继承并进一步加剧了历史上的偏见和社会刻板印象，这严重阻碍了它们在在线临床诊断、金融信贷等高风险领域的部署。然而，当前的公平性研究主要集中在独立同分布数据上，并不能简单地复制到具有拓扑依赖的非独立同分布图结构中。现有的公平图学习通常偏好于使用成对约束来实现公平性，但无法克服维度限制并将其推广到多个敏感属性；此外，大多数研究集中在处理技术上来强制并调整公平性，在预处理阶段构建一个模型无关的去偏置GNN框架，以防止下游误用并提高训练的可靠性在先前的工作中，GNN往往倾向于增强公平性或增加预测性能，因此在二者之间进行全面权衡仍然是一个挑战。

    Despite remarkable success in diverse web-based applications, Graph Neural Networks(GNNs) inherit and further exacerbate historical discrimination and social stereotypes, which critically hinder their deployments in high-stake domains such as online clinical diagnosis, financial crediting, etc. However, current fairness research that primarily craft on i.i.d data, cannot be trivially replicated to non-i.i.d. graph structures with topological dependence among samples. Existing fair graph learning typically favors pairwise constraints to achieve fairness but fails to cast off dimensional limitations and generalize them into multiple sensitive attributes; besides, most studies focus on in-processing techniques to enforce and calibrate fairness, constructing a model-agnostic debiasing GNN framework at the pre-processing stage to prevent downstream misuses and improve training reliability is still largely under-explored. Furthermore, previous work on GNNs tend to enhance either fairness or 
    
[^17]: CreINNs: Credal-Set Interval Neural Networks用于分类任务中的不确定性估计

    CreINNs: Credal-Set Interval Neural Networks for Uncertainty Estimation in Classification Tasks. (arXiv:2401.05043v1 [cs.LG])

    [http://arxiv.org/abs/2401.05043](http://arxiv.org/abs/2401.05043)

    CreINNs是一种用于分类任务的Credal-Set Interval Neural Networks，通过保留传统的区间神经网络结构，捕捉权重不确定性，并使用概率区间的数学框架预测可信区间。实验结果表明，CreINNs在不确定性估计方面优于变分贝叶斯神经网络和深度集成，并且具有较低的计算复杂度和模型大小。

    

    不确定性估计对于提高神经网络的可靠性越来越有吸引力。在这项工作中，我们提出了新颖的Credal-Set Interval Neural Networks（CreINNs），用于分类任务。CreINNs保留了传统的区间神经网络结构，通过确定性区间捕捉权重的不确定性，同时使用概率区间的数学框架预测可信区间。在一个超出分发检测基准（CIFAR10 vs SVHN）上的实验验证中，CreINNs相比于变分贝叶斯神经网络（BNNs）和深度集成（DEs），在认知不确定性估计方面表现出色。此外，与变分BNNs相比，CreINNs的计算复杂度显著降低，并且比DEs具有较小的模型大小。

    Uncertainty estimation is increasingly attractive for improving the reliability of neural networks. In this work, we present novel credal-set interval neural networks (CreINNs) designed for classification tasks. CreINNs preserve the traditional interval neural network structure, capturing weight uncertainty through deterministic intervals, while forecasting credal sets using the mathematical framework of probability intervals. Experimental validations on an out-of-distribution detection benchmark (CIFAR10 vs SVHN) showcase that CreINNs outperform epistemic uncertainty estimation when compared to variational Bayesian neural networks (BNNs) and deep ensembles (DEs). Furthermore, CreINNs exhibit a notable reduction in computational complexity compared to variational BNNs and demonstrate smaller model sizes than DEs.
    
[^18]: 可逆解决非规则采样时间序列的神经微分方程分析方法

    Invertible Solution of Neural Differential Equations for Analysis of Irregularly-Sampled Time Series. (arXiv:2401.04979v1 [cs.LG])

    [http://arxiv.org/abs/2401.04979](http://arxiv.org/abs/2401.04979)

    我们提出了一种可逆解决非规则采样时间序列的神经微分方程分析方法，通过引入神经流的概念，我们的方法既保证了可逆性又降低了计算负担，并且在分类和插值任务中表现出了优异的性能。

    

    为了处理非规则和不完整的时间序列数据的复杂性，我们提出了一种基于神经微分方程（NDE）的可逆解决方案。虽然基于NDE的方法是分析非规则采样时间序列的一种强大方法，但它们通常不能保证在其标准形式下进行可逆变换。我们的方法建议使用具有神经流的神经控制微分方程（Neural CDEs）的变种，该方法在保持较低的计算负担的同时确保了可逆性。此外，它还可以训练双重潜在空间，增强了对动态时间动力学的建模能力。我们的研究提出了一个先进的框架，在分类和插值任务中都表现出色。我们方法的核心是一个经过精心设计的增强型双重潜在状态架构，用于在各种时间序列任务中提高精度。实证分析表明，我们的方法明显优于现有模型。

    To handle the complexities of irregular and incomplete time series data, we propose an invertible solution of Neural Differential Equations (NDE)-based method. While NDE-based methods are a powerful method for analyzing irregularly-sampled time series, they typically do not guarantee reversible transformations in their standard form. Our method suggests the variation of Neural Controlled Differential Equations (Neural CDEs) with Neural Flow, which ensures invertibility while maintaining a lower computational burden. Additionally, it enables the training of a dual latent space, enhancing the modeling of dynamic temporal dynamics. Our research presents an advanced framework that excels in both classification and interpolation tasks. At the core of our approach is an enhanced dual latent states architecture, carefully designed for high precision across various time series tasks. Empirical analysis demonstrates that our method significantly outperforms existing models. This work significan
    
[^19]: 将其推向展示极限：多模态视觉触觉模仿学习与力匹配

    Push it to the Demonstrated Limit: Multimodal Visuotactile Imitation Learning with Force Matching. (arXiv:2311.01248v1 [cs.RO])

    [http://arxiv.org/abs/2311.01248](http://arxiv.org/abs/2311.01248)

    本研究利用视觉触觉传感器和模仿学习相结合，通过配对优化触觉力量曲线和简化传感器应用，对接触丰富的操作任务进行了研究。

    

    光学触觉传感器已经成为机器人操作过程中获取密集接触信息的有效手段。最近引入的“透视你的皮肤”（STS）型传感器具有视觉和触觉模式，通过利用半透明表面和可控照明实现。本文研究了视觉触觉传感与模仿学习在富有接触的操作任务中的好处。首先，我们使用触觉力测量和一种新的算法，在运动示范中产生更好匹配人体示范者的力曲线。其次，我们添加了视觉/触觉STS模式切换作为控制策略输出，简化传感器的应用。最后，我们研究了多种观察配置，比较和对比了视觉/触觉数据（包括模式切换和不切换）与手腕挂载的眼在手摄像机的视觉数据的价值。我们在一个广泛的实验系列上进行实验。

    Optical tactile sensors have emerged as an effective means to acquire dense contact information during robotic manipulation. A recently-introduced `see-through-your-skin' (STS) variant of this type of sensor has both visual and tactile modes, enabled by leveraging a semi-transparent surface and controllable lighting. In this work, we investigate the benefits of pairing visuotactile sensing with imitation learning for contact-rich manipulation tasks. First, we use tactile force measurements and a novel algorithm during kinesthetic teaching to yield a force profile that better matches that of the human demonstrator. Second, we add visual/tactile STS mode switching as a control policy output, simplifying the application of the sensor. Finally, we study multiple observation configurations to compare and contrast the value of visual/tactile data (both with and without mode switching) with visual data from a wrist-mounted eye-in-hand camera. We perform an extensive series of experiments on a
    
[^20]: 通过大型语言模型的知识注入：评估和推进临床文本数据生成

    Knowledge-Infused Prompting: Assessing and Advancing Clinical Text Data Generation with Large Language Models. (arXiv:2311.00287v1 [cs.CL])

    [http://arxiv.org/abs/2311.00287](http://arxiv.org/abs/2311.00287)

    本文提出了一种通过大型语言模型进行临床文本生成的创新方法ClinGen，该方法将外部领域特定的知识和语言模型结合起来，提高了临床自然语言处理任务的性能，并丰富了样本的多样性。

    

    临床自然语言处理需要能够应对领域特定挑战的方法，例如复杂的医学术语和临床背景。最近，大型语言模型（LLMs）在这个领域显示出了潜力。然而，它们的直接部署可能导致隐私问题，并受到资源限制。为了解决这个挑战，我们深入研究了使用LLMs进行临床NLP任务的合成临床文本生成。我们提出了一种创新的、资源高效的方法ClinGen，它将知识注入到这个过程中。我们的模型涉及临床知识提取和基于上下文的LLM提示。临床主题和写作风格都来自外部领域特定的知识图谱和LLMs，以引导数据生成。我们在7个临床NLP任务和16个数据集上进行了广泛的实证研究，结果显示ClinGen在各种任务中始终提高了性能，有效地使真实数据集的分布对齐，并显著丰富了样本的多样性。

    Clinical natural language processing requires methods that can address domain-specific challenges, such as complex medical terminology and clinical contexts. Recently, large language models (LLMs) have shown promise in this domain. Yet, their direct deployment can lead to privacy issues and are constrained by resources. To address this challenge, we delve into synthetic clinical text generation using LLMs for clinical NLP tasks. We propose an innovative, resource-efficient approach, ClinGen, which infuses knowledge into the process. Our model involves clinical knowledge extraction and context-informed LLM prompting. Both clinical topics and writing styles are drawn from external domain-specific knowledge graphs and LLMs to guide data generation. Our extensive empirical study across 7 clinical NLP tasks and 16 datasets reveals that ClinGen consistently enhances performance across various tasks, effectively aligning the distribution of real datasets and significantly enriching the divers
    
[^21]: 分层联邦学习中的子模型划分：算法设计与收敛分析

    Submodel Partitioning in Hierarchical Federated Learning: Algorithm Design and Convergence Analysis. (arXiv:2310.17890v1 [cs.LG])

    [http://arxiv.org/abs/2310.17890](http://arxiv.org/abs/2310.17890)

    本文提出了一种针对分层联邦学习的新方法：分层独立子模型训练（HIST）。该方法通过将全局模型划分为不相交的子模型，并在分层结构中分布，以降低边缘设备上的计算、通信和存储负担，同时节约资源。

    

    分层联邦学习（HFL）相较传统的“星型拓扑”架构的联邦学习具有更好的可扩展性。然而，在资源受限的物联网（IoT）设备上训练大规模模型时，HFL仍然会对边缘设备造成重大的计算、通信和存储负担。本文提出了一种新的联邦学习方法——分层独立子模型训练（HIST），旨在解决分层场景下的这些问题。HIST的关键思想是分层版本的模型划分，即在每一轮中将全局模型划分为不相交的子模型，并将它们分布在不同的细胞中，使得每个细胞只负责训练全模型的一个划分。这样每个客户端可以节省计算和存储成本，同时减轻整个分层结构中的通信负载。我们对HIST在非凸优化问题下的收敛性行为进行了特征化分析。

    Hierarchical federated learning (HFL) has demonstrated promising scalability advantages over the traditional "star-topology" architecture-based federated learning (FL). However, HFL still imposes significant computation, communication, and storage burdens on the edge, especially when training a large-scale model over resource-constrained Internet of Things (IoT) devices. In this paper, we propose hierarchical independent submodel training (HIST), a new FL methodology that aims to address these issues in hierarchical settings. The key idea behind HIST is a hierarchical version of model partitioning, where we partition the global model into disjoint submodels in each round, and distribute them across different cells, so that each cell is responsible for training only one partition of the full model. This enables each client to save computation/storage costs while alleviating the communication loads throughout the hierarchy. We characterize the convergence behavior of HIST for non-convex 
    
[^22]: 使用星系目录进行场级别的基于模拟的推断：系统效应的影响

    Field-level simulation-based inference with galaxy catalogs: the impact of systematic effects. (arXiv:2310.15234v1 [astro-ph.CO])

    [http://arxiv.org/abs/2310.15234](http://arxiv.org/abs/2310.15234)

    本文提出了一种使用星系目录进行场级别的基于模拟的推断方法，能够鲁棒地推断出宇宙学参数，解决了观测受到的系统效应的影响。

    

    最近的研究表明，一种从星系红移调查中限制宇宙学参数的有效方法是训练图神经网络进行场级别的无似然推断，而不对尺度进行剪切。具体而言，德桑蒂等人（2023年）开发了能够准确推断出通过仅包含星系位置和径向速度的目录来确定$\Omega_{\rm m}$值的模型，这些模型具有对天体物理和亚网格模型的不确定性具有鲁棒性。然而，观测受到许多效应的影响，包括1）掩蔽效应，2）特异速度和径向距离的不确定性，以及3）不同的星系选择。此外，观测只允许我们测量红移，纠缠了星系的径向位置和速度。在本文中，我们使用来自CAMELS项目中不同代码运行的最新水动力学模拟生成的星系目录来训练和测试我们的模型，这些模拟考虑了这些观测效应。

    It has been recently shown that a powerful way to constrain cosmological parameters from galaxy redshift surveys is to train graph neural networks to perform field-level likelihood-free inference without imposing cuts on scale. In particular, de Santi et al. (2023) developed models that could accurately infer the value of $\Omega_{\rm m}$ from catalogs that only contain the positions and radial velocities of galaxies that are robust to uncertainties in astrophysics and subgrid models. However, observations are affected by many effects, including 1) masking, 2) uncertainties in peculiar velocities and radial distances, and 3) different galaxy selections. Moreover, observations only allow us to measure redshift, intertwining galaxies' radial positions and velocities. In this paper we train and test our models on galaxy catalogs, created from thousands of state-of-the-art hydrodynamic simulations run with different codes from the CAMELS project, that incorporate these observational effect
    
[^23]: 闭式扩散模型

    Closed-Form Diffusion Models. (arXiv:2310.12395v1 [cs.LG])

    [http://arxiv.org/abs/2310.12395](http://arxiv.org/abs/2310.12395)

    本研究提出了一种闭式扩散模型，通过显式平滑的闭式得分函数来生成新样本，无需训练，且在消费级CPU上能够实现与神经SGMs相竞争的采样速度。

    

    基于得分的生成模型(SGMs)通过迭代地使用扰动目标函数的得分函数来从目标分布中采样。对于任何有限的训练集，可以闭式地评估这个得分函数，但由此得到的SGMs会记忆其训练数据，不能生成新样本。在实践中，可以通过训练神经网络来近似得分函数，但这种近似的误差有助于推广，然而神经SGMs的训练和采样代价高，而且对于这种误差提供的有效正则化方法在理论上尚不清楚。因此，在这项工作中，我们采用显式平滑的闭式得分来获得一个生成新样本的SGMs，而无需训练。我们分析了我们的模型，并提出了一个基于最近邻的高效得分函数估计器。利用这个估计器，我们的方法在消费级CPU上运行时能够达到与神经SGMs相竞争的采样速度。

    Score-based generative models (SGMs) sample from a target distribution by iteratively transforming noise using the score function of the perturbed target. For any finite training set, this score function can be evaluated in closed form, but the resulting SGM memorizes its training data and does not generate novel samples. In practice, one approximates the score by training a neural network via score-matching. The error in this approximation promotes generalization, but neural SGMs are costly to train and sample, and the effective regularization this error provides is not well-understood theoretically. In this work, we instead explicitly smooth the closed-form score to obtain an SGM that generates novel samples without training. We analyze our model and propose an efficient nearest-neighbor-based estimator of its score function. Using this estimator, our method achieves sampling times competitive with neural SGMs while running on consumer-grade CPUs.
    
[^24]: 随机森林中超参数对变量选择的影响

    Effect of hyperparameters on variable selection in random forests. (arXiv:2309.06943v1 [stat.ML])

    [http://arxiv.org/abs/2309.06943](http://arxiv.org/abs/2309.06943)

    这项研究评估了随机森林中超参数对变量选择的影响，在高维组学研究中，适当设置RF超参数对选择重要变量具有重要意义。

    

    随机森林（RF）在高维组学研究中适用于预测建模和变量选择。先前研究了RF算法的超参数对预测性能和变量重要性估计的影响，但超参数对基于RF的变量选择的影响尚不清楚。我们利用理论分布和实证基因表达数据进行了两个模拟研究，评估了Vita和Boruta变量选择 procedures 在选择重要变量（敏感性）的同时控制虚警率（FDR）的能力。我们的结果表明，在训练数据集中，要比训练数据集的抽取策略和最小终端节点大小更能影响选择 procedures。RF超参数的合适设置取决于

    Random forests (RFs) are well suited for prediction modeling and variable selection in high-dimensional omics studies. The effect of hyperparameters of the RF algorithm on prediction performance and variable importance estimation have previously been investigated. However, how hyperparameters impact RF-based variable selection remains unclear. We evaluate the effects on the Vita and the Boruta variable selection procedures based on two simulation studies utilizing theoretical distributions and empirical gene expression data. We assess the ability of the procedures to select important variables (sensitivity) while controlling the false discovery rate (FDR). Our results show that the proportion of splitting candidate variables (mtry.prop) and the sample fraction (sample.fraction) for the training dataset influence the selection procedures more than the drawing strategy of the training datasets and the minimal terminal node size. A suitable setting of the RF hyperparameters depends on the
    
[^25]: 机器学习在信任与安全方面的挑战：一个针对虚假信息检测的案例研究

    The Challenges of Machine Learning for Trust and Safety: A Case Study on Misinformation Detection. (arXiv:2308.12215v1 [cs.LG])

    [http://arxiv.org/abs/2308.12215](http://arxiv.org/abs/2308.12215)

    本研究通过虚假信息检测为例，检查了机器学习在信任与安全问题中学术与实践之间的脱节，并发现了文献中存在的严重不足之处，包括任务不符合在线服务面临的挑战、数据集和模型评估不真实、评估不独立于模型训练等。在此基础上，提出了评估机器学习应用于信任与安全问题的建议。

    

    我们使用虚假信息检测作为案例研究，检查了在将机器学习应用于信任与安全问题上学术和实践之间的脱节。我们对该领域中270篇广受引用的论文进行了自动检测虚假信息的文献系统化，并对子集中的论文进行了数据和代码的可用性、设计失误、可复现性和泛化性等方面的研究。我们发现文献中存在严重的不足之处，这对所声称的性能和实用性提出了质疑。检测任务通常与在线服务真正面临的挑战有本质上的区别。数据集和模型评估通常不代表现实世界的情景，而且评估往往不独立于模型训练。数据和代码的可用性很差。模型在领域外的数据上泛化能力不强。基于这些结果，我们提出了评估机器学习应用于信任与安全问题的建议。

    We examine the disconnect between scholarship and practice in applying machine learning to trust and safety problems, using misinformation detection as a case study. We systematize literature on automated detection of misinformation across a corpus of 270 well-cited papers in the field. We then examine subsets of papers for data and code availability, design missteps, reproducibility, and generalizability. We find significant shortcomings in the literature that call into question claimed performance and practicality. Detection tasks are often meaningfully distinct from the challenges that online services actually face. Datasets and model evaluation are often non-representative of real-world contexts, and evaluation frequently is not independent of model training. Data and code availability is poor. Models do not generalize well to out-of-domain data. Based on these results, we offer recommendations for evaluating machine learning applications to trust and safety problems. Our aim is fo
    
[^26]: 用于量化生成式语言模型不确定性的PAC神经预测集学习

    PAC Neural Prediction Set Learning to Quantify the Uncertainty of Generative Language Models. (arXiv:2307.09254v1 [cs.LG])

    [http://arxiv.org/abs/2307.09254](http://arxiv.org/abs/2307.09254)

    本文提出了一种使用神经网络来量化生成式语言模型不确定性的PAC神经预测集学习方法，通过在多种语言数据集和模型上的实验证明，相比于标准基准方法，我们的方法平均提高了63％的量化不确定性。

    

    学习和量化模型的不确定性是增强模型可信度的关键任务。由于对生成虚构事实的担忧，最近兴起的生成式语言模型（GLM）特别强调可靠的不确定性量化的需求。本文提出了一种学习神经预测集模型的方法，该方法能够以可能近似正确（PAC）的方式量化GLM的不确定性。与现有的预测集模型通过标量值参数化不同，我们提出通过神经网络参数化预测集，实现更精确的不确定性量化，但仍满足PAC保证。通过在四种类型的语言数据集和六种类型的模型上展示，我们的方法相比标准基准方法平均提高了63％的量化不确定性。

    Uncertainty learning and quantification of models are crucial tasks to enhance the trustworthiness of the models. Importantly, the recent surge of generative language models (GLMs) emphasizes the need for reliable uncertainty quantification due to the concerns on generating hallucinated facts. In this paper, we propose to learn neural prediction set models that comes with the probably approximately correct (PAC) guarantee for quantifying the uncertainty of GLMs. Unlike existing prediction set models, which are parameterized by a scalar value, we propose to parameterize prediction sets via neural networks, which achieves more precise uncertainty quantification but still satisfies the PAC guarantee. We demonstrate the efficacy of our method on four types of language datasets and six types of models by showing that our method improves the quantified uncertainty by $63\%$ on average, compared to a standard baseline method.
    
[^27]: 随机集合卷积神经网络（RS-CNN）用于认识论深度学习

    Random-Set Convolutional Neural Network (RS-CNN) for Epistemic Deep Learning. (arXiv:2307.05772v1 [cs.LG])

    [http://arxiv.org/abs/2307.05772](http://arxiv.org/abs/2307.05772)

    这篇论文提出了一种新的随机集合卷积神经网络（RS-CNN）用于分类，通过预测信念函数而不是概率矢量集合，以表示模型的置信度和认识不确定性。基于认识论深度学习方法，该模型能够估计由有限训练集引起的认识不确定性。

    

    机器学习越来越多地应用于安全关键领域，对抗攻击的鲁棒性至关重要，错误的预测可能导致潜在的灾难性后果。这突出了学习系统需要能够确定模型对其预测的置信度以及与之相关联的认识不确定性的手段，“知道一个模型不知道”。在本文中，我们提出了一种新颖的用于分类的随机集合卷积神经网络（RS-CNN），其预测信念函数而不是概率矢量集合，使用随机集合的数学，即对样本空间的幂集的分布。基于认识论深度学习方法，随机集模型能够表示机器学习中由有限训练集引起的“认识性”不确定性。我们通过近似预测信念函数相关联的置信集的大小来估计认识不确定性。

    Machine learning is increasingly deployed in safety-critical domains where robustness against adversarial attacks is crucial and erroneous predictions could lead to potentially catastrophic consequences. This highlights the need for learning systems to be equipped with the means to determine a model's confidence in its prediction and the epistemic uncertainty associated with it, 'to know when a model does not know'. In this paper, we propose a novel Random-Set Convolutional Neural Network (RS-CNN) for classification which predicts belief functions rather than probability vectors over the set of classes, using the mathematics of random sets, i.e., distributions over the power set of the sample space. Based on the epistemic deep learning approach, random-set models are capable of representing the 'epistemic' uncertainty induced in machine learning by limited training sets. We estimate epistemic uncertainty by approximating the size of credal sets associated with the predicted belief func
    
[^28]: SDC-HSDD-NDSA: 使用层次次级导向差异和归一化密度自适应的结构检测聚类算法

    SDC-HSDD-NDSA: Structure Detecting Cluster by Hierarchical Secondary Directed Differential with Normalized Density and Self-Adaption. (arXiv:2307.00677v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2307.00677](http://arxiv.org/abs/2307.00677)

    本文提出了一种基于密度的聚类算法，能够检测到高密度区域中的结构，具有先前算法所不具备的能力。

    

    基于密度的聚类算法是最受欢迎的聚类算法之一，因为它能够识别任意形状的聚类，只要不同的高密度聚类之间有低密度区域分隔。然而，通过低密度区域将聚类分隔开的要求并不是微不足道的，因为高密度区域可能具有不同的结构，应该被聚类到不同的组中。这种情况说明了我们已知的所有先前基于密度的聚类算法的主要缺陷--无法检测高密度聚类中的结构。因此，本文旨在提供一种基于密度的聚类方案，既具有先前方法的能力，又能够检测到高密度区域中未被低密度区分开的结构。该算法采用层次次级导向差异、层次化、归一化密度以及自适应系数，因此被称为结构检测聚类算法。

    Density-based clustering could be the most popular clustering algorithm since it can identify clusters of arbitrary shape as long as different (high-density) clusters are separated by low-density regions. However, the requirement of the separateness of clusters by low-density regions is not trivial since a high-density region might have different structures which should be clustered into different groups. Such a situation demonstrates the main flaw of all previous density-based clustering algorithms we have known--structures in a high-density cluster could not be detected. Therefore, this paper aims to provide a density-based clustering scheme that not only has the ability previous ones have but could also detect structures in a high-density region not separated by low-density ones. The algorithm employs secondary directed differential, hierarchy, normalized density, as well as the self-adaption coefficient, and thus is called Structure Detecting Cluster by Hierarchical Secondary Direc
    
[^29]: 可泛化的一次性绳索操作策略及其参数感知性。

    Generalizable One-shot Rope Manipulation with Parameter-Aware Policy. (arXiv:2306.09872v1 [cs.LG])

    [http://arxiv.org/abs/2306.09872](http://arxiv.org/abs/2306.09872)

    GenORM通过增加可变形绳索参数和使用各种可变形绳索的模拟训练操作策略，实现利用一次真实演示处理不同可形变绳索，从而节省演示时间和提高适用性。

    

    以绳索在运动过程中的固有不确定性为因素，以往绳索操作方法往往需要数百次真实演示来为每个绳索训练操作策略，即使是简单的“到达目标”任务，这限制了它们在我们不断变化的世界中的应用。为了解决这个问题，我们介绍了GenORM，一个框架，它可以让操作策略通过一次真实演示就可以处理不同可形变的绳索。我们通过在策略上增加可变形绳索参数并使用各种模拟可变形绳索来训练它，使策略能够根据不同的绳索参数调整行动。在推断时，GenORM通过最小化真实演示和模拟点云的网格密度差异来估计可变形绳索参数。通过可微分物理模拟器的帮助，我们仅需要一次演示数据就可以处理不同的绳索。

    Due to the inherent uncertainty in their deformability during motion, previous methods in rope manipulation often require hundreds of real-world demonstrations to train a manipulation policy for each rope, even for simple tasks such as rope goal reaching, which hinder their applications in our ever-changing world. To address this issue, we introduce GenORM, a framework that allows the manipulation policy to handle different deformable ropes with a single real-world demonstration. To achieve this, we augment the policy by conditioning it on deformable rope parameters and training it with a diverse range of simulated deformable ropes so that the policy can adjust actions based on different rope parameters. At the time of inference, given a new rope, GenORM estimates the deformable rope parameters by minimizing the disparity between the grid density of point clouds of real-world demonstrations and simulations. With the help of a differentiable physics simulator, we require only a single r
    
[^30]: 重新评估损失函数：增强深度学习模型对标签噪声的鲁棒性

    Reevaluating Loss Functions: Enhancing Robustness to Label Noise in Deep Learning Models. (arXiv:2306.05497v1 [cs.LG])

    [http://arxiv.org/abs/2306.05497](http://arxiv.org/abs/2306.05497)

    本文研究了使用噪声鲁棒损失函数增强深度学习模型对标签噪声的鲁棒性，并提出了一种无需超参数调整的新技术：包括输出偏置。

    

    大规模标注的数据集中难免会出现错误的标签，这给深度神经网络的训练带来了极大的挑战，因为它们很容易适应这些错误的标签。只有使用不受噪声干扰的鲁棒模型进行训练，才能获得良好的泛化性能。创建噪声鲁棒模型的一种简单而有效的方式是使用噪声鲁棒损失函数。然而，提出的损失函数数量众多，它们通常伴随着超参数，而且可能学习速度比广泛使用但对噪声敏感的交叉熵损失要慢。通过启发式考虑和广泛的数值实验，我们研究了在哪些情况下提出的损失函数适用，并提出了如何选择合适的损失的建议。此外，我们提出了一种新的技术来增强带有有界损失函数的学习：包括输出偏置，即略微增加与正确标签相对应的神经元预激活。令人惊讶的是，我们发现这种技术在无需超参数调整的情况下表现与最先进的方法类似。

    Large annotated datasets inevitably contain incorrect labels, which poses a major challenge for the training of deep neural networks as they easily fit the labels. Only when training with a robust model that is not easily distracted by the noise, a good generalization performance can be achieved. A simple yet effective way to create a noise robust model is to use a noise robust loss function. However, the number of proposed loss functions is large, they often come with hyperparameters, and may learn slower than the widely used but noise sensitive Cross Entropy loss. By heuristic considerations and extensive numerical experiments, we study in which situations the proposed loss functions are applicable and give suggestions on how to choose an appropriate loss. Additionally, we propose a novel technique to enhance learning with bounded loss functions: the inclusion of an output bias, i.e. a slight increase in the neuron pre-activation corresponding to the correct label. Surprisingly, we f
    
[^31]: 机器学习中的不确定性来源 -- 一个统计学家的视角

    Sources of Uncertainty in Machine Learning -- A Statisticians' View. (arXiv:2305.16703v1 [stat.ML])

    [http://arxiv.org/abs/2305.16703](http://arxiv.org/abs/2305.16703)

    本文讨论了机器学习中不确定性的来源和类型，从统计学家的视角出发，分类别介绍了随机性和认知性不确定性的概念，证明了不确定性来源各异，不可简单归为两类。同时，与统计学概念进行类比，探讨不确定性在机器学习中的作用。

    

    机器学习和深度学习已经取得了令人瞩目的成就，使我们能够回答几年前难以想象的问题。除了这些成功之外，越来越清晰的是，在纯预测之外，量化不确定性也是相关和必要的。虽然近年来已经出现了这方面的第一批概念和思想，但本文采用了一个概念性的视角，并探讨了可能的不确定性来源。通过采用统计学家的视角，我们讨论了与机器学习更常见相关的随机性和认知性不确定性的概念。本文旨在规范这两种类型的不确定性，并证明不确定性的来源各异，并且不总是可以分解为随机性和认知性。通过将统计概念与机器学习中的不确定性进行类比，我们也展示了统计学概念和机器学习中不确定性的作用。

    Machine Learning and Deep Learning have achieved an impressive standard today, enabling us to answer questions that were inconceivable a few years ago. Besides these successes, it becomes clear, that beyond pure prediction, which is the primary strength of most supervised machine learning algorithms, the quantification of uncertainty is relevant and necessary as well. While first concepts and ideas in this direction have emerged in recent years, this paper adopts a conceptual perspective and examines possible sources of uncertainty. By adopting the viewpoint of a statistician, we discuss the concepts of aleatoric and epistemic uncertainty, which are more commonly associated with machine learning. The paper aims to formalize the two types of uncertainty and demonstrates that sources of uncertainty are miscellaneous and can not always be decomposed into aleatoric and epistemic. Drawing parallels between statistical concepts and uncertainty in machine learning, we also demonstrate the rol
    
[^32]: DiFaReli: 扩散人脸重照技术

    DiFaReli : Diffusion Face Relighting. (arXiv:2304.09479v1 [cs.CV])

    [http://arxiv.org/abs/2304.09479](http://arxiv.org/abs/2304.09479)

    DiFaReli提出了一种新方法，通过利用条件扩散隐式模型解码解耦的光编码以及从现成的估算器推断出的与3D形状和面部身份相关的其他编码，能够处理单视角的野外环境下的人脸重照，无需光线舞台数据、多视图图像或光照基础事实，实验表明其效果优于现有方法。

    

    我们提出了一种新方法，用于处理野外环境下的单视角人脸重照。处理全局照明或投影阴影等非漫反射效应一直是人脸重照领域的难点。以往的研究通常假定兰伯特反射表面，简化光照模型，或者需要估计三维形状、反射率或阴影图。然而，这种估计是容易出错的，需要许多具有光照基础事实的训练样本才能很好地推广。我们的研究绕过了准确估计固有组件的需要，可以仅通过2D图像训练而不需要任何光线舞台数据、多视图图像或光照基础事实。我们的关键思想是利用条件扩散隐式模型（DDIM）解码解耦的光编码以及从现成的估算器推断出的与3D形状和面部身份相关的其他编码。我们还提出了一种新的调节技术，通过使用归一化方案，简化光与几何之间复杂互动的建模。在多个基准数据集上的实验表明，我们的方法优于现有方法。

    We present a novel approach to single-view face relighting in the wild. Handling non-diffuse effects, such as global illumination or cast shadows, has long been a challenge in face relighting. Prior work often assumes Lambertian surfaces, simplified lighting models or involves estimating 3D shape, albedo, or a shadow map. This estimation, however, is error-prone and requires many training examples with lighting ground truth to generalize well. Our work bypasses the need for accurate estimation of intrinsic components and can be trained solely on 2D images without any light stage data, multi-view images, or lighting ground truth. Our key idea is to leverage a conditional diffusion implicit model (DDIM) for decoding a disentangled light encoding along with other encodings related to 3D shape and facial identity inferred from off-the-shelf estimators. We also propose a novel conditioning technique that eases the modeling of the complex interaction between light and geometry by using a ren
    
[^33]: 自适应 LQR 算法的近乎必然 $\sqrt{T}$ 后悔上限分析

    Almost Surely $\sqrt{T}$ Regret Bound for Adaptive LQR. (arXiv:2301.05537v2 [math.OC] UPDATED)

    [http://arxiv.org/abs/2301.05537](http://arxiv.org/abs/2301.05537)

    本文提出了一种自适应LQR控制器，在几乎必然的情况下具有 $\tilde{ \mathcal{O}}(\sqrt{T})$ 后悔上限证明，且具有断电机制保证安全并对性能影响很小。

    

    对于未知系统参数的线性二次调节问题(LQR)已经得到广泛研究，但是至今仍不清楚是否能几乎必然地达到 $\tilde{ \mathcal{O}}(\sqrt{T})$ 的后悔上限，而本文则提出了一种自适应LQR控制器，在几乎必然的情况下具有 $\tilde{ \mathcal{O}}(\sqrt{T})$ 后悔上限的证明。该控制器具有断电机制，可以绕过潜在的安全隐患并确保系统参数估计的收敛性，但被证明只会有有限次触发，并对控制器的渐近性能几乎没有影响。通过在田纳西伊士曼(Tennessee Eastman)工艺中进行仿真验证了该控制器的有效性。

    The Linear-Quadratic Regulation (LQR) problem with unknown system parameters has been widely studied, but it has remained unclear whether $\tilde{ \mathcal{O}}(\sqrt{T})$ regret, which is the best known dependence on time, can be achieved almost surely. In this paper, we propose an adaptive LQR controller with almost surely $\tilde{ \mathcal{O}}(\sqrt{T})$ regret upper bound. The controller features a circuit-breaking mechanism, which circumvents potential safety breach and guarantees the convergence of the system parameter estimate, but is shown to be triggered only finitely often and hence has negligible effect on the asymptotic performance of the controller. The proposed controller is also validated via simulation on Tennessee Eastman Process~(TEP), a commonly used industrial process example.
    
[^34]: 移动机器人的2D推动操作中的集体智能

    Collective Intelligence for 2D Push Manipulation with Mobile Robots. (arXiv:2211.15136v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2211.15136](http://arxiv.org/abs/2211.15136)

    本研究利用基于软体物理模拟器的规划器和基于注意力的神经网络，实现了移动机器人2D协作推动操作中的集体智能，比传统方法具有更好的性能并具备环境自适应能力。

    

    自然系统通常表现出能够自我组织和适应变化的集体智能，但大多数人工系统缺乏这种等效性。本文探讨使用移动机器人进行2D协作推动操作的集体智能系统的可能性。我们展示了将从软体物理模拟派生的规划器提炼为基于注意力的神经网络后，我们的多机器人推动操作系统相对于基线系统具有更好的性能，并可适应外部扰动和环境变化完成任务。

    While natural systems often present collective intelligence that allows them to self-organize and adapt to changes, the equivalent is missing in most artificial systems. We explore the possibility of such a system in the context of cooperative 2D push manipulations using mobile robots. Although conventional works demonstrate potential solutions for the problem in restricted settings, they have computational and learning difficulties. More importantly, these systems do not possess the ability to adapt when facing environmental changes. In this work, we show that by distilling a planner derived from a differentiable soft-body physics simulator into an attention-based neural network, our multi-robot push manipulation system achieves better performance than baselines. In addition, our system also generalizes to configurations not seen during training and is able to adapt toward task completions when external turbulence and environmental changes are applied. Supplementary videos can be foun
    
[^35]: R2C-GAN: 用于盲目X射线恢复和COVID-19分类的恢复到分类生成对抗网络

    R2C-GAN: Restore-to-Classify GANs for Blind X-Ray Restoration and COVID-19 Classification. (arXiv:2209.14770v2 [eess.IV] UPDATED)

    [http://arxiv.org/abs/2209.14770](http://arxiv.org/abs/2209.14770)

    R2C-GAN是一种用于盲目X射线恢复和COVID-19分类的生成对抗网络，通过图像恢复提高X射线图像质量，并实现更高的诊断性能。

    

    探索了针对盲目X射线恢复的联合模型：恢复到分类生成对抗网络(R2C-GANs)。该模型在保持疾病完整性的同时进行图像恢复，从而提高X射线图像的质量并实现更高的诊断性能。将恢复任务定义为从质量较差包含有噪声、模糊或过/欠曝图片到高质量图像领域的图像到图像翻译问题。R2C-GAN模型能够学习两个领域之间的正向和反向转换。

    Restoration of poor quality images with a blended set of artifacts plays a vital role for a reliable diagnosis. Existing studies have focused on specific restoration problems such as image deblurring, denoising, and exposure correction where there is usually a strong assumption on the artifact type and severity. As a pioneer study in blind X-ray restoration, we propose a joint model for generic image restoration and classification: Restore-to-Classify Generative Adversarial Networks (R2C-GANs). Such a jointly optimized model keeps any disease intact after the restoration. Therefore, this will naturally lead to a higher diagnosis performance thanks to the improved X-ray image quality. To accomplish this crucial objective, we define the restoration task as an Image-to-Image translation problem from poor quality having noisy, blurry, or over/under-exposed images to high quality image domain. The proposed R2C-GAN model is able to learn forward and inverse transforms between the two domains
    

