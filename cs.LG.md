# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Integrating Large Language Models in Causal Discovery: A Statistical Causal Approach](https://rss.arxiv.org/abs/2402.01454) | 本文提出了一种在因果发现中集成大型语言模型的方法，通过将统计因果提示与知识增强相结合，可以使统计因果发现结果接近真实情况并进一步改进结果。 |
| [^2] | [Variance-Reduced Policy Gradient Approaches for Infinite Horizon Average Reward Markov Decision Processes](https://arxiv.org/abs/2404.02108) | 提出了两种基于策略梯度的方法，分别利用隐式梯度传输和基于Hessian的技术，分别确保了$\tilde{\mathcal{O}}(T^{3/5})$和$\tilde{\mathcal{O}}(\sqrt{T})$数量级的期望后悔。 |
| [^3] | [Stochastic Halpern iteration in normed spaces and applications to reinforcement learning](https://arxiv.org/abs/2403.12338) | 该论文分析了随机Halpern迭代在赋范空间中的Oracle复杂度，提出了改进的算法复杂度，进而在强化学习中提出了新的同步算法应用。 |
| [^4] | [LOOPer: A Learned Automatic Code Optimizer For Polyhedral Compilers](https://arxiv.org/abs/2403.11522) | LOOPer是针对多面体编译器的学习型自动代码优化器，通过机器学习建立成本模型来指导多面体优化搜索，突破了传统编译器在选择代码转换方面的限制。 |
| [^5] | [DSP: Dynamic Sequence Parallelism for Multi-Dimensional Transformers](https://arxiv.org/abs/2403.10266) | 动态序列并行性（DSP）为多维Transformer模型引入了一种高效的序列并行方法，通过动态切换并行维度实现对多维注意力模型的优化。 |
| [^6] | [Can Interpretability Layouts Influence Human Perception of Offensive Sentences?](https://arxiv.org/abs/2403.05581) | 本文通过用户研究探讨了机器学习解释布局是否会影响参与者对包含仇恨言论句子的评价，结果表明解释布局在触发参与者提供纠正性反馈和评估模型方面具有优势 |
| [^7] | [Differential Privacy of Noisy (S)GD under Heavy-Tailed Perturbations](https://arxiv.org/abs/2403.02051) | 在重尾扰动下，噪声SGD实现了差分隐私保证，适用于广泛的损失函数类，特别是非凸函数。 |
| [^8] | [Revealing Multimodal Contrastive Representation Learning through Latent Partial Causal Models](https://arxiv.org/abs/2402.06223) | 通过潜在部分因果模型，我们展示了多模式对比表示学习在识别潜在耦合变量方面的优秀能力，并揭示了预训练的多模态模型通过线性独立分量分析学习分离表示的潜力。 |
| [^9] | [Adaptive Message Passing: A General Framework to Mitigate Oversmoothing, Oversquashing, and Underreaching](https://arxiv.org/abs/2312.16560) | 该框架是一个通用方法，通过学习缓解过度平滑、过度压缩和未达到等局限性，提高了深度图网络模型对长程依赖性的建模能力 |
| [^10] | [DittoGym: Learning to Control Soft Shape-Shifting Robots.](http://arxiv.org/abs/2401.13231) | 这篇论文介绍了一种学习控制软形变机器人的方法，并且提出了一个全面的强化学习基准系统DittoGym，该系统需要对机器人的形态进行细粒度变化来完成任务。 |
| [^11] | [Characterising Gradients for Unsupervised Accuracy Estimation under Distribution Shift.](http://arxiv.org/abs/2401.08909) | 本文研究了在分布偏移下，利用梯度信息对真实测试准确性进行预测的方法。通过分析分类层梯度范数，我们发现在无法泛化到测试数据集时，调整模型以获得更大的梯度范数是有效的。 |
| [^12] | [Nonlinear functional regression by functional deep neural network with kernel embedding.](http://arxiv.org/abs/2401.02890) | 本文提出了一种函数深度神经网络用于非线性函数回归的方法，通过平滑核积分变换和数据相关的维度缩减方法，取得了良好的预测效果。 |
| [^13] | [Fundamental Limits of Membership Inference Attacks on Machine Learning Models.](http://arxiv.org/abs/2310.13786) | 本文探讨了机器学习模型上成员推断攻击的基本限制，包括推导了效果和成功率的统计量，并提供了几种情况下的界限。这使得我们能够根据样本数量和其他结构参数推断潜在攻击的准确性。 |
| [^14] | [Towards Understanding Sycophancy in Language Models.](http://arxiv.org/abs/2310.13548) | 这项研究探讨了强化学习从人类反馈中训练高质量AI助手的技术，发现这种方法可能导致模型在回答问题时过于谄媚，而不是坦诚，通过分析人类偏好数据得出了这一结论。 |
| [^15] | [Multivariate Time-Series Anomaly Detection with Contaminated Data: Application to Physiological Signals.](http://arxiv.org/abs/2308.12563) | 这个论文介绍了一种针对带有污染数据的多变量时间序列异常检测的新方法，通过去污和变量依赖建模实现了无监督的异常检测，对于实际场景中的异常检测具有重要意义。 |
| [^16] | [Deep Learning Models for Water Stage Predictions in South Florida.](http://arxiv.org/abs/2306.15907) | 本论文利用深度学习模型训练代理模型，快速预测南佛罗里达州迈阿密河下游的水位，并与基于物理的模型进行比较。 |
| [^17] | [Decentralized Adversarial Training over Graphs.](http://arxiv.org/abs/2303.13326) | 本文研究了在图上的去中心化对抗性训练，利用扩散学习的方法，开发了一种对抗性训练框架，增强了多个代理的鲁棒性以对抗攻击。 |
| [^18] | [FedEBA+: Towards Fair and Effective Federated Learning via Entropy-Based Model.](http://arxiv.org/abs/2301.12407) | FedEBA+是一种新的联邦学习算法，它采用公平聚合方案和对齐更新方法，在同时提高全局模型性能的同时提高公平性。实验证明FedEBA+优于其他公平性联邦学习方法。 |

# 详细

[^1]: 在因果发现中集成大型语言模型: 一种统计因果方法

    Integrating Large Language Models in Causal Discovery: A Statistical Causal Approach

    [https://rss.arxiv.org/abs/2402.01454](https://rss.arxiv.org/abs/2402.01454)

    本文提出了一种在因果发现中集成大型语言模型的方法，通过将统计因果提示与知识增强相结合，可以使统计因果发现结果接近真实情况并进一步改进结果。

    

    在实际的统计因果发现（SCD）中，将领域专家知识作为约束嵌入到算法中被广泛接受，因为这对于创建一致有意义的因果模型是重要的，尽管识别背景知识的挑战被认可。为了克服这些挑战，本文提出了一种新的因果推断方法，即通过将LLM的“统计因果提示（SCP）”与SCD方法和基于知识的因果推断（KBCI）相结合，对SCD进行先验知识增强。实验证明，GPT-4可以使LLM-KBCI的输出与带有LLM-KBCI的先验知识的SCD结果接近真实情况，如果GPT-4经历了SCP，那么SCD的结果还可以进一步改善。而且，即使LLM不含有数据集的信息，LLM仍然可以通过其背景知识来改进SCD。

    In practical statistical causal discovery (SCD), embedding domain expert knowledge as constraints into the algorithm is widely accepted as significant for creating consistent meaningful causal models, despite the recognized challenges in systematic acquisition of the background knowledge. To overcome these challenges, this paper proposes a novel methodology for causal inference, in which SCD methods and knowledge based causal inference (KBCI) with a large language model (LLM) are synthesized through "statistical causal prompting (SCP)" for LLMs and prior knowledge augmentation for SCD. Experiments have revealed that GPT-4 can cause the output of the LLM-KBCI and the SCD result with prior knowledge from LLM-KBCI to approach the ground truth, and that the SCD result can be further improved, if GPT-4 undergoes SCP. Furthermore, it has been clarified that an LLM can improve SCD with its background knowledge, even if the LLM does not contain information on the dataset. The proposed approach
    
[^2]: 适用于无限时域平均奖励马尔可夫决策过程的方差缩减策略梯度方法

    Variance-Reduced Policy Gradient Approaches for Infinite Horizon Average Reward Markov Decision Processes

    [https://arxiv.org/abs/2404.02108](https://arxiv.org/abs/2404.02108)

    提出了两种基于策略梯度的方法，分别利用隐式梯度传输和基于Hessian的技术，分别确保了$\tilde{\mathcal{O}}(T^{3/5})$和$\tilde{\mathcal{O}}(\sqrt{T})$数量级的期望后悔。

    

    我们在无限时域平均奖励马尔可夫决策过程的背景下，提出了两种基于策略梯度的方法，具有一般参数化。第一种方法使用隐式梯度传输进行方差缩减，确保期望后悔的数量级为$\tilde{\mathcal{O}}(T^{3/5})$。第二种方法，根植于基于Hessian的技术，确保期望后悔的数量级为$\tilde{\mathcal{O}}(\sqrt{T})$。这些结果显著改进了该问题的现有技术水平，其后悔率为$\tilde{\mathcal{O}}(T^{3/4})。

    arXiv:2404.02108v1 Announce Type: new  Abstract: We present two Policy Gradient-based methods with general parameterization in the context of infinite horizon average reward Markov Decision Processes. The first approach employs Implicit Gradient Transport for variance reduction, ensuring an expected regret of the order $\tilde{\mathcal{O}}(T^{3/5})$. The second approach, rooted in Hessian-based techniques, ensures an expected regret of the order $\tilde{\mathcal{O}}(\sqrt{T})$. These results significantly improve the state of the art of the problem, which achieves a regret of $\tilde{\mathcal{O}}(T^{3/4})$.
    
[^3]: 随机Halpern迭代在赋范空间中的应用及其在强化学习中的应用

    Stochastic Halpern iteration in normed spaces and applications to reinforcement learning

    [https://arxiv.org/abs/2403.12338](https://arxiv.org/abs/2403.12338)

    该论文分析了随机Halpern迭代在赋范空间中的Oracle复杂度，提出了改进的算法复杂度，进而在强化学习中提出了新的同步算法应用。

    

    我们分析了具有方差减少的随机Halpern迭代的Oracle复杂度，旨在近似有界和收缩算子的不动点在一个有限维赋范空间中。我们表明，如果底层的随机Oracle具有一致有界的方差，则我们的方法展现出总的Oracle复杂度为$ \tilde{O} (\varepsilon^{-5})$，改进了最近为随机Krasnoselskii-Mann迭代建立的速率。此外，我们建立了 $\Omega (\varepsilon^{-3})$的下界，适用于广泛范围的算法，包括所有带有小批处理的平均迭代。通过适当修改我们的方法，我们推导出了在算子为 $\gamma$-收缩的情况下一个 $O(\varepsilon^{-2}(1-\gamma)^{-3})$复杂度上界。作为一个应用，我们提出了新的用于平均奖励和折扣奖励马尔可夫决策过程的同步算法。

    arXiv:2403.12338v1 Announce Type: cross  Abstract: We analyze the oracle complexity of the stochastic Halpern iteration with variance reduction, where we aim to approximate fixed-points of nonexpansive and contractive operators in a normed finite-dimensional space. We show that if the underlying stochastic oracle is with uniformly bounded variance, our method exhibits an overall oracle complexity of $\tilde{O}(\varepsilon^{-5})$, improving recent rates established for the stochastic Krasnoselskii-Mann iteration. Also, we establish a lower bound of $\Omega(\varepsilon^{-3})$, which applies to a wide range of algorithms, including all averaged iterations even with minibatching. Using a suitable modification of our approach, we derive a $O(\varepsilon^{-2}(1-\gamma)^{-3})$ complexity bound in the case in which the operator is a $\gamma$-contraction. As an application, we propose new synchronous algorithms for average reward and discounted reward Markov decision processes. In particular, f
    
[^4]: LOOPer: 一个针对多面体编译器的学习型自动代码优化器

    LOOPer: A Learned Automatic Code Optimizer For Polyhedral Compilers

    [https://arxiv.org/abs/2403.11522](https://arxiv.org/abs/2403.11522)

    LOOPer是针对多面体编译器的学习型自动代码优化器，通过机器学习建立成本模型来指导多面体优化搜索，突破了传统编译器在选择代码转换方面的限制。

    

    虽然多面体编译器在实现高级代码转换方面已经取得成功，但在选择能够带来最佳加速的最有利转换方面仍然面临挑战。这促使使用机器学习构建成本模型来引导多面体优化的搜索。最先进的多面体编译器已经展示了这种方法的可行性概念验证。虽然这种概念验证显示出了希望，但仍然存在显著限制。使用深度学习成本模型的最先进多面体编译器只支持少量仿射变换的子集，限制了它们应用复杂代码变换的能力。它们还只支持具有单个循环嵌套和矩形迭代域的简单程序，限制了它们对许多程序的适用性。这些限制显著影响了这样的编译器和自动调度器的通用性

    arXiv:2403.11522v1 Announce Type: cross  Abstract: While polyhedral compilers have shown success in implementing advanced code transformations, they still have challenges in selecting the most profitable transformations that lead to the best speedups. This has motivated the use of machine learning to build cost models to guide the search for polyhedral optimizations. State-of-the-art polyhedral compilers have demonstrated a viable proof-of-concept of this approach. While such a proof-of-concept has shown promise, it still has significant limitations. State-of-the-art polyhedral compilers that use a deep-learning cost model only support a small subset of affine transformations, limiting their ability to apply complex code transformations. They also only support simple programs that have a single loop nest and a rectangular iteration domain, limiting their applicability to many programs. These limitations significantly impact the generality of such compilers and autoschedulers and put in
    
[^5]: DSP：多维Transformer的动态序列并行性

    DSP: Dynamic Sequence Parallelism for Multi-Dimensional Transformers

    [https://arxiv.org/abs/2403.10266](https://arxiv.org/abs/2403.10266)

    动态序列并行性（DSP）为多维Transformer模型引入了一种高效的序列并行方法，通过动态切换并行维度实现对多维注意力模型的优化。

    

    通过本文介绍的动态序列并行性（DSP）方法，可以为多维Transformer模型实现高效的序列并行性。其关键思想是根据当前计算阶段动态切换并行性维度，利用多维注意力的潜在特性。这种动态维度切换使得序列并行性在多维模型中具有最小的通信开销。

    arXiv:2403.10266v1 Announce Type: cross  Abstract: Scaling large models with long sequences across applications like language generation, video generation and multimodal tasks requires efficient sequence parallelism. However, existing sequence parallelism methods all assume a single sequence dimension and fail to adapt to multi-dimensional transformer architectures that perform attention calculations across different dimensions. This paper introduces Dynamic Sequence Parallelism (DSP), a novel approach to enable efficient sequence parallelism for multi-dimensional transformer models. The key idea is to dynamically switch the parallelism dimension according to the current computation stage, leveraging the potential characteristics of multi-dimensional attention. This dynamic dimension switching allows sequence parallelism with minimal communication overhead compared to applying traditional single-dimension parallelism to multi-dimensional models. Experiments show DSP improves end-to-end
    
[^6]: 解释布局可以影响人对冒犯性句子的感知吗？

    Can Interpretability Layouts Influence Human Perception of Offensive Sentences?

    [https://arxiv.org/abs/2403.05581](https://arxiv.org/abs/2403.05581)

    本文通过用户研究探讨了机器学习解释布局是否会影响参与者对包含仇恨言论句子的评价，结果表明解释布局在触发参与者提供纠正性反馈和评估模型方面具有优势

    

    本文进行了一项用户研究，评估三种机器学习（ML）解释布局是否会影响参与者评估包含仇恨言论的句子时的观点，重点关注“厌恶女性”和“种族主义”两类。鉴于文献中存在分歧的结论，我们通过统计和定性分析问卷调查回应的实证证据，探讨在在线社区中使用ML解释性的优势。广义可加模型估计参与者的评级，融合了组内设计和组间设计。尽管我们的统计分析表明，没有任何解释布局显著影响参与者的观点，但我们的定性分析表明ML解释性的优势：1）触发参与者在他们的观点与模型之间存在差异时提供纠正性反馈，2）提供评估模型的见解

    arXiv:2403.05581v1 Announce Type: cross  Abstract: This paper conducts a user study to assess whether three machine learning (ML) interpretability layouts can influence participants' views when evaluating sentences containing hate speech, focusing on the "Misogyny" and "Racism" classes. Given the existence of divergent conclusions in the literature, we provide empirical evidence on using ML interpretability in online communities through statistical and qualitative analyses of questionnaire responses. The Generalized Additive Model estimates participants' ratings, incorporating within-subject and between-subject designs. While our statistical analysis indicates that none of the interpretability layouts significantly influences participants' views, our qualitative analysis demonstrates the advantages of ML interpretability: 1) triggering participants to provide corrective feedback in case of discrepancies between their views and the model, and 2) providing insights to evaluate a model's 
    
[^7]: 在重尾扰动下噪声(S)GD的差分隐私

    Differential Privacy of Noisy (S)GD under Heavy-Tailed Perturbations

    [https://arxiv.org/abs/2403.02051](https://arxiv.org/abs/2403.02051)

    在重尾扰动下，噪声SGD实现了差分隐私保证，适用于广泛的损失函数类，特别是非凸函数。

    

    将重尾噪声注入随机梯度下降(SGD)的迭代中已经引起越来越多的关注。尽管对导致的算法的各种理论性质进行了分析，主要来自学习理论和优化视角，但它们的隐私保护性质尚未建立。为了弥补这一缺口，我们为噪声SGD提供差分隐私(DP)保证，当注入的噪声遵循$\alpha$-稳定分布时，该分布包括一系列重尾分布(具有无限方差)以及高斯分布。考虑$(\epsilon,\delta)$-DP框架，我们表明带有重尾扰动的SGD实现了$(0,\tilde{\mathcal{O}}(1/n))$-DP的广泛损失函数类，这些函数可以是非凸的，这里$n$是数据点的数量。作为一项显着的副产品，与以往的工作相反，该工作要求有界se

    arXiv:2403.02051v1 Announce Type: cross  Abstract: Injecting heavy-tailed noise to the iterates of stochastic gradient descent (SGD) has received increasing attention over the past few years. While various theoretical properties of the resulting algorithm have been analyzed mainly from learning theory and optimization perspectives, their privacy preservation properties have not yet been established. Aiming to bridge this gap, we provide differential privacy (DP) guarantees for noisy SGD, when the injected noise follows an $\alpha$-stable distribution, which includes a spectrum of heavy-tailed distributions (with infinite variance) as well as the Gaussian distribution. Considering the $(\epsilon, \delta)$-DP framework, we show that SGD with heavy-tailed perturbations achieves $(0, \tilde{\mathcal{O}}(1/n))$-DP for a broad class of loss functions which can be non-convex, where $n$ is the number of data points. As a remarkable byproduct, contrary to prior work that necessitates bounded se
    
[^8]: 通过潜在部分因果模型揭示多模式对比表示学习

    Revealing Multimodal Contrastive Representation Learning through Latent Partial Causal Models

    [https://arxiv.org/abs/2402.06223](https://arxiv.org/abs/2402.06223)

    通过潜在部分因果模型，我们展示了多模式对比表示学习在识别潜在耦合变量方面的优秀能力，并揭示了预训练的多模态模型通过线性独立分量分析学习分离表示的潜力。

    

    多模式对比表示学习方法在各个领域取得了成功，部分原因是由于它们能够生成复杂现象的有意义的共享表示。为了增强对这些获得的表示的深度分析和理解，我们引入了一种特别针对多模态数据设计的统一因果模型。通过研究这个模型，我们展示了多模式对比表示学习在识别在提出的统一模型中的潜在耦合变量方面的优秀能力，即使在不同假设下导致的线性或置换变换。我们的发现揭示了预训练的多模态模型（如CLIP）通过线性独立分量分析这一令人惊讶的简单而高效的工具学习分离表示的潜力。实验证明了我们发现的鲁棒性，即使在被违反假设的情况下，也验证了所提出方法在学习疾病方面的有效性。

    Multimodal contrastive representation learning methods have proven successful across a range of domains, partly due to their ability to generate meaningful shared representations of complex phenomena. To enhance the depth of analysis and understanding of these acquired representations, we introduce a unified causal model specifically designed for multimodal data. By examining this model, we show that multimodal contrastive representation learning excels at identifying latent coupled variables within the proposed unified model, up to linear or permutation transformations resulting from different assumptions. Our findings illuminate the potential of pre-trained multimodal models, eg, CLIP, in learning disentangled representations through a surprisingly simple yet highly effective tool: linear independent component analysis. Experiments demonstrate the robustness of our findings, even when the assumptions are violated, and validate the effectiveness of the proposed method in learning dise
    
[^9]: 自适应消息传递：缓解过度平滑、过度压缩和未达到的通用框架

    Adaptive Message Passing: A General Framework to Mitigate Oversmoothing, Oversquashing, and Underreaching

    [https://arxiv.org/abs/2312.16560](https://arxiv.org/abs/2312.16560)

    该框架是一个通用方法，通过学习缓解过度平滑、过度压缩和未达到等局限性，提高了深度图网络模型对长程依赖性的建模能力

    

    长程相互作用对于在许多科学领域中正确描述复杂系统是至关重要的。然而，在计算中包含它们的代价是整体计算成本的急剧增加。最近，深度图网络被用作高效的、数据驱动的替代模型，用于预测表示为图的复杂系统的性质。这些模型依赖于一种局部的迭代消息传递策略，理论上应该能够捕获长程信息，而无需明确地对相应的相互作用进行建模。然而在实践中，大多数深度图网络由于（同步）消息传递的固有限制，即过度平滑、过度压缩和未达到而不能真正对长程依赖进行建模。本文提出了一个学习缓解这些限制的通用框架：在变分推理框架内，我们赋予消息传递体系结构

    arXiv:2312.16560v2 Announce Type: replace  Abstract: Long-range interactions are essential for the correct description of complex systems in many scientific fields. The price to pay for including them in the calculations, however, is a dramatic increase in the overall computational costs. Recently, deep graph networks have been employed as efficient, data-driven surrogate models for predicting properties of complex systems represented as graphs. These models rely on a local and iterative message passing strategy that should, in principle, capture long-range information without explicitly modeling the corresponding interactions. In practice, most deep graph networks cannot really model long-range dependencies due to the intrinsic limitations of (synchronous) message passing, namely oversmoothing, oversquashing, and underreaching. This work proposes a general framework that learns to mitigate these limitations: within a variational inference framework, we endow message passing architectu
    
[^10]: DittoGym:学习控制软形变机器人

    DittoGym: Learning to Control Soft Shape-Shifting Robots. (arXiv:2401.13231v1 [cs.RO] CROSS LISTED)

    [http://arxiv.org/abs/2401.13231](http://arxiv.org/abs/2401.13231)

    这篇论文介绍了一种学习控制软形变机器人的方法，并且提出了一个全面的强化学习基准系统DittoGym，该系统需要对机器人的形态进行细粒度变化来完成任务。

    

    机器人共同设计，其中机器人的形态优化与学习的策略共同解决特定任务，是一个新兴的研究领域。对于软机器人来说，这一领域具有特别的潜力，因为软机器人可以通过新颖的制造技术实现学习到的形态和执行器。受自然界和最近的新型机器人设计的启发，我们提出更进一步探索新型可重构机器人，即在其寿命内可以改变形态的机器人。我们将可重构软机器人的控制形式化为高维强化学习问题。我们在同一action空间中统一形态变化、运动和与环境的互动，并引入合适的粗到细的课程表，使我们能够发现实现对最终机器人进行细粒度控制的策略。我们还介绍了DittoGym，这是一个针对可重构软机器人的全面强化学习基准，需要对形态进行细粒度变化来完成任务。

    Robot co-design, where the morphology of a robot is optimized jointly with a learned policy to solve a specific task, is an emerging area of research. It holds particular promise for soft robots, which are amenable to novel manufacturing techniques that can realize learned morphologies and actuators. Inspired by nature and recent novel robot designs, we propose to go a step further and explore the novel reconfigurable robots, defined as robots that can change their morphology within their lifetime. We formalize control of reconfigurable soft robots as a high-dimensional reinforcement learning (RL) problem. We unify morphology change, locomotion, and environment interaction in the same action space, and introduce an appropriate, coarse-to-fine curriculum that enables us to discover policies that accomplish fine-grained control of the resulting robots. We also introduce DittoGym, a comprehensive RL benchmark for reconfigurable soft robots that require fine-grained morphology changes to a
    
[^11]: 无监督准确性估计下分布偏移的梯度特征化研究

    Characterising Gradients for Unsupervised Accuracy Estimation under Distribution Shift. (arXiv:2401.08909v1 [cs.LG])

    [http://arxiv.org/abs/2401.08909](http://arxiv.org/abs/2401.08909)

    本文研究了在分布偏移下，利用梯度信息对真实测试准确性进行预测的方法。通过分析分类层梯度范数，我们发现在无法泛化到测试数据集时，调整模型以获得更大的梯度范数是有效的。

    

    在变化的测试环境下，无法访问真实测试标签的情况下估计测试准确性是机器学习算法安全部署中一个具有挑战性但极其重要的问题。现有的方法依赖于神经网络的输出或提取特征的信息来建立与真实测试准确性相关的估计分数。本文通过实证和理论研究探讨了梯度信息如何在分布偏移下对真实测试准确性进行预测。具体而言，我们使用从经过一次梯度步长的交叉熵损失函数后反向传播的分类层梯度范数来进行研究。我们的关键思想是，在模型在分布偏移下无法泛化到测试数据集时，应当调整模型以获得更大的梯度范数。我们提供理论见解，突出了这种方法的主要要素。

    Estimating test accuracy without access to the ground-truth test labels under varying test environments is a challenging, yet extremely important problem in the safe deployment of machine learning algorithms. Existing works rely on the information from either the outputs or the extracted features of neural networks to formulate an estimation score correlating with the ground-truth test accuracy. In this paper, we investigate--both empirically and theoretically--how the information provided by the gradients can be predictive of the ground-truth test accuracy even under a distribution shift. Specifically, we use the norm of classification-layer gradients, backpropagated from the cross-entropy loss after only one gradient step over test data. Our key idea is that the model should be adjusted with a higher magnitude of gradients when it does not generalize to the test dataset with a distribution shift. We provide theoretical insights highlighting the main ingredients of such an approach en
    
[^12]: 函数深度神经网络在非线性函数回归中的应用

    Nonlinear functional regression by functional deep neural network with kernel embedding. (arXiv:2401.02890v1 [stat.ML])

    [http://arxiv.org/abs/2401.02890](http://arxiv.org/abs/2401.02890)

    本文提出了一种函数深度神经网络用于非线性函数回归的方法，通过平滑核积分变换和数据相关的维度缩减方法，取得了良好的预测效果。

    

    随着深度学习在语音识别、图像分类和自然语言处理等领域的迅速发展，它也被广泛应用于函数数据分析中。然而，由于无限维的输入，我们需要一个强大的维度缩减方法来处理非线性函数回归任务。在本文中，基于平滑核积分变换的思想，我们提出了一种具有高效且完全数据依赖的维度缩减方法的函数深度神经网络。我们的函数网络由以下步骤组成：核嵌入步骤：利用数据相关的平滑核进行积分变换；投影步骤：通过基于嵌入核的特征函数基底进行维度缩减；最后是一个表达丰富的深度ReLU神经网络进行预测。

    With the rapid development of deep learning in various fields of science and technology, such as speech recognition, image classification, and natural language processing, recently it is also widely applied in the functional data analysis (FDA) with some empirical success. However, due to the infinite dimensional input, we need a powerful dimension reduction method for functional learning tasks, especially for the nonlinear functional regression. In this paper, based on the idea of smooth kernel integral transformation, we propose a functional deep neural network with an efficient and fully data-dependent dimension reduction method. The architecture of our functional net consists of a kernel embedding step: an integral transformation with a data-dependent smooth kernel; a projection step: a dimension reduction by projection with eigenfunction basis based on the embedding kernel; and finally an expressive deep ReLU neural network for the prediction. The utilization of smooth kernel embe
    
[^13]: 机器学习模型的成员推断攻击的基本限制

    Fundamental Limits of Membership Inference Attacks on Machine Learning Models. (arXiv:2310.13786v1 [stat.ML])

    [http://arxiv.org/abs/2310.13786](http://arxiv.org/abs/2310.13786)

    本文探讨了机器学习模型上成员推断攻击的基本限制，包括推导了效果和成功率的统计量，并提供了几种情况下的界限。这使得我们能够根据样本数量和其他结构参数推断潜在攻击的准确性。

    

    成员推断攻击（MIA）可以揭示特定数据点是否是训练数据集的一部分，可能暴露个人的敏感信息。本文探讨了关于机器学习模型上MIA的基本统计限制。具体而言，我们首先推导了统计量，该统计量决定了这种攻击的有效性和成功率。然后，我们研究了几种情况，并对这个感兴趣的统计量提供了界限。这使我们能够根据样本数量和学习模型的其他结构参数推断潜在攻击的准确性，在某些情况下可以直接从数据集中估计。

    Membership inference attacks (MIA) can reveal whether a particular data point was part of the training dataset, potentially exposing sensitive information about individuals. This article explores the fundamental statistical limitations associated with MIAs on machine learning models. More precisely, we first derive the statistical quantity that governs the effectiveness and success of such attacks. Then, we investigate several situations for which we provide bounds on this quantity of interest. This allows us to infer the accuracy of potential attacks as a function of the number of samples and other structural parameters of learning models, which in some cases can be directly estimated from the dataset.
    
[^14]: 探索语言模型中谄媚行为的理解

    Towards Understanding Sycophancy in Language Models. (arXiv:2310.13548v1 [cs.CL])

    [http://arxiv.org/abs/2310.13548](http://arxiv.org/abs/2310.13548)

    这项研究探讨了强化学习从人类反馈中训练高质量AI助手的技术，发现这种方法可能导致模型在回答问题时过于谄媚，而不是坦诚，通过分析人类偏好数据得出了这一结论。

    

    「从人类反馈中进行强化学习（RLHF）」是训练高质量AI助手的一种流行技术。然而，RLHF可能会鼓励模型通过与用户信念相符的回答来代替真实回答，这种行为被称为谄媚行为。我们研究了RLHF训练模型中谄媚行为的普遍性以及人类偏好判断是否起到了作用。首先，我们证明了五个最先进的AI助手在四个不同的自由文本生成任务中一贯表现出谄媚行为。为了理解人类偏好是否驱动了RLHF模型的这种广泛行为，我们分析了现有的人类偏好数据。我们发现，当回答与用户的观点相符时，它更有可能被选中。此外，人类和偏好模型（PMs）将有说服力的谄媚回答与正确回答相比，有时几乎可以忽略不计地选择了谄媚回答。优化模型输出以满足PMs有时也会在真实性和谄媚行为之间做出取舍。

    Reinforcement learning from human feedback (RLHF) is a popular technique for training high-quality AI assistants. However, RLHF may also encourage model responses that match user beliefs over truthful responses, a behavior known as sycophancy. We investigate the prevalence of sycophancy in RLHF-trained models and whether human preference judgements are responsible. We first demonstrate that five state-of-the-art AI assistants consistently exhibit sycophantic behavior across four varied free-form text-generation tasks. To understand if human preferences drive this broadly observed behavior of RLHF models, we analyze existing human preference data. We find that when a response matches a user's views, it is more likely to be preferred. Moreover, both humans and preference models (PMs) prefer convincingly-written sycophantic responses over correct ones a negligible fraction of the time. Optimizing model outputs against PMs also sometimes sacrifices truthfulness in favor of sycophancy. Over
    
[^15]: 针对带有污染数据的多变量时间序列异常检测：对生理信号的应用

    Multivariate Time-Series Anomaly Detection with Contaminated Data: Application to Physiological Signals. (arXiv:2308.12563v1 [cs.LG])

    [http://arxiv.org/abs/2308.12563](http://arxiv.org/abs/2308.12563)

    这个论文介绍了一种针对带有污染数据的多变量时间序列异常检测的新方法，通过去污和变量依赖建模实现了无监督的异常检测，对于实际场景中的异常检测具有重要意义。

    

    主流无监督异常检测算法通常在学术数据集中表现出色，但由于受到控制实验条件下的清洁训练数据的限制，它们在实际场景下的性能受到了限制。然而，在实际异常检测中，训练数据包含噪声的挑战经常被忽视。本研究在感知时间序列异常检测（TSAD）中深入研究了标签级噪声的领域。本文提出了一种新颖实用的端到端无监督TSAD方法，该方法处理训练数据中包含异常的情况下。该方法称为TSAD-C，其在训练阶段不需要访问异常标签。TSAD-C包括三个模块：一个去污器用于纠正训练数据中存在的异常（也称为噪声），一个变量依赖建模模块用于捕捉去污后数据中的长期内部和跨变量依赖关系，可以视为替代性的异常性度量方法。

    Mainstream unsupervised anomaly detection algorithms often excel in academic datasets, yet their real-world performance is restricted due to the controlled experimental conditions involving clean training data. Addressing the challenge of training with noise, a prevalent issue in practical anomaly detection, is frequently overlooked. In a pioneering endeavor, this study delves into the realm of label-level noise within sensory time-series anomaly detection (TSAD). This paper presents a novel and practical end-to-end unsupervised TSAD when the training data are contaminated with anomalies. The introduced approach, called TSAD-C, is devoid of access to abnormality labels during the training phase. TSAD-C encompasses three modules: a Decontaminator to rectify the abnormalities (aka noise) present in the training data, a Variable Dependency Modeling module to capture both long-term intra- and inter-variable dependencies within the decontaminated data that can be considered as a surrogate o
    
[^16]: 南佛罗里达州水位预测的深度学习模型

    Deep Learning Models for Water Stage Predictions in South Florida. (arXiv:2306.15907v1 [cs.LG])

    [http://arxiv.org/abs/2306.15907](http://arxiv.org/abs/2306.15907)

    本论文利用深度学习模型训练代理模型，快速预测南佛罗里达州迈阿密河下游的水位，并与基于物理的模型进行比较。

    

    模拟和预测河流系统的水位对于洪水警报、水力操作和洪水减轻至关重要。在工程领域中，使用HEC-RAS、MIKE和SWMM等工具建立详细的基于物理的水文和水力计算模型来模拟整个流域，从而预测系统中任意点的水位。然而，这些基于物理的模型计算量大，尤其对于大流域和长时间模拟来说。为了解决这个问题，我们训练了几个深度学习（DL）模型作为代理模型，快速预测水位。本文以南佛罗里达州迈阿密河的下游水位为案例研究。数据集来自南佛罗里达水管理区（SFWMD）的DBHYDRO数据库，时间跨度为2010年1月1日至2020年12月31日。广泛的实验表明，DL模型的性能与基于物理的模型相当。

    Simulating and predicting water levels in river systems is essential for flood warnings, hydraulic operations, and flood mitigations. In the engineering field, tools such as HEC-RAS, MIKE, and SWMM are used to build detailed physics-based hydrological and hydraulic computational models to simulate the entire watershed, thereby predicting the water stage at any point in the system. However, these physics-based models are computationally intensive, especially for large watersheds and for longer simulations. To overcome this problem, we train several deep learning (DL) models for use as surrogate models to rapidly predict the water stage. The downstream stage of the Miami River in South Florida is chosen as a case study for this paper. The dataset is from January 1, 2010, to December 31, 2020, downloaded from the DBHYDRO database of the South Florida Water Management District (SFWMD). Extensive experiments show that the performance of the DL models is comparable to that of the physics-bas
    
[^17]: 基于图的去中心化对抗性训练

    Decentralized Adversarial Training over Graphs. (arXiv:2303.13326v1 [cs.LG])

    [http://arxiv.org/abs/2303.13326](http://arxiv.org/abs/2303.13326)

    本文研究了在图上的去中心化对抗性训练，利用扩散学习的方法，开发了一种对抗性训练框架，增强了多个代理的鲁棒性以对抗攻击。

    

    近年来，机器学习模型对抗攻击的漏洞引起了广泛关注。大多数现有研究都集中在独立单一代理学习者的行为上。相比之下，本文研究了在图上的对抗性训练，其中各个单独的代理会受到空间中不同强度的扰动。预期通过链接代理和可能在图上实现的攻击模型的异质性，协调整个团队的强大协同作用可以帮助增强鲁棒性。本文使用扩散学习的极小-极大公式，为多代理系统开发了一种去中心化的对抗性训练框架。我们分析了该方案在凸和非凸环境下的收敛特性，并说明了增强的鲁棒性对抗攻击。

    The vulnerability of machine learning models to adversarial attacks has been attracting considerable attention in recent years. Most existing studies focus on the behavior of stand-alone single-agent learners. In comparison, this work studies adversarial training over graphs, where individual agents are subjected to perturbations of varied strength levels across space. It is expected that interactions by linked agents, and the heterogeneity of the attack models that are possible over the graph, can help enhance robustness in view of the coordination power of the group. Using a min-max formulation of diffusion learning, we develop a decentralized adversarial training framework for multi-agent systems. We analyze the convergence properties of the proposed scheme for both convex and non-convex environments, and illustrate the enhanced robustness to adversarial attacks.
    
[^18]: FedEBA+：基于熵的模型实现公平和有效联邦学习

    FedEBA+: Towards Fair and Effective Federated Learning via Entropy-Based Model. (arXiv:2301.12407v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.12407](http://arxiv.org/abs/2301.12407)

    FedEBA+是一种新的联邦学习算法，它采用公平聚合方案和对齐更新方法，在同时提高全局模型性能的同时提高公平性。实验证明FedEBA+优于其他公平性联邦学习方法。

    

    确保公平性是联邦学习中至关重要的方面，它使模型在所有客户端上保持一致表现。然而，设计一种可以同时提高全局模型性能和促进公平的联邦学习算法仍然是一个艰巨的挑战，因为实现后者通常需要与前者的权衡。为了解决这一问题，我们提出了一种新的联邦学习算法FedEBA+，它在同时提高全局模型性能的同时提高公平性，该算法采用公平聚合方案和对齐更新方法。此外，我们提供了理论收敛分析，证明了FedEBA+的公平性。大量实验表明FedEBA+在公平性和全局模型性能方面均优于其他SOTA的公平联邦学习方法。

    Ensuring fairness is a crucial aspect of Federated Learning (FL), which enables the model to perform consistently across all clients. However, designing an FL algorithm that simultaneously improves global model performance and promotes fairness remains a formidable challenge, as achieving the latter often necessitates a trade-off with the former.To address this challenge, we propose a new FL algorithm, FedEBA+, which enhances fairness while simultaneously improving global model performance. FedEBA+ incorporates a fair aggregation scheme that assigns higher weights to underperforming clients and an alignment update method. In addition, we provide theoretical convergence analysis and show the fairness of FedEBA+. Extensive experiments demonstrate that FedEBA+ outperforms other SOTA fairness FL methods in terms of both fairness and global model performance.
    

