# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Diffusion Denoising as a Certified Defense against Clean-label Poisoning](https://arxiv.org/abs/2403.11981) | 提出了一种扩散去噪作为针对干净标签中毒的认证防御，能将攻击成功率降低到0-16%，同时几乎不影响测试准确性，为未来开发更强干净标签攻击和利用该防御措施作为强有力基础提供了重要启示。 |
| [^2] | [CleanAgent: Automating Data Standardization with LLM-based Agents](https://arxiv.org/abs/2403.08291) | 提出了一个具有声明性、统一API的Python库，通过简洁的API调用简化LLM的代码生成流程 |
| [^3] | [Data-Efficient Operator Learning via Unsupervised Pretraining and In-Context Learning](https://arxiv.org/abs/2402.15734) | 该论文提出了一种通过无监督预训练和上下文学习方法实现PDE运算符学习的高效方式，以提高数据效率并改善模型的外域性能。 |
| [^4] | [Online Control of Linear Systems with Unbounded and Degenerate Noise](https://arxiv.org/abs/2402.10252) | 这项研究揭示了在线控制问题中，对于凸成本，可以实现 $ \widetilde{O}(\sqrt{T}) $ 的遗憾界，甚至在存在无界噪声的情况下；同时，在成本具有强凸性时，可以在不需要噪声协方差是非退化的情况下建立 $ O({\rm poly} (\log T)) $ 的遗憾界。 |
| [^5] | [Gradient-flow adaptive importance sampling for Bayesian leave one out cross-validation for sigmoidal classification models](https://arxiv.org/abs/2402.08151) | 本研究引入了渐变流自适应重要性抽样的方法，用于稳定贝叶斯分类模型的留一交叉验证预测的蒙特卡罗近似，以评估模型的普适性。 |
| [^6] | [Generalization Bounds for Heavy-Tailed SDEs through the Fractional Fokker-Planck Equation](https://arxiv.org/abs/2402.07723) | 本论文通过分数阻尼库仑方程证明了重尾SDE的高概率泛化界限，并且相对于参数维度，界限的依赖性要好于p。 |
| [^7] | [On Calibration and Conformal Prediction of Deep Classifiers](https://arxiv.org/abs/2402.05806) | 本文研究了温度缩放对符合预测方法的影响，通过实证研究发现，校准对自适应C方法产生了有害的影响。 |
| [^8] | [PreGIP: Watermarking the Pretraining of Graph Neural Networks for Deep Intellectual Property Protection](https://arxiv.org/abs/2402.04435) | PreGIP是针对深度知识产权保护的一种图神经网络预训练水印技术，它通过添加无任务的水印损失来给预训练的GNN编码器的嵌入空间添加水印，并采用抗微调的水印注入方法 |
| [^9] | [Enhancing Score-Based Sampling Methods with Ensembles](https://arxiv.org/abs/2401.17539) | 这项研究通过引入集成方法来增强基于分数的抽样方法，成功开发了一种利用粒子集合动态计算近似反扩散漂移的无梯度抽样技术，并在多个示例中展示了其有效性，包括对复杂概率分布的建模和在地球物理科学中的应用。 |
| [^10] | [Multilingual Text-to-Image Generation Magnifies Gender Stereotypes and Prompt Engineering May Not Help You](https://arxiv.org/abs/2401.16092) | 多语言文本到图像生成模型存在性别偏见；通过MAGBIG评估模型时，发现模型对不同语言具有重要差异；我们呼吁研究多语言模型领域消除性别偏见。 |
| [^11] | [Don't Push the Button! Exploring Data Leakage Risks in Machine Learning and Transfer Learning.](http://arxiv.org/abs/2401.13796) | 本文讨论了机器学习中的数据泄露问题，即未预期的信息污染训练数据，影响模型性能评估，用户可能由于缺乏理解而忽视关键步骤，导致乐观的性能估计在实际场景中不成立。 |
| [^12] | [CCFC: Bridging Federated Clustering and Contrastive Learning.](http://arxiv.org/abs/2401.06634) | 本论文桥接了联邦聚类和对比学习，提出了一种名为CCFC的新联邦聚类方法。通过表示学习，CCFC在某些情况下聚类性能甚至是最佳基准方法的两倍。与最相关的基准方法相比，在最显著的案例中，CCFC的NMI得分提高了0.4155。同时，CCFC还能有效处理联邦场景下的数据分布和质量差异。 |
| [^13] | [Sampling and Uniqueness Sets in Graphon Signal Processing.](http://arxiv.org/abs/2401.06279) | 本论文研究了大规模图谱族上的采样集特性，并将“可移除集合”和“唯一性集合”的概念推广到了图谱信号处理中。通过利用图谱表示法，可以比较具有不同节点数和边数以及不同节点标记的图谱之间的采样集，并证明了具有相同图谱表示的采样集序列的收敛性。 |
| [^14] | [CAFE: Conflict-Aware Feature-wise Explanations.](http://arxiv.org/abs/2310.20363) | CAFE是一种冲突感知的特征解释方法，通过解决现有方法的局限性，提供了对特征冲突的增强鲁棒性和更好的解释能力。 |
| [^15] | [Learning Successor Representations with Distributed Hebbian Temporal Memory.](http://arxiv.org/abs/2310.13391) | 本文提出了一种名为DHTM的算法，它基于因子图形式和多组成神经元模型，利用分布式表示、稀疏转移矩阵和局部Hebbian样学习规则来解决在线隐藏表示学习的挑战。实验结果表明，DHTM在变化的环境中比经典的LSTM效果更好，并与更先进的类似RNN的算法性能相当，可以加速继任者表示的时间差异学习。 |
| [^16] | [Advective Diffusion Transformers for Topological Generalization in Graph Learning.](http://arxiv.org/abs/2310.06417) | 本研究探索了在不同的图拓扑存在下，图扩散方程如何对GNN进行外推和概括，揭示了基于局部扩散的现有模型在概括能力上的不足，并提出了非局部扩散的潜力。 |
| [^17] | [Discovering the Interpretability-Performance Pareto Front of Decision Trees with Dynamic Programming.](http://arxiv.org/abs/2309.12701) | 本文提出了一种使用动态规划找到最优决策树的方法，可以得到多个可解释性-性能权衡的最优决策树，使用户可以根据自己的需求选择最适合的树。 |
| [^18] | [Distribution-Free Inference for the Regression Function of Binary Classification.](http://arxiv.org/abs/2308.01835) | 本文提出了一种分布无关的方法来推断二元分类问题中的回归函数，通过构建置信区间来解决该问题，相关算法经过验证具有可靠性。 |
| [^19] | [Fact-Checking of AI-Generated Reports.](http://arxiv.org/abs/2307.14634) | 本文提出了一种使用相关联的图像对AI生成报告进行事实核查的新方法，以区分报告中的真假句子。这对加快临床工作流程，提高准确性并降低总体成本具有重要意义。 |
| [^20] | [Kernel $\epsilon$-Greedy for Contextual Bandits.](http://arxiv.org/abs/2306.17329) | 本文提出了基于核的$\epsilon$-贪心策略应用于情境脉冲中的方法，通过在线加权核岭回归估计器实现对奖励函数的估计，并证明了其一致性和依赖于RKHS维度的次线性后悔率，在有限维RKHS的边际条件下实现了最优后悔率。 |
| [^21] | [Time Series Classification for Detecting Parkinson's Disease from Wrist Motions.](http://arxiv.org/abs/2304.11265) | 该研究使用InceptionTime和ROCKET方法进行时间序列分类，以监测帕金森病患者的手腕运动。研究发现，所有方法都适用于估计震颤严重程度和肌肉强直的存在，但在检测运动障碍方面存在困难。具有岭分类器的InceptionTime方法展示了最先进的分类性能，显示时间序列分类在基于可穿戴设备的PD症状监测中具有潜力。 |
| [^22] | [A Neural Lambda Calculus: Neurosymbolic AI meets the foundations of computing and functional programming.](http://arxiv.org/abs/2304.09276) | 本文提出了一种神经λ演算法，使用λ语言编程，研究神经网络在执行整个程序的能力，旨在拓展神经网络在符号人工智能领域的应用。 |
| [^23] | [Efficient distributed representations beyond negative sampling.](http://arxiv.org/abs/2303.17475) | 本文介绍了一种高效的分布式表示（嵌入）学习方法，通过线性时间估计softmax归一化常数来实现学习过程，该方法优于负采样方法并在多项测试中验证了其有效性。 |

# 详细

[^1]: 扩散去噪作为一种针对干净标签中毒的认证防御

    Diffusion Denoising as a Certified Defense against Clean-label Poisoning

    [https://arxiv.org/abs/2403.11981](https://arxiv.org/abs/2403.11981)

    提出了一种扩散去噪作为针对干净标签中毒的认证防御，能将攻击成功率降低到0-16%，同时几乎不影响测试准确性，为未来开发更强干净标签攻击和利用该防御措施作为强有力基础提供了重要启示。

    

    我们提出了一种针对干净标签中毒攻击的认证防御方法。这些攻击通过向训练数据中注入少量的毒害样本（例如1%），其中包含$p$-范数受限的对抗性扰动，从而诱导对测试输入的目标误分类。受到$去噪平滑$实现的对抗鲁棒性的启发，我们展示了如何使用一个现成的扩散模型对篡改的训练数据进行消毒。我们广泛测试了我们的防御措施对七种干净标签中毒攻击的防护效果，并且将它们的攻击成功率降低到0-16%，同时测试准确性几乎没有下降。我们将我们的防御与现有的针对干净标签中毒的对策进行比较，显示出我们的防御效果最佳，并提供最佳的模型效用。我们的结果凸显了未来需要开展更强大的干净标签攻击并使用我们的认证但实用的防御作为稳固基础的必要性。

    arXiv:2403.11981v1 Announce Type: cross  Abstract: We present a certified defense to clean-label poisoning attacks. These attacks work by injecting a small number of poisoning samples (e.g., 1%) that contain $p$-norm bounded adversarial perturbations into the training data to induce a targeted misclassification of a test-time input. Inspired by the adversarial robustness achieved by $denoised$ $smoothing$, we show how an off-the-shelf diffusion model can sanitize the tampered training data. We extensively test our defense against seven clean-label poisoning attacks and reduce their attack success to 0-16% with only a negligible drop in the test time accuracy. We compare our defense with existing countermeasures against clean-label poisoning, showing that the defense reduces the attack success the most and offers the best model utility. Our results highlight the need for future work on developing stronger clean-label attacks and using our certified yet practical defense as a strong base
    
[^2]: CleanAgent：基于LLM代理自动化数据标准化

    CleanAgent: Automating Data Standardization with LLM-based Agents

    [https://arxiv.org/abs/2403.08291](https://arxiv.org/abs/2403.08291)

    提出了一个具有声明性、统一API的Python库，通过简洁的API调用简化LLM的代码生成流程

    

    数据标准化是数据科学生命周期中至关重要的一部分。虽然诸如Pandas之类的工具提供了强大的功能，但它们的复杂性以及需要定制代码以适应不同列类型的手动操作带来了重大挑战。尽管大型语言模型（LLMs）如ChatGPT已经展现出通过自然语言理解和代码生成自动化此过程的潜力，但仍需要专业程度的编程知识和持续互动以进行及时的完善。为了解决这些挑战，我们的关键想法是提出一个具有声明性、统一API的Python库，用于标准化列类型，通过简洁的API调用简化LLM的代码生成流程。我们首先提出了Dataprep.Clean，作为Dataprep库的一个组件，通过一行代码实现特定列类型的标准化，极大降低了复杂性。然后我们介绍了CleanAgen

    arXiv:2403.08291v1 Announce Type: cross  Abstract: Data standardization is a crucial part in data science life cycle. While tools like Pandas offer robust functionalities, their complexity and the manual effort required for customizing code to diverse column types pose significant challenges. Although large language models (LLMs) like ChatGPT have shown promise in automating this process through natural language understanding and code generation, it still demands expert-level programming knowledge and continuous interaction for prompt refinement. To solve these challenges, our key idea is to propose a Python library with declarative, unified APIs for standardizing column types, simplifying the code generation of LLM with concise API calls. We first propose Dataprep.Clean which is written as a component of the Dataprep Library, offers a significant reduction in complexity by enabling the standardization of specific column types with a single line of code. Then we introduce the CleanAgen
    
[^3]: 通过无监督预训练和上下文学习实现高效的运算符学习

    Data-Efficient Operator Learning via Unsupervised Pretraining and In-Context Learning

    [https://arxiv.org/abs/2402.15734](https://arxiv.org/abs/2402.15734)

    该论文提出了一种通过无监督预训练和上下文学习方法实现PDE运算符学习的高效方式，以提高数据效率并改善模型的外域性能。

    

    近年来，人们见证了将机器学习方法与物理领域特定洞察力相结合，以解决基于偏微分方程（PDEs）的科学问题的潜力。然而，由于数据密集，这些方法仍然需要大量PDE数据。 这重新引入了对昂贵的数值PDE解决方案的需求，部分削弱了避免这些昂贵模拟的原始目标。 在这项工作中，为了寻求数据效率，我们设计了用于PDE运算符学习的无监督预训练和上下文学习方法。 为了减少对带有模拟解的训练数据的需求，我们使用基于重构的代理任务在未标记的PDE数据上预训练神经运算符。 为了提高超出分布性能，我们进一步帮助神经运算符灵活地利用上下文学习方法，而无需额外的训练成本或设计。 在各种PD上进行了大量实证评估

    arXiv:2402.15734v1 Announce Type: new  Abstract: Recent years have witnessed the promise of coupling machine learning methods and physical domain-specific insight for solving scientific problems based on partial differential equations (PDEs). However, being data-intensive, these methods still require a large amount of PDE data. This reintroduces the need for expensive numerical PDE solutions, partially undermining the original goal of avoiding these expensive simulations. In this work, seeking data efficiency, we design unsupervised pretraining and in-context learning methods for PDE operator learning. To reduce the need for training data with simulated solutions, we pretrain neural operators on unlabeled PDE data using reconstruction-based proxy tasks. To improve out-of-distribution performance, we further assist neural operators in flexibly leveraging in-context learning methods, without incurring extra training costs or designs. Extensive empirical evaluations on a diverse set of PD
    
[^4]: 具有无界和退化噪声的线性系统在线控制

    Online Control of Linear Systems with Unbounded and Degenerate Noise

    [https://arxiv.org/abs/2402.10252](https://arxiv.org/abs/2402.10252)

    这项研究揭示了在线控制问题中，对于凸成本，可以实现 $ \widetilde{O}(\sqrt{T}) $ 的遗憾界，甚至在存在无界噪声的情况下；同时，在成本具有强凸性时，可以在不需要噪声协方差是非退化的情况下建立 $ O({\rm poly} (\log T)) $ 的遗憾界。

    

    本文研究了在可能存在无界和退化噪声的情况下控制线性系统的问题，其中成本函数未知，被称为在线控制问题。与现有的仅假设噪声有界性的研究不同，我们揭示了对于凸成本，即使在存在无界噪声的情况下也可以实现 $ \widetilde{O}(\sqrt{T}) $ 的遗憾界，其中 $ T $ 表示时间跨度。此外，当成本具有强凸性时，我们建立了一个 $ O({\rm poly} (\log T)) $ 的遗憾界，而不需要噪声协方差是非退化的假设，这在文献中是必需的。消除噪声秩的关键是与噪声协方差相关联的系统转化。这同时实现了在线控制算法的参数减少。

    arXiv:2402.10252v1 Announce Type: cross  Abstract: This paper investigates the problem of controlling a linear system under possibly unbounded and degenerate noise with unknown cost functions, known as an online control problem. In contrast to the existing work, which assumes the boundedness of noise, we reveal that for convex costs, an $ \widetilde{O}(\sqrt{T}) $ regret bound can be achieved even for unbounded noise, where $ T $ denotes the time horizon. Moreover, when the costs are strongly convex, we establish an $ O({\rm poly} (\log T)) $ regret bound without the assumption that noise covariance is non-degenerate, which has been required in the literature. The key ingredient in removing the rank assumption on noise is a system transformation associated with the noise covariance. This simultaneously enables the parameter reduction of an online control algorithm.
    
[^5]: 渐变流自适应重要性抽样用于sigmoid分类模型的贝叶斯留一交叉验证

    Gradient-flow adaptive importance sampling for Bayesian leave one out cross-validation for sigmoidal classification models

    [https://arxiv.org/abs/2402.08151](https://arxiv.org/abs/2402.08151)

    本研究引入了渐变流自适应重要性抽样的方法，用于稳定贝叶斯分类模型的留一交叉验证预测的蒙特卡罗近似，以评估模型的普适性。

    

    我们引入了一组梯度流引导的自适应重要性抽样（IS）变换，用于稳定贝叶斯分类模型的点级留一交叉验证（LOO）预测的蒙特卡罗近似。可以利用这种方法来评估模型的普适性，例如计算与AIC类似的LOO或计算LOO ROC / PRC曲线以及派生的度量指标，如AUROC和AUPRC。通过变分法和梯度流，我们推导出两个简单的非线性单步变换，利用梯度信息将模型的预训练完整数据后验靠近目标LOO后验预测分布。这样，变换稳定了重要性权重。因为变换涉及到似然函数的梯度，所以结果的蒙特卡罗积分依赖于模型Hessian的Jacobian行列式。我们推导出了这些Jacobian行列式的闭合精确公式。

    We introduce a set of gradient-flow-guided adaptive importance sampling (IS) transformations to stabilize Monte-Carlo approximations of point-wise leave one out cross-validated (LOO) predictions for Bayesian classification models. One can leverage this methodology for assessing model generalizability by for instance computing a LOO analogue to the AIC or computing LOO ROC/PRC curves and derived metrics like the AUROC and AUPRC. By the calculus of variations and gradient flow, we derive two simple nonlinear single-step transformations that utilize gradient information to shift a model's pre-trained full-data posterior closer to the target LOO posterior predictive distributions. In doing so, the transformations stabilize importance weights. Because the transformations involve the gradient of the likelihood function, the resulting Monte Carlo integral depends on Jacobian determinants with respect to the model Hessian. We derive closed-form exact formulae for these Jacobian determinants in
    
[^6]: 通过分数阻尼库仑方程证明重尾SDEs的泛化界限

    Generalization Bounds for Heavy-Tailed SDEs through the Fractional Fokker-Planck Equation

    [https://arxiv.org/abs/2402.07723](https://arxiv.org/abs/2402.07723)

    本论文通过分数阻尼库仑方程证明了重尾SDE的高概率泛化界限，并且相对于参数维度，界限的依赖性要好于p。

    

    过去几年来，理解重尾随机优化算法的泛化性能引起了越来越多的关注。在利用重尾随机微分方程作为代理来阐明随机优化器的有趣方面时，先前的工作要么提供预期的泛化界限，要么引入了不可计算的信息论术语。为了解决这些缺点，在本文中，我们证明了重尾SDE的高概率泛化界限，这些界限不含任何非平凡的信息论术语。为了实现这个目标，我们基于估计与所谓的分数阻尼库仑方程相关联的熵流，开发了新的证明技术（这是一种控制相应重尾SDE分布演化的偏微分方程）。除了获得高概率界限之外，我们还展示了我们的界限相对于参数维度的依赖性要好于p。

    Understanding the generalization properties of heavy-tailed stochastic optimization algorithms has attracted increasing attention over the past years. While illuminating interesting aspects of stochastic optimizers by using heavy-tailed stochastic differential equations as proxies, prior works either provided expected generalization bounds, or introduced non-computable information theoretic terms. Addressing these drawbacks, in this work, we prove high-probability generalization bounds for heavy-tailed SDEs which do not contain any nontrivial information theoretic terms. To achieve this goal, we develop new proof techniques based on estimating the entropy flows associated with the so-called fractional Fokker-Planck equation (a partial differential equation that governs the evolution of the distribution of the corresponding heavy-tailed SDE). In addition to obtaining high-probability bounds, we show that our bounds have a better dependence on the dimension of parameters as compared to p
    
[^7]: 关于深度分类器的校准和符合预测研究

    On Calibration and Conformal Prediction of Deep Classifiers

    [https://arxiv.org/abs/2402.05806](https://arxiv.org/abs/2402.05806)

    本文研究了温度缩放对符合预测方法的影响，通过实证研究发现，校准对自适应C方法产生了有害的影响。

    

    在许多分类应用中，深度神经网络（DNN）基于分类器的预测需要伴随一些置信度指示。针对这个目标，有两种流行的后处理方法：1）校准：修改分类器的softmax值，使其最大值（与预测相关）更好地估计正确概率；和2）符合预测（CP）：设计一个基于softmax值的分数，从中产生一组预测，具有理论上保证正确类别边际覆盖的特性。尽管在实践中两种指示都可能是需要的，但到目前为止它们之间的相互作用尚未得到研究。为了填补这一空白，在本文中，我们研究了温度缩放，这是最常见的校准技术，对重要的CP方法的影响。我们首先进行了一项广泛的实证研究，其中显示了一些重要的洞察，其中包括令人惊讶的发现，即校准对流行的自适应C方法产生了有害的影响。

    In many classification applications, the prediction of a deep neural network (DNN) based classifier needs to be accompanied with some confidence indication. Two popular post-processing approaches for that aim are: 1) calibration: modifying the classifier's softmax values such that their maximum (associated with the prediction) better estimates the correctness probability; and 2) conformal prediction (CP): devising a score (based on the softmax values) from which a set of predictions with theoretically guaranteed marginal coverage of the correct class is produced. While in practice both types of indications can be desired, so far the interplay between them has not been investigated. Toward filling this gap, in this paper we study the effect of temperature scaling, arguably the most common calibration technique, on prominent CP methods. We start with an extensive empirical study that among other insights shows that, surprisingly, calibration has a detrimental effect on popular adaptive C
    
[^8]: PreGIP: 针对深度知识产权保护的图神经网络预训练水印技术

    PreGIP: Watermarking the Pretraining of Graph Neural Networks for Deep Intellectual Property Protection

    [https://arxiv.org/abs/2402.04435](https://arxiv.org/abs/2402.04435)

    PreGIP是针对深度知识产权保护的一种图神经网络预训练水印技术，它通过添加无任务的水印损失来给预训练的GNN编码器的嵌入空间添加水印，并采用抗微调的水印注入方法

    

    图神经网络（GNNs）的预训练在促进各种下游任务中显示出巨大的能力。由于预训练通常需要大量的数据和计算资源，预训练的GNNs成为合法拥有者的高价值知识产权（IP）。然而，对手可能会非法复制和部署预训练的GNN模型用于其下游任务。虽然已经开始尝试为IP保护添加GNN分类器的水印，但这些方法需要目标分类任务才能进行水印处理，因此不适用于GNN模型的自监督预训练。因此，在这项工作中，我们提出了一个新框架PreGIP，用于在保持嵌入空间高质量的同时，给GNN编码器的预训练添加水印以进行IP保护。PreGIP引入了无任务的水印损失来给预训练的GNN编码器的嵌入空间添加水印。同时采用了抗微调的水印注入方法。我们还进行了理论分析和扩展实验证明了方法的有效性和鲁棒性。

    Pretraining on Graph Neural Networks (GNNs) has shown great power in facilitating various downstream tasks. As pretraining generally requires huge amount of data and computational resources, the pretrained GNNs are high-value Intellectual Properties (IP) of the legitimate owner. However, adversaries may illegally copy and deploy the pretrained GNN models for their downstream tasks. Though initial efforts have been made to watermark GNN classifiers for IP protection, these methods require the target classification task for watermarking, and thus are not applicable to self-supervised pretraining of GNN models. Hence, in this work, we propose a novel framework named PreGIP to watermark the pretraining of GNN encoder for IP protection while maintain the high-quality of the embedding space. PreGIP incorporates a task-free watermarking loss to watermark the embedding space of pretrained GNN encoder. A finetuning-resistant watermark injection is further deployed. Theoretical analysis and exte
    
[^9]: 用集成方法增强基于分数的抽样方法

    Enhancing Score-Based Sampling Methods with Ensembles

    [https://arxiv.org/abs/2401.17539](https://arxiv.org/abs/2401.17539)

    这项研究通过引入集成方法来增强基于分数的抽样方法，成功开发了一种利用粒子集合动态计算近似反扩散漂移的无梯度抽样技术，并在多个示例中展示了其有效性，包括对复杂概率分布的建模和在地球物理科学中的应用。

    

    我们在基于分数的抽样方法中引入了集成方法，以开发利用粒子集合动态计算近似反扩散漂移的无梯度抽样技术。我们介绍了底层方法，并强调它与生成扩散模型和先前介绍的Föllmer抽样器的关系。我们通过各种示例证明了集成策略的有效性，涵盖了从低维到中等维度的抽样问题，包括多峰和高度非高斯概率分布，并与传统方法如NUTS进行比较。我们的发现突出了在梯度不可用的情况下，集成策略在建模复杂概率分布方面的潜力。最后，我们展示了在地球物理科学的贝叶斯反演问题中的应用。

    We introduce ensembles within score-based sampling methods to develop gradient-free approximate sampling techniques that leverage the collective dynamics of particle ensembles to compute approximate reverse diffusion drifts. We introduce the underlying methodology, emphasizing its relationship with generative diffusion models and the previously introduced F\"ollmer sampler. We demonstrate the efficacy of ensemble strategies through various examples, ranging from low- to medium-dimensionality sampling problems, including multi-modal and highly non-Gaussian probability distributions, and provide comparisons to traditional methods like NUTS. Our findings highlight the potential of ensemble strategies for modeling complex probability distributions in situations where gradients are unavailable. Finally, we showcase its application in the context of Bayesian inversion problems within the geophysical sciences.
    
[^10]: 多语言文本到图像生成放大了性别刻板印象，并且修正工程可能无法帮助您

    Multilingual Text-to-Image Generation Magnifies Gender Stereotypes and Prompt Engineering May Not Help You

    [https://arxiv.org/abs/2401.16092](https://arxiv.org/abs/2401.16092)

    多语言文本到图像生成模型存在性别偏见；通过MAGBIG评估模型时，发现模型对不同语言具有重要差异；我们呼吁研究多语言模型领域消除性别偏见。

    

    最近，文本到图像生成模型在图像质量、灵活性和文本对齐方面取得了令人惊讶的结果，并因此在越来越多的应用中得到应用。通过改善多语言能力，更多的社群现在可以访问这种技术。然而，正如我们将展示的那样，多语言模型与单语模型一样受到(性别)偏见的困扰。此外，人们自然期望这些模型在不同语言之间提供类似的结果，但事实并非如此，不同语言之间存在重要的差异。因此，我们提出了一个旨在促进没有性别偏见的多语言模型研究的新基准MAGBIG。我们研究了多语言T2I模型是否通过MAGBIG放大了性别偏见。为此，我们使用多语言提示请求特定职业或特质的人像图像(使用形容词)。我们的结果不仅表明模型偏离了规范的假设，...

    Text-to-image generation models have recently achieved astonishing results in image quality, flexibility, and text alignment and are consequently employed in a fast-growing number of applications. Through improvements in multilingual abilities, a larger community now has access to this kind of technology. Yet, as we will show, multilingual models suffer similarly from (gender) biases as monolingual models. Furthermore, the natural expectation is that these models will provide similar results across languages, but this is not the case and there are important differences between languages. Thus, we propose a novel benchmark MAGBIG intending to foster research in multilingual models without gender bias. We investigate whether multilingual T2I models magnify gender bias with MAGBIG. To this end, we use multilingual prompts requesting portrait images of persons of a certain occupation or trait (using adjectives). Our results show not only that models deviate from the normative assumption th
    
[^11]: 不要按按钮！探索机器学习和迁移学习中的数据泄露风险

    Don't Push the Button! Exploring Data Leakage Risks in Machine Learning and Transfer Learning. (arXiv:2401.13796v1 [cs.LG])

    [http://arxiv.org/abs/2401.13796](http://arxiv.org/abs/2401.13796)

    本文讨论了机器学习中的数据泄露问题，即未预期的信息污染训练数据，影响模型性能评估，用户可能由于缺乏理解而忽视关键步骤，导致乐观的性能估计在实际场景中不成立。

    

    机器学习（ML）在各个领域取得了革命性的进展，为多个领域提供了预测能力。然而，随着ML工具的日益可获得性，许多从业者缺乏深入的ML专业知识，采用了“按按钮”方法，利用用户友好的界面而忽视了底层算法的深入理解。虽然这种方法提供了便利，但它引发了对结果可靠性的担忧，导致了错误的性能评估等挑战。本文解决了ML中的一个关键问题，即数据泄露，其中未预期的信息污染了训练数据，影响了模型的性能评估。由于缺乏理解，用户可能会无意中忽视关键步骤，从而导致在现实场景中可能不成立的乐观性能估计。评估性能与实际在新数据上的性能的差异是一个重要的关注点。本文特别将ML中的数据泄露分为不同类别，并讨论了相关解决方法。

    Machine Learning (ML) has revolutionized various domains, offering predictive capabilities in several areas. However, with the increasing accessibility of ML tools, many practitioners, lacking deep ML expertise, adopt a "push the button" approach, utilizing user-friendly interfaces without a thorough understanding of underlying algorithms. While this approach provides convenience, it raises concerns about the reliability of outcomes, leading to challenges such as incorrect performance evaluation. This paper addresses a critical issue in ML, known as data leakage, where unintended information contaminates the training data, impacting model performance evaluation. Users, due to a lack of understanding, may inadvertently overlook crucial steps, leading to optimistic performance estimates that may not hold in real-world scenarios. The discrepancy between evaluated and actual performance on new data is a significant concern. In particular, this paper categorizes data leakage in ML, discussi
    
[^12]: CCFC：桥接联邦聚类和对比学习

    CCFC: Bridging Federated Clustering and Contrastive Learning. (arXiv:2401.06634v1 [cs.LG])

    [http://arxiv.org/abs/2401.06634](http://arxiv.org/abs/2401.06634)

    本论文桥接了联邦聚类和对比学习，提出了一种名为CCFC的新联邦聚类方法。通过表示学习，CCFC在某些情况下聚类性能甚至是最佳基准方法的两倍。与最相关的基准方法相比，在最显著的案例中，CCFC的NMI得分提高了0.4155。同时，CCFC还能有效处理联邦场景下的数据分布和质量差异。

    

    联邦聚类是对于联邦场景中集中聚类的重要扩展，可以让多个数据持有客户端在保留本地数据的同时协同进行数据分组。在集中场景中，通过表示学习驱动的聚类在处理高维复杂数据方面取得了重大进展。然而，联邦聚类和表示学习的结合仍然未被充分研究。为了弥合这一差距，我们首先为学习聚类友好的表示定制了一个聚类对比模型。然后，我们利用这个模型作为提出新的联邦聚类方法的基础，称为聚类对比联邦聚类（CCFC）。受益于表示学习，CCFC的聚类性能在某些情况下甚至是最佳基准方法的两倍。与最相关的基准方法相比，在最显著的案例中，这种收益导致NMI得分的显著提高，最高达到0.4155。此外，CCFC还可以有效地处理在联邦场景下出现的数据分布和质量差异。

    Federated clustering, an essential extension of centralized clustering for federated scenarios, enables multiple data-holding clients to collaboratively group data while keeping their data locally. In centralized scenarios, clustering driven by representation learning has made significant advancements in handling high-dimensional complex data. However, the combination of federated clustering and representation learning remains underexplored. To bridge this, we first tailor a cluster-contrastive model for learning clustering-friendly representations. Then, we harness this model as the foundation for proposing a new federated clustering method, named cluster-contrastive federated clustering (CCFC). Benefiting from representation learning, the clustering performance of CCFC even double those of the best baseline methods in some cases. Compared to the most related baseline, the benefit results in substantial NMI score improvements of up to 0.4155 on the most conspicuous case. Moreover, CCF
    
[^13]: 图谱信号处理中的采样和唯一性集

    Sampling and Uniqueness Sets in Graphon Signal Processing. (arXiv:2401.06279v1 [cs.LG])

    [http://arxiv.org/abs/2401.06279](http://arxiv.org/abs/2401.06279)

    本论文研究了大规模图谱族上的采样集特性，并将“可移除集合”和“唯一性集合”的概念推广到了图谱信号处理中。通过利用图谱表示法，可以比较具有不同节点数和边数以及不同节点标记的图谱之间的采样集，并证明了具有相同图谱表示的采样集序列的收敛性。

    

    在这项工作中，我们通过利用图谱和图极限的理论，研究了大规模图谱族上采样集的特性。为此，我们将“可移除集合”和“唯一性集合”的概念扩展到了图谱信号领域，这些概念最初是用于分析图谱上的信号的。我们给出了$\Lambda-$可移除集合的正式定义，并在得到从图谱中一个给定$\Lambda-$可移除集合的补集中的样本时，给出了一个频带有限的图谱信号可以以唯一方式表示的条件。通过利用这些结果，我们证明了图谱表示法可以作为一种共同的框架来比较具有不同节点数和边数以及不同节点标记的图谱之间的采样集。此外，对于收敛到一个图谱的图序列，我们还证明了具有相同$[0,1]$中图谱表示的采样集序列也是收敛的。我们利用这种收敛性。

    In this work, we study the properties of sampling sets on families of large graphs by leveraging the theory of graphons and graph limits. To this end, we extend to graphon signals the notion of removable and uniqueness sets, which was developed originally for the analysis of signals on graphs. We state the formal definition of a $\Lambda-$removable set and conditions under which a bandlimited graphon signal can be represented in a unique way when its samples are obtained from the complement of a given $\Lambda-$removable set in the graphon. By leveraging such results we show that graphon representations of graphs and graph signals can be used as a common framework to compare sampling sets between graphs with different numbers of nodes and edges, and different node labelings. Additionally, given a sequence of graphs that converges to a graphon, we show that the sequences of sampling sets whose graphon representation is identical in $[0,1]$ are convergent as well. We exploit the converge
    
[^14]: CAFE: 冲突感知的特征解释

    CAFE: Conflict-Aware Feature-wise Explanations. (arXiv:2310.20363v1 [cs.LG])

    [http://arxiv.org/abs/2310.20363](http://arxiv.org/abs/2310.20363)

    CAFE是一种冲突感知的特征解释方法，通过解决现有方法的局限性，提供了对特征冲突的增强鲁棒性和更好的解释能力。

    

    特征归因方法被广泛用于解释神经模型，通过确定单个输入特征对模型输出的影响来解释模型。我们提出了一种新颖的特征归因方法，CAFE（冲突感知的特征解释），它解决了现有方法的三个局限性：对冲突特征影响的忽视，对偏差项影响的缺乏考虑，以及对激活函数局部变化过于敏感。与其他方法不同，CAFE提供了防止高估神经元输入影响的保护机制，并单独追踪输入特征和偏差的正向和负向影响，从而增强了稳健性和发现特征冲突的能力。实验证明，CAFE在合成表格数据上能更好地识别冲突特征，并在几个真实世界的表格数据集上展现了最佳的全面可信度，而计算性能也很高。

    Feature attribution methods are widely used to explain neural models by determining the influence of individual input features on the models' outputs. We propose a novel feature attribution method, CAFE (Conflict-Aware Feature-wise Explanations), that addresses three limitations of the existing methods: their disregard for the impact of conflicting features, their lack of consideration for the influence of bias terms, and an overly high sensitivity to local variations in the underpinning activation functions. Unlike other methods, CAFE provides safeguards against overestimating the effects of neuron inputs and separately traces positive and negative influences of input features and biases, resulting in enhanced robustness and increased ability to surface feature conflicts. We show experimentally that CAFE is better able to identify conflicting features on synthetic tabular data and exhibits the best overall fidelity on several real-world tabular datasets, while being highly computation
    
[^15]: 使用分布式Hebbian Temporal Memory学习继任者表示法

    Learning Successor Representations with Distributed Hebbian Temporal Memory. (arXiv:2310.13391v1 [cs.LG])

    [http://arxiv.org/abs/2310.13391](http://arxiv.org/abs/2310.13391)

    本文提出了一种名为DHTM的算法，它基于因子图形式和多组成神经元模型，利用分布式表示、稀疏转移矩阵和局部Hebbian样学习规则来解决在线隐藏表示学习的挑战。实验结果表明，DHTM在变化的环境中比经典的LSTM效果更好，并与更先进的类似RNN的算法性能相当，可以加速继任者表示的时间差异学习。

    

    本文提出了一种新颖的方法来解决在线隐藏表示学习的挑战，该方法用于在不稳定的、部分可观测的环境中进行决策。所提出的算法，分布式Hebbian Temporal Memory (DHTM)，基于因子图形式和多组成神经元模型。DHTM旨在捕捉顺序数据关系并对未来观察作出累积预测，形成继任者表示。受新皮层的神经生理学模型启发，该算法利用分布式表示、稀疏转移矩阵和局部Hebbian样学习规则克服了传统时间记忆算法（如RNN和HMM）的不稳定性和慢速学习过程。实验结果表明，DHTM优于经典的LSTM，并与更先进的类似RNN的算法性能相当，在变化的环境中加速了继任者表示的时间差异学习。此外，我们还进行了比较。

    This paper presents a novel approach to address the challenge of online hidden representation learning for decision-making under uncertainty in non-stationary, partially observable environments. The proposed algorithm, Distributed Hebbian Temporal Memory (DHTM), is based on factor graph formalism and a multicomponent neuron model. DHTM aims to capture sequential data relationships and make cumulative predictions about future observations, forming Successor Representation (SR). Inspired by neurophysiological models of the neocortex, the algorithm utilizes distributed representations, sparse transition matrices, and local Hebbian-like learning rules to overcome the instability and slow learning process of traditional temporal memory algorithms like RNN and HMM. Experimental results demonstrate that DHTM outperforms classical LSTM and performs comparably to more advanced RNN-like algorithms, speeding up Temporal Difference learning for SR in changing environments. Additionally, we compare
    
[^16]: 用于图学习中的拓扑概括的流动扩散变压器

    Advective Diffusion Transformers for Topological Generalization in Graph Learning. (arXiv:2310.06417v1 [cs.LG])

    [http://arxiv.org/abs/2310.06417](http://arxiv.org/abs/2310.06417)

    本研究探索了在不同的图拓扑存在下，图扩散方程如何对GNN进行外推和概括，揭示了基于局部扩散的现有模型在概括能力上的不足，并提出了非局部扩散的潜力。

    

    图扩散方程与图神经网络（GNN）密切相关，并且最近引起了人们的关注，作为分析GNN动力学、形式化其表达能力和证明架构选择的有原则的框架。图学习中的一个关键问题是GNN的概括能力。当前方法的一个主要限制在于假设训练集和测试集中的图拓扑来自相同的分布。本文通过探索图扩散方程在不同图拓扑存在下的外推和概括能力，迈出了解析GNN概括性的一步。我们首先展示了基于图上局部扩散的现有模型在概括能力上的不足，这是由于对拓扑变化的指数敏感性引起的。随后的分析揭示了非局部扩散的潜力，它倡导对完全连接的潜在图进行特征传播。

    Graph diffusion equations are intimately related to graph neural networks (GNNs) and have recently attracted attention as a principled framework for analyzing GNN dynamics, formalizing their expressive power, and justifying architectural choices. One key open questions in graph learning is the generalization capabilities of GNNs. A major limitation of current approaches hinges on the assumption that the graph topologies in the training and test sets come from the same distribution. In this paper, we make steps towards understanding the generalization of GNNs by exploring how graph diffusion equations extrapolate and generalize in the presence of varying graph topologies. We first show deficiencies in the generalization capability of existing models built upon local diffusion on graphs, stemming from the exponential sensitivity to topology variation. Our subsequent analysis reveals the promise of non-local diffusion, which advocates for feature propagation over fully-connected latent gr
    
[^17]: 使用动态规划发现决策树的可解释性-性能帕累托前沿

    Discovering the Interpretability-Performance Pareto Front of Decision Trees with Dynamic Programming. (arXiv:2309.12701v1 [cs.LG])

    [http://arxiv.org/abs/2309.12701](http://arxiv.org/abs/2309.12701)

    本文提出了一种使用动态规划找到最优决策树的方法，可以得到多个可解释性-性能权衡的最优决策树，使用户可以根据自己的需求选择最适合的树。

    

    众所周知，决策树由于可以被人类检查和解释而具有固有的可解释性。此外，最近硬件的进步重新引起了对最优决策树算法的关注，这些算法比通常的贪婪方法产生更准确的树。然而，这些最优算法返回的是一个优化手动定义的可解释性-性能权衡的单个树，通过指定最大决策节点数量来获得，对于这个权衡的质量没有进一步的洞察。在本文中，我们提出了一种新的马尔可夫决策问题（MDP）形式来找到最优决策树。这种形式的主要优点是，我们可以通过解决一个单一的动态规划问题计算出多个可解释性-性能权衡的最优决策树，让用户事后选择最适合他们需求的树。在实证方面，我们证明我们的方法在准确性和运行时间方面与最先进的算法竞争力相当。

    Decision trees are known to be intrinsically interpretable as they can be inspected and interpreted by humans. Furthermore, recent hardware advances have rekindled an interest for optimal decision tree algorithms, that produce more accurate trees than the usual greedy approaches. However, these optimal algorithms return a single tree optimizing a hand defined interpretability-performance trade-off, obtained by specifying a maximum number of decision nodes, giving no further insights about the quality of this trade-off. In this paper, we propose a new Markov Decision Problem (MDP) formulation for finding optimal decision trees. The main interest of this formulation is that we can compute the optimal decision trees for several interpretability-performance trade-offs by solving a single dynamic program, letting the user choose a posteriori the tree that best suits their needs. Empirically, we show that our method is competitive with state-of-the-art algorithms in terms of accuracy and run
    
[^18]: 分布无关推断二元分类的回归函数

    Distribution-Free Inference for the Regression Function of Binary Classification. (arXiv:2308.01835v1 [stat.ML])

    [http://arxiv.org/abs/2308.01835](http://arxiv.org/abs/2308.01835)

    本文提出了一种分布无关的方法来推断二元分类问题中的回归函数，通过构建置信区间来解决该问题，相关算法经过验证具有可靠性。

    

    二元分类的一个关键对象是回归函数，即给定输入的类别标签的条件期望。通过回归函数，不仅可以定义贝叶斯最优分类器，还可以编码对应的错误分类概率。本文提出了一种重采样框架，用于构建精确、分布无关且非渐近保证的真实回归函数的置信区间，根据用户选择的置信水平。然后，提出了特定的算法来演示该框架。证明了构建的置信区间是强一致的，也就是说，任何错误的模型最终被排除的概率为1。排除的程度也通过可能近似正确类型的界限进行了量化。最后，通过数值实验验证了算法，并将方法与近似渐近置信椭圆进行了比较。

    One of the key objects of binary classification is the regression function, i.e., the conditional expectation of the class labels given the inputs. With the regression function not only a Bayes optimal classifier can be defined, but it also encodes the corresponding misclassification probabilities. The paper presents a resampling framework to construct exact, distribution-free and non-asymptotically guaranteed confidence regions for the true regression function for any user-chosen confidence level. Then, specific algorithms are suggested to demonstrate the framework. It is proved that the constructed confidence regions are strongly consistent, that is, any false model is excluded in the long run with probability one. The exclusion is quantified with probably approximately correct type bounds, as well. Finally, the algorithms are validated via numerical experiments, and the methods are compared to approximate asymptotic confidence ellipsoids.
    
[^19]: AI生成报告的事实核查

    Fact-Checking of AI-Generated Reports. (arXiv:2307.14634v1 [cs.AI])

    [http://arxiv.org/abs/2307.14634](http://arxiv.org/abs/2307.14634)

    本文提出了一种使用相关联的图像对AI生成报告进行事实核查的新方法，以区分报告中的真假句子。这对加快临床工作流程，提高准确性并降低总体成本具有重要意义。

    

    随着生成人工智能（AI）的进步，现在可以生成逼真的自动报告来对放射学图像进行初步阅读。这可以加快临床工作流程，提高准确性并降低总体成本。然而，众所周知，这种模型往往会产生幻觉，导致生成报告中出现错误的发现。在本文中，我们提出了一种使用相关联的图像对AI生成报告进行事实核查的新方法。具体而言，通过学习图像与描述真实或潜在虚假发现的句子之间的关联，开发的核查者区分报告中的真假句子。为了训练这样的核查者，我们首先通过扰动原始与图像相关的放射学报告中的发现，创建了一个新的伪造报告数据集。然后将来自这些报告的真假句子的文本编码与图像编码配对，学习映射到真/假标签的关系。

    With advances in generative artificial intelligence (AI), it is now possible to produce realistic-looking automated reports for preliminary reads of radiology images. This can expedite clinical workflows, improve accuracy and reduce overall costs. However, it is also well-known that such models often hallucinate, leading to false findings in the generated reports. In this paper, we propose a new method of fact-checking of AI-generated reports using their associated images. Specifically, the developed examiner differentiates real and fake sentences in reports by learning the association between an image and sentences describing real or potentially fake findings. To train such an examiner, we first created a new dataset of fake reports by perturbing the findings in the original ground truth radiology reports associated with images. Text encodings of real and fake sentences drawn from these reports are then paired with image encodings to learn the mapping to real/fake labels. The utility 
    
[^20]: 基于核的$\epsilon$-贪心策略在情境脉冲中的应用

    Kernel $\epsilon$-Greedy for Contextual Bandits. (arXiv:2306.17329v1 [stat.ML])

    [http://arxiv.org/abs/2306.17329](http://arxiv.org/abs/2306.17329)

    本文提出了基于核的$\epsilon$-贪心策略应用于情境脉冲中的方法，通过在线加权核岭回归估计器实现对奖励函数的估计，并证明了其一致性和依赖于RKHS维度的次线性后悔率，在有限维RKHS的边际条件下实现了最优后悔率。

    

    我们考虑了情境脉冲中的基于核的$\epsilon$-贪心策略。更具体地说，在有限数量的臂的情况下，我们认为平均奖励函数位于再生核希尔伯特空间（RKHS）中。我们提出了一种用于奖励函数的在线加权核岭回归估计器。在对探索概率序列$\{\epsilon_t\}_t$和正则化参数$\{\lambda_t\}_t$的一些条件下，我们证明了所提出的估计器的一致性。我们还证明，对于任何核和相应的RKHS的选择，我们可以实现依赖于RKHS内在维度的次线性后悔率。此外，在有限维RKHS的边际条件下，我们实现了$\sqrt{T}$的最优后悔率。

    We consider a kernelized version of the $\epsilon$-greedy strategy for contextual bandits. More precisely, in a setting with finitely many arms, we consider that the mean reward functions lie in a reproducing kernel Hilbert space (RKHS). We propose an online weighted kernel ridge regression estimator for the reward functions. Under some conditions on the exploration probability sequence, $\{\epsilon_t\}_t$, and choice of the regularization parameter, $\{\lambda_t\}_t$, we show that the proposed estimator is consistent. We also show that for any choice of kernel and the corresponding RKHS, we achieve a sub-linear regret rate depending on the intrinsic dimensionality of the RKHS. Furthermore, we achieve the optimal regret rate of $\sqrt{T}$ under a margin condition for finite-dimensional RKHS.
    
[^21]: 手腕动作时间序列分类用于帕金森病检测

    Time Series Classification for Detecting Parkinson's Disease from Wrist Motions. (arXiv:2304.11265v1 [cs.LG])

    [http://arxiv.org/abs/2304.11265](http://arxiv.org/abs/2304.11265)

    该研究使用InceptionTime和ROCKET方法进行时间序列分类，以监测帕金森病患者的手腕运动。研究发现，所有方法都适用于估计震颤严重程度和肌肉强直的存在，但在检测运动障碍方面存在困难。具有岭分类器的InceptionTime方法展示了最先进的分类性能，显示时间序列分类在基于可穿戴设备的PD症状监测中具有潜力。

    

    帕金森病是一种神经退行性疾病，具有频繁变化的运动症状，持续的症状监测可以实现更有针对性的治疗。传统的时间序列分类和深度学习技术在使用可穿戴加速度计数据进行PD症状监测时性能有限，因为PD运动模式具有复杂性，但数据集很小。我们研究了InceptionTime和RandOm卷积核变换（ROCKET），因为它们是TSC的最新技术，并且对于PD症状监测非常有前景：InceptionTime的高学习能力适用于建模复杂运动模式，而ROCKET适用于小数据集。我们使用随机搜索找到了最高得分的InceptionTime结构，并将其与具有岭分类器和多层感知器（MLP）的ROCKET进行了比较，用于PD患者的手腕运动。我们发现，所有方法都适用于估计震颤严重程度和肌肉强直的存在，但在检测运动障碍方面存在困难。具有岭分类器的InceptionTime优于其他方法，并实现了最先进的分类性能，展示了TSC在基于可穿戴设备的PD症状监测中的潜力。

    Parkinson's disease (PD) is a neurodegenerative disease with frequently changing motor symptoms where continuous symptom monitoring enables more targeted treatment. Classical time series classification (TSC) and deep learning techniques have limited performance for PD symptom monitoring using wearable accelerometer data because PD movement patterns are complex, but datasets are small. We investigate InceptionTime and RandOm Convolutional KErnel Transform (ROCKET) because they are state-of-the-art for TSC and promising for PD symptom monitoring: InceptionTime's high learning capacity is suited to modeling complex movement patterns while ROCKET is suited to small datasets. We used a random search to find the highest-scoring InceptionTime architecture and compared it to ROCKET with a ridge classifier and a multi-layer perceptron (MLP) on wrist motions of PD patients. We find that all approaches are suitable for estimating tremor severity and bradykinesia presence but struggle with detecti
    
[^22]: 一种神经λ演算法：神经符号人工智能遇见计算和函数式编程的基础。

    A Neural Lambda Calculus: Neurosymbolic AI meets the foundations of computing and functional programming. (arXiv:2304.09276v1 [cs.LG])

    [http://arxiv.org/abs/2304.09276](http://arxiv.org/abs/2304.09276)

    本文提出了一种神经λ演算法，使用λ语言编程，研究神经网络在执行整个程序的能力，旨在拓展神经网络在符号人工智能领域的应用。

    

    在过去几十年中，基于深度神经网络的模型成为了机器学习中的主导范式。最近，人们越来越认为在符号学习中使用人工神经网络是越来越相关的。为了研究神经网络在符号人工智能领域的能力，研究人员已经探索了深度神经网络学习数学构造（如加法和乘法）、逻辑推理（如定理证明器）甚至执行计算机程序的能力。然而，后者对于神经网络来说是太复杂的任务，结果并不总是成功的，并且往往需要在学习过程中引入有偏见的元素，以限制可能要执行的程序的范围。在这项工作中，我们将分析神经网络学习如何执行整个程序的能力。为此，我们提出了一种不同的方法。我们不使用命令式编程语言，而是采用λ语言进行编程。

    Over the last decades, deep neural networks based-models became the dominant paradigm in machine learning. Further, the use of artificial neural networks in symbolic learning has been seen as increasingly relevant recently. To study the capabilities of neural networks in the symbolic AI domain, researchers have explored the ability of deep neural networks to learn mathematical constructions, such as addition and multiplication, logic inference, such as theorem provers, and even the execution of computer programs. The latter is known to be too complex a task for neural networks. Therefore, the results were not always successful, and often required the introduction of biased elements in the learning process, in addition to restricting the scope of possible programs to be executed. In this work, we will analyze the ability of neural networks to learn how to execute programs as a whole. To do so, we propose a different approach. Instead of using an imperative programming language, with com
    
[^23]: 超越负采样的高效分布式表示方法

    Efficient distributed representations beyond negative sampling. (arXiv:2303.17475v1 [cs.LG])

    [http://arxiv.org/abs/2303.17475](http://arxiv.org/abs/2303.17475)

    本文介绍了一种高效的分布式表示（嵌入）学习方法，通过线性时间估计softmax归一化常数来实现学习过程，该方法优于负采样方法并在多项测试中验证了其有效性。

    

    本文介绍了一种高效的学习分布式表示（也称为嵌入）的方法。该方法通过最小化一个类似于Word2Vec算法中引入并在多个工作中采用的目标函数来实现。优化计算的瓶颈是softmax归一化常数的计算，这需要与样本大小呈二次比例的操作数。这种复杂度不适用于大型数据集，所以负采样是一个常见的解决方法，可以在与样本大小线性相关的时间内获得分布式表示。然而，负采样会改变损失函数，因此解决的是与最初提出的不同的优化问题。我们的贡献在于展示如何通过线性时间估计softmax归一化常数，从而设计了一种有效的优化策略来学习分布式表示。我们使用不同的数据集进行测试，并展示了我们的方法在嵌入质量和训练时间方面优于负采样。

    This article describes an efficient method to learn distributed representations, also known as embeddings. This is accomplished minimizing an objective function similar to the one introduced in the Word2Vec algorithm and later adopted in several works. The optimization computational bottleneck is the calculation of the softmax normalization constants for which a number of operations scaling quadratically with the sample size is required. This complexity is unsuited for large datasets and negative sampling is a popular workaround, allowing one to obtain distributed representations in linear time with respect to the sample size. Negative sampling consists, however, in a change of the loss function and hence solves a different optimization problem from the one originally proposed. Our contribution is to show that the sotfmax normalization constants can be estimated in linear time, allowing us to design an efficient optimization strategy to learn distributed representations. We test our ap
    

