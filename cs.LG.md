# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Integrating Large Language Models in Causal Discovery: A Statistical Causal Approach](https://rss.arxiv.org/abs/2402.01454) | 本文提出了一种在因果发现中集成大型语言模型的方法，通过将统计因果提示与知识增强相结合，可以使统计因果发现结果接近真实情况并进一步改进结果。 |
| [^2] | [Comment on "Machine learning conservation laws from differential equations"](https://arxiv.org/abs/2404.02896) | 评论了另一篇关于从微分方程中学习守恒定律的文章中存在的严重推导错误 |
| [^3] | [Universal representations for financial transactional data: embracing local, global, and external contexts](https://arxiv.org/abs/2404.02047) | 提出了一个金融交易数据通用表示的学习框架，结合了本地、全局和外部语境，提出了新颖的生成模型和整合外部信息的方法，并在本地任务中表现出超越性能。 |
| [^4] | [ADVREPAIR:Provable Repair of Adversarial Attack](https://arxiv.org/abs/2404.01642) | ADVREPAIR是一种利用有限数据进行对抗攻击的可证修复的新方法，通过形式验证构建补丁模块，在稳健邻域内提供可证和专门的修复，同时具有泛化到其他输入的防御能力。 |
| [^5] | [Constants of Motion for Conserved and Non-conserved Dynamics](https://arxiv.org/abs/2403.19418) | 该论文通过机器学习技术得到的动态模型，结合李对称技术分析得到了守恒和非守恒情况下1D和2D谐振子的运动积分，展示了非守恒模型中存在的能量守恒常数，以及在各种频率比例情况下推广了角动量。 |
| [^6] | [Goal-Oriented Bayesian Optimal Experimental Design for Nonlinear Models using Markov Chain Monte Carlo](https://arxiv.org/abs/2403.18072) | 提出了一种适用于非线性模型的预测目标导向最优实验设计方法，通过最大化QoIs的期望信息增益来确定实验设计。 |
| [^7] | [Stochastic Gradient Langevin Unlearning](https://arxiv.org/abs/2403.17105) | 本工作提出了随机梯度 Langevin 反遗忘方法，为近似反遗忘问题提供了隐私保障，并展示了小批次梯度更新相较于全批次的优越性能。 |
| [^8] | [Circuit Transformer: End-to-end Circuit Design by Predicting the Next Gate](https://arxiv.org/abs/2403.13838) | 本研究探索了通过预测下一个逻辑门来实现电路设计的可能性。 |
| [^9] | [VL-ICL Bench: The Devil in the Details of Benchmarking Multimodal In-Context Learning](https://arxiv.org/abs/2403.13164) | 大型语言模型的视觉变种在识别、推理和基准确定等领域取得了显著进展，但多模态上下文学习的广泛能力和限制仍未得到充分探讨。 |
| [^10] | [A Probabilistic Approach for Alignment with Human Comparisons](https://arxiv.org/abs/2403.10771) | 通过提出的两阶段“监督微调+人类比较”框架，本文研究了如何有效利用人类比较来改善AI模型的对齐，特别是在面对嘈杂数据和高维模型时。 |
| [^11] | [Divide and Conquer: Provably Unveiling the Pareto Front with Multi-Objective Reinforcement Learning](https://arxiv.org/abs/2402.07182) | 这项研究介绍了一个名为IPRO的算法，利用分解任务为一系列单目标问题方法，可可靠地揭示多目标强化学习中实现最优表现的策略的帕累托前沿，同时提供收敛保证和未发现解的距离上限。 |
| [^12] | [ForestColl: Efficient Collective Communications on Heterogeneous Network Fabrics](https://arxiv.org/abs/2402.06787) | ForestColl是一种针对任意网络拓扑生成高效调度的工具，通过构建广播/聚合生成跨越树的通信调度，实现了理论上的最小网络拥塞，并在实验中表现出高于供应商自带通信库的性能。 |
| [^13] | [Function Aligned Regression: A Method Explicitly Learns Functional Derivatives from Data](https://arxiv.org/abs/2402.06104) | 该论文提出了一种名为FAR的方法，通过捕捉函数导数来更好、更高效地拟合底层真实函数。在合成数据集和八个真实世界任务中证明了该方法的有效性。 |
| [^14] | [EUGENE: Explainable Unsupervised Approximation of Graph Edit Distance](https://arxiv.org/abs/2402.05885) | EUGENE是一种可解释的无监督图编辑距离近似方法，可以通过生成编辑路径来近似计算图编辑距离，同时消除了ground-truth生成和数据特定训练的需求。 |
| [^15] | [Group Distributionally Robust Dataset Distillation with Risk Minimization](https://arxiv.org/abs/2402.04676) | 这项研究关注数据集蒸馏与其泛化能力的关系，尤其是在面对不常见的子组的样本时，如何确保模型在合成数据集上的训练可以表现良好。 |
| [^16] | [Humans Beat Deep Networks at Recognizing Objects in Unusual Poses, Given Enough Time](https://arxiv.org/abs/2402.03973) | 人类在识别不寻常姿势中的物体上表现优于深度网络，当给予足够时间时。然而，随着图像曝光时间的限制，人类的表现降至深度网络的水平，这暗示人类在识别不寻常姿势中的物体时需要额外的心理过程。此外，人类与网络之间的错误模式也存在不同。因此，我们需要进一步研究，以提高计算机视觉系统的鲁棒性水平。 |
| [^17] | [Probabilistic Actor-Critic: Learning to Explore with PAC-Bayes Uncertainty](https://arxiv.org/abs/2402.03055) | 概率演员-评论家算法（PAC）通过在评论家中建模和推断不确定性，以改进强化学习中的连续控制性能，并实现自适应的探索策略。 |
| [^18] | [Statistics without Interpretation: A Sober Look at Explainable Machine Learning](https://arxiv.org/abs/2402.02870) | 解释算法往往数学上复杂且难以解释，这导致解释错误。为了向前推进，解释算法需要明确其输出的解释方式，并澄清可以和不能回答的问题。这一论点基于统计学和解释之间的区别，以及可解释机器学习和应用统计学之间的相似性。 |
| [^19] | [Role of Momentum in Smoothing Objective Function in Implicit Graduated Optimization](https://arxiv.org/abs/2402.02325) | 这篇论文揭示了具有动量的随机梯度下降算法平滑了目标函数，影响程度由多个超参数决定，同时提供了对动量改善泛化能力的理论解释和新见解。 |
| [^20] | [Predictable Reinforcement Learning Dynamics through Entropy Rate Minimization](https://arxiv.org/abs/2311.18703) | 该论文提出了一种名为PA-RL的方法，通过最小化熵率来引导强化学习智能体展现可预测的行为。研究展示了如何利用平均替代奖励实现确定性策略，并在动态模型的基础上近似计算值函数。 |
| [^21] | [Investigating the Quality of DermaMNIST and Fitzpatrick17k Dermatological Image Datasets.](http://arxiv.org/abs/2401.14497) | 本文研究了DermaMNIST和Fitzpatrick17k皮肤科图像数据集的质量问题，对数据重复、数据泄漏、错误标记和缺乏测试分区等方面进行了详细分析，并提出纠正措施。 |
| [^22] | [Blind Channel Estimation and Joint Symbol Detection with Data-Driven Factor Graphs.](http://arxiv.org/abs/2401.12627) | 本论文研究了在时变线性干扰信道上基于因子图的盲信道估计和联合符号检测方法。通过使用置信传播算法和期望最大化算法相互交织的迭代，可以降低复杂度并提高性能。通过引入数据驱动的方法，算法在离线训练样本数量较少的情况下也能取得显著的性能提升。 |
| [^23] | [DSAC-T: Distributional Soft Actor-Critic with Three Refinements.](http://arxiv.org/abs/2310.05858) | 本论文介绍了DSAC-T，通过评论者梯度调整、双值分布学习和基于方差的目标回报裁剪等三个改进对标准DSAC进行了改进，解决了标准DSAC存在的不稳定学习过程和对任务特定奖励缩放的问题，提高了算法的性能和适应性。 |
| [^24] | [Energy-Guided Continuous Entropic Barycenter Estimation for General Costs.](http://arxiv.org/abs/2310.01105) | 本文提出了一种基于能量导向的方法用于近似计算任意OT成本函数的连续熵OT巴氏中心，该方法具有优越的性能，并且能与基于能量的模型（EBMs）学习过程无缝连接。 |
| [^25] | [Supersonic: Learning to Generate Source Code Optimisations in C/C++.](http://arxiv.org/abs/2309.14846) | Supersonic 是一个神经方法，用于在C/C++中进行源代码优化。与GPT-3.5-Turbo和GPT-4相比，它在代码优化任务上表现更好，并且改变的程度更小。 |
| [^26] | [Quantum-noise-limited optical neural networks operating at a few quanta per activation.](http://arxiv.org/abs/2307.15712) | 本文研究了在极低功率下操作的光学神经网络，其中一些层只使用一个光子来引发神经元激活。尽管存在极高的噪声，仍可以训练这些网络以高精度执行确定性图像分类任务。 |
| [^27] | [Instance-Optimal Cluster Recovery in the Labeled Stochastic Block Model.](http://arxiv.org/abs/2306.12968) | 本论文提出了一种算法，名为实例自适应聚类（IAC），它能够在标记随机块模型（LSBM）中恢复隐藏的群集。IAC包括一次谱聚类和一个迭代的基于似然的簇分配改进，不需要任何模型参数，是高效的。 |
| [^28] | [A Survey on Knowledge Graphs for Healthcare: Resources, Applications, and Promises.](http://arxiv.org/abs/2306.04802) | 本论文综述了医疗知识图谱(HKGs)的构建流程、关键技术和利用方法以及现有资源，并深入探讨了HKG在各种医疗领域的变革性影响。 |
| [^29] | [Global universal approximation of functional input maps on weighted spaces.](http://arxiv.org/abs/2306.03303) | 本文提出了功能性输入神经网络，可以在带权重空间上完成全局函数逼近。这一方法适用于连续函数的推广，还可用于路径空间函数的逼近，同时也可以逼近线性函数签名。 |
| [^30] | [Evil from Within: Machine Learning Backdoors through Hardware Trojans.](http://arxiv.org/abs/2304.08411) | 本文介绍了一种在常见机器学习硬件加速器内的后门攻击方法，将最小后门概念和可配置的硬件木马结合使用，从而对目前的防御措施构成挑战。 |
| [^31] | [Partial Neural Optimal Transport.](http://arxiv.org/abs/2303.07988) | 我们提出了一种新的神经方法来计算部分最优输运映射，并在合成例子上进行了测试。 |
| [^32] | [Holistic Robust Data-Driven Decisions.](http://arxiv.org/abs/2207.09560) | 这篇论文提出了一种全面稳健的数据驱动公式，能够同时保护三个过拟合的源头：有限样本数据的统计误差、数据点的有限精度测量引起的数据噪声，以及被破坏的部分数据。 |
| [^33] | [Wasserstein multivariate auto-regressive models for modeling distributional time series and its application in graph learning.](http://arxiv.org/abs/2207.05442) | 本文提出了一种新的自回归模型，用于分析多元分布时间序列。并且在Wasserstein空间中建模了随机对象，提供了该模型的解的存在性和一致估计器。此方法可以应用于年龄分布和自行车共享网络的观察数据。 |
| [^34] | [Hierarchical Correlation Clustering and Tree Preserving Embedding.](http://arxiv.org/abs/2002.07756) | 本文提出了一种分层相关聚类方法，可应用于正负配对不相似度，并研究了使用此方法进行无监督表征学习的方法。 |

# 详细

[^1]: 在因果发现中集成大型语言模型: 一种统计因果方法

    Integrating Large Language Models in Causal Discovery: A Statistical Causal Approach

    [https://rss.arxiv.org/abs/2402.01454](https://rss.arxiv.org/abs/2402.01454)

    本文提出了一种在因果发现中集成大型语言模型的方法，通过将统计因果提示与知识增强相结合，可以使统计因果发现结果接近真实情况并进一步改进结果。

    

    在实际的统计因果发现（SCD）中，将领域专家知识作为约束嵌入到算法中被广泛接受，因为这对于创建一致有意义的因果模型是重要的，尽管识别背景知识的挑战被认可。为了克服这些挑战，本文提出了一种新的因果推断方法，即通过将LLM的“统计因果提示（SCP）”与SCD方法和基于知识的因果推断（KBCI）相结合，对SCD进行先验知识增强。实验证明，GPT-4可以使LLM-KBCI的输出与带有LLM-KBCI的先验知识的SCD结果接近真实情况，如果GPT-4经历了SCP，那么SCD的结果还可以进一步改善。而且，即使LLM不含有数据集的信息，LLM仍然可以通过其背景知识来改进SCD。

    In practical statistical causal discovery (SCD), embedding domain expert knowledge as constraints into the algorithm is widely accepted as significant for creating consistent meaningful causal models, despite the recognized challenges in systematic acquisition of the background knowledge. To overcome these challenges, this paper proposes a novel methodology for causal inference, in which SCD methods and knowledge based causal inference (KBCI) with a large language model (LLM) are synthesized through "statistical causal prompting (SCP)" for LLMs and prior knowledge augmentation for SCD. Experiments have revealed that GPT-4 can cause the output of the LLM-KBCI and the SCD result with prior knowledge from LLM-KBCI to approach the ground truth, and that the SCD result can be further improved, if GPT-4 undergoes SCP. Furthermore, it has been clarified that an LLM can improve SCD with its background knowledge, even if the LLM does not contain information on the dataset. The proposed approach
    
[^2]: 对“从微分方程中学习守恒定律”一文的评论

    Comment on "Machine learning conservation laws from differential equations"

    [https://arxiv.org/abs/2404.02896](https://arxiv.org/abs/2404.02896)

    评论了另一篇关于从微分方程中学习守恒定律的文章中存在的严重推导错误

    

    在此评论中，作者回顾了刘, 马德哈万和泰格马克提出的与作者提出的一维阻尼谐振子的守恒量相类似的结果，指出他们推导中存在六个严重错误，导致他们的方法和结果均不正确。

    arXiv:2404.02896v1 Announce Type: new  Abstract: In lieu of abstract, first paragraph reads: Six months after the author derived a constant of motion for a 1D damped harmonic oscillator [1], a similar result appeared by Liu, Madhavan, and Tegmark [2, 3], without citing the author. However, their derivation contained six serious errors, causing both their method and result to be incorrect. In this Comment, those errors are reviewed.
    
[^3]: 金融交易数据的通用表示：融合本地、全局和外部语境

    Universal representations for financial transactional data: embracing local, global, and external contexts

    [https://arxiv.org/abs/2404.02047](https://arxiv.org/abs/2404.02047)

    提出了一个金融交易数据通用表示的学习框架，结合了本地、全局和外部语境，提出了新颖的生成模型和整合外部信息的方法，并在本地任务中表现出超越性能。

    

    金融交易的有效处理对银行数据分析至关重要。然而，在这一领域中，大多数方法专注于为独立问题提供专门化解决方案，而不是构建适用于许多问题的通用表示。我们提出了一个表示学习框架，旨在解决各种企业挑战。我们还提出了考虑数据特定性的新颖生成模型，并提出了一种整合外部信息到客户表示的方式，借鉴其他客户行动的见解。最后，我们提供了一个基准，描述了全球范围内的表示质量，涉及整个交易历史；本地范围内，反映客户当前状态；动态范围内，捕捉表示随时间演变的情况。我们的生成方法在本地任务中表现出色，对于下一个MCC预测任务的ROC-AUC提升高达14％，对于dow...

    arXiv:2404.02047v1 Announce Type: cross  Abstract: Effective processing of financial transactions is essential for banking data analysis. However, in this domain, most methods focus on specialized solutions to stand-alone problems instead of constructing universal representations suitable for many problems. We present a representation learning framework that addresses diverse business challenges. We also suggest novel generative models that account for data specifics, and a way to integrate external information into a client's representation, leveraging insights from other customers' actions. Finally, we offer a benchmark, describing representation quality globally, concerning the entire transaction history; locally, reflecting the client's current state; and dynamically, capturing representation evolution over time. Our generative approach demonstrates superior performance in local tasks, with an increase in ROC-AUC of up to 14\% for the next MCC prediction task and up to 46\% for dow
    
[^4]: ADVREPAIR：对抗攻击的可证修复

    ADVREPAIR:Provable Repair of Adversarial Attack

    [https://arxiv.org/abs/2404.01642](https://arxiv.org/abs/2404.01642)

    ADVREPAIR是一种利用有限数据进行对抗攻击的可证修复的新方法，通过形式验证构建补丁模块，在稳健邻域内提供可证和专门的修复，同时具有泛化到其他输入的防御能力。

    

    深度神经网络(DNNs)在安全关键领域中的部署日益增加，但它们对抗性攻击的脆弱性构成严重的安全风险。现有的使用有限数据的神经元级方法在修复对手方面缺乏效力，因为对抗攻击机制的固有复杂性，而对抗训练，利用大量对抗样本增强鲁棒性，缺乏可证性。在本文中，我们提出了ADVREPAIR，一种利用有限数据进行对抗攻击的可证修复的新方法。通过利用形式验证，ADVREPAIR构建补丁模块，当与原始网络集成时，在稳健邻域内提供可证和专门的修复。此外，我们的方法还包括一种启发式机制来分配补丁模块，使得这种防御对抗攻击泛化到其他输入。ADVREPAIR展示了卓越的效率。

    arXiv:2404.01642v1 Announce Type: new  Abstract: Deep neural networks (DNNs) are increasingly deployed in safety-critical domains, but their vulnerability to adversarial attacks poses serious safety risks. Existing neuron-level methods using limited data lack efficacy in fixing adversaries due to the inherent complexity of adversarial attack mechanisms, while adversarial training, leveraging a large number of adversarial samples to enhance robustness, lacks provability. In this paper, we propose ADVREPAIR, a novel approach for provable repair of adversarial attacks using limited data. By utilizing formal verification, ADVREPAIR constructs patch modules that, when integrated with the original network, deliver provable and specialized repairs within the robustness neighborhood. Additionally, our approach incorporates a heuristic mechanism for assigning patch modules, allowing this defense against adversarial attacks to generalize to other inputs. ADVREPAIR demonstrates superior efficienc
    
[^5]: 运动的守恒和非守恒动力学的运动积分

    Constants of Motion for Conserved and Non-conserved Dynamics

    [https://arxiv.org/abs/2403.19418](https://arxiv.org/abs/2403.19418)

    该论文通过机器学习技术得到的动态模型，结合李对称技术分析得到了守恒和非守恒情况下1D和2D谐振子的运动积分，展示了非守恒模型中存在的能量守恒常数，以及在各种频率比例情况下推广了角动量。

    

    这篇论文首先介绍了一个通过应用机器学习技术（FJet）到时间序列数据获得的动力学模型；然后利用李对称技术对该动力学模型进行分析以获得运动积分。该分析针对1D和2D谐振子的守恒和非守恒情况进行。对于1D谐振子，在欠阻尼、过阻尼和临界阻尼情况下找到了运动积分。对于非守恒模型的存在这样的常数是对整个系统（即振荡器加耗散环境）能量守恒的一种表现的新颖解释。对于2D谐振子，在等向和非等向情况下找到了运动积分，包括频率不可共轭的情况；还推广到任意维度。此外，还确定了一个常数，它将角动量推广到所有频率比例的情况。

    arXiv:2403.19418v1 Announce Type: new  Abstract: This paper begins with a dynamical model that was obtained by applying a machine learning technique (FJet) to time-series data; this dynamical model is then analyzed with Lie symmetry techniques to obtain constants of motion. This analysis is performed on both the conserved and non-conserved cases of the 1D and 2D harmonic oscillators. For the 1D oscillator, constants are found in the cases where the system is underdamped, overdamped, and critically damped. The novel existence of such a constant for a non-conserved model is interpreted as a manifestation of the conservation of energy of the {\em total} system (i.e., oscillator plus dissipative environment). For the 2D oscillator, constants are found for the isotropic and anisotropic cases, including when the frequencies are incommensurate; it is also generalized to arbitrary dimensions. In addition, a constant is identified which generalizes angular momentum for all ratios of the frequen
    
[^6]: 非线性模型的目标导向贝叶斯最优实验设计与马尔可夫链蒙特卡洛方法

    Goal-Oriented Bayesian Optimal Experimental Design for Nonlinear Models using Markov Chain Monte Carlo

    [https://arxiv.org/abs/2403.18072](https://arxiv.org/abs/2403.18072)

    提出了一种适用于非线性模型的预测目标导向最优实验设计方法，通过最大化QoIs的期望信息增益来确定实验设计。

    

    最优实验设计（OED）提供了一种系统化的方法来量化和最大化实验数据的价值。在贝叶斯方法下，传统的OED会最大化对模型参数的期望信息增益（EIG）。然而，我们通常感兴趣的不是参数本身，而是依赖于参数的非线性方式的预测感兴趣量（QoIs）。我们提出了一个适用于非线性观测和预测模型的预测目标导向OED（GO-OED）的计算框架，该框架寻求提供对QoIs的最大EIG的实验设计。具体地，我们提出了用于QoI EIG的嵌套蒙特卡洛估计器，其中采用马尔可夫链蒙特卡洛进行后验采样，利用核密度估计来评估后验预测密度及其与先验预测之间的Kullback-Leibler散度。GO-OED设计通过在设计空间中最大化EIG来获得。

    arXiv:2403.18072v1 Announce Type: cross  Abstract: Optimal experimental design (OED) provides a systematic approach to quantify and maximize the value of experimental data. Under a Bayesian approach, conventional OED maximizes the expected information gain (EIG) on model parameters. However, we are often interested in not the parameters themselves, but predictive quantities of interest (QoIs) that depend on the parameters in a nonlinear manner. We present a computational framework of predictive goal-oriented OED (GO-OED) suitable for nonlinear observation and prediction models, which seeks the experimental design providing the greatest EIG on the QoIs. In particular, we propose a nested Monte Carlo estimator for the QoI EIG, featuring Markov chain Monte Carlo for posterior sampling and kernel density estimation for evaluating the posterior-predictive density and its Kullback-Leibler divergence from the prior-predictive. The GO-OED design is then found by maximizing the EIG over the des
    
[^7]: 随机梯度 Langevin 反遗忘

    Stochastic Gradient Langevin Unlearning

    [https://arxiv.org/abs/2403.17105](https://arxiv.org/abs/2403.17105)

    本工作提出了随机梯度 Langevin 反遗忘方法，为近似反遗忘问题提供了隐私保障，并展示了小批次梯度更新相较于全批次的优越性能。

    

    “被遗忘的权利”是用户数据隐私的法律所确保的越来越重要。机器反遗忘旨在高效地消除已训练模型参数上某些数据点的影响，使其近似于从头开始重新训练模型。本研究提出了随机梯度 Langevin 反遗忘，这是第一个基于带有隐私保障的噪声随机梯度下降（SGD）的反遗忘框架，适用于凸性假设下的近似反遗忘问题。我们的结果表明，与全批次对应方法相比，小批次梯度更新在隐私复杂度权衡方面提供了更好的性能。我们的反遗忘方法具有诸多算法优势，包括与重新训练相比的复杂度节省，以及支持顺序和批量反遗忘。为了检验我们方法的隐私-效用-复杂度权衡，我们在基准数据集上进行了实验比较。

    arXiv:2403.17105v1 Announce Type: new  Abstract: ``The right to be forgotten'' ensured by laws for user data privacy becomes increasingly important. Machine unlearning aims to efficiently remove the effect of certain data points on the trained model parameters so that it can be approximately the same as if one retrains the model from scratch. This work proposes stochastic gradient Langevin unlearning, the first unlearning framework based on noisy stochastic gradient descent (SGD) with privacy guarantees for approximate unlearning problems under convexity assumption. Our results show that mini-batch gradient updates provide a superior privacy-complexity trade-off compared to the full-batch counterpart. There are numerous algorithmic benefits of our unlearning approach, including complexity saving compared to retraining, and supporting sequential and batch unlearning. To examine the privacy-utility-complexity trade-off of our method, we conduct experiments on benchmark datasets compared 
    
[^8]: 电路变压器：通过预测下一个门实现端到端电路设计

    Circuit Transformer: End-to-end Circuit Design by Predicting the Next Gate

    [https://arxiv.org/abs/2403.13838](https://arxiv.org/abs/2403.13838)

    本研究探索了通过预测下一个逻辑门来实现电路设计的可能性。

    

    语言是人类通过序列符号表达的突出能力，近年来大型语言模型（LLMs）已经在计算上掌握了这种能力。通过利用巨大的神经模型不断预测下一个单词，LLMs展现出了前所未有的理解和推理能力。电路作为电子设计的“语言”，通过逻辑门的级联连接来指定电子设备的功能。在这项工作中，我们首次探索了这种可能性，以通过简单地预测下一个逻辑门来征服电子设计任务。

    arXiv:2403.13838v1 Announce Type: new  Abstract: Language, a prominent human ability to express through sequential symbols, has been computationally mastered by recent advances of large language models (LLMs). By predicting the next word recurrently with huge neural models, LLMs have shown unprecedented capabilities in understanding and reasoning. Circuit, as the "language" of electronic design, specifies the functionality of an electronic device by cascade connections of logic gates. Then, can circuits also be mastered by a a sufficiently large "circuit model", which can conquer electronic design tasks by simply predicting the next logic gate? In this work, we take the first step to explore such possibilities. Two primary barriers impede the straightforward application of LLMs to circuits: their complex, non-sequential structure, and the intolerance of hallucination due to strict constraints (e.g., equivalence). For the first barrier, we encode a circuit as a memory-less, depth-first 
    
[^9]: VL-ICL Bench: 基于细节的多模态上下文学习基准测试中的细节之魔

    VL-ICL Bench: The Devil in the Details of Benchmarking Multimodal In-Context Learning

    [https://arxiv.org/abs/2403.13164](https://arxiv.org/abs/2403.13164)

    大型语言模型的视觉变种在识别、推理和基准确定等领域取得了显著进展，但多模态上下文学习的广泛能力和限制仍未得到充分探讨。

    

    大型语言模型（LLMs）以其著名的出现式上下文学习（ICL）而闻名——即在仅提供几个示例作为提示的情况下，快速适应新任务的能力，而无需更新模型的权重。构建在LLMs之上的视觉大型语言模型（VLLMs）在识别、推理和基准确定等领域取得了显著进展。然而，对于\emph{多模态ICL}的研究主要集中在少样本视觉问题回答（VQA）和图像字幕上，我们将展示二者既没有充分利用ICL的优势，也没有测试其限制。对多模态ICL的更广泛能力和局限性尚未得到充分探讨。在本研究中，我们引入了一个全面的多模态上下文学习基准测试 VL-ICL Bench，涵盖了涉及图像和文本作为输入和输出的广泛任务范围，并涵盖了从{感知到推理和长期上下文长度}的不同类型挑战。

    arXiv:2403.13164v1 Announce Type: new  Abstract: Large language models (LLMs) famously exhibit emergent in-context learning (ICL) -- the ability to rapidly adapt to new tasks using few-shot examples provided as a prompt, without updating the model's weights. Built on top of LLMs, vision large language models (VLLMs) have advanced significantly in areas such as recognition, reasoning, and grounding. However, investigations into \emph{multimodal ICL} have predominantly focused on few-shot visual question answering (VQA), and image captioning, which we will show neither exploit the strengths of ICL, nor test its limitations. The broader capabilities and limitations of multimodal ICL remain under-explored. In this study, we introduce a comprehensive benchmark VL-ICL Bench for multimodal in-context learning, encompassing a broad spectrum of tasks that involve both images and text as inputs and outputs, and different types of challenges, from {perception to reasoning and long context length}
    
[^10]: 一种基于概率的人类比较对齐方法

    A Probabilistic Approach for Alignment with Human Comparisons

    [https://arxiv.org/abs/2403.10771](https://arxiv.org/abs/2403.10771)

    通过提出的两阶段“监督微调+人类比较”框架，本文研究了如何有效利用人类比较来改善AI模型的对齐，特别是在面对嘈杂数据和高维模型时。

    

    一个增长的趋势是将人类知识整合到学习框架中，利用微妙的人类反馈来完善AI模型。尽管取得了这些进展，但尚未开发出描述人类比较何时改善传统监督微调过程的特定条件的全面理论框架。为弥补这一差距，本文研究了有效利用人类比较来解决由嘈杂数据和高维模型引起的限制。我们提出了一个将机器学习与人类反馈通过概率二分方法联系起来的两阶段“监督微调+人类比较”（SFT+HC）框架。这两阶段框架首先通过SFT过程从带有噪声标记的数据中学习低维表示，然后利用人类比较来改进模型对齐。为了检验对齐阶段的效力，我们引入了一个新概念，称为“标签噪声到一致性”

    arXiv:2403.10771v1 Announce Type: new  Abstract: A growing trend involves integrating human knowledge into learning frameworks, leveraging subtle human feedback to refine AI models. Despite these advances, no comprehensive theoretical framework describing the specific conditions under which human comparisons improve the traditional supervised fine-tuning process has been developed. To bridge this gap, this paper studies the effective use of human comparisons to address limitations arising from noisy data and high-dimensional models. We propose a two-stage "Supervised Fine Tuning+Human Comparison" (SFT+HC) framework connecting machine learning with human feedback through a probabilistic bisection approach. The two-stage framework first learns low-dimensional representations from noisy-labeled data via an SFT procedure, and then uses human comparisons to improve the model alignment. To examine the efficacy of the alignment phase, we introduce a novel concept termed the "label-noise-to-co
    
[^11]: 分而治之：用多目标强化学习可靠地揭示帕累托前沿

    Divide and Conquer: Provably Unveiling the Pareto Front with Multi-Objective Reinforcement Learning

    [https://arxiv.org/abs/2402.07182](https://arxiv.org/abs/2402.07182)

    这项研究介绍了一个名为IPRO的算法，利用分解任务为一系列单目标问题方法，可可靠地揭示多目标强化学习中实现最优表现的策略的帕累托前沿，同时提供收敛保证和未发现解的距离上限。

    

    在多目标强化学习中，获取在不同偏好下实现最优表现的策略的帕累托前沿是一个重大挑战。我们引入了迭代帕累托参考优化（IPRO），这是一个原则性算法，它将找到帕累托前沿的任务分解成一系列具有各种解决方法的单目标问题。这使我们能够在每个步骤中建立收敛保证并提供未发现帕累托最优解的距离上限。实证评估表明，IPRO能够与需要额外领域知识的方法相匹配或优于它们。通过利用问题特定的单目标求解器，我们的方法也有望在多目标强化学习之外的应用中发挥作用，比如路径规划和优化问题。

    A significant challenge in multi-objective reinforcement learning is obtaining a Pareto front of policies that attain optimal performance under different preferences. We introduce Iterated Pareto Referent Optimisation (IPRO), a principled algorithm that decomposes the task of finding the Pareto front into a sequence of single-objective problems for which various solution methods exist. This enables us to establish convergence guarantees while providing an upper bound on the distance to undiscovered Pareto optimal solutions at each step. Empirical evaluations demonstrate that IPRO matches or outperforms methods that require additional domain knowledge. By leveraging problem-specific single-objective solvers, our approach also holds promise for applications beyond multi-objective reinforcement learning, such as in pathfinding and optimisation.
    
[^12]: ForestColl: 异构网络结构上高效的集合通信

    ForestColl: Efficient Collective Communications on Heterogeneous Network Fabrics

    [https://arxiv.org/abs/2402.06787](https://arxiv.org/abs/2402.06787)

    ForestColl是一种针对任意网络拓扑生成高效调度的工具，通过构建广播/聚合生成跨越树的通信调度，实现了理论上的最小网络拥塞，并在实验中表现出高于供应商自带通信库的性能。

    

    随着现代深度神经网络模型越来越大，加速器之间的集合通信（如allreduce等）成为一个重要的性能瓶颈。在当今高度多样化和异构的网络结构下设计高效的通信调度是一项具有挑战性的任务。本文提出了一种名为ForestColl的工具，它能够为任意网络拓扑生成高效的调度。ForestColl使用广播/聚合生成跨越树作为通信调度，实现了理论上的最小网络拥塞。其调度生成运行在强多项式时间内，且具有高扩展性。ForestColl支持包括交换网络和直接连接在内的任何网络结构，以及任何网络图结构。我们在多集群的AMD MI250和NVIDIA A100平台上评估了ForestColl。与供应商自己优化的通信库RCCL和NCCL相比，ForestColl的调度性能提高了高达52％。ForestColl还优于其他...

    As modern DNN models grow ever larger, collective communications between the accelerators (allreduce, etc.) emerge as a significant performance bottleneck. Designing efficient communication schedules is challenging given today's highly diverse and heterogeneous network fabrics. In this paper, we present ForestColl, a tool that generates efficient schedules for any network topology. ForestColl constructs broadcast/aggregation spanning trees as the communication schedule, achieving theoretically minimum network congestion. Its schedule generation runs in strongly polynomial time and is highly scalable. ForestColl supports any network fabrics, including both switching fabrics and direct connections, as well as any network graph structure. We evaluated ForestColl on multi-cluster AMD MI250 and NVIDIA A100 platforms. ForestColl's schedules achieved up to 52\% higher performance compared to the vendors' own optimized communication libraries, RCCL and NCCL. ForestColl also outperforms other s
    
[^13]: 功能对齐回归：一种从数据中明确学习函数导数的方法

    Function Aligned Regression: A Method Explicitly Learns Functional Derivatives from Data

    [https://arxiv.org/abs/2402.06104](https://arxiv.org/abs/2402.06104)

    该论文提出了一种名为FAR的方法，通过捕捉函数导数来更好、更高效地拟合底层真实函数。在合成数据集和八个真实世界任务中证明了该方法的有效性。

    

    回归是机器学习中的一个基本任务，在过去几十年中引起了广泛关注。传统的回归方法主要通过使用损失函数来将模型预测与每个个体数据样本的真实值对齐，然而，我们发现这种方法可能导致在不同样本之间关系的预测不够优化。近期的研究工作引入了标签相似性信息来改进回归方法，但在完全捕捉底层真实函数的复杂性方面仍存在明显的差距。在本文中，我们提出了FAR（功能对齐回归）作为一种更好、更高效的解决方案，通过捕捉函数导数来拟合底层真实函数。我们在两个合成数据集和六个领域的八个大规模真实世界任务中验证了该方法的有效性。

    Regression is a fundamental task in machine learning that has garnered extensive attention over the past decades. The conventional approach for regression involves employing loss functions that primarily concentrate on aligning model prediction with the ground truth for each individual data sample, which, as we show, can result in sub-optimal prediction of the relationships between the different samples. Recent research endeavors have introduced novel perspectives by incorporating label similarity information to regression. However, a notable gap persists in these approaches when it comes to fully capturing the intricacies of the underlying ground truth function. In this work, we propose FAR (Function Aligned Regression) as a arguably better and more efficient solution to fit the underlying function of ground truth by capturing functional derivatives. We demonstrate the effectiveness of the proposed method practically on 2 synthetic datasets and on 8 extensive real-world tasks from 6 b
    
[^14]: EUGENE: 可解释的无监督图编辑距离近似方法

    EUGENE: Explainable Unsupervised Approximation of Graph Edit Distance

    [https://arxiv.org/abs/2402.05885](https://arxiv.org/abs/2402.05885)

    EUGENE是一种可解释的无监督图编辑距离近似方法，可以通过生成编辑路径来近似计算图编辑距离，同时消除了ground-truth生成和数据特定训练的需求。

    

    在生物学、化学、推荐系统和社交网络分析等领域，需要识别与查询图结构距离较小的图形。在多种测量图间距离的方法中，图编辑距离（GED）因其可理解性而被认为是首选，但其计算的NP难度限制了其应用。目前最先进的GED近似方法主要采用神经方法，然而，这些方法（i）缺少与近似的GED对应的解释性编辑路径；（ii）需要通过NP难问题生成ground-truth GED进行训练；（iii）需要在每个数据集上进行独立训练。本文提出了一种高效的代数无监督方法EUGENE，它近似计算GED并生成与近似成本对应的编辑路径，同时消除了生成ground-truth和数据特定训练的需求。广泛的实验评估表明，EUGENE的上述优点并不以效力为代价。

    The need to identify graphs having small structural distance from a query arises in biology, chemistry, recommender systems, and social network analysis. Among several methods to measure inter graph distance, Graph Edit Distance (GED) is preferred for its comprehensibility, yet hindered by the NP-hardness of its computation. State-of-the-art GED approximations predominantly employ neural methods, which, however, (i) lack an explanatory edit path corresponding to the approximated GED; (ii) require the NP-hard generation of ground-truth GEDs for training; and (iii) necessitate separate training on each dataset. In this paper, we propose an efficient algebraic unsuper vised method, EUGENE, that approximates GED and yields edit paths corresponding to the approx imated cost, while eliminating the need for ground truth generation and data-specific training. Extensive experimental evaluation demonstrates that the aforementioned benefits of EUGENE do not come at the cost of efficacy. Specifica
    
[^15]: 带风险最小化的分组分布鲁棒数据集蒸馏

    Group Distributionally Robust Dataset Distillation with Risk Minimization

    [https://arxiv.org/abs/2402.04676](https://arxiv.org/abs/2402.04676)

    这项研究关注数据集蒸馏与其泛化能力的关系，尤其是在面对不常见的子组的样本时，如何确保模型在合成数据集上的训练可以表现良好。

    

    数据集蒸馏（DD）已成为一种广泛采用的技术，用于构建一个合成数据集，该数据集在捕捉训练数据集的基本信息方面起到重要作用，从而方便准确训练神经模型。其应用涵盖了转移学习、联邦学习和神经架构搜索等各个领域。构建合成数据的最流行方法依赖于使模型在合成数据集和训练数据集上的收敛性能相匹配。然而，目标是将训练数据集视为辅助，就像训练集是人口分布的近似替代品一样，而后者才是我们感兴趣的数据。尽管其受欢迎程度很高，但尚未探索的一个方面是DD与其泛化能力的关系，特别是跨不常见的子组。也就是说，当面对来自罕见子组的样本时，我们如何确保在合成数据集上训练的模型表现良好。

    Dataset distillation (DD) has emerged as a widely adopted technique for crafting a synthetic dataset that captures the essential information of a training dataset, facilitating the training of accurate neural models. Its applications span various domains, including transfer learning, federated learning, and neural architecture search. The most popular methods for constructing the synthetic data rely on matching the convergence properties of training the model with the synthetic dataset and the training dataset. However, targeting the training dataset must be thought of as auxiliary in the same sense that the training set is an approximate substitute for the population distribution, and the latter is the data of interest. Yet despite its popularity, an aspect that remains unexplored is the relationship of DD to its generalization, particularly across uncommon subgroups. That is, how can we ensure that a model trained on the synthetic dataset performs well when faced with samples from re
    
[^16]: 给予足够时间，人类在识别不寻常姿势中的物体上击败了深度网络

    Humans Beat Deep Networks at Recognizing Objects in Unusual Poses, Given Enough Time

    [https://arxiv.org/abs/2402.03973](https://arxiv.org/abs/2402.03973)

    人类在识别不寻常姿势中的物体上表现优于深度网络，当给予足够时间时。然而，随着图像曝光时间的限制，人类的表现降至深度网络的水平，这暗示人类在识别不寻常姿势中的物体时需要额外的心理过程。此外，人类与网络之间的错误模式也存在不同。因此，我们需要进一步研究，以提高计算机视觉系统的鲁棒性水平。

    

    深度学习在几个物体识别基准上正在缩小与人类的差距。本文在涉及从不寻常视角观察物体的挑战性图像中对这一差距进行了研究。我们发现人类在识别不寻常姿势中的物体时表现出色，与先进的预训练网络（EfficientNet、SWAG、ViT、SWIN、BEiT、ConvNext）相比，这些网络在此情况下普遍脆弱。值得注意的是，随着我们限制图像曝光时间，人类的表现下降到深度网络的水平，这表明人类在识别不寻常姿势中的物体时需要额外的心理过程（需要额外的时间）。最后，我们分析了人类与网络的错误模式，发现即使在限制时间的情况下，人类与前馈深度网络也有不同。我们得出结论，需要更多的工作将计算机视觉系统带到人类视觉系统的鲁棒性水平。理解在外部情况下发生的心理过程的本质是必要的。

    Deep learning is closing the gap with humans on several object recognition benchmarks. Here we investigate this gap in the context of challenging images where objects are seen from unusual viewpoints. We find that humans excel at recognizing objects in unusual poses, in contrast with state-of-the-art pretrained networks (EfficientNet, SWAG, ViT, SWIN, BEiT, ConvNext) which are systematically brittle in this condition. Remarkably, as we limit image exposure time, human performance degrades to the level of deep networks, suggesting that additional mental processes (requiring additional time) take place when humans identify objects in unusual poses. Finally, our analysis of error patterns of humans vs. networks reveals that even time-limited humans are dissimilar to feed-forward deep networks. We conclude that more work is needed to bring computer vision systems to the level of robustness of the human visual system. Understanding the nature of the mental processes taking place during extr
    
[^17]: 概率演员-评论家：学习以PAC-Bayes不确定性进行探索

    Probabilistic Actor-Critic: Learning to Explore with PAC-Bayes Uncertainty

    [https://arxiv.org/abs/2402.03055](https://arxiv.org/abs/2402.03055)

    概率演员-评论家算法（PAC）通过在评论家中建模和推断不确定性，以改进强化学习中的连续控制性能，并实现自适应的探索策略。

    

    我们引入了概率演员-评论家（PAC），这是一种新颖的强化学习算法，通过缓解探索与利用的平衡问题，改进了连续控制性能。PAC通过将随机策略和评论家无缝融合，创建了评论家不确定性估计和演员训练之间的动态协同作用。我们的PAC算法的关键贡献在于通过Probably Approximately Correct-Bayesian（PAC-Bayes）分析，明确建模和推断评论家的认知不确定性。这种对评论家不确定性的融入使PAC能够在学习过程中自适应调整其探索策略，指导演员的决策过程。与现有技术中的固定或预定的探索方案相比，PAC表现出更好的效果。通过PAC-Bayes分析引导的随机策略和评论家之间的协同作用，是向深度强化学习中更具自适应性和有效性的探索策略迈出的关键一步。

    We introduce Probabilistic Actor-Critic (PAC), a novel reinforcement learning algorithm with improved continuous control performance thanks to its ability to mitigate the exploration-exploitation trade-off. PAC achieves this by seamlessly integrating stochastic policies and critics, creating a dynamic synergy between the estimation of critic uncertainty and actor training. The key contribution of our PAC algorithm is that it explicitly models and infers epistemic uncertainty in the critic through Probably Approximately Correct-Bayesian (PAC-Bayes) analysis. This incorporation of critic uncertainty enables PAC to adapt its exploration strategy as it learns, guiding the actor's decision-making process. PAC compares favorably against fixed or pre-scheduled exploration schemes of the prior art. The synergy between stochastic policies and critics, guided by PAC-Bayes analysis, represents a fundamental step towards a more adaptive and effective exploration strategy in deep reinforcement lear
    
[^18]: 没有解释的统计学：对可解释机器学习的冷静观察

    Statistics without Interpretation: A Sober Look at Explainable Machine Learning

    [https://arxiv.org/abs/2402.02870](https://arxiv.org/abs/2402.02870)

    解释算法往往数学上复杂且难以解释，这导致解释错误。为了向前推进，解释算法需要明确其输出的解释方式，并澄清可以和不能回答的问题。这一论点基于统计学和解释之间的区别，以及可解释机器学习和应用统计学之间的相似性。

    

    在关于解释算法的快速发展的文献中，这些算法往往不清楚所用于何处及其使用方式。我们认为这是因为解释算法往往在数学上复杂且难以解释。然而，没有清晰解释的复杂统计方法很可能导致解释的错误，这一事实在文献中越来越明显。为了向前推进，关于解释算法的论文应明确解释算法的输出如何解释。他们还应澄清在给出解释的情况下可以回答哪些关于函数的问题，以及哪些问题无法回答。我们的论点基于统计学和它们的解释之间的区别。它还依赖于可解释机器学习和应用统计学之间的相似之处。

    In the rapidly growing literature on explanation algorithms, it often remains unclear what precisely these algorithms are for and how they should be used. We argue that this is because explanation algorithms are often mathematically complex but don't admit a clear interpretation. Unfortunately, complex statistical methods that don't have a clear interpretation are bound to lead to errors in interpretation, a fact that has become increasingly apparent in the literature. In order to move forward, papers on explanation algorithms should make clear how precisely the output of the algorithms should be interpreted. They should also clarify what questions about the function can and cannot be answered given the explanations. Our argument is based on the distinction between statistics and their interpretation. It also relies on parallels between explainable machine learning and applied statistics.
    
[^19]: 动量在隐式逐步优化中对目标函数的平滑作用的角色

    Role of Momentum in Smoothing Objective Function in Implicit Graduated Optimization

    [https://arxiv.org/abs/2402.02325](https://arxiv.org/abs/2402.02325)

    这篇论文揭示了具有动量的随机梯度下降算法平滑了目标函数，影响程度由多个超参数决定，同时提供了对动量改善泛化能力的理论解释和新见解。

    

    虽然具有动量的随机梯度下降（SGD）具有快速收敛和良好的泛化能力，但对此缺乏理论解释。本文展示了具有动量的SGD平滑了目标函数，其程度由学习率、批大小、动量因子、随机梯度的方差以及梯度范数的上界确定。这一理论发现揭示了为什么动量改善了泛化能力，并提供了关于动量因子等超参数作用的新见解。我们还提出了一种利用SGD动量平滑特性的隐式逐步优化算法，并提供了实验结果支持我们的观点，即SGD动量平滑了目标函数。

    While stochastic gradient descent (SGD) with momentum has fast convergence and excellent generalizability, a theoretical explanation for this is lacking. In this paper, we show that SGD with momentum smooths the objective function, the degree of which is determined by the learning rate, the batch size, the momentum factor, the variance of the stochastic gradient, and the upper bound of the gradient norm. This theoretical finding reveals why momentum improves generalizability and provides new insights into the role of the hyperparameters, including momentum factor. We also present an implicit graduated optimization algorithm that exploits the smoothing properties of SGD with momentum and provide experimental results supporting our assertion that SGD with momentum smooths the objective function.
    
[^20]: 通过熵率最小化实现可预测的强化学习动态

    Predictable Reinforcement Learning Dynamics through Entropy Rate Minimization

    [https://arxiv.org/abs/2311.18703](https://arxiv.org/abs/2311.18703)

    该论文提出了一种名为PA-RL的方法，通过最小化熵率来引导强化学习智能体展现可预测的行为。研究展示了如何利用平均替代奖励实现确定性策略，并在动态模型的基础上近似计算值函数。

    

    在强化学习中，智能体没有动机展示可预测的行为，通常通过策略熵正则化推动智能体在探索上随机化其行为。从人的角度来看，这使得强化学习智能体很难解释和预测；从安全角度来看，更难以进行形式化验证。我们提出了一种新的方法，称为可预测性感知强化学习（PA-RL），用于引导智能体展现可预测的行为，其利用状态序列熵率作为可预测性度量。我们展示了如何将熵率制定为平均奖励目标，并且由于其熵奖励函数依赖于策略，我们引入了一个动作相关的替代熵，以利用PG方法。我们证明了最小化平均替代奖励的确定性策略存在，并且最小化了实际熵率。我们还展示了如何在学习到的动态模型的基础上近似计算与值函数。

    In Reinforcement Learning (RL), agents have no incentive to exhibit predictable behaviors, and are often pushed (through e.g. policy entropy regularization) to randomize their actions in favor of exploration. From a human perspective, this makes RL agents hard to interpret and predict, and from a safety perspective, even harder to formally verify. We propose a novel method to induce predictable behavior in RL agents, referred to as Predictability-Aware RL (PA-RL), which employs the state sequence entropy rate as a predictability measure. We show how the entropy rate can be formulated as an average reward objective, and since its entropy reward function is policy-dependent, we introduce an action-dependent surrogate entropy enabling the use of PG methods. We prove that deterministic policies minimizing the average surrogate reward exist and also minimize the actual entropy rate, and show how, given a learned dynamical model, we are able to approximate the value function associated to th
    
[^21]: 研究DermaMNIST和Fitzpatrick17k皮肤科图像数据集的质量

    Investigating the Quality of DermaMNIST and Fitzpatrick17k Dermatological Image Datasets. (arXiv:2401.14497v1 [cs.CV])

    [http://arxiv.org/abs/2401.14497](http://arxiv.org/abs/2401.14497)

    本文研究了DermaMNIST和Fitzpatrick17k皮肤科图像数据集的质量问题，对数据重复、数据泄漏、错误标记和缺乏测试分区等方面进行了详细分析，并提出纠正措施。

    

    深度学习在皮肤科任务中取得的显著进展使我们更接近于达到与人类专家相当的诊断准确性。然而，尽管大型数据集在可靠的深度神经网络模型的开发中起着关键作用，但数据集中的数据质量和其正确使用至关重要。多种因素可以影响数据质量，如重复数据的存在，训练-测试分区的数据泄漏，错误标记的图像以及缺乏明确定义的测试分区。在本文中，我们对两个流行的皮肤科图像数据集DermaMNIST和Fitzpatrick17k进行了详细分析，揭示了这些数据质量问题，测量了这些问题对基准结果的影响，并对数据集提出了纠正措施。通过公开我们的分析流程和配套代码，确保我们分析的可重复性，我们旨在鼓励类似的探索并促进这方面的研究发展。

    The remarkable progress of deep learning in dermatological tasks has brought us closer to achieving diagnostic accuracies comparable to those of human experts. However, while large datasets play a crucial role in the development of reliable deep neural network models, the quality of data therein and their correct usage are of paramount importance. Several factors can impact data quality, such as the presence of duplicates, data leakage across train-test partitions, mislabeled images, and the absence of a well-defined test partition. In this paper, we conduct meticulous analyses of two popular dermatological image datasets: DermaMNIST and Fitzpatrick17k, uncovering these data quality issues, measure the effects of these problems on the benchmark results, and propose corrections to the datasets. Besides ensuring the reproducibility of our analysis, by making our analysis pipeline and the accompanying code publicly available, we aim to encourage similar explorations and to facilitate the 
    
[^22]: 基于数据驱动因子图的盲信道估计和联合符号检测

    Blind Channel Estimation and Joint Symbol Detection with Data-Driven Factor Graphs. (arXiv:2401.12627v1 [cs.IT])

    [http://arxiv.org/abs/2401.12627](http://arxiv.org/abs/2401.12627)

    本论文研究了在时变线性干扰信道上基于因子图的盲信道估计和联合符号检测方法。通过使用置信传播算法和期望最大化算法相互交织的迭代，可以降低复杂度并提高性能。通过引入数据驱动的方法，算法在离线训练样本数量较少的情况下也能取得显著的性能提升。

    

    我们研究了在时变线性干扰信道上盲联合信道估计和符号检测的因子图框架的应用。具体来说，我们考虑了最大似然估计的期望最大化（EM）算法，该算法通常由于需要在每次迭代中计算逐符号后验分布而导致计算复杂度高。我们通过在适当的因子图上使用置信传播（BP）算法来有效地逼近后验分布，从而解决了这个问题。通过交织BP和EM的迭代，检测复杂度进一步减少到每个EM步骤只需要一次BP迭代。此外，我们提出了我们算法的数据驱动版本，它引入了BP更新的动量，并学习了适当的EM参数更新计划，从而在仅有少量离线训练样本的情况下显著改善了性能-复杂度权衡。我们的数值实验证明了其出色的性能。

    We investigate the application of the factor graph framework for blind joint channel estimation and symbol detection on time-variant linear inter-symbol interference channels. In particular, we consider the expectation maximization (EM) algorithm for maximum likelihood estimation, which typically suffers from high complexity as it requires the computation of the symbol-wise posterior distributions in every iteration. We address this issue by efficiently approximating the posteriors using the belief propagation (BP) algorithm on a suitable factor graph. By interweaving the iterations of BP and EM, the detection complexity can be further reduced to a single BP iteration per EM step. In addition, we propose a data-driven version of our algorithm that introduces momentum in the BP updates and learns a suitable EM parameter update schedule, thereby significantly improving the performance-complexity tradeoff with a few offline training samples. Our numerical experiments demonstrate the excel
    
[^23]: DSAC-T: 带有三个改进的分布式软角色扮演者—评论者

    DSAC-T: Distributional Soft Actor-Critic with Three Refinements. (arXiv:2310.05858v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2310.05858](http://arxiv.org/abs/2310.05858)

    本论文介绍了DSAC-T，通过评论者梯度调整、双值分布学习和基于方差的目标回报裁剪等三个改进对标准DSAC进行了改进，解决了标准DSAC存在的不稳定学习过程和对任务特定奖励缩放的问题，提高了算法的性能和适应性。

    

    强化学习在处理复杂的决策和控制任务方面已经被证明非常有效。然而，常见的无模型的强化学习方法往往面临严重的性能下降问题，这是由于众所周知的过估计问题所引起的。作为对这个问题的回应，我们最近引入了一种离线策略的强化学习算法，称为分布式软角色扮演者评论者（DSAC或DSAC-v1），它通过学习连续的高斯值分布来有效提高值估计的准确性。然而，标准DSAC也存在一些缺点，包括时而不稳定的学习过程和对任务特定的奖励缩放的需求，这可能会阻碍其在一些特殊任务中的整体性能和适应性。本文进一步引入了三个对标准DSAC的重要改进，以解决这些问题。这些改进包括评论者梯度调整、双值分布学习和基于方差的目标回报裁剪。修改后的强化学习算法称为DSAC-T。

    Reinforcement learning (RL) has proven to be highly effective in tackling complex decision-making and control tasks. However, prevalent model-free RL methods often face severe performance degradation due to the well-known overestimation issue. In response to this problem, we recently introduced an off-policy RL algorithm, called distributional soft actor-critic (DSAC or DSAC-v1), which can effectively improve the value estimation accuracy by learning a continuous Gaussian value distribution. Nonetheless, standard DSAC has its own shortcomings, including occasionally unstable learning processes and needs for task-specific reward scaling, which may hinder its overall performance and adaptability in some special tasks. This paper further introduces three important refinements to standard DSAC in order to address these shortcomings. These refinements consist of critic gradient adjusting, twin value distribution learning, and variance-based target return clipping. The modified RL algorithm 
    
[^24]: 基于能量导向的连续熵巴氏中心估计方法及其在一般成本问题中的应用

    Energy-Guided Continuous Entropic Barycenter Estimation for General Costs. (arXiv:2310.01105v1 [cs.LG])

    [http://arxiv.org/abs/2310.01105](http://arxiv.org/abs/2310.01105)

    本文提出了一种基于能量导向的方法用于近似计算任意OT成本函数的连续熵OT巴氏中心，该方法具有优越的性能，并且能与基于能量的模型（EBMs）学习过程无缝连接。

    

    优化输运（OT）巴氏中心是一种在捕捉概率分布几何特性的同时对其进行平均的数学方法。本文提出了一种新颖的算法，用于近似计算任意OT成本函数的连续熵OT巴氏中心。我们的方法基于最近在机器学习社区中受到关注的基于弱OT的连续熵最优输运问题的对偶重构。除了创新性之外，我们的方法还具有以下若干优势特点：（i）我们建立了对恢复解的质量界限；（ii）该方法与基于能量的模型（EBMs）学习过程无缝连接，可以使用经过良好调整的算法解决感兴趣的问题；（iii）它提供了一种直观的优化方案，避免使用极小-极大、强化等复杂技巧。为了验证我们的方法，我们考虑了s

    Optimal transport (OT) barycenters are a mathematically grounded way of averaging probability distributions while capturing their geometric properties. In short, the barycenter task is to take the average of a collection of probability distributions w.r.t. given OT discrepancies. We propose a novel algorithm for approximating the continuous Entropic OT (EOT) barycenter for arbitrary OT cost functions. Our approach is built upon the dual reformulation of the EOT problem based on weak OT, which has recently gained the attention of the ML community. Beyond its novelty, our method enjoys several advantageous properties: (i) we establish quality bounds for the recovered solution; (ii) this approach seemlessly interconnects with the Energy-Based Models (EBMs) learning procedure enabling the use of well-tuned algorithms for the problem of interest; (iii) it provides an intuitive optimization scheme avoiding min-max, reinforce and other intricate technical tricks. For validation, we consider s
    
[^25]: Supersonic: 学习在C/C++中生成源代码优化

    Supersonic: Learning to Generate Source Code Optimisations in C/C++. (arXiv:2309.14846v1 [cs.SE])

    [http://arxiv.org/abs/2309.14846](http://arxiv.org/abs/2309.14846)

    Supersonic 是一个神经方法，用于在C/C++中进行源代码优化。与GPT-3.5-Turbo和GPT-4相比，它在代码优化任务上表现更好，并且改变的程度更小。

    

    软件优化在保持功能的同时改善资源效率。传统上，这是由开发人员和编译器完成的过程。本文介绍了第三种选择，即在源代码级别进行自动优化。我们提出了Supersonic，一个针对优化的轻微源代码修改的神经方法。使用seq2seq模型，Supersonic在C / C ++程序对（$x_{t}$，$x_{t+1}$）上进行训练，其中$x_{t+1}$是$x_{t}$的优化版本，并输出一个差异。Supersonic的性能在竞技编程任务上与OpenAI的GPT-3.5-Turbo和GPT-4进行了基准测试。实验表明，Supersonic不仅在代码优化任务上胜过了这两个模型，而且改变的程度比GPT-3.5-Turbo小了600多倍，比GPT-4小了3700多倍。

    Software optimization refines programs for resource efficiency while preserving functionality. Traditionally, it is a process done by developers and compilers. This paper introduces a third option, automated optimization at the source code level. We present Supersonic, a neural approach targeting minor source code modifications for optimization. Using a seq2seq model, Supersonic is trained on C/C++ program pairs ($x_{t}$, $x_{t+1}$), where $x_{t+1}$ is an optimized version of $x_{t}$, and outputs a diff. Supersonic's performance is benchmarked against OpenAI's GPT-3.5-Turbo and GPT-4 on competitive programming tasks. The experiments show that Supersonic not only outperforms both models on the code optimization task, but also minimizes the extent of change with a more than 600x smaller than GPT-3.5-Turbo and 3700x smaller than GPT-4.
    
[^26]: 少量子激活下量子噪声受限的光学神经网络

    Quantum-noise-limited optical neural networks operating at a few quanta per activation. (arXiv:2307.15712v1 [physics.optics])

    [http://arxiv.org/abs/2307.15712](http://arxiv.org/abs/2307.15712)

    本文研究了在极低功率下操作的光学神经网络，其中一些层只使用一个光子来引发神经元激活。尽管存在极高的噪声，仍可以训练这些网络以高精度执行确定性图像分类任务。

    

    模拟物理神经网络被通常在相对高功率下操作，以保证信噪比大于10。本文研究了在极低功率下操作模拟系统时会发生什么，即系统行为变得高度随机且噪声不再是信号的小扰动。我们在光学神经网络中研究了这个问题，其中一些层只使用一个光子来引发神经元激活。在这种极低功率下，神经元激活受到量子噪声的主导，这是由于单光子检测弱光信号的基本概率性质。我们表明，尽管噪声极大（信噪比约为1），仍然可以训练随机光学神经网络以高精度执行确定性图像分类任务。

    Analog physical neural networks, which hold promise for improved energy efficiency and speed compared to digital electronic neural networks, are nevertheless typically operated in a relatively high-power regime so that the signal-to-noise ratio (SNR) is large (>10). What happens if an analog system is instead operated in an ultra-low-power regime, in which the behavior of the system becomes highly stochastic and the noise is no longer a small perturbation on the signal? In this paper, we study this question in the setting of optical neural networks operated in the limit where some layers use only a single photon to cause a neuron activation. Neuron activations in this limit are dominated by quantum noise from the fundamentally probabilistic nature of single-photon detection of weak optical signals. We show that it is possible to train stochastic optical neural networks to perform deterministic image-classification tasks with high accuracy in spite of the extremely high noise (SNR ~ 1) 
    
[^27]: 标记随机块模型中的最优簇恢复问题

    Instance-Optimal Cluster Recovery in the Labeled Stochastic Block Model. (arXiv:2306.12968v1 [cs.SI])

    [http://arxiv.org/abs/2306.12968](http://arxiv.org/abs/2306.12968)

    本论文提出了一种算法，名为实例自适应聚类（IAC），它能够在标记随机块模型（LSBM）中恢复隐藏的群集。IAC包括一次谱聚类和一个迭代的基于似然的簇分配改进，不需要任何模型参数，是高效的。

    

    本文考虑在有限数量的簇的情况下，用标记随机块模型（LSBM）恢复隐藏的社群，其中簇大小随着物品总数$n$的增长而线性增长。在LSBM中，为每对物品（独立地）观测到一个标签。我们的目标是设计一种有效的算法，利用观测到的标签来恢复簇。为此，我们重新审视了关于期望被任何聚类算法误分类的物品数量的实例特定下界。我们提出了实例自适应聚类（IAC），这是第一个在期望和高概率下都能匹配这些下界表现的算法。IAC由一次谱聚类算法和一个迭代的基于似然的簇分配改进组成。这种方法基于实例特定的下界，不需要任何模型参数，包括簇的数量。通过仅执行一次谱聚类，IAC在计算和存储方面都是高效的。

    We consider the problem of recovering hidden communities in the Labeled Stochastic Block Model (LSBM) with a finite number of clusters, where cluster sizes grow linearly with the total number $n$ of items. In the LSBM, a label is (independently) observed for each pair of items. Our objective is to devise an efficient algorithm that recovers clusters using the observed labels. To this end, we revisit instance-specific lower bounds on the expected number of misclassified items satisfied by any clustering algorithm. We present Instance-Adaptive Clustering (IAC), the first algorithm whose performance matches these lower bounds both in expectation and with high probability. IAC consists of a one-time spectral clustering algorithm followed by an iterative likelihood-based cluster assignment improvement. This approach is based on the instance-specific lower bound and does not require any model parameters, including the number of clusters. By performing the spectral clustering only once, IAC m
    
[^28]: 医疗知识图谱综述：资源、应用和前景

    A Survey on Knowledge Graphs for Healthcare: Resources, Applications, and Promises. (arXiv:2306.04802v1 [cs.AI])

    [http://arxiv.org/abs/2306.04802](http://arxiv.org/abs/2306.04802)

    本论文综述了医疗知识图谱(HKGs)的构建流程、关键技术和利用方法以及现有资源，并深入探讨了HKG在各种医疗领域的变革性影响。

    

    医疗知识图谱(HKGs)已成为组织医学知识的有结构且可解释的有为工具，提供了医学概念及其关系的全面视图。然而，数据异质性和覆盖范围有限等挑战仍然存在，强调了在HKG领域需要进一步研究的必要性。本综述是HKG的第一份综合概述。我们总结了HKG构建的流程和关键技术（即从头开始和通过集成），以及常见的利用方法（即基于模型和非基于模型）。为了为研究人员提供有价值的资源，我们根据它们捕获的数据类型和应用领域（该资源存储于https://github.com/lujiaying/Awesome-HealthCare-KnowledgeBase）组织了现有的HKG，并提供了相关的统计信息。在应用部分，我们深入探讨了HKG在各种医疗领域的变革性影响。

    Healthcare knowledge graphs (HKGs) have emerged as a promising tool for organizing medical knowledge in a structured and interpretable way, which provides a comprehensive view of medical concepts and their relationships. However, challenges such as data heterogeneity and limited coverage remain, emphasizing the need for further research in the field of HKGs. This survey paper serves as the first comprehensive overview of HKGs. We summarize the pipeline and key techniques for HKG construction (i.e., from scratch and through integration), as well as the common utilization approaches (i.e., model-free and model-based). To provide researchers with valuable resources, we organize existing HKGs (The resource is available at https://github.com/lujiaying/Awesome-HealthCare-KnowledgeBase) based on the data types they capture and application domains, supplemented with pertinent statistical information. In the application section, we delve into the transformative impact of HKGs across various hea
    
[^29]: 带权重空间上功能性输入映射的全局普适逼近

    Global universal approximation of functional input maps on weighted spaces. (arXiv:2306.03303v1 [stat.ML])

    [http://arxiv.org/abs/2306.03303](http://arxiv.org/abs/2306.03303)

    本文提出了功能性输入神经网络，可以在带权重空间上完成全局函数逼近。这一方法适用于连续函数的推广，还可用于路径空间函数的逼近，同时也可以逼近线性函数签名。

    

    我们引入了所谓的功能性输入神经网络，定义在可能是无限维带权重空间上，其值也在可能是无限维的输出空间中。为此，我们使用一个加性族作为隐藏层映射，以及一个非线性激活函数应用于每个隐藏层。依靠带权重空间上的Stone-Weierstrass定理，我们可以证明连续函数的推广的全局普适逼近结果，超越了常规紧集逼近。这特别适用于通过功能性输入神经网络逼近（非先见之明的）路径空间函数。作为带权Stone-Weierstrass定理的进一步应用，我们证明了线性函数签名的全局普适逼近结果。我们还在这个设置中引入了高斯过程回归的观点，并展示了签名内核的再生核希尔伯特空间是某些高斯过程的Cameron-Martin空间。

    We introduce so-called functional input neural networks defined on a possibly infinite dimensional weighted space with values also in a possibly infinite dimensional output space. To this end, we use an additive family as hidden layer maps and a non-linear activation function applied to each hidden layer. Relying on Stone-Weierstrass theorems on weighted spaces, we can prove a global universal approximation result for generalizations of continuous functions going beyond the usual approximation on compact sets. This then applies in particular to approximation of (non-anticipative) path space functionals via functional input neural networks. As a further application of the weighted Stone-Weierstrass theorem we prove a global universal approximation result for linear functions of the signature. We also introduce the viewpoint of Gaussian process regression in this setting and show that the reproducing kernel Hilbert space of the signature kernels are Cameron-Martin spaces of certain Gauss
    
[^30]: 来自内部的邪恶: 通过硬件木马进行机器学习后门攻击

    Evil from Within: Machine Learning Backdoors through Hardware Trojans. (arXiv:2304.08411v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2304.08411](http://arxiv.org/abs/2304.08411)

    本文介绍了一种在常见机器学习硬件加速器内的后门攻击方法，将最小后门概念和可配置的硬件木马结合使用，从而对目前的防御措施构成挑战。

    

    后门会对机器学习造成严重威胁，因为它们可能破坏安全关键的系统，如自动驾驶汽车。本文介绍了一种后门攻击方法，完全居于用于机器学习的常见硬件加速器内，从而对当前防御措施构成挑战。为了使这种攻击实用，我们克服了两个挑战：首先，由于硬件加速器上的存储空间严重受限，因此我们引入了所谓的最小后门概念，只改变少量模型参数即可激活后门。其次，我们开发了一种可配置的硬件木马，可以与后门一起使用。

    Backdoors pose a serious threat to machine learning, as they can compromise the integrity of security-critical systems, such as self-driving cars. While different defenses have been proposed to address this threat, they all rely on the assumption that the hardware on which the learning models are executed during inference is trusted. In this paper, we challenge this assumption and introduce a backdoor attack that completely resides within a common hardware accelerator for machine learning. Outside of the accelerator, neither the learning model nor the software is manipulated, so that current defenses fail. To make this attack practical, we overcome two challenges: First, as memory on a hardware accelerator is severely limited, we introduce the concept of a minimal backdoor that deviates as little as possible from the original model and is activated by replacing a few model parameters only. Second, we develop a configurable hardware trojan that can be provisioned with the backdoor and p
    
[^31]: 部分神经最优输运

    Partial Neural Optimal Transport. (arXiv:2303.07988v1 [cs.LG])

    [http://arxiv.org/abs/2303.07988](http://arxiv.org/abs/2303.07988)

    我们提出了一种新的神经方法来计算部分最优输运映射，并在合成例子上进行了测试。

    

    我们提出了一种新颖的神经方法来计算部分最优输运（OT）映射，即指定质量的度量部分之间的OT映射。我们在合成例子上测试了我们的部分神经最优输运算法。

    We propose a novel neural method to compute partial optimal transport (OT) maps, i.e., OT maps between parts of measures of the specified masses. We test our partial neural optimal transport algorithm on synthetic examples.
    
[^32]: 全面稳健的数据驱动决策

    Holistic Robust Data-Driven Decisions. (arXiv:2207.09560v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2207.09560](http://arxiv.org/abs/2207.09560)

    这篇论文提出了一种全面稳健的数据驱动公式，能够同时保护三个过拟合的源头：有限样本数据的统计误差、数据点的有限精度测量引起的数据噪声，以及被破坏的部分数据。

    

    设计具有良好样本外性能的机器学习和决策的数据驱动公式是一个关键的挑战。好的样本内性能不一定能保证好的样本外性能，这被普遍认为是过拟合问题。实际的过拟合通常不能归因于单一原因，而是由多个因素同时引起的。我们在这里考虑了三个过拟合的源头：（一）统计误差，由于使用有限的样本数据而产生的误差，（二）数据噪声，当数据点只用有限精度测量时产生的噪声，（三）数据错误，即全部数据中有一小部分数据被完全破坏。我们认为，尽管现有的数据驱动公式在单独处理这三个源头时可能是稳健的，但它们不能同时提供对所有过拟合源头的全面保护。我们设计了一种新颖的数据驱动公式，可以保证这种全面保护。

    The design of data-driven formulations for machine learning and decision-making with good out-of-sample performance is a key challenge. The observation that good in-sample performance does not guarantee good out-of-sample performance is generally known as overfitting. Practical overfitting can typically not be attributed to a single cause but instead is caused by several factors all at once. We consider here three overfitting sources: (i) statistical error as a result of working with finite sample data, (ii) data noise which occurs when the data points are measured only with finite precision, and finally (iii) data misspecification in which a small fraction of all data may be wholly corrupted. We argue that although existing data-driven formulations may be robust against one of these three sources in isolation they do not provide holistic protection against all overfitting sources simultaneously. We design a novel data-driven formulation which does guarantee such holistic protection an
    
[^33]: Wasserstein多元自回归模型用于建模分布时间序列及其在图形学习中的应用

    Wasserstein multivariate auto-regressive models for modeling distributional time series and its application in graph learning. (arXiv:2207.05442v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2207.05442](http://arxiv.org/abs/2207.05442)

    本文提出了一种新的自回归模型，用于分析多元分布时间序列。并且在Wasserstein空间中建模了随机对象，提供了该模型的解的存在性和一致估计器。此方法可以应用于年龄分布和自行车共享网络的观察数据。

    

    我们提出了一种新的自回归模型，用于统计分析多元分布时间序列。感兴趣的数据包括一组在实线有界间隔上支持的概率测度的多个系列，并且被不同时间瞬间所索引。概率测度被建模为Wasserstein空间中的随机对象。我们通过在Lebesgue测度的切空间中建立自回归模型，首先对所有原始测度进行居中处理，以便它们的Fréchet平均值成为Lebesgue测度。利用迭代随机函数系统的理论，提供了这样一个模型的解的存在性、唯一性和平稳性的结果。我们还提出了模型系数的一致估计器。除了对模拟数据的分析，我们还使用两个实际数据集进行了模型演示：一个是不同国家年龄分布的观察数据集，另一个是巴黎自行车共享网络的观察数据集。

    We propose a new auto-regressive model for the statistical analysis of multivariate distributional time series. The data of interest consist of a collection of multiple series of probability measures supported over a bounded interval of the real line, and that are indexed by distinct time instants. The probability measures are modelled as random objects in the Wasserstein space. We establish the auto-regressive model in the tangent space at the Lebesgue measure by first centering all the raw measures so that their Fr\'echet means turn to be the Lebesgue measure. Using the theory of iterated random function systems, results on the existence, uniqueness and stationarity of the solution of such a model are provided. We also propose a consistent estimator for the model coefficient. In addition to the analysis of simulated data, the proposed model is illustrated with two real data sets made of observations from age distribution in different countries and bike sharing network in Paris. Final
    
[^34]: 分层相关聚类和维持树结构嵌入

    Hierarchical Correlation Clustering and Tree Preserving Embedding. (arXiv:2002.07756v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2002.07756](http://arxiv.org/abs/2002.07756)

    本文提出了一种分层相关聚类方法，可应用于正负配对不相似度，并研究了使用此方法进行无监督表征学习的方法。

    

    我们提出了一种分层相关聚类方法，扩展了著名的相关聚类方法，可以产生适用于正负配对不相似度的分层聚类。接下来，我们研究了使用这种分层相关聚类的无监督表征学习。为此，我们首先研究将相应的分层嵌入用于维持树结构嵌入和特征提取。然后，我们研究了最小最大距离度量扩展到相关聚类的方法，作为另一种表征学习范式。最后，我们在多个数据集上展示了我们方法的性能。

    We propose a hierarchical correlation clustering method that extends the well-known correlation clustering to produce hierarchical clusters applicable to both positive and negative pairwise dissimilarities. Then, in the following, we study unsupervised representation learning with such hierarchical correlation clustering. For this purpose, we first investigate embedding the respective hierarchy to be used for tree-preserving embedding and feature extraction. Thereafter, we study the extension of minimax distance measures to correlation clustering, as another representation learning paradigm. Finally, we demonstrate the performance of our methods on several datasets.
    

