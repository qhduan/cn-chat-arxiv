# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [TESSERACT: Eliminating Experimental Bias in Malware Classification across Space and Time (Extended Version)](https://rss.arxiv.org/abs/2402.01359) | 本文提出TESSERACT方法，消除了恶意软件分类中的实验偏差，解决了常见的空间和时间偏差问题。通过公平实验设计约束和新指标AUT实现了更准确和稳定的分类器。 |
| [^2] | [Unsolvable Problem Detection: Evaluating Trustworthiness of Vision Language Models](https://arxiv.org/abs/2403.20331) | 本文提出了一个新颖且重要的挑战，即Unsolvable Problem Detection（UPD），用于评估视觉语言模型在视觉问答任务中能否在面对不可解问题时保持答案的能力，并通过广泛实验发现大多数模型存在改进的空间。 |
| [^3] | [Dynamic Relative Representations for Goal-Oriented Semantic Communications](https://arxiv.org/abs/2403.16986) | 本文提出了一个新颖的面向目标的语义通信框架，利用相对表示通过潜在空间对齐来缓解语义不匹配，并实现了能效高、延迟低的目标导向语义通信。 |
| [^4] | [Genetic Programming for Explainable Manifold Learning](https://arxiv.org/abs/2403.14139) | 遗传规划方法提出了用于可解释流形学习的新方法，帮助解决当前流形学习中功能映射不明确的挑战。 |
| [^5] | [Floralens: a Deep Learning Model for the Portuguese Native Flora](https://arxiv.org/abs/2403.12072) | 本论文开发了一种用于从公开数据集构建生物分类群数据集以及利用深度卷积神经网络推导模型的简化方法，并以葡萄牙本地植物为案例研究。 |
| [^6] | [A Survey of Source Code Representations for Machine Learning-Based Cybersecurity Tasks](https://arxiv.org/abs/2403.10646) | 本研究调查了用于基于机器学习的网络安全任务的源代码表示方法，发现基于图的表示是最受欢迎的，而分词器和抽象语法树是最流行的两种表示方法。 |
| [^7] | [Optimizing LLM Queries in Relational Workloads](https://arxiv.org/abs/2403.05821) | 本文研究了如何优化在关系查询中调用LLM的分析型工作负载的推理过程，发现关系查询为加速LLM推理提供了新颖的机会。 |
| [^8] | [Bayesian Off-Policy Evaluation and Learning for Large Action Spaces](https://arxiv.org/abs/2402.14664) | 该论文提出了一个统一的贝叶斯框架，通过结构化和信息丰富的先验捕捉动作之间的相关性，提出了一个适用于离策略评估和学习的通用贝叶斯方法sDM，并引入了能评估算法在多问题实例中平均表现的贝叶斯指标，分析了sDM在OPE和OPL中利用动作相关性的优势，并展示了其强大性能 |
| [^9] | [Induced Model Matching: How Restricted Models Can Help Larger Ones](https://arxiv.org/abs/2402.12513) | 提出了引导模型匹配（IMM）方法，通过使完整模型的性能与受限模型对齐，将受限模型的知识传递给完整模型，具有广泛的应用性。 |
| [^10] | [FuseMoE: Mixture-of-Experts Transformers for Fleximodal Fusion](https://arxiv.org/abs/2402.03226) | 本论文提出了一种名为FuseMoE的专家混合Transformer框架，通过创新的门控函数实现灵活融合多模态数据，能够有效地处理缺失模态和不规则采样数据，同时改善模型的预测性能，在临床风险预测任务中具有实际应用价值。 |
| [^11] | [Pruner: An Efficient Cross-Platform Tensor Compiler with Dual Awareness](https://arxiv.org/abs/2402.02361) | Pruner是一种高效跨平台张量编译器，通过参数化静态分析器（PSA）和模式感知成本模型（PaCM）实现张量程序优化，并使用动量转移学习（MTL）策略实现了跨平台适应性。 |
| [^12] | [CroissantLLM: A Truly Bilingual French-English Language Model](https://arxiv.org/abs/2402.00786) | CroissantLLM是一个1.3B的双语语言模型，通过使用1:1的英语-法语预训练数据比例、自定义的分词器和双语调优数据集进行训练，实现了高性能和开源。模型还发布了训练数据集和多个检查点，以及一个法语基准测试 FrenchBench。 |
| [^13] | [Navigating Explanatory Multiverse Through Counterfactual Path Geometry.](http://arxiv.org/abs/2306.02786) | 该论文提出了解释性多元宇宙的概念，用于导航和比较所有可能的反事实路径的几何关系。 |
| [^14] | [GBG++: A Fast and Stable Granular Ball Generation Method for Classification.](http://arxiv.org/abs/2305.18450) | 本文提出了一种基于关注机制的快速稳定的颗粒球生成方法，可以在分类任务中应用。 |
| [^15] | [SIMGA: A Simple and Effective Heterophilous Graph Neural Network with Efficient Global Aggregation.](http://arxiv.org/abs/2305.09958) | 本文章提出了一种简单有效的异质图神经网络模型SIMGA，它通过SimRank全局聚合来解决异质性节点聚合的问题，具有接近于线性的传播效率，同时具有良好的有效性和可扩展性。 |
| [^16] | [Similarity of Neural Network Models: A Survey of Functional and Representational Measures.](http://arxiv.org/abs/2305.06329) | 本文综述了神经网络模型相似度的两个观点：表示性相似和功能相似，提供了这两个家族的详细描述，并总结和讨论了其属性和关系，并提出了实践建议。 |

# 详细

[^1]: TESSERACT: 消除恶意软件分类中的实验偏差的空间和时间方法（扩展版）

    TESSERACT: Eliminating Experimental Bias in Malware Classification across Space and Time (Extended Version)

    [https://rss.arxiv.org/abs/2402.01359](https://rss.arxiv.org/abs/2402.01359)

    本文提出TESSERACT方法，消除了恶意软件分类中的实验偏差，解决了常见的空间和时间偏差问题。通过公平实验设计约束和新指标AUT实现了更准确和稳定的分类器。

    

    机器学习在检测恶意软件方面扮演着关键角色。尽管许多研究报告的F1分数高达0.99，但问题仍未完全解决。恶意软件检测器常常在操作系统和攻击方法不断演化时出现性能下降，这会导致之前学习到的知识对于新输入的准确决策变得不足够。本文认为常见的研究结果由于检测任务中的两种普遍的实验偏差而被夸大：空间偏差是由数据分布不代表真实部署的情况引起的；时间偏差是由于数据的不正确时间分割引起的，导致了不现实的配置。为了解决这些偏差，我们引入了一组公平实验设计的约束，并提出了一个用于在真实环境中评估分类器稳定性的新指标AUT。我们还提出了一种用于调整训练数据以提高分类器鲁棒性的算法。

    Machine learning (ML) plays a pivotal role in detecting malicious software. Despite the high F1-scores reported in numerous studies reaching upwards of 0.99, the issue is not completely solved. Malware detectors often experience performance decay due to constantly evolving operating systems and attack methods, which can render previously learned knowledge insufficient for accurate decision-making on new inputs. This paper argues that commonly reported results are inflated due to two pervasive sources of experimental bias in the detection task: spatial bias caused by data distributions that are not representative of a real-world deployment; and temporal bias caused by incorrect time splits of data, leading to unrealistic configurations. To address these biases, we introduce a set of constraints for fair experiment design, and propose a new metric, AUT, for classifier robustness in real-world settings. We additionally propose an algorithm designed to tune training data to enhance classif
    
[^2]: 不可解问题检测：评估视觉语言模型的可信度

    Unsolvable Problem Detection: Evaluating Trustworthiness of Vision Language Models

    [https://arxiv.org/abs/2403.20331](https://arxiv.org/abs/2403.20331)

    本文提出了一个新颖且重要的挑战，即Unsolvable Problem Detection（UPD），用于评估视觉语言模型在视觉问答任务中能否在面对不可解问题时保持答案的能力，并通过广泛实验发现大多数模型存在改进的空间。

    

    本文介绍了一个新颖而重要的挑战，即Unsolvable Problem Detection（UPD），用于评估视觉语言模型（VLMs）在视觉问答（VQA）任务中面对不可解问题时保持答案的能力。UPD包括三个不同的设置：缺失答案检测（AAD）、不兼容答案集检测（IASD）和不兼容视觉问题检测（IVQD）。通过广泛的实验深入研究UPD问题表明，大多数VLMs，包括GPT-4V和LLaVA-Next-34B，在各种程度上都很难应对我们的基准测试，突显了改进的重要空间。为了解决UPD，我们探索了无需训练和基于训练的解决方案，提供了对其有效性和局限性的新见解。我们希望我们的见解，以及在提议的UPD设置内的未来努力，将增强对VLMs的更广泛理解和发展。

    arXiv:2403.20331v1 Announce Type: cross  Abstract: This paper introduces a novel and significant challenge for Vision Language Models (VLMs), termed Unsolvable Problem Detection (UPD). UPD examines the VLM's ability to withhold answers when faced with unsolvable problems in the context of Visual Question Answering (VQA) tasks. UPD encompasses three distinct settings: Absent Answer Detection (AAD), Incompatible Answer Set Detection (IASD), and Incompatible Visual Question Detection (IVQD). To deeply investigate the UPD problem, extensive experiments indicate that most VLMs, including GPT-4V and LLaVA-Next-34B, struggle with our benchmarks to varying extents, highlighting significant room for the improvements. To address UPD, we explore both training-free and training-based solutions, offering new insights into their effectiveness and limitations. We hope our insights, together with future efforts within the proposed UPD settings, will enhance the broader understanding and development of
    
[^3]: 面向目标导向语义通信的动态相对表示

    Dynamic Relative Representations for Goal-Oriented Semantic Communications

    [https://arxiv.org/abs/2403.16986](https://arxiv.org/abs/2403.16986)

    本文提出了一个新颖的面向目标的语义通信框架，利用相对表示通过潜在空间对齐来缓解语义不匹配，并实现了能效高、延迟低的目标导向语义通信。

    

    在未来的6G无线网络中，通信的语义和有效性方面将发挥基础作用，将含义和相关性纳入传输。然而，当设备使用不同的语言、逻辑或内部表示时，会出现障碍，导致语义不匹配，可能危及理解。在潜在空间通信中，这一挑战表现为深度神经网络对数据进行编码时高维表示不匹配。本文提出了一个新颖的面向目标的语义通信框架，利用相对表示来通过潜在空间对齐缓解语义不匹配。我们提出了一种动态优化策略，以调整相对表示、通信参数和计算资源，实现能效高、延迟低的目标导向语义通信。数值结果证明了我们的方法在缓解中起作用的有效性。

    arXiv:2403.16986v1 Announce Type: cross  Abstract: In future 6G wireless networks, semantic and effectiveness aspects of communications will play a fundamental role, incorporating meaning and relevance into transmissions. However, obstacles arise when devices employ diverse languages, logic, or internal representations, leading to semantic mismatches that might jeopardize understanding. In latent space communication, this challenge manifests as misalignment within high-dimensional representations where deep neural networks encode data. This paper presents a novel framework for goal-oriented semantic communication, leveraging relative representations to mitigate semantic mismatches via latent space alignment. We propose a dynamic optimization strategy that adapts relative representations, communication parameters, and computation resources for energy-efficient, low-latency, goal-oriented semantic communications. Numerical results demonstrate our methodology's effectiveness in mitigating
    
[^4]: 用于可解释流形学习的遗传规划

    Genetic Programming for Explainable Manifold Learning

    [https://arxiv.org/abs/2403.14139](https://arxiv.org/abs/2403.14139)

    遗传规划方法提出了用于可解释流形学习的新方法，帮助解决当前流形学习中功能映射不明确的挑战。

    

    流形学习技术在机器学习中发挥着关键作用，通过揭示高维数据中的低维嵌入，从而将数据转换为更低维的表示形式，提高了数据分析的效率和可解释性。然而，当前流形学习方法的一个显著挑战是它们缺乏明确的功能映射，在许多现实世界应用中解释性至关重要。遗传规划以其可解释的基于功能树的模型而闻名，已成为解决这一挑战的一种有希望的方法。先前的研究利用多目标遗传规划来平衡流形质量与嵌入维度，产生了一系列嵌入大小下的功能映射。然而，这些映射树经常变得复杂，阻碍了解释性。作为回应，在本文中，我们提出了用于可解释流形学习的遗传规划（GP-EMaL）。

    arXiv:2403.14139v1 Announce Type: cross  Abstract: Manifold learning techniques play a pivotal role in machine learning by revealing lower-dimensional embeddings within high-dimensional data, thus enhancing both the efficiency and interpretability of data analysis by transforming the data into a lower-dimensional representation. However, a notable challenge with current manifold learning methods is their lack of explicit functional mappings, crucial for explainability in many real-world applications. Genetic programming, known for its interpretable functional tree-based models, has emerged as a promising approach to address this challenge. Previous research leveraged multi-objective GP to balance manifold quality against embedding dimensionality, producing functional mappings across a range of embedding sizes. Yet, these mapping trees often became complex, hindering explainability. In response, in this paper, we introduce Genetic Programming for Explainable Manifold Learning (GP-EMaL),
    
[^5]: Floralens：一种用于葡萄牙本地植物的深度学习模型

    Floralens: a Deep Learning Model for the Portuguese Native Flora

    [https://arxiv.org/abs/2403.12072](https://arxiv.org/abs/2403.12072)

    本论文开发了一种用于从公开数据集构建生物分类群数据集以及利用深度卷积神经网络推导模型的简化方法，并以葡萄牙本地植物为案例研究。

    

    机器学习技术，特别是深度卷积神经网络，在许多公民科学平台中对生物物种进行基于图像的识别是至关重要的。然而，构建足够大小和样本的数据集来训练网络以及网络架构的选择本身仍然很少有文献记录，因此不容易被复制。在本文中，我们开发了一种简化的方法，用于从公开可用的研究级数据集构建生物分类群的数据集，并利用这些数据集使用谷歌的AutoML Vision云服务提供的现成深度卷积神经网络来推导模型。我们的案例研究是葡萄牙本地植物，基于由葡萄牙植物学会提供的高质量数据集，并通过添加来自iNaturalist、Pl@ntNet和Observation.org的采集数据进行扩展。我们发现通过谨慎地

    arXiv:2403.12072v1 Announce Type: cross  Abstract: Machine-learning techniques, namely deep convolutional neural networks, are pivotal for image-based identification of biological species in many Citizen Science platforms. However, the construction of critically sized and sampled datasets to train the networks and the choice of the network architectures itself remains little documented and, therefore, does not lend itself to be easily replicated. In this paper, we develop a streamlined methodology for building datasets for biological taxa from publicly available research-grade datasets and for deriving models from these datasets using off-the-shelf deep convolutional neural networks such as those provided by Google's AutoML Vision cloud service. Our case study is the Portuguese native flora, anchored in a high-quality dataset, provided by the Sociedade Portuguesa de Bot\^anica, scaled up by adding sampled data from iNaturalist, Pl@ntNet, and Observation.org. We find that with a careful
    
[^6]: 用于基于机器学习的网络安全任务的源代码表示调查

    A Survey of Source Code Representations for Machine Learning-Based Cybersecurity Tasks

    [https://arxiv.org/abs/2403.10646](https://arxiv.org/abs/2403.10646)

    本研究调查了用于基于机器学习的网络安全任务的源代码表示方法，发现基于图的表示是最受欢迎的，而分词器和抽象语法树是最流行的两种表示方法。

    

    arXiv:2403.10646v1 公告类型: 新的 摘要: 用于网络安全相关软件工程任务的机器学习技术越来越受欢迎。源代码的表示是该技术的关键部分，可以影响模型学习源代码特征的方式。随着越来越多的这些技术被开发，了解该领域的当前状态对于更好地理解已有内容和尚未存在的内容是有价值的。本文对这些现有的基于ML的方法进行了研究，展示了不同网络安全任务和编程语言所使用的表示类型。此外，我们研究了不同表示所使用的模型类型。我们发现基于图的表示是最受欢迎的表示类别，而分词器和抽象语法树（ASTs）是最受欢迎的表示方法。我们还发现网络安全领域最受欢迎的

    arXiv:2403.10646v1 Announce Type: new  Abstract: Machine learning techniques for cybersecurity-related software engineering tasks are becoming increasingly popular. The representation of source code is a key portion of the technique that can impact the way the model is able to learn the features of the source code. With an increasing number of these techniques being developed, it is valuable to see the current state of the field to better understand what exists and what's not there yet. This paper presents a study of these existing ML-based approaches and demonstrates what type of representations were used for different cybersecurity tasks and programming languages. Additionally, we study what types of models are used with different representations. We have found that graph-based representations are the most popular category of representation, and Tokenizers and Abstract Syntax Trees (ASTs) are the two most popular representations overall. We also found that the most popular cybersecur
    
[^7]: 在关系型工作负载中优化LLM查询

    Optimizing LLM Queries in Relational Workloads

    [https://arxiv.org/abs/2403.05821](https://arxiv.org/abs/2403.05821)

    本文研究了如何优化在关系查询中调用LLM的分析型工作负载的推理过程，发现关系查询为加速LLM推理提供了新颖的机会。

    

    arXiv:2403.05821v1 公告类型: 新的 摘要: 分析性数据库提供商（例如Redshift、Databricks、BigQuery）已迅速增加对通过本机用户自定义函数（UDFs）调用大型语言模型（LLMs）的支持，以帮助用户在分析型工作负载内执行自然语言任务，例如分类、实体提取和翻译。本文探讨了如何优化关系查询中调用LLM的分析工作负载的推理。我们展示了关系查询为加速LLM推理提供了新颖的机会，包括重新排序行以最大化LLM推理引擎内的键值（KV）缓存重用，重新排序行内的列以进一步。

    arXiv:2403.05821v1 Announce Type: new  Abstract: Analytical database providers (e.g., Redshift, Databricks, BigQuery) have rapidly added support for invoking Large Language Models (LLMs) through native user-defined functions (UDFs) to help users perform natural language tasks, such as classification, entity extraction, and translation, inside analytical workloads. For instance, an analyst might want to extract customer sentiments on millions of product reviews. However, LLM inference is highly expensive in both computational and economic terms: for example, an NVIDIA L4 GPU running Llama2-7B can only process 6 KB of text per second. In this paper, we explore how to optimize LLM inference for analytical workloads that invoke LLMs within relational queries. We show that relational queries present novel opportunities for accelerating LLM inference, including reordering rows to maximize key-value (KV) cache reuse within the LLM inference engine, reordering columns within a row to further i
    
[^8]: 大动作空间的贝叶斯离策略评估与学习

    Bayesian Off-Policy Evaluation and Learning for Large Action Spaces

    [https://arxiv.org/abs/2402.14664](https://arxiv.org/abs/2402.14664)

    该论文提出了一个统一的贝叶斯框架，通过结构化和信息丰富的先验捕捉动作之间的相关性，提出了一个适用于离策略评估和学习的通用贝叶斯方法sDM，并引入了能评估算法在多问题实例中平均表现的贝叶斯指标，分析了sDM在OPE和OPL中利用动作相关性的优势，并展示了其强大性能

    

    在交互式系统中，动作经常是相关的，这为大动作空间中更有效的离策略评估（OPE）和学习（OPL）提供了机会。我们引入了一个统一的贝叶斯框架，通过结构化和信息丰富的先验来捕捉这些相关性。在该框架中，我们提出了sDM，一个为OPE和OPL设计的通用贝叶斯方法，既有算法基础又有理论基础。值得注意的是，sDM利用动作相关性而不会影响计算效率。此外，受在线贝叶斯赌博机启发，我们引入了评估算法在多个问题实例中平均性能的贝叶斯指标，偏离传统的最坏情况评估。我们分析了sDM在OPE和OPL中的表现，凸显了利用动作相关性的好处。实证证据展示了sDM的强大性能。

    arXiv:2402.14664v1 Announce Type: cross  Abstract: In interactive systems, actions are often correlated, presenting an opportunity for more sample-efficient off-policy evaluation (OPE) and learning (OPL) in large action spaces. We introduce a unified Bayesian framework to capture these correlations through structured and informative priors. In this framework, we propose sDM, a generic Bayesian approach designed for OPE and OPL, grounded in both algorithmic and theoretical foundations. Notably, sDM leverages action correlations without compromising computational efficiency. Moreover, inspired by online Bayesian bandits, we introduce Bayesian metrics that assess the average performance of algorithms across multiple problem instances, deviating from the conventional worst-case assessments. We analyze sDM in OPE and OPL, highlighting the benefits of leveraging action correlations. Empirical evidence showcases the strong performance of sDM.
    
[^9]: 引导模型匹配：受限模型如何帮助更大的模型

    Induced Model Matching: How Restricted Models Can Help Larger Ones

    [https://arxiv.org/abs/2402.12513](https://arxiv.org/abs/2402.12513)

    提出了引导模型匹配（IMM）方法，通过使完整模型的性能与受限模型对齐，将受限模型的知识传递给完整模型，具有广泛的应用性。

    

    我们考虑在训练更大、具有完整特征的模型时，是否可以利用受限特征的非常准确的预测模型。这个受限模型可以被视为“辅助信息”，可以通过来自辅助源数据集的详尽数据或在相同数据集上通过施加限制来获得。我们提出了一种方法，将受限模型的知识传递给完整模型，通过使完整模型的上下文受限性能与受限模型的性能对齐。我们将这种方法称为引导模型匹配（IMM），首先通过以逻辑回归为玩具示例来说明其普适性。然后我们探讨了IMM在语言建模中的应用，这也是最初的灵感来源，IMM在这里提供了明确的基础，与在技术中隐式使用受限模型的方法相对应，例如添加噪声。

    arXiv:2402.12513v1 Announce Type: new  Abstract: We consider scenarios where a very accurate predictive model using restricted features is available at the time of training of a larger, full-featured, model. This restricted model may be thought of as "side-information", derived either from an auxiliary exhaustive dataset or on the same dataset, by forcing the restriction. How can the restricted model be useful to the full model? We propose an approach for transferring the knowledge of the restricted model to the full model, by aligning the full model's context-restricted performance with that of the restricted model's. We call this methodology Induced Model Matching (IMM) and first illustrate its general applicability by using logistic regression as a toy example. We then explore IMM's use in language modeling, the application that initially inspired it, and where it offers an explicit foundation in contrast to the implicit use of restricted models in techniques such as noising. We dem
    
[^10]: FuseMoE：用于灵活多模态融合的专家混合Transformer

    FuseMoE: Mixture-of-Experts Transformers for Fleximodal Fusion

    [https://arxiv.org/abs/2402.03226](https://arxiv.org/abs/2402.03226)

    本论文提出了一种名为FuseMoE的专家混合Transformer框架，通过创新的门控函数实现灵活融合多模态数据，能够有效地处理缺失模态和不规则采样数据，同时改善模型的预测性能，在临床风险预测任务中具有实际应用价值。

    

    随着机器学习模型在关键领域越来越多地处理多模态数据，它们面临处理多种模态的双重挑战，这些模态经常因缺失元素而不完整，以及收集样本的时间不规则性和稀疏性。成功利用这种复杂数据，同时克服高质量训练样本的稀缺性，是提高这些模型预测性能的关键。我们引入了``FuseMoE''，这是一个集成创新门控函数的专家混合框架。FuseMoE旨在整合多种模态，并且在处理缺失模态和不规则采样数据轨迹的情况下非常有效。在理论上，我们独特的门控函数有助于提高收敛速度，在多个下游任务中表现更好。FuseMoE的实际实用性通过一系列具有挑战性的临床风险预测任务得到验证。

    As machine learning models in critical fields increasingly grapple with multimodal data, they face the dual challenges of handling a wide array of modalities, often incomplete due to missing elements, and the temporal irregularity and sparsity of collected samples. Successfully leveraging this complex data, while overcoming the scarcity of high-quality training samples, is key to improving these models' predictive performance. We introduce ``FuseMoE'', a mixture-of-experts framework incorporated with an innovative gating function. Designed to integrate a diverse number of modalities, FuseMoE is effective in managing scenarios with missing modalities and irregularly sampled data trajectories. Theoretically, our unique gating function contributes to enhanced convergence rates, leading to better performance in multiple downstream tasks. The practical utility of FuseMoE in real world is validated by a challenging set of clinical risk prediction tasks.
    
[^11]: Pruner:一种具有双重感知能力的高效跨平台张量编译器

    Pruner: An Efficient Cross-Platform Tensor Compiler with Dual Awareness

    [https://arxiv.org/abs/2402.02361](https://arxiv.org/abs/2402.02361)

    Pruner是一种高效跨平台张量编译器，通过参数化静态分析器（PSA）和模式感知成本模型（PaCM）实现张量程序优化，并使用动量转移学习（MTL）策略实现了跨平台适应性。

    

    对深度学习加速器（DLAs）上的张量程序优化对于有效的模型部署至关重要。虽然基于搜索的深度学习编译器（DLC）与手动方法相比取得了显著的性能提升，但仍然面临着搜索效率低和跨平台适应性差的挑战。在本文中，我们提出了Pruner，遵循硬件/软件协同设计原则来分层提升张量程序优化。Pruner由两个主要组件组成：参数化静态分析器（PSA）和模式感知成本模型（PaCM）。前者作为一种硬件感知和公式化的性能分析工具，引导搜索空间的修剪，而后者根据关键的数据流模式实现了对张量程序的性能预测。此外，为了保证有效的跨平台适应性，我们设计了一个动量转移学习（MTL）策略。

    Tensor program optimization on Deep Learning Accelerators (DLAs) is critical for efficient model deployment. Although search-based Deep Learning Compilers (DLCs) have achieved significant performance gains compared to manual methods, they still suffer from the persistent challenges of low search efficiency and poor cross-platform adaptability. In this paper, we propose $\textbf{Pruner}$, following hardware/software co-design principles to hierarchically boost tensor program optimization. Pruner comprises two primary components: a Parameterized Static Analyzer ($\textbf{PSA}$) and a Pattern-aware Cost Model ($\textbf{PaCM}$). The former serves as a hardware-aware and formulaic performance analysis tool, guiding the pruning of the search space, while the latter enables the performance prediction of tensor programs according to the critical data-flow patterns. Furthermore, to ensure effective cross-platform adaptation, we design a Momentum Transfer Learning ($\textbf{MTL}$) strategy using
    
[^12]: CroissantLLM: 一个真正的双语法语-英语语言模型

    CroissantLLM: A Truly Bilingual French-English Language Model

    [https://arxiv.org/abs/2402.00786](https://arxiv.org/abs/2402.00786)

    CroissantLLM是一个1.3B的双语语言模型，通过使用1:1的英语-法语预训练数据比例、自定义的分词器和双语调优数据集进行训练，实现了高性能和开源。模型还发布了训练数据集和多个检查点，以及一个法语基准测试 FrenchBench。

    

    我们介绍了CroissantLLM，这是一个在3T个英语和法语标记上预训练的13亿语言模型，为研究和工业社区带来了一种高性能的、完全开源的双语模型，可以在消费级本地硬件上快速运行。为此，我们首次尝试使用1:1的英语-法语预训练数据比例、自定义的分词器和双语调优数据集来训练一种内在双语的模型。我们发布了训练数据集，其中包含了一个法语分割，其中包含了手工策划、高质量和多样化的数据源。为了评估在英语以外的性能，我们创建了一个新的基准测试 FrenchBench，包括一系列分类和生成任务，涵盖了模型在法语语言中性能的各个方面。此外，为了保持透明度并促进进一步的大规模语言模型研究，我们发布了代码库和各种模型规模、训练数据分布上的几十个检查点。

    We introduce CroissantLLM, a 1.3B language model pretrained on a set of 3T English and French tokens, to bring to the research and industrial community a high-performance, fully open-sourced bilingual model that runs swiftly on consumer-grade local hardware. To that end, we pioneer the approach of training an intrinsically bilingual model with a 1:1 English-to-French pretraining data ratio, a custom tokenizer, and bilingual finetuning datasets. We release the training dataset, notably containing a French split with manually curated, high-quality, and varied data sources. To assess performance outside of English, we craft a novel benchmark, FrenchBench, consisting of an array of classification and generation tasks, covering various orthogonal aspects of model performance in the French Language. Additionally, rooted in transparency and to foster further Large Language Model research, we release codebases, and dozens of checkpoints across various model sizes, training data distributions, 
    
[^13]: 通过反事实路径几何导航解释性多元宇宙

    Navigating Explanatory Multiverse Through Counterfactual Path Geometry. (arXiv:2306.02786v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.02786](http://arxiv.org/abs/2306.02786)

    该论文提出了解释性多元宇宙的概念，用于导航和比较所有可能的反事实路径的几何关系。

    

    反事实解释是解释（不透明的）预测模型决策的事实标准。其生成往往受到算法和特定领域约束的影响，如基于密度的可行性和属性的（不）可变性或变化的方向性，旨在最大化其在现实生活中的实用性。除了对反事实实例本身的要求之外，已知算法可行性路径与事实数据点之间的连接，即算法可诉求，已成为重要的技术考虑因素。尽管这两个要求确保了旅程的步骤和目的地的合理性，但目前的文献忽略了这种反事实路径的多样性。为了解决这个缺点，我们引入了一种新颖的解释性多元宇宙概念，涵盖了所有可能的反事实旅程；然后展示了如何导航、推理和比较这些轨迹的几何关系。

    Counterfactual explanations are the de facto standard when tasked with interpreting decisions of (opaque) predictive models. Their generation is often subject to algorithmic and domain-specific constraints -- such as density-based feasibility and attribute (im)mutability or directionality of change -- that aim to maximise their real-life utility. In addition to desiderata with respect to the counterfactual instance itself, existence of a viable path connecting it with the factual data point, known as algorithmic recourse, has become an important technical consideration. While both of these requirements ensure that the steps of the journey as well as its destination are admissible, current literature neglects the multiplicity of such counterfactual paths. To address this shortcoming we introduce the novel concept of explanatory multiverse that encompasses all the possible counterfactual journeys; we then show how to navigate, reason about and compare the geometry of these trajectories -
    
[^14]: GBG++：分类的快速和稳定的颗粒球生成方法

    GBG++: A Fast and Stable Granular Ball Generation Method for Classification. (arXiv:2305.18450v1 [cs.LG])

    [http://arxiv.org/abs/2305.18450](http://arxiv.org/abs/2305.18450)

    本文提出了一种基于关注机制的快速稳定的颗粒球生成方法，可以在分类任务中应用。

    

    颗粒球计算作为一种高效、稳健、可扩展的学习方法，已成为颗粒计算的研究热点。颗粒球计算包括两个阶段：颗粒球生成（GBG）和基于颗粒球（GB）的多粒度学习。然而，现有的GBG方法的稳定性和效率需要进一步提高，因为它们在很大程度上依赖于k均值或k分割。此外，基于GB的分类器仅单向考虑GB的几何特征构建分类规则，而忽视了GB的质量。因此，本文提出了一种快速稳定的基于关注机制的GBG（GBG++）方法。具体而言，所提出的GBG++方法仅需要在分割每个GB时计算从数据驱动的中心到未分割样本的距离，而不是随机选择中心并计算它到所有样本的距离。此外，引入了一种异常值检测方法。

    Granular ball computing (GBC), as an efficient, robust, and scalable learning method, has become a popular research topic of granular computing. GBC includes two stages: granular ball generation (GBG) and multi-granularity learning based on the granular ball (GB). However, the stability and efficiency of existing GBG methods need to be further improved due to their strong dependence on $k$-means or $k$-division. In addition, GB-based classifiers only unilaterally consider the GB's geometric characteristics to construct classification rules, but the GB's quality is ignored. Therefore, in this paper, based on the attention mechanism, a fast and stable GBG (GBG++) method is proposed first. Specifically, the proposed GBG++ method only needs to calculate the distances from the data-driven center to the undivided samples when splitting each GB, instead of randomly selecting the center and calculating the distances between it to all samples. Moreover, an outlier detection method is introduced
    
[^15]: SIMGA：一种简单有效的异质图神经网络结构与高效的全局聚合

    SIMGA: A Simple and Effective Heterophilous Graph Neural Network with Efficient Global Aggregation. (arXiv:2305.09958v1 [cs.LG])

    [http://arxiv.org/abs/2305.09958](http://arxiv.org/abs/2305.09958)

    本文章提出了一种简单有效的异质图神经网络模型SIMGA，它通过SimRank全局聚合来解决异质性节点聚合的问题，具有接近于线性的传播效率，同时具有良好的有效性和可扩展性。

    

    图神经网络在图学习领域取得了巨大成功，但遇到异质性时会出现性能下降，即因为局部和统一聚合而导致的相邻节点不相似。现有的异质性图神经网络中，试图整合全局聚合的尝试通常需要迭代地维护和更新全图信息，对于一个具有 $n$ 个节点的图，这需要 $\mathcal{O}(n^2)$ 的计算效率，从而导致对大型图的扩展性较差。在本文中，我们提出了 SIMGA，一种将 SimRank 结构相似度测量作为全局聚合的 GNN 结构。 SIMGA 的设计简单，且在效率和有效性方面都有着有 promising 的结果。SIMGA 的简单性使其成为第一个可以实现接近于线性的 $n$ 传播效率的异质性 GNN 模型。我们从理论上证明了它的有效性，将 SimRank 视为 GNN 的一种新解释，并证明了汇聚节点表示的有效性。

    Graph neural networks (GNNs) realize great success in graph learning but suffer from performance loss when meeting heterophily, i.e. neighboring nodes are dissimilar, due to their local and uniform aggregation. Existing attempts in incoorporating global aggregation for heterophilous GNNs usually require iteratively maintaining and updating full-graph information, which entails $\mathcal{O}(n^2)$ computation efficiency for a graph with $n$ nodes, leading to weak scalability to large graphs. In this paper, we propose SIMGA, a GNN structure integrating SimRank structural similarity measurement as global aggregation. The design of SIMGA is simple, yet it leads to promising results in both efficiency and effectiveness. The simplicity of SIMGA makes it the first heterophilous GNN model that can achieve a propagation efficiency near-linear to $n$. We theoretically demonstrate its effectiveness by treating SimRank as a new interpretation of GNN and prove that the aggregated node representation
    
[^16]: 神经网络模型的相似度：功能和表示性测量的综述

    Similarity of Neural Network Models: A Survey of Functional and Representational Measures. (arXiv:2305.06329v1 [cs.LG])

    [http://arxiv.org/abs/2305.06329](http://arxiv.org/abs/2305.06329)

    本文综述了神经网络模型相似度的两个观点：表示性相似和功能相似，提供了这两个家族的详细描述，并总结和讨论了其属性和关系，并提出了实践建议。

    

    衡量神经网络的相似性已成为一个非常重要且备受研究关注的问题，以了解和利用神经网络的差异。虽然有几种观点可以描述神经网络的相似性，但是本文特别关注两个互补的观点，即(i) 表示性相似，考虑中间神经层的激活差异，和(ii) 功能相似，考虑模型输出的差异。在本文中，我们全面概述了这两个神经网络模型相似性测量的家族。除了提供现有测量的详细描述外，我们还总结和讨论了这些测量的属性和关系，并指出了开放的研究问题。此外，我们提供了实用建议，可以指导研究人员和实践者利用这些测量。我们希望本文为我们的社区参与更多有用的工作奠定基础。

    Measuring similarity of neural networks has become an issue of great importance and research interest to understand and utilize differences of neural networks. While there are several perspectives on how neural networks can be similar, we specifically focus on two complementing perspectives, i.e., (i) representational similarity, which considers how activations of intermediate neural layers differ, and (ii) functional similarity, which considers how models differ in their outputs. In this survey, we provide a comprehensive overview of these two families of similarity measures for neural network models. In addition to providing detailed descriptions of existing measures, we summarize and discuss results on the properties and relationships of these measures, and point to open research problems. Further, we provide practical recommendations that can guide researchers as well as practitioners in applying the measures. We hope our work lays a foundation for our community to engage in more s
    

